{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13100387-c7ec-4f15-b3a8-26c60cded3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install geopandas\n",
    "! pip install pandas\n",
    "! pip install pygeos\n",
    "! pip install boto\n",
    "! pip install s3fs\n",
    "! pip install shapely\n",
    "! pip install gcsfs\n",
    "!pip install contextily\n",
    "!pip install matplotlib-scalebar\n",
    "!pip install sklearn\n",
    "!pip install zipfile\n",
    "!pip install random\n",
    "import random\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import time\n",
    "from itertools import groupby\n",
    "import geopandas as gpd\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818ade1-929a-4ec6-9ed9-2cefc8593ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addGeometryIdToDataFrame(df, gdf, xcol, ycol, idColumn=\"geometry\", df_geom='epsg:4326'): \n",
    "    gdf.crs = {'init': 'epsg:4326'}\n",
    "    gdf_data = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[xcol], df[ycol]))\n",
    "    gdf_data.crs = {'init': df_geom}\n",
    "    joined = gpd.sjoin(gdf_data.to_crs('epsg:26910'), gdf.to_crs('epsg:26910'))\n",
    "    gdf_data = gdf_data.merge(joined['zip'], left_index=True, right_index=True, how=\"left\")\n",
    "    gdf_data.rename(columns={'zip': idColumn}, inplace=True)\n",
    "    df = pd.DataFrame(gdf_data.drop(columns='geometry'))\n",
    "    # df.drop(columns=[xcol, ycol], inplace=True)\n",
    "    \n",
    "    return df.loc[~df.index.duplicated(keep='first'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ef9cfb-8471-421f-b655-8207d9405823",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Read\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m BGs \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minputs/geo_export_9539336a-a70d-42a4-93a6-0df79b218c82.shp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m Dir_sce \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msfbay-baseline2018-30pct-20230710\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m Dir_sce_TR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msfbay-tr-30pct-20230716\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gpd' is not defined"
     ]
    }
   ],
   "source": [
    "#Read\n",
    "BGs = gpd.read_file('inputs/geo_export_9539336a-a70d-42a4-93a6-0df79b218c82.shp')\n",
    "\n",
    "Dir_sce = 'sfbay-baseline2018-30pct-20230710'\n",
    "Dir_sce_TR = 'sfbay-tr-30pct-20230716'\n",
    "year = '2018'\n",
    "ite = '10'\n",
    "\n",
    "Dir_beam = 'gs://beam-core-outputs/'+Dir_sce+'/beam/year-'+year+'-iteration-'+ite+'/ITERS/it.0'\n",
    "Dir_act = 'gs://beam-core-outputs/'+Dir_sce+'/activitysim/year-'+year+'-iteration-'+ite\n",
    "Dir_beam_TR = 'gs://beam-core-outputs/'+Dir_sce_TR+'/beam/year-'+year+'-iteration-'+ite+'/ITERS/it.0'\n",
    "Dir_act_TR = 'gs://beam-core-outputs/'+Dir_sce_TR+'/activitysim/year-'+year+'-iteration-'+ite\n",
    "\n",
    "Persons = pd.read_csv(Dir_act+'/persons.csv.gz', nrows = None)\n",
    "Households = pd.read_csv(Dir_act+'/households.csv.gz', nrows = None)\n",
    "Plans = pd.read_csv(Dir_beam+'/0.plans.csv.gz', nrows = None)\n",
    "\n",
    "person_table_path = 'outputs/person_database.csv'\n",
    "Scale = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575c51e-09e0-49a1-b12e-cc6b87dfdad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc39a3-b2f5-42ae-a683-206dfe369c0f",
   "metadata": {},
   "source": [
    "# ***PERSON TABLE ANALYSIS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5fd3f-2f43-4a8d-8526-9272a8e8a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(person_table_path)\n",
    "\n",
    "df = df[df['Vehicles Used Baseline'].astype(str) != '[]']\n",
    "df = df[~((df['Chosen Mode Baseline'] == 'walk') & (df['Trip Length Baseline'] > 5000))]\n",
    "\n",
    "\n",
    "race_dict = {\n",
    "    1: \"White alone\",\n",
    "    2: \"Black or African American alone\",\n",
    "    3: \"American Indian alone\",\n",
    "    4: \"Alaska Native alone\",\n",
    "    5: \"American Indian and Alaska Native tribes specified; or American Indian or Alaska Native, not specified and no other races\",\n",
    "    6: \"Asian alone\",\n",
    "    7: \"Native Hawaiian and Other Pacific Islander alone\",\n",
    "    8: \"Some Other Race alone\",\n",
    "    9: \"Two or More Races\"\n",
    "}\n",
    "def addGeometryIdToDataFrame(df, gdf, xcol, ycol, idColumn=\"geometry\", df_geom='epsg:32610'): \n",
    "    gdf.set_crs(epsg = \"3310\", inplace = True)\n",
    "    gdf_data = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[xcol], df[ycol]))\n",
    "    gdf_data.set_crs(epsg = \"32610\", inplace = True)\n",
    "    joined = gpd.sjoin(gdf_data.to_crs('epsg:26910'), gdf.to_crs('epsg:26910'))\n",
    "    gdf_data = gdf_data.merge(joined['ZCTA'], left_index=True, right_index=True, how=\"left\")\n",
    "    gdf_data.rename(columns={'ZCTA': idColumn}, inplace=True)\n",
    "    df = pd.DataFrame(gdf_data.drop(columns='geometry'))\n",
    "#     df.drop(columns=[xcol, ycol], inplace=True)\n",
    "    return df.loc[~df.index.duplicated(keep='first'), :]\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "zipcode = gpd.read_file('inputs/ZCTA2010.shp')\n",
    "print(len(df))\n",
    "\n",
    "df = addGeometryIdToDataFrame(df, zipcode, 'X Activity From TR', 'Y Activity From TR', 'ZIP Departure TR')\n",
    "print(len(df))\n",
    "\n",
    "df = addGeometryIdToDataFrame(df, zipcode, 'X Activity To TR', 'Y Activity To TR', 'ZIP Arrival TR')\n",
    "print(len(df))\n",
    "\n",
    "df = addGeometryIdToDataFrame(df, zipcode, 'X Activity From Baseline', 'Y Activity From Baseline', 'ZIP Departure Baseline')\n",
    "print(len(df))\n",
    "\n",
    "df = addGeometryIdToDataFrame(df, zipcode, 'X Activity To Baseline', 'Y Activity To Baseline', 'ZIP Arrival Baseline')\n",
    "print(len(df))\n",
    "\n",
    "\n",
    "#Add Switch From Column SF - Van Ness\n",
    "switch_type = []\n",
    "for agencies_baseline, project in zip(df['Bus agencies Used Baseline'],df['Project Tried']):\n",
    "    if agencies_baseline == '[]':\n",
    "        switch_type.append('Switch from another mode')\n",
    "    elif project == 'SF - Central Subway' and 'SF' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    elif project == 'AC - 1TEMPO' and 'AC' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    elif project == 'CA - Electrification Project' and 'ca' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    elif project == 'SF - Van Ness' and 'SF' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    elif project == 'BA - Extension and Core project' and 'BA' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    else:\n",
    "        switch_type.append('Switch from another transit agency')\n",
    "\n",
    "df['Switch From'] = switch_type\n",
    "print(len(df))\n",
    "\n",
    "persons = pd.read_csv('gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/activitysim/final_persons.csv')\n",
    "households = pd.read_csv('gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/activitysim/final_households.csv')\n",
    "\n",
    "person_to_pincome = dict(zip(persons.person_id, persons.earning))\n",
    "person_to_race = dict(zip(persons.person_id, persons.race_id))\n",
    "\n",
    "person_to_hs = dict(zip(persons.person_id, persons.household_id))\n",
    "hs_to_income = dict(zip(households.household_id, households.income_in_thousands*1000))\n",
    "person_to_income = {key: hs_to_income[person_to_hs[key]] for key in person_to_hs}\n",
    "\n",
    "\n",
    "df['HS Income'] = df['Person'].map(person_to_income) \n",
    "df['Person Income'] = df['Person'].map(person_to_pincome) \n",
    "df['Person Race ID'] = df['Person'].map(person_to_race) \n",
    "df['Person Race'] = df['Person Race ID'].map(race_dict) \n",
    "\n",
    "df.to_csv('outputs/person_databaseTR-upgraded.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d72bae-001d-4de5-b5fa-c7cdce24c8eb",
   "metadata": {},
   "source": [
    "# **Ridership**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691868e-1eae-49fa-9dc5-8994887a1ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "dict_project = {\n",
    "    'AC - 1TEMPO':'1T',\n",
    "    'BA - Extension and Core project':'BA',\n",
    "    'CA - Electrification Project':'CA',\n",
    "    'SF - Central Subway':'T',\n",
    "    'SF - Van Ness': '49'\n",
    "}\n",
    "\n",
    "veh_to_route_bs = pd.read_csv('outputs/routetovehicledictBaseline2018.csv')\n",
    "veh_to_route_bs = veh_to_route_bs.set_index('trip_id')['route_id'].to_dict()\n",
    "veh_to_route_TR = pd.read_csv('outputs/routetovehicledictFuture2018.csv')\n",
    "veh_to_route_TR = veh_to_route_TR.set_index('trip_id')['route_id'].to_dict()\n",
    "\n",
    "from_indexes = [\n",
    "\n",
    "                '1', '49', 'K/T', 'J', 'L', 'M', 'N', \n",
    "                'BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', \n",
    "                'BA - Yellow', 'Car', 'CarPool','TNC', 'TNC-Pool','Walk', 'Bike', \n",
    "    'CA', 'AC - others', 'SF - others','AM','AY','CC','CE','CM',\n",
    "    'DE','EM','FF','GG','HF','MA','PE','RV', 'SB',\n",
    "    'SC','SL','SM','SO','SR','ST','TD','UC','VC','VN','VT','WC','WH',\n",
    "                'Other']\n",
    "to_indexes_dict = {'CA':['CA:12867','CA:12868','CA:12869'], '1T':'AC:1-142', '49':'SF:12327', 'T':'SF:12476', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue':'BA:11', \n",
    "              'BA Green':'BA:5', 'BA Orange':'BA:3', 'BA Red':'BA:7', 'BA Yellow':'BA:1'}\n",
    "to_indexes = ['CA', '1T', '49', 'T', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue', \n",
    "              'BA Green', 'BA Orange', 'BA Red', 'BA Yellow']\n",
    "FT3 = pd.DataFrame(0, index=from_indexes, columns=to_indexes)\n",
    "\n",
    "for veh_bs, veh_tr, project, mode_base in zip(list(df['Vehicles Used Baseline']), list(df['Vehicles Used TR']), list(df['Project Tried']), list(df['Chosen Mode Baseline'])):\n",
    "    # routes_bs = veh_to_route_bs[veh_bs]\n",
    "    # routes_TR = veh_to_route_TR[veh_tr]\n",
    "    # veh_bs = ','.join(veh_bs)\n",
    "    # veh_tr = ','.join(veh_tr)\n",
    "    found = 0\n",
    "    \n",
    "    fixed_string = veh_bs.replace(\" \", \", \")\n",
    "    veh_bs = ast.literal_eval(fixed_string)\n",
    "    fixed_string = veh_tr.replace(\" \", \", \")\n",
    "    veh_tr = ast.literal_eval(fixed_string)\n",
    "\n",
    "    routes_bs = [veh_to_route_bs.get(key, '0') for key in veh_bs]\n",
    "    routes_TR = [veh_to_route_TR.get(key, '0') for key in veh_tr]\n",
    "    BARTS = []\n",
    "    if project != 'BA - Extension and Core project' :\n",
    "        BARTS.append(dict_project[project])\n",
    "    else:\n",
    "        \n",
    "        if 'BA:1' in routes_TR or 'BA:2' in routes_TR :\n",
    "            BARTS.append('BA Yellow')\n",
    "        if 'BA:3' in routes_TR or 'BA:4' in routes_TR :\n",
    "            BARTS.append('BA Orange')\n",
    "        if 'BA:5' in routes_TR or 'BA:6' in routes_TR :\n",
    "            BARTS.append('BA Green')\n",
    "        if 'BA:7' in routes_TR or 'BA:8' in routes_TR :\n",
    "            BARTS.append('BA Red')\n",
    "        if 'BA:11' in routes_TR or 'BA:12' in routes_TR :\n",
    "            BARTS.append('BA Blue')\n",
    "            \n",
    "    for BAR in BARTS:\n",
    "        \n",
    "        if BAR == '1T':\n",
    "            if 'AC:1-142' in routes_bs:\n",
    "                FT3.loc['1',BAR] += 1\n",
    "                found+=1\n",
    "            if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in [item for item in routes_TR if item != 'AC:1T-142']) and not any('AC:1-142' in s for s in routes_bs) :\n",
    "                FT3.loc['AC - others',BAR] += 1\n",
    "                found+=1\n",
    "        if BAR == 'CA':\n",
    "            if any('CA:' in s for s in routes_bs) :\n",
    "                FT3.loc['CA',BAR] += 1\n",
    "                found+=1\n",
    "        if BAR == 'BA Yellow':\n",
    "            if 'BA:1' in routes_bs:\n",
    "                FT3.loc['BA - Yellow',BAR] += 1\n",
    "                found+=1\n",
    "        if BAR == 'BA Orange':\n",
    "            if 'BA:3' in routes_bs:\n",
    "                FT3.loc['BA - Orange',BAR] += 1\n",
    "                found+=1\n",
    "        if BAR == 'BA Green':\n",
    "            if 'BA:5' in routes_bs:\n",
    "                FT3.loc['BA - Green',BAR] += 1\n",
    "                found+=1\n",
    "        if BAR == 'BA Red':\n",
    "            if 'BA:7' in routes_bs:\n",
    "                FT3.loc['BA - Red',BAR] += 1\n",
    "                found+=1\n",
    "        if BAR == 'BA Blue':\n",
    "            if 'BA:11' in routes_bs:\n",
    "                FT3.loc['BA - Blue',BAR] += 1\n",
    "                found+=1\n",
    "        if BAR == 'T':\n",
    "            if 'SF:12476' in routes_bs:\n",
    "                FT3.loc['K/T',BAR] += 1\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:1001']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT3.loc['SF - others',BAR] += 1\n",
    "                found+=1\n",
    "        if BAR == '49':\n",
    "            if 'SF:12327' in routes_bs:\n",
    "                FT3.loc['49',BAR] += 1\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:18608']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT3.loc['SF - others',BAR] += 1\n",
    "                found+=1\n",
    "        \n",
    "\n",
    "        # if any('AC:' in s for s in routes_bs):\n",
    "        #     FT.loc['AC',BAR] += 1\n",
    "        # if any('SF:' in s for s in routes_bs):\n",
    "        #     FT.loc['SF',BAR] += 1\n",
    "        # if any('BA:' in s for s in routes_bs):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "            \n",
    "        if 'AC:1-142' in routes_bs and 'AC:1T-142' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['1',BAR] += 1\n",
    "            found+=1\n",
    "        if 'SF:12327' in routes_bs and 'SF:18608' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['49',BAR] += 1\n",
    "            found+=1\n",
    "        if 'SF:12476' in routes_bs and 'SF:1001' not in routes_TR and 'SF:1002' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['K/T',BAR] += 1\n",
    "            found+=1\n",
    "        if 'SF:12475' in routes_bs and 'SF:12375' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['J',BAR] += 1\n",
    "            found+=1\n",
    "        if 'SF:12477' in routes_bs and 'SF:12377' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['L',BAR] += 1\n",
    "            found+=1\n",
    "        if 'SF:12478' in routes_bs and 'SF:12378' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['M',BAR] += 1\n",
    "            found+=1\n",
    "        if 'SF:12479' in routes_bs and 'SF:12379' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['N',BAR] += 1\n",
    "            found+=1\n",
    "        if 'BA:1' in routes_bs and 'BA:1' not in routes_TR and 'BA:2' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['BA - Yellow',BAR] += 1\n",
    "            found+=1\n",
    "        if 'BA:3' in routes_bs and 'BA:3' not in routes_TR and 'BA:4' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['BA - Orange',BAR] += 1\n",
    "            found+=1\n",
    "        if 'BA:5' in routes_bs and 'BA:5' not in routes_TR and 'BA:6' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['BA - Green',BAR] += 1\n",
    "            found+=1\n",
    "        if 'BA:7' in routes_bs and 'BA:7' not in routes_TR and 'BA:8' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['BA - Red',BAR] += 1\n",
    "            found+=1\n",
    "        if 'BA:11' in routes_bs and 'BA:11' not in routes_TR and 'BA:12' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['BA - Blue',BAR] += 1\n",
    "            found+=1\n",
    "            \n",
    "        if mode_base =='walk' :\n",
    "            FT3.loc['Walk',BAR] += 1\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail' :\n",
    "            FT3.loc['TNC',BAR] += 1\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail_pooled' :\n",
    "            FT3.loc['TNC-Pool',BAR] += 1\n",
    "            found+=1\n",
    "        if mode_base =='car' :\n",
    "            FT3.loc['Car',BAR] += 1\n",
    "            found+=1\n",
    "        if mode_base =='car_hov2' :\n",
    "            FT3.loc['CarPool',BAR] += 1\n",
    "            found+=1\n",
    "        if mode_base =='car_hov3' :\n",
    "            FT3.loc['CarPool',BAR] += 1\n",
    "            found+=1\n",
    "        if mode_base =='bike' :\n",
    "            FT3.loc['Bike',BAR] += 1\n",
    "            found+=1\n",
    "\n",
    "            \n",
    "        if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in routes_TR) and not any('AC:1-142' in s for s in routes_bs)  and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['AC - others',BAR] += 1\n",
    "            found+=1\n",
    "        if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in routes_TR) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['SF - others',BAR] += 1\n",
    "            found+=1\n",
    "        # if any('BA:' in s for s in routes_bs) and not any('BA:' in s for s in routes_TR):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "        #     found+=1\n",
    "        \n",
    "        if any('CA:' in s for s in routes_bs) and not any('CA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['CA',BAR] += 1\n",
    "            found+=1\n",
    "        if any('AM:' in s for s in routes_bs) and not any('AM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['AM',BAR] += 1\n",
    "            found+=1\n",
    "        if any('AY:' in s for s in routes_bs) and not any('AY:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['AY',BAR] += 1\n",
    "            found+=1\n",
    "        if any('CC:' in s for s in routes_bs) and not any('CC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['CC',BAR] += 1\n",
    "            found+=1\n",
    "        if any('CE:' in s for s in routes_bs) and not any('CE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['CE',BAR] += 1\n",
    "            found+=1\n",
    "        if any('CM:' in s for s in routes_bs) and not any('CM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['CM',BAR] += 1\n",
    "            found+=1\n",
    "        if any('DE:' in s for s in routes_bs) and not any('DE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['DE',BAR] += 1\n",
    "            found+=1\n",
    "        if any('EM:' in s for s in routes_bs) and not any('EM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['EM',BAR] += 1\n",
    "            found+=1\n",
    "        if any('GG:' in s for s in routes_bs) and not any('GG:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['GG',BAR] += 1\n",
    "            found+=1\n",
    "        if any('HF:' in s for s in routes_bs) and not any('HF:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['HF',BAR] += 1\n",
    "            found+=1\n",
    "        if any('MA:' in s for s in routes_bs) and not any('MA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['MA',BAR] += 1\n",
    "            found+=1\n",
    "        if any('PE:' in s for s in routes_bs) and not any('PE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['PE',BAR] += 1\n",
    "            found+=1\n",
    "        if any('RV:' in s for s in routes_bs) and not any('RV:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['RV',BAR] += 1\n",
    "            found+=1\n",
    "        if any('SB:' in s for s in routes_bs) and not any('SB:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['SB',BAR] += 1\n",
    "            found+=1\n",
    "        if any('SC:' in s for s in routes_bs) and not any('SC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['SC',BAR] += 1\n",
    "            found+=1\n",
    "        if any('SL:' in s for s in routes_bs) and not any('SL:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['SL',BAR] += 1\n",
    "            found+=1\n",
    "        if any('SM:' in s for s in routes_bs) and not any('SM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['SM',BAR] += 1\n",
    "            found+=1\n",
    "        if any('SO:' in s for s in routes_bs) and not any('SO:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['SO',BAR] += 1\n",
    "            found+=1\n",
    "        if any('SR:' in s for s in routes_bs) and not any('SR:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['SR',BAR] += 1\n",
    "            found+=1\n",
    "        if any('ST:' in s for s in routes_bs) and not any('ST:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['ST',BAR] += 1\n",
    "            found+=1\n",
    "        if any('TD:' in s for s in routes_bs) and not any('TD:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['TD',BAR] += 1\n",
    "            found+=1\n",
    "        if any('UC:' in s for s in routes_bs) and not any('UC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['UC',BAR] += 1\n",
    "            found+=1\n",
    "        if any('VC:' in s for s in routes_bs) and not any('VC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['VC',BAR] += 1\n",
    "            found+=1\n",
    "        if any('VN:' in s for s in routes_bs) and not any('VN:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['VN',BAR] += 1\n",
    "            found+=1\n",
    "        if any('VT:' in s for s in routes_bs) and not any('VT:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['VT',BAR] += 1\n",
    "            found+=1\n",
    "        if any('WC:' in s for s in routes_bs) and not any('WC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['WC',BAR] += 1\n",
    "            found+=1\n",
    "        if any('WH:' in s for s in routes_bs) and not any('WH:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT3.loc['WH',BAR] += 1\n",
    "            found+=1    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        if found == 0:\n",
    "            FT3.loc['Other',BAR] += 1  \n",
    "FT3.loc['Total'] = [FT3['CA'].sum(),FT3['1T'].sum(),FT3['49'].sum(),FT3['T'].sum(),FT3['BA Blue'].sum(),FT3['BA Green'].sum(),FT3['BA Orange'].sum(),FT3['BA Red'].sum(),FT3['BA Yellow'].sum()]\n",
    "\n",
    "FT3 = (FT3/Scale).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeacdbf-b95f-4f9f-a05c-e1335a25bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FT3/FT3.loc['Total']*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc0b0f-be3f-4c8c-b6d8-ac70fc785937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def add_row_name_to_bars(ax, bottoms, values, column_names, row_name, threshold):\n",
    "    new_bottoms = [bottom + value for bottom, value in zip(bottoms, values)]\n",
    "    for i, (bottom, new_bottom) in enumerate(zip(bottoms, new_bottoms)):\n",
    "        mid_point = (bottom + new_bottom) / 2\n",
    "        if (new_bottom - bottom) > threshold:  # Only add text if there's enough space\n",
    "            ax.text(i, mid_point, row_name, ha='center', va='center', color='black', fontsize=15)\n",
    "    return new_bottoms\n",
    "\n",
    "# Sample data preparation\n",
    "# [Your data preparation code here, e.g., loading the df3 DataFrame]\n",
    "df3 = FT3\n",
    "df3 = df3.drop(\"Total\", axis=0)\n",
    "# Color mapping for the first plot\n",
    "color_mapping1= {\n",
    "    '1': '#A8D5BA',        # Light Green\n",
    "    'AC - others': '#A8D5BA',\n",
    "    '49': '#F2B5B5',      # Light Red\n",
    "    'K/T': '#F2B5B5',\n",
    "    'J': '#F2B5B5',\n",
    "    'L': '#F2B5B5',\n",
    "    'M': '#F2B5B5',\n",
    "    'N': '#F2B5B5',\n",
    "    'SF - others': '#F2B5B5',\n",
    "    'BART': '#A9AEEF',    # Light Blue\n",
    "    'BA - Blue': '#A9AEEF',\n",
    "    'BA - Green': '#A9AEEF',  # Pastel Green\n",
    "    'BA - Orange': '#A9AEEF',  # Pastel Orange\n",
    "    'BA - Red': '#A9AEEF',     # Pastel Red\n",
    "    'BA - Yellow': '#A9AEEF',  # Pastel Yellow\n",
    "    'Car': '#D7CCC8',         # Soft Red\n",
    "    'CarPool': '#D7CCC8',     # Light Grey\n",
    "    'TNC': '#D7CCC8',\n",
    "    'TNC-Pool': '#D7CCC8',\n",
    "    'Walk': '#D7CCC8',\n",
    "    'Bike': '#D7CCC8',\n",
    "    'CA': '#80CBC4',          # Soft Blue\n",
    "    'AM': '#CEA2E1',         # Soft Purple\n",
    "    'AY': '#CEA2E1',\n",
    "    'CC': '#CEA2E1',\n",
    "    'CE': '#CEA2E1',\n",
    "    'CM': '#CEA2E1',\n",
    "    'DE': '#CEA2E1',\n",
    "    'EM': '#CEA2E1',\n",
    "    'FF': '#CEA2E1',\n",
    "    'GG': '#CEA2E1',\n",
    "    'HF': '#CEA2E1',\n",
    "    'MA': '#CEA2E1',\n",
    "    'PE': '#CEA2E1',\n",
    "    'RV': '#CEA2E1',\n",
    "    'SB': '#CEA2E1',\n",
    "    'SC': '#CEA2E1',\n",
    "    'SL': '#CEA2E1',\n",
    "    'SM': '#CEA2E1',\n",
    "    'SO': '#CEA2E1',\n",
    "    'SR': '#CEA2E1',\n",
    "    'ST': '#CEA2E1',\n",
    "    'TD': '#CEA2E1',\n",
    "    'UC': '#CEA2E1',\n",
    "    'VC': '#CEA2E1',\n",
    "    'VN': '#CEA2E1',\n",
    "    'VT': '#CEA2E1',\n",
    "    'WC': '#CEA2E1',\n",
    "    'WH': '#CEA2E1',\n",
    "    'Other': '#F5F5F5'        # Light Grey\n",
    "}\n",
    "color_mapping2 = {\n",
    "    '1': '#F5F5F5',  # muted dark green\n",
    "    'AC - others': '#F5F5F5',\n",
    "    '49': '#F5F5F5',  # muted dark red\n",
    "    'K/T': '#F5F5F5',\n",
    "    'J': '#F5F5F5',\n",
    "    'L': '#F5F5F5',\n",
    "    'M': '#F5F5F5',\n",
    "    'N': '#F5F5F5',\n",
    "    'SF - others': '#F5F5F5',\n",
    "    'BART': '#F5F5F5',\n",
    "    'BA - Blue': '#BBDEFB',  # muted blue\n",
    "    'BA - Green': '#C8E6C9',  # muted green\n",
    "    'BA - Orange': '#FFE0B2',  # muted orange\n",
    "    'BA - Red': '#FFCDD2',  # muted red\n",
    "    'BA - Yellow': '#FFF9C4',  # muted yellow\n",
    "    'Car': '#F5F5F5',  # dark red\n",
    "    'CarPool': '#F5F5F5',  # grey\n",
    "    'TNC': '#F5F5F5',\n",
    "    'TNC-Pool': '#F5F5F5',\n",
    "    'Walk': '#F5F5F5',\n",
    "    'Bike': '#F5F5F5',\n",
    "    'CA': '#F5F5F5',  # muted dark blue\n",
    "    'AM': '#F5F5F5',  # muted dark purple\n",
    "    'AY': '#F5F5F5',\n",
    "    'CC': '#F5F5F5',\n",
    "    'CE': '#F5F5F5',\n",
    "    'CM': '#F5F5F5',\n",
    "    'DE': '#F5F5F5',\n",
    "    'EM': '#F5F5F5',\n",
    "    'FF': '#F5F5F5',\n",
    "    'GG': '#F5F5F5',\n",
    "    'HF': '#F5F5F5',\n",
    "    'MA': '#F5F5F5',\n",
    "    'PE': '#F5F5F5',\n",
    "    'RV': '#F5F5F5',\n",
    "    'SB': '#F5F5F5',\n",
    "    'SC': '#F5F5F5',\n",
    "    'SL': '#F5F5F5',\n",
    "    'SM': '#F5F5F5',\n",
    "    'SO': '#F5F5F5',\n",
    "    'SR': '#F5F5F5',\n",
    "    'ST': '#F5F5F5',\n",
    "    'TD': '#F5F5F5',\n",
    "    'UC': '#F5F5F5',\n",
    "    'VC': '#F5F5F5',\n",
    "    'VN': '#F5F5F5',\n",
    "    'VT': '#F5F5F5',\n",
    "    'WC': '#F5F5F5',\n",
    "    'WH': '#F5F5F5',\n",
    "    'Other': '#F5F5F5'  # grey\n",
    "}\n",
    "desired_order2 = [\n",
    "    'AC - others', '1', \n",
    "    'SF - others', '49', \n",
    "    'K/T', 'J', 'L', 'M', 'N', \n",
    "    'BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', 'BA - Yellow', \n",
    "    'Car', 'CarPool', 'TNC', 'TNC-Pool', 'Walk', 'Bike', \n",
    "    'CA',\n",
    "    'AM', 'AY', 'CC', 'CE', 'CM', 'DE', 'EM', 'FF', 'GG', 'HF', 'MA', 'PE', 'RV', 'SB', 'SC', \n",
    "    'SL', 'SM', 'SO', 'SR', 'ST', 'TD', 'UC', 'VC', 'VN', 'VT', 'WC', 'WH',\n",
    "    'Other'\n",
    "]\n",
    "desired_order1 = [\n",
    "    'AC - others', '1', \n",
    "    'SF - others', '49', \n",
    "    'K/T', 'J', 'L', 'M', 'N', \n",
    "    'BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', 'BA - Yellow', \n",
    "    'Car', 'CarPool', 'TNC', 'TNC-Pool', 'Walk', 'Bike', \n",
    "    'CA',\n",
    "    'AM', 'AY', 'CC', 'CE', 'CM', 'DE', 'EM', 'FF', 'GG', 'HF', 'MA', 'PE', 'RV', 'SB', 'SC', \n",
    "    'SL', 'SM', 'SO', 'SR', 'ST', 'TD', 'UC', 'VC', 'VN', 'VT', 'WC', 'WH',\n",
    "    'Other'\n",
    "]\n",
    "# Assuming you have df3 and color_mapping set as before\n",
    "\n",
    "# Aggregate BA - type rows into BART\n",
    "# ba_rows = ['BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', 'BA - Yellow']\n",
    "# df3.loc['BART'] = df3.loc[ba_rows].sum()\n",
    "\n",
    "# Filter and reorder the rows for both plots\n",
    "df_first_plot = df3.loc[desired_order1,['CA', '1T','49', 'T']]\n",
    "df_second_plot = df3.loc[desired_order2,['BA Blue', 'BA Green', 'BA Orange', 'BA Red', 'BA Yellow']]\n",
    "\n",
    "# Create subplots with 1 row and 2 columns\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "threshold1 = 2 * 220  # This is just an example value; adjust as needed\n",
    "# Plotting the first graph\n",
    "bottoms = [0] * len(df_first_plot.columns)\n",
    "for row_name in df_first_plot.index:\n",
    "\n",
    "    values = df_first_plot.loc[row_name]\n",
    "    axs[0].bar(df_first_plot.columns, values, bottom=bottoms, color=color_mapping1[row_name], edgecolor='white')\n",
    "    bottoms = add_row_name_to_bars(axs[0], bottoms, values, df_first_plot.columns, row_name, threshold1)\n",
    "\n",
    "\n",
    "threshold2 = 2 * 2000  # This is just an example value; adjust as needed\n",
    "# Plotting the second graph\n",
    "bottoms = [0] * len(df_second_plot.columns)\n",
    "for row_name in df_second_plot.index:\n",
    "\n",
    "    values = df_second_plot.loc[row_name]\n",
    "    axs[1].bar(df_second_plot.columns, values, bottom=bottoms, color=color_mapping2[row_name], edgecolor='white')\n",
    "    bottoms = add_row_name_to_bars(axs[1], bottoms, values, df_second_plot.columns, row_name, threshold2)\n",
    "\n",
    "\n",
    "# axs[1].set_ylabel('Share')\n",
    "# axs[1].set_title('Stacked Bar Chart - Second Set of Categories')\n",
    "\n",
    "# Add % to the y-axis labels for the first plot\n",
    "# y_ticks_0 = axs[0].get_yticks()\n",
    "# axs[0].set_yticklabels(['{:.0f}%'.format(y) for y in y_ticks_0])\n",
    "\n",
    "# # Add % to the y-axis labels for the second plot\n",
    "# y_ticks_1 = axs[1].get_yticks()\n",
    "# axs[1].set_yticklabels(['{:.0f}%'.format(y) for y in y_ticks_1])\n",
    "\n",
    "axs[0].set_xticks(range(len(df_first_plot.columns)))\n",
    "axs[0].set_xticklabels(['CA', '1T BRT', '49 BRT', 'T'])\n",
    "\n",
    "# Changing x labels for the second plot\n",
    "axs[1].set_xticks(range(len(df_second_plot.columns)))\n",
    "axs[1].set_xticklabels(['BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', 'BA - Yellow'])\n",
    "\n",
    "axs[0].set_xticks(range(len(df_first_plot.columns)))\n",
    "axs[0].set_xticklabels(['Caltrain', '1Tempo BRT', 'Van Ness BRT', 'Central Subway'])\n",
    "\n",
    "# Changing x labels for the second plot\n",
    "axs[1].set_xticks(range(len(df_second_plot.columns)))\n",
    "axs[1].set_xticklabels(['BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', 'BA - Yellow'])\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('stacked_bar_chart_high_quality.png', dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c808fee-245b-48f3-83fa-84313eeea420",
   "metadata": {},
   "source": [
    "# **Transfers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de1cb3-7754-474d-ba7b-c4da27243b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "dict_project = {\n",
    "    'AC - 1TEMPO':'1T',\n",
    "    'BA - Extension and Core project':'BA',\n",
    "    'CA - Electrification Project':'CA',\n",
    "    'SF - Central Subway':'T',\n",
    "    'SF - Van Ness': '49'\n",
    "}\n",
    "\n",
    "veh_to_route_bs = pd.read_csv('outputs/routetovehicledictBaseline2018.csv')\n",
    "veh_to_route_bs = veh_to_route_bs.set_index('trip_id')['route_id'].to_dict()\n",
    "veh_to_route_TR = pd.read_csv('outputs/routetovehicledictFuture2018.csv')\n",
    "veh_to_route_TR = veh_to_route_TR.set_index('trip_id')['route_id'].to_dict()\n",
    "\n",
    "from_indexes = [\n",
    "\n",
    "                '1', '49', 'K/T', 'J', 'L', 'M', 'N', \n",
    "                'BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', \n",
    "                'BA - Yellow', 'Car', 'CarPool','TNC', 'TNC-Pool','Walk', 'Bike', \n",
    "    'CA', 'AC - others', 'SF - others','AM','AY','CC','CE','CM',\n",
    "    'DE','EM','FF','GG','HF','MA','PE','RV', 'SB',\n",
    "    'SC','SL','SM','SO','SR','ST','TD','UC','VC','VN','VT','WC','WH',\n",
    "                'Other']\n",
    "to_indexes_dict = {'CA':['CA:12867','CA:12868','CA:12869'], '1T':'AC:1-142', '49':'SF:12327', 'T':'SF:12476', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue':'BA:11', \n",
    "              'BA Green':'BA:5', 'BA Orange':'BA:3', 'BA Red':'BA:7', 'BA Yellow':'BA:1'}\n",
    "to_indexes = ['CA', '1T', '49', 'T', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue', \n",
    "              'BA Green', 'BA Orange', 'BA Red', 'BA Yellow']\n",
    "FT = pd.DataFrame(0, index=from_indexes, columns=to_indexes)\n",
    "\n",
    "for veh_bs, veh_tr, project, mode_base in zip(list(df['Vehicles Used Baseline']), list(df['Vehicles Used TR']), list(df['Project Tried']), list(df['Chosen Mode Baseline'])):\n",
    "    # routes_bs = veh_to_route_bs[veh_bs]\n",
    "    # routes_TR = veh_to_route_TR[veh_tr]\n",
    "    # veh_bs = ','.join(veh_bs)\n",
    "    # veh_tr = ','.join(veh_tr)\n",
    "    \n",
    "\n",
    "    found = 0\n",
    "    \n",
    "    fixed_string = veh_bs.replace(\" \", \", \")\n",
    "    veh_bs = ast.literal_eval(fixed_string)\n",
    "    fixed_string = veh_tr.replace(\" \", \", \")\n",
    "    veh_tr = ast.literal_eval(fixed_string)\n",
    "\n",
    "    routes_bs = [veh_to_route_bs.get(key, '0') for key in veh_bs]\n",
    "    routes_TR = [veh_to_route_TR.get(key, '0') for key in veh_tr]\n",
    "    \n",
    "    attr = len(routes_TR) - len(routes_bs)\n",
    "    \n",
    "    BARTS = []\n",
    "    if project != 'BA - Extension and Core project' :\n",
    "        BARTS.append(dict_project[project])\n",
    "    else:\n",
    "        \n",
    "        if 'BA:1' in routes_TR or 'BA:2' in routes_TR :\n",
    "            BARTS.append('BA Yellow')\n",
    "        if 'BA:3' in routes_TR or 'BA:4' in routes_TR :\n",
    "            BARTS.append('BA Orange')\n",
    "        if 'BA:5' in routes_TR or 'BA:6' in routes_TR :\n",
    "            BARTS.append('BA Green')\n",
    "        if 'BA:7' in routes_TR or 'BA:8' in routes_TR :\n",
    "            BARTS.append('BA Red')\n",
    "        if 'BA:11' in routes_TR or 'BA:12' in routes_TR :\n",
    "            BARTS.append('BA Blue')\n",
    "            \n",
    "    for BAR in BARTS:\n",
    "        \n",
    "        if BAR == '1T':\n",
    "            if 'AC:1-142' in routes_bs:\n",
    "                FT.loc['1',BAR] += attr\n",
    "                found+=1\n",
    "            if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in [item for item in routes_TR if item != 'AC:1T-142']) and not any('AC:1-142' in s for s in routes_bs) :\n",
    "                FT.loc['AC - others',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'CA':\n",
    "            if any('CA:' in s for s in routes_bs) :\n",
    "                FT.loc['CA',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Yellow':\n",
    "            if 'BA:1' in routes_bs:\n",
    "                FT.loc['BA - Yellow',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Orange':\n",
    "            if 'BA:3' in routes_bs:\n",
    "                FT.loc['BA - Orange',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Green':\n",
    "            if 'BA:5' in routes_bs:\n",
    "                FT.loc['BA - Green',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Red':\n",
    "            if 'BA:7' in routes_bs:\n",
    "                FT.loc['BA - Red',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Blue':\n",
    "            if 'BA:11' in routes_bs:\n",
    "                FT.loc['BA - Blue',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'T':\n",
    "            if 'SF:12476' in routes_bs:\n",
    "                FT.loc['K/T',BAR] += attr\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:1001']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT.loc['SF - others',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == '49':\n",
    "            if 'SF:12327' in routes_bs:\n",
    "                FT.loc['49',BAR] += attr\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:18608']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT.loc['SF - others',BAR] += attr\n",
    "                found+=1\n",
    "        \n",
    "\n",
    "        # if any('AC:' in s for s in routes_bs):\n",
    "        #     FT.loc['AC',BAR] += 1\n",
    "        # if any('SF:' in s for s in routes_bs):\n",
    "        #     FT.loc['SF',BAR] += 1\n",
    "        # if any('BA:' in s for s in routes_bs):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "            \n",
    "        if 'AC:1-142' in routes_bs and 'AC:1T-142' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['1',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12327' in routes_bs and 'SF:18608' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['49',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12476' in routes_bs and 'SF:1001' not in routes_TR and 'SF:1002' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['K/T',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12475' in routes_bs and 'SF:12375' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['J',BAR] += attr\n",
    "            found+=1\n",
    "            # if BAR == 'CA':\n",
    "            #     print(routes_bs, routes_TR, attr)\n",
    "        if 'SF:12477' in routes_bs and 'SF:12377' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['L',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12478' in routes_bs and 'SF:12378' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['M',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12479' in routes_bs and 'SF:12379' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['N',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:1' in routes_bs and 'BA:1' not in routes_TR and 'BA:2' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Yellow',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:3' in routes_bs and 'BA:3' not in routes_TR and 'BA:4' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Orange',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:5' in routes_bs and 'BA:5' not in routes_TR and 'BA:6' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Green',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:7' in routes_bs and 'BA:7' not in routes_TR and 'BA:8' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Red',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:11' in routes_bs and 'BA:11' not in routes_TR and 'BA:12' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Blue',BAR] += attr\n",
    "            found+=1\n",
    "            \n",
    "        if mode_base =='walk' :\n",
    "            FT.loc['Walk',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail' :\n",
    "            FT.loc['TNC',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail_pooled' :\n",
    "            FT.loc['TNC-Pool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car' :\n",
    "            FT.loc['Car',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car_hov2' :\n",
    "            FT.loc['CarPool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car_hov3' :\n",
    "            FT.loc['CarPool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='bike' :\n",
    "            FT.loc['Bike',BAR] += attr\n",
    "            found+=1\n",
    "\n",
    "            \n",
    "        if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in routes_TR) and not any('AC:1-142' in s for s in routes_bs)  and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AC - others',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in routes_TR) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SF - others',BAR] += attr\n",
    "            found+=1\n",
    "        # if any('BA:' in s for s in routes_bs) and not any('BA:' in s for s in routes_TR):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "        #     found+=1\n",
    "        \n",
    "        if any('CA:' in s for s in routes_bs) and not any('CA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CA',BAR] += attr\n",
    "            found+=1\n",
    "        if any('AM:' in s for s in routes_bs) and not any('AM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('AY:' in s for s in routes_bs) and not any('AY:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AY',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CC:' in s for s in routes_bs) and not any('CC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CE:' in s for s in routes_bs) and not any('CE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CM:' in s for s in routes_bs) and not any('CM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('DE:' in s for s in routes_bs) and not any('DE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['DE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('EM:' in s for s in routes_bs) and not any('EM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['EM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('GG:' in s for s in routes_bs) and not any('GG:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['GG',BAR] += attr\n",
    "            found+=1\n",
    "        if any('HF:' in s for s in routes_bs) and not any('HF:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['HF',BAR] += attr\n",
    "            found+=1\n",
    "        if any('MA:' in s for s in routes_bs) and not any('MA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['MA',BAR] += attr\n",
    "            found+=1\n",
    "        if any('PE:' in s for s in routes_bs) and not any('PE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['PE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('RV:' in s for s in routes_bs) and not any('RV:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['RV',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SB:' in s for s in routes_bs) and not any('SB:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SB',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SC:' in s for s in routes_bs) and not any('SC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SL:' in s for s in routes_bs) and not any('SL:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SL',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SM:' in s for s in routes_bs) and not any('SM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SO:' in s for s in routes_bs) and not any('SO:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SO',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SR:' in s for s in routes_bs) and not any('SR:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SR',BAR] += attr\n",
    "            found+=1\n",
    "        if any('ST:' in s for s in routes_bs) and not any('ST:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['ST',BAR] += attr\n",
    "            found+=1\n",
    "        if any('TD:' in s for s in routes_bs) and not any('TD:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['TD',BAR] += attr\n",
    "            found+=1\n",
    "        if any('UC:' in s for s in routes_bs) and not any('UC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['UC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VC:' in s for s in routes_bs) and not any('VC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VN:' in s for s in routes_bs) and not any('VN:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VN',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VT:' in s for s in routes_bs) and not any('VT:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VT',BAR] += attr\n",
    "            found+=1\n",
    "        if any('WC:' in s for s in routes_bs) and not any('WC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['WC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('WH:' in s for s in routes_bs) and not any('WH:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['WH',BAR] += attr\n",
    "            found+=1    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        if found == 0:\n",
    "            FT.loc['Other',BAR] += attr  \n",
    "FT.loc['Total'] = [FT['CA'].sum(),FT['1T'].sum(),FT['49'].sum(),FT['T'].sum(),FT['BA Blue'].sum(),FT['BA Green'].sum(),FT['BA Orange'].sum(),FT['BA Red'].sum(),FT['BA Yellow'].sum()]\n",
    "\n",
    "FT = (FT/Scale).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec251c1f-62ec-49c0-994a-02e96282c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6a36f-28cb-4593-8b6f-f21cfd3d33f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FT/FT3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646c9dd3-4e3f-492f-9066-0169048a8b0b",
   "metadata": {},
   "source": [
    "# **Durations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57e3b9-1da3-482e-9c00-19c9d16c8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "\n",
    "dict_project = {\n",
    "    'AC - 1TEMPO':'1T',\n",
    "    'BA - Extension and Core project':'BA',\n",
    "    'CA - Electrification Project':'CA',\n",
    "    'SF - Central Subway':'T',\n",
    "    'SF - Van Ness': '49'\n",
    "}\n",
    "\n",
    "veh_to_route_bs = pd.read_csv('outputs/routetovehicledictBaseline2018.csv')\n",
    "veh_to_route_bs = veh_to_route_bs.set_index('trip_id')['route_id'].to_dict()\n",
    "veh_to_route_TR = pd.read_csv('outputs/routetovehicledictFuture2018.csv')\n",
    "veh_to_route_TR = veh_to_route_TR.set_index('trip_id')['route_id'].to_dict()\n",
    "\n",
    "from_indexes = [\n",
    "\n",
    "                '1', '49', 'K/T', 'J', 'L', 'M', 'N', \n",
    "                'BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', \n",
    "                'BA - Yellow', 'Car', 'CarPool','TNC', 'TNC-Pool','Walk', 'Bike', \n",
    "    'CA', 'AC - others', 'SF - others','AM','AY','CC','CE','CM',\n",
    "    'DE','EM','FF','GG','HF','MA','PE','RV', 'SB',\n",
    "    'SC','SL','SM','SO','SR','ST','TD','UC','VC','VN','VT','WC','WH',\n",
    "                'Other']\n",
    "to_indexes_dict = {'CA':['CA:12867','CA:12868','CA:12869'], '1T':'AC:1-142', '49':'SF:12327', 'T':'SF:12476', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue':'BA:11', \n",
    "              'BA Green':'BA:5', 'BA Orange':'BA:3', 'BA Red':'BA:7', 'BA Yellow':'BA:1'}\n",
    "to_indexes = ['CA', '1T', '49', 'T', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue', \n",
    "              'BA Green', 'BA Orange', 'BA Red', 'BA Yellow']\n",
    "FT = pd.DataFrame(0, index=from_indexes, columns=to_indexes)\n",
    "\n",
    "\n",
    "for veh_bs, veh_tr, project, mode_base, dur_bs, dur_tr in zip(list(df['Vehicles Used Baseline']), list(df['Vehicles Used TR']), list(df['Project Tried'])\n",
    "                                              , list(df['Chosen Mode Baseline']),   list(df['Trip Duration Baseline']),   list(df['Trip Duration TR'])):\n",
    "    # routes_bs = veh_to_route_bs[veh_bs]\n",
    "    # routes_TR = veh_to_route_TR[veh_tr]\n",
    "    # veh_bs = ','.join(veh_bs)\n",
    "    # veh_tr = ','.join(veh_tr)\n",
    "    \n",
    "\n",
    "    found = 0\n",
    "    \n",
    "    fixed_string = veh_bs.replace(\" \", \", \")\n",
    "    veh_bs = ast.literal_eval(fixed_string)\n",
    "    fixed_string = veh_tr.replace(\" \", \", \")\n",
    "    veh_tr = ast.literal_eval(fixed_string)\n",
    "\n",
    "    routes_bs = [veh_to_route_bs.get(key, '0') for key in veh_bs]\n",
    "    routes_TR = [veh_to_route_TR.get(key, '0') for key in veh_tr]\n",
    "    \n",
    "    attr = dur_tr - dur_bs\n",
    "    \n",
    "    BARTS = []\n",
    "    if project != 'BA - Extension and Core project' :\n",
    "        BARTS.append(dict_project[project])\n",
    "    else:\n",
    "        \n",
    "        if 'BA:1' in routes_TR or 'BA:2' in routes_TR :\n",
    "            BARTS.append('BA Yellow')\n",
    "        if 'BA:3' in routes_TR or 'BA:4' in routes_TR :\n",
    "            BARTS.append('BA Orange')\n",
    "        if 'BA:5' in routes_TR or 'BA:6' in routes_TR :\n",
    "            BARTS.append('BA Green')\n",
    "        if 'BA:7' in routes_TR or 'BA:8' in routes_TR :\n",
    "            BARTS.append('BA Red')\n",
    "        if 'BA:11' in routes_TR or 'BA:12' in routes_TR :\n",
    "            BARTS.append('BA Blue')\n",
    "            \n",
    "    for BAR in BARTS:\n",
    "        \n",
    "        if BAR == '1T':\n",
    "            if 'AC:1-142' in routes_bs:\n",
    "                FT.loc['1',BAR] += attr\n",
    "                found+=1\n",
    "            if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in [item for item in routes_TR if item != 'AC:1T-142']) and not any('AC:1-142' in s for s in routes_bs) :\n",
    "                FT.loc['AC - others',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'CA':\n",
    "            if any('CA:' in s for s in routes_bs) :\n",
    "                FT.loc['CA',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Yellow':\n",
    "            if 'BA:1' in routes_bs:\n",
    "                FT.loc['BA - Yellow',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Orange':\n",
    "            if 'BA:3' in routes_bs:\n",
    "                FT.loc['BA - Orange',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Green':\n",
    "            if 'BA:5' in routes_bs:\n",
    "                FT.loc['BA - Green',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Red':\n",
    "            if 'BA:7' in routes_bs:\n",
    "                FT.loc['BA - Red',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Blue':\n",
    "            if 'BA:11' in routes_bs:\n",
    "                FT.loc['BA - Blue',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'T':\n",
    "            if 'SF:12476' in routes_bs:\n",
    "                FT.loc['K/T',BAR] += attr\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:1001']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT.loc['SF - others',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == '49':\n",
    "            if 'SF:12327' in routes_bs:\n",
    "                FT.loc['49',BAR] += attr\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:18608']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT.loc['SF - others',BAR] += attr\n",
    "                found+=1\n",
    "        \n",
    "\n",
    "        # if any('AC:' in s for s in routes_bs):\n",
    "        #     FT.loc['AC',BAR] += 1\n",
    "        # if any('SF:' in s for s in routes_bs):\n",
    "        #     FT.loc['SF',BAR] += 1\n",
    "        # if any('BA:' in s for s in routes_bs):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "            \n",
    "        if 'AC:1-142' in routes_bs and 'AC:1T-142' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['1',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12327' in routes_bs and 'SF:18608' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['49',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12476' in routes_bs and 'SF:1001' not in routes_TR and 'SF:1002' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['K/T',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12475' in routes_bs and 'SF:12375' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['J',BAR] += attr\n",
    "            found+=1\n",
    "            # if BAR == 'CA':\n",
    "            #     print(routes_bs, routes_TR, attr)\n",
    "        if 'SF:12477' in routes_bs and 'SF:12377' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['L',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12478' in routes_bs and 'SF:12378' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['M',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12479' in routes_bs and 'SF:12379' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['N',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:1' in routes_bs and 'BA:1' not in routes_TR and 'BA:2' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Yellow',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:3' in routes_bs and 'BA:3' not in routes_TR and 'BA:4' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Orange',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:5' in routes_bs and 'BA:5' not in routes_TR and 'BA:6' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Green',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:7' in routes_bs and 'BA:7' not in routes_TR and 'BA:8' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Red',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:11' in routes_bs and 'BA:11' not in routes_TR and 'BA:12' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Blue',BAR] += attr\n",
    "            found+=1\n",
    "            \n",
    "        if mode_base =='walk' :\n",
    "            FT.loc['Walk',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail' :\n",
    "            FT.loc['TNC',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail_pooled' :\n",
    "            FT.loc['TNC-Pool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car' :\n",
    "            FT.loc['Car',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car_hov2' :\n",
    "            FT.loc['CarPool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car_hov3' :\n",
    "            FT.loc['CarPool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='bike' :\n",
    "            FT.loc['Bike',BAR] += attr\n",
    "            found+=1\n",
    "\n",
    "            \n",
    "        if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in routes_TR) and not any('AC:1-142' in s for s in routes_bs)  and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AC - others',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in routes_TR) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SF - others',BAR] += attr\n",
    "            found+=1\n",
    "        # if any('BA:' in s for s in routes_bs) and not any('BA:' in s for s in routes_TR):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "        #     found+=1\n",
    "        \n",
    "        if any('CA:' in s for s in routes_bs) and not any('CA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CA',BAR] += attr\n",
    "            found+=1\n",
    "        if any('AM:' in s for s in routes_bs) and not any('AM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('AY:' in s for s in routes_bs) and not any('AY:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AY',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CC:' in s for s in routes_bs) and not any('CC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CE:' in s for s in routes_bs) and not any('CE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CM:' in s for s in routes_bs) and not any('CM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('DE:' in s for s in routes_bs) and not any('DE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['DE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('EM:' in s for s in routes_bs) and not any('EM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['EM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('GG:' in s for s in routes_bs) and not any('GG:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['GG',BAR] += attr\n",
    "            found+=1\n",
    "        if any('HF:' in s for s in routes_bs) and not any('HF:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['HF',BAR] += attr\n",
    "            found+=1\n",
    "        if any('MA:' in s for s in routes_bs) and not any('MA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['MA',BAR] += attr\n",
    "            found+=1\n",
    "        if any('PE:' in s for s in routes_bs) and not any('PE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['PE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('RV:' in s for s in routes_bs) and not any('RV:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['RV',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SB:' in s for s in routes_bs) and not any('SB:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SB',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SC:' in s for s in routes_bs) and not any('SC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SL:' in s for s in routes_bs) and not any('SL:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SL',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SM:' in s for s in routes_bs) and not any('SM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SO:' in s for s in routes_bs) and not any('SO:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SO',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SR:' in s for s in routes_bs) and not any('SR:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SR',BAR] += attr\n",
    "            found+=1\n",
    "        if any('ST:' in s for s in routes_bs) and not any('ST:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['ST',BAR] += attr\n",
    "            found+=1\n",
    "        if any('TD:' in s for s in routes_bs) and not any('TD:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['TD',BAR] += attr\n",
    "            found+=1\n",
    "        if any('UC:' in s for s in routes_bs) and not any('UC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['UC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VC:' in s for s in routes_bs) and not any('VC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VN:' in s for s in routes_bs) and not any('VN:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VN',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VT:' in s for s in routes_bs) and not any('VT:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VT',BAR] += attr\n",
    "            found+=1\n",
    "        if any('WC:' in s for s in routes_bs) and not any('WC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['WC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('WH:' in s for s in routes_bs) and not any('WH:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['WH',BAR] += attr\n",
    "            found+=1    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        if found == 0:\n",
    "            FT.loc['Other',BAR] += attr  \n",
    "FT.loc['Total'] = [FT['CA'].sum(),FT['1T'].sum(),FT['49'].sum(),FT['T'].sum(),FT['BA Blue'].sum(),FT['BA Green'].sum(),FT['BA Orange'].sum(),FT['BA Red'].sum(),FT['BA Yellow'].sum()]\n",
    "\n",
    "FT = (FT/Scale).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91bbab-8300-4d7d-a36d-e6ca5187a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c17c70-0e1e-4136-bfe3-22f4abc843bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FT/FT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe09d40-2a07-4648-ac3a-e436babd85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def add_row_name_to_bars(ax, bottoms, values, column_names, row_name, threshold):\n",
    "    new_bottoms = [bottom + value for bottom, value in zip(bottoms, values)]\n",
    "    for i, (bottom, new_bottom, value) in enumerate(zip(bottoms, new_bottoms, values)):\n",
    "        mid_point = (bottom + new_bottom) / 2\n",
    "        if abs(value) > threshold * 350:  # Use different thresholds for each plot\n",
    "            ax.text(i, mid_point, row_name, ha='center', va='center', color='black', fontsize=12)\n",
    "    return new_bottoms\n",
    "def separate_pos_neg(values):\n",
    "    pos_values = [v if v >= 0 else 0 for v in values]\n",
    "    neg_values = [v if v < 0 else 0 for v in values]\n",
    "    pos_bottoms = [0] * len(values)\n",
    "    neg_bottoms = [0] * len(values)\n",
    "    for i, (pos_val, neg_val) in enumerate(zip(pos_values, neg_values)):\n",
    "        if pos_val > 0:\n",
    "            pos_bottoms[i] = pos_val\n",
    "        if neg_val < 0:\n",
    "            neg_bottoms[i] = neg_val\n",
    "    return pos_values, neg_values, pos_bottoms, neg_bottoms\n",
    "\n",
    "# Sample data preparation\n",
    "# [Your data preparation code here, e.g., loading the df3 DataFrame]\n",
    "df3 = FT/3600\n",
    "df3 = df3.drop(\"Total\", axis=0)\n",
    "# df3 = df3.drop(\"Other\", axis=0)\n",
    "# Color mapping for the first plot\n",
    "color_mapping1= {\n",
    "    '1': '#A8D5BA',        # Light Green\n",
    "    'AC - others': '#A8D5BA',\n",
    "    '49': '#F2B5B5',      # Light Red\n",
    "    'K/T': '#F2B5B5',\n",
    "    'J': '#F2B5B5',\n",
    "    'L': '#F2B5B5',\n",
    "    'M': '#F2B5B5',\n",
    "    'N': '#F2B5B5',\n",
    "    'SF - others': '#F2B5B5',\n",
    "    'BART': '#A9AEEF',    # Light Blue\n",
    "    'BA - Blue': '#A9AEEF',\n",
    "    'BA - Green': '#BEE9C4',  # Pastel Green\n",
    "    'BA - Orange': '#FFDAC1',  # Pastel Orange\n",
    "    'BA - Red': '#FFB6B6',     # Pastel Red\n",
    "    'BA - Yellow': '#FFF5B7',  # Pastel Yellow\n",
    "    'Car': '#D7CCC8',         # Soft Red\n",
    "    'CarPool': '#D7CCC8',     # Light Grey\n",
    "    'TNC': '#D7CCC8',\n",
    "    'TNC-Pool': '#D7CCC8',\n",
    "    'Walk': '#D7CCC8',\n",
    "    'Bike': '#D7CCC8',\n",
    "    'CA': '#80CBC4',          # Soft Blue\n",
    "    'AM': '#CEA2E1',         # Soft Purple\n",
    "    'AY': '#CEA2E1',\n",
    "    'CC': '#CEA2E1',\n",
    "    'CE': '#CEA2E1',\n",
    "    'CM': '#CEA2E1',\n",
    "    'DE': '#CEA2E1',\n",
    "    'EM': '#CEA2E1',\n",
    "    'FF': '#CEA2E1',\n",
    "    'GG': '#CEA2E1',\n",
    "    'HF': '#CEA2E1',\n",
    "    'MA': '#CEA2E1',\n",
    "    'PE': '#CEA2E1',\n",
    "    'RV': '#CEA2E1',\n",
    "    'SB': '#CEA2E1',\n",
    "    'SC': '#CEA2E1',\n",
    "    'SL': '#CEA2E1',\n",
    "    'SM': '#CEA2E1',\n",
    "    'SO': '#CEA2E1',\n",
    "    'SR': '#CEA2E1',\n",
    "    'ST': '#CEA2E1',\n",
    "    'TD': '#CEA2E1',\n",
    "    'UC': '#CEA2E1',\n",
    "    'VC': '#CEA2E1',\n",
    "    'VN': '#CEA2E1',\n",
    "    'VT': '#CEA2E1',\n",
    "    'WC': '#CEA2E1',\n",
    "    'WH': '#CEA2E1',\n",
    "    'Other': '#F5F5F5'        # Light Grey\n",
    "}\n",
    "color_mapping2 = {\n",
    "    '1': '#F5F5F5',  # muted dark green\n",
    "    'AC - others': '#F5F5F5',\n",
    "    '49': '#F5F5F5',  # muted dark red\n",
    "    'K/T': '#F5F5F5',\n",
    "    'J': '#F5F5F5',\n",
    "    'L': '#F5F5F5',\n",
    "    'M': '#F5F5F5',\n",
    "    'N': '#F5F5F5',\n",
    "    'SF - others': '#F5F5F5',\n",
    "    'BART': '#F5F5F5',\n",
    "    'BA - Blue': '#BBDEFB',  # muted blue\n",
    "    'BA - Green': '#C8E6C9',  # muted green\n",
    "    'BA - Orange': '#FFE0B2',  # muted orange\n",
    "    'BA - Red': '#FFCDD2',  # muted red\n",
    "    'BA - Yellow': '#FFF9C4',  # muted yellow\n",
    "    'Car': '#F5F5F5',  # dark red\n",
    "    'CarPool': '#F5F5F5',  # grey\n",
    "    'TNC': '#F5F5F5',\n",
    "    'TNC-Pool': '#F5F5F5',\n",
    "    'Walk': '#F5F5F5',\n",
    "    'Bike': '#F5F5F5',\n",
    "    'CA': '#F5F5F5',  # muted dark blue\n",
    "    'AM': '#F5F5F5',  # muted dark purple\n",
    "    'AY': '#F5F5F5',\n",
    "    'CC': '#F5F5F5',\n",
    "    'CE': '#F5F5F5',\n",
    "    'CM': '#F5F5F5',\n",
    "    'DE': '#F5F5F5',\n",
    "    'EM': '#F5F5F5',\n",
    "    'FF': '#F5F5F5',\n",
    "    'GG': '#F5F5F5',\n",
    "    'HF': '#F5F5F5',\n",
    "    'MA': '#F5F5F5',\n",
    "    'PE': '#F5F5F5',\n",
    "    'RV': '#F5F5F5',\n",
    "    'SB': '#F5F5F5',\n",
    "    'SC': '#F5F5F5',\n",
    "    'SL': '#F5F5F5',\n",
    "    'SM': '#F5F5F5',\n",
    "    'SO': '#F5F5F5',\n",
    "    'SR': '#F5F5F5',\n",
    "    'ST': '#F5F5F5',\n",
    "    'TD': '#F5F5F5',\n",
    "    'UC': '#F5F5F5',\n",
    "    'VC': '#F5F5F5',\n",
    "    'VN': '#F5F5F5',\n",
    "    'VT': '#F5F5F5',\n",
    "    'WC': '#F5F5F5',\n",
    "    'WH': '#F5F5F5',\n",
    "    'Other': '#F5F5F5'  # grey\n",
    "}\n",
    "desired_order2 = [\n",
    "    'AC - others', '1', \n",
    "    'SF - others', '49', \n",
    "    'K/T', 'J', 'L', 'M', 'N', \n",
    "    'BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', 'BA - Yellow', \n",
    "    'Car', 'CarPool', 'TNC', 'TNC-Pool', 'Walk', 'Bike', \n",
    "    'CA',\n",
    "    'AM', 'AY', 'CC', 'CE', 'CM', 'DE', 'EM', 'FF', 'GG', 'HF', 'MA', 'PE', 'RV', 'SB', 'SC', \n",
    "    'SL', 'SM', 'SO', 'SR', 'ST', 'TD', 'UC', 'VC', 'VN', 'VT', 'WC', 'WH',\n",
    "    'Other'\n",
    "]\n",
    "desired_order1 = [\n",
    "    'AC - others', '1', \n",
    "    'SF - others', '49', \n",
    "    'K/T', 'J', 'L', 'M', 'N', \n",
    "    'BART', \n",
    "    'Car', 'CarPool', 'TNC', 'TNC-Pool', 'Walk', 'Bike', \n",
    "    'CA',\n",
    "    'AM', 'AY', 'CC', 'CE', 'CM', 'DE', 'EM', 'FF', 'GG', 'HF', 'MA', 'PE', 'RV', 'SB', 'SC', \n",
    "    'SL', 'SM', 'SO', 'SR', 'ST', 'TD', 'UC', 'VC', 'VN', 'VT', 'WC', 'WH',\n",
    "    'Other'\n",
    "]\n",
    "# Assuming you have df3 and color_mapping set as before\n",
    "\n",
    "# Aggregate BA - type rows into BART\n",
    "ba_rows = ['BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', 'BA - Yellow']\n",
    "df3.loc['BART'] = df3.loc[ba_rows].sum()\n",
    "\n",
    "# Filter and reorder the rows for both plots\n",
    "df_first_plot = df3.loc[desired_order1,['CA', '1T','49', 'T']]\n",
    "df_second_plot = df3.loc[desired_order2,['BA Blue', 'BA Green', 'BA Orange', 'BA Red', 'BA Yellow']]\n",
    "\n",
    "# Create subplots with 1 row and 2 columns\n",
    "# Function to separate positive and negative values for stacking\n",
    "\n",
    "\n",
    "# Create subplots with 1 row and 2 columns\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Plotting the first graph\n",
    "pos_bottoms = [0] * len(df_first_plot.columns)\n",
    "neg_bottoms = [0] * len(df_first_plot.columns)\n",
    "for row_name in df_first_plot.index:\n",
    "    values = df_first_plot.loc[row_name]\n",
    "    pos_values = [v if v >= 0 else 0 for v in values]\n",
    "    neg_values = [v if v < 0 else 0 for v in values]\n",
    "\n",
    "    axs[0].bar(df_first_plot.columns, pos_values, bottom=pos_bottoms, color=color_mapping1[row_name], edgecolor='white')\n",
    "    axs[0].bar(df_first_plot.columns, neg_values, bottom=neg_bottoms, color=color_mapping1[row_name], edgecolor='white')\n",
    "\n",
    "    pos_bottoms = add_row_name_to_bars(axs[0], pos_bottoms, pos_values, df_first_plot.columns, row_name, threshold=650/3600)\n",
    "    neg_bottoms = add_row_name_to_bars(axs[0], neg_bottoms, neg_values, df_first_plot.columns, row_name, threshold=650/3600)\n",
    "\n",
    "# Plotting the second graph\n",
    "pos_bottoms = [0] * len(df_second_plot.columns)\n",
    "neg_bottoms = [0] * len(df_second_plot.columns)\n",
    "for row_name in df_second_plot.index:\n",
    "    values = df_second_plot.loc[row_name]\n",
    "    pos_values = [v if v >= 0 else 0 for v in values]\n",
    "    neg_values = [v if v < 0 else 0 for v in values]\n",
    "\n",
    "    axs[1].bar(df_second_plot.columns, pos_values, bottom=pos_bottoms, color=color_mapping2[row_name], edgecolor='white')\n",
    "    axs[1].bar(df_second_plot.columns, neg_values, bottom=neg_bottoms, color=color_mapping2[row_name], edgecolor='white')\n",
    "\n",
    "    pos_bottoms = add_row_name_to_bars(axs[1], pos_bottoms, pos_values, df_second_plot.columns, row_name, threshold=1800/3600)\n",
    "    neg_bottoms = add_row_name_to_bars(axs[1], neg_bottoms, neg_values, df_second_plot.columns, row_name, threshold=1800/3600)\n",
    "# axs[0].set_ylim(-90*11.23, 115*11.23)# Adjust the upper limit as necessary\n",
    "# axs[1].set_ylim(-150*11.23,1350*11.23) # Adjust the upper limit as necessary\n",
    "axs[0].axhline(0, color='black', linewidth=0.5)\n",
    "axs[1].axhline(0, color='black', linewidth=0.5)\n",
    "\n",
    "\n",
    "axs[0].set_xticks(range(len(df_first_plot.columns)))\n",
    "axs[0].set_xticklabels(['Caltrain', '1Tempo BRT', 'Van Ness BRT', 'Central Subway'])\n",
    "\n",
    "# Changing x labels for the second plot\n",
    "axs[1].set_xticks(range(len(df_second_plot.columns)))\n",
    "axs[1].set_xticklabels(['BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', 'BA - Yellow'])\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('divergence_stacked_bar_chart_high_qualitydur.png', dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790a274-d5d7-4599-9e8f-dc70716c1ab1",
   "metadata": {},
   "source": [
    "# **Lengths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9e055-7c73-4b4a-bce5-bb9986131a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "dict_project = {\n",
    "    'AC - 1TEMPO':'1T',\n",
    "    'BA - Extension and Core project':'BA',\n",
    "    'CA - Electrification Project':'CA',\n",
    "    'SF - Central Subway':'T',\n",
    "    'SF - Van Ness': '49'\n",
    "}\n",
    "\n",
    "veh_to_route_bs = pd.read_csv('outputs/routetovehicledictBaseline2018.csv')\n",
    "veh_to_route_bs = veh_to_route_bs.set_index('trip_id')['route_id'].to_dict()\n",
    "veh_to_route_TR = pd.read_csv('outputs/routetovehicledictFuture2018.csv')\n",
    "veh_to_route_TR = veh_to_route_TR.set_index('trip_id')['route_id'].to_dict()\n",
    "\n",
    "from_indexes = [\n",
    "\n",
    "                '1', '49', 'K/T', 'J', 'L', 'M', 'N', \n",
    "                'BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', \n",
    "                'BA - Yellow', 'Car', 'CarPool','TNC', 'TNC-Pool','Walk', 'Bike', \n",
    "    'CA', 'AC - others', 'SF - others','AM','AY','CC','CE','CM',\n",
    "    'DE','EM','FF','GG','HF','MA','PE','RV', 'SB',\n",
    "    'SC','SL','SM','SO','SR','ST','TD','UC','VC','VN','VT','WC','WH',\n",
    "                'Other']\n",
    "to_indexes_dict = {'CA':['CA:12867','CA:12868','CA:12869'], '1T':'AC:1-142', '49':'SF:12327', 'T':'SF:12476', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue':'BA:11', \n",
    "              'BA Green':'BA:5', 'BA Orange':'BA:3', 'BA Red':'BA:7', 'BA Yellow':'BA:1'}\n",
    "to_indexes = ['CA', '1T', '49', 'T', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue', \n",
    "              'BA Green', 'BA Orange', 'BA Red', 'BA Yellow']\n",
    "FT = pd.DataFrame(0, index=from_indexes, columns=to_indexes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for veh_bs, veh_tr, project, mode_base, dist_bs, dist_tr in zip(list(df['Vehicles Used Baseline']), list(df['Vehicles Used TR']), list(df['Project Tried']), \n",
    "                                              list(df['Chosen Mode Baseline']), list(df['Trip Length Baseline']), list(df['Trip Length TR'])):\n",
    "    # routes_bs = veh_to_route_bs[veh_bs]\n",
    "    # routes_TR = veh_to_route_TR[veh_tr]\n",
    "    # veh_bs = ','.join(veh_bs)\n",
    "    # veh_tr = ','.join(veh_tr)\n",
    "    \n",
    "\n",
    "    found = 0\n",
    "    \n",
    "    fixed_string = veh_bs.replace(\" \", \", \")\n",
    "    veh_bs = ast.literal_eval(fixed_string)\n",
    "    fixed_string = veh_tr.replace(\" \", \", \")\n",
    "    veh_tr = ast.literal_eval(fixed_string)\n",
    "\n",
    "    routes_bs = [veh_to_route_bs.get(key, '0') for key in veh_bs]\n",
    "    routes_TR = [veh_to_route_TR.get(key, '0') for key in veh_tr]\n",
    "    \n",
    "    attr = dist_tr - dist_bs\n",
    "    \n",
    "    BARTS = []\n",
    "    if project != 'BA - Extension and Core project' :\n",
    "        BARTS.append(dict_project[project])\n",
    "    else:\n",
    "        \n",
    "        if 'BA:1' in routes_TR or 'BA:2' in routes_TR :\n",
    "            BARTS.append('BA Yellow')\n",
    "        if 'BA:3' in routes_TR or 'BA:4' in routes_TR :\n",
    "            BARTS.append('BA Orange')\n",
    "        if 'BA:5' in routes_TR or 'BA:6' in routes_TR :\n",
    "            BARTS.append('BA Green')\n",
    "        if 'BA:7' in routes_TR or 'BA:8' in routes_TR :\n",
    "            BARTS.append('BA Red')\n",
    "        if 'BA:11' in routes_TR or 'BA:12' in routes_TR :\n",
    "            BARTS.append('BA Blue')\n",
    "            \n",
    "    for BAR in BARTS:\n",
    "        \n",
    "        if BAR == '1T':\n",
    "            if 'AC:1-142' in routes_bs:\n",
    "                FT.loc['1',BAR] += attr\n",
    "                found+=1\n",
    "            if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in [item for item in routes_TR if item != 'AC:1T-142']) and not any('AC:1-142' in s for s in routes_bs) :\n",
    "                FT.loc['AC - others',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'CA':\n",
    "            if any('CA:' in s for s in routes_bs) :\n",
    "                FT.loc['CA',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Yellow':\n",
    "            if 'BA:1' in routes_bs:\n",
    "                FT.loc['BA - Yellow',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Orange':\n",
    "            if 'BA:3' in routes_bs:\n",
    "                FT.loc['BA - Orange',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Green':\n",
    "            if 'BA:5' in routes_bs:\n",
    "                FT.loc['BA - Green',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Red':\n",
    "            if 'BA:7' in routes_bs:\n",
    "                FT.loc['BA - Red',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Blue':\n",
    "            if 'BA:11' in routes_bs:\n",
    "                FT.loc['BA - Blue',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'T':\n",
    "            if 'SF:12476' in routes_bs:\n",
    "                FT.loc['K/T',BAR] += attr\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:1001']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT.loc['SF - others',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == '49':\n",
    "            if 'SF:12327' in routes_bs:\n",
    "                FT.loc['49',BAR] += attr\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:18608']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT.loc['SF - others',BAR] += attr\n",
    "                found+=1\n",
    "        \n",
    "\n",
    "        # if any('AC:' in s for s in routes_bs):\n",
    "        #     FT.loc['AC',BAR] += 1\n",
    "        # if any('SF:' in s for s in routes_bs):\n",
    "        #     FT.loc['SF',BAR] += 1\n",
    "        # if any('BA:' in s for s in routes_bs):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "            \n",
    "        if 'AC:1-142' in routes_bs and 'AC:1T-142' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['1',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12327' in routes_bs and 'SF:18608' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['49',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12476' in routes_bs and 'SF:1001' not in routes_TR and 'SF:1002' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['K/T',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12475' in routes_bs and 'SF:12375' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['J',BAR] += attr\n",
    "            found+=1\n",
    "            # if BAR == 'CA':\n",
    "            #     print(routes_bs, routes_TR, attr)\n",
    "        if 'SF:12477' in routes_bs and 'SF:12377' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['L',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12478' in routes_bs and 'SF:12378' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['M',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12479' in routes_bs and 'SF:12379' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['N',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:1' in routes_bs and 'BA:1' not in routes_TR and 'BA:2' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Yellow',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:3' in routes_bs and 'BA:3' not in routes_TR and 'BA:4' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Orange',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:5' in routes_bs and 'BA:5' not in routes_TR and 'BA:6' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Green',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:7' in routes_bs and 'BA:7' not in routes_TR and 'BA:8' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Red',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:11' in routes_bs and 'BA:11' not in routes_TR and 'BA:12' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Blue',BAR] += attr\n",
    "            found+=1\n",
    "            \n",
    "        if mode_base =='walk' :\n",
    "            FT.loc['Walk',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail' :\n",
    "            FT.loc['TNC',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail_pooled' :\n",
    "            FT.loc['TNC-Pool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car' :\n",
    "            FT.loc['Car',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car_hov2' :\n",
    "            FT.loc['CarPool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car_hov3' :\n",
    "            FT.loc['CarPool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='bike' :\n",
    "            FT.loc['Bike',BAR] += attr\n",
    "            found+=1\n",
    "\n",
    "            \n",
    "        if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in routes_TR) and not any('AC:1-142' in s for s in routes_bs)  and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AC - others',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in routes_TR) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SF - others',BAR] += attr\n",
    "            found+=1\n",
    "        # if any('BA:' in s for s in routes_bs) and not any('BA:' in s for s in routes_TR):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "        #     found+=1\n",
    "        \n",
    "        if any('CA:' in s for s in routes_bs) and not any('CA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CA',BAR] += attr\n",
    "            found+=1\n",
    "        if any('AM:' in s for s in routes_bs) and not any('AM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('AY:' in s for s in routes_bs) and not any('AY:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AY',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CC:' in s for s in routes_bs) and not any('CC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CE:' in s for s in routes_bs) and not any('CE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CM:' in s for s in routes_bs) and not any('CM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('DE:' in s for s in routes_bs) and not any('DE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['DE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('EM:' in s for s in routes_bs) and not any('EM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['EM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('GG:' in s for s in routes_bs) and not any('GG:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['GG',BAR] += attr\n",
    "            found+=1\n",
    "        if any('HF:' in s for s in routes_bs) and not any('HF:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['HF',BAR] += attr\n",
    "            found+=1\n",
    "        if any('MA:' in s for s in routes_bs) and not any('MA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['MA',BAR] += attr\n",
    "            found+=1\n",
    "        if any('PE:' in s for s in routes_bs) and not any('PE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['PE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('RV:' in s for s in routes_bs) and not any('RV:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['RV',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SB:' in s for s in routes_bs) and not any('SB:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SB',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SC:' in s for s in routes_bs) and not any('SC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SL:' in s for s in routes_bs) and not any('SL:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SL',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SM:' in s for s in routes_bs) and not any('SM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SO:' in s for s in routes_bs) and not any('SO:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SO',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SR:' in s for s in routes_bs) and not any('SR:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SR',BAR] += attr\n",
    "            found+=1\n",
    "        if any('ST:' in s for s in routes_bs) and not any('ST:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['ST',BAR] += attr\n",
    "            found+=1\n",
    "        if any('TD:' in s for s in routes_bs) and not any('TD:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['TD',BAR] += attr\n",
    "            found+=1\n",
    "        if any('UC:' in s for s in routes_bs) and not any('UC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['UC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VC:' in s for s in routes_bs) and not any('VC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VN:' in s for s in routes_bs) and not any('VN:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VN',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VT:' in s for s in routes_bs) and not any('VT:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VT',BAR] += attr\n",
    "            found+=1\n",
    "        if any('WC:' in s for s in routes_bs) and not any('WC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['WC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('WH:' in s for s in routes_bs) and not any('WH:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['WH',BAR] += attr\n",
    "            found+=1    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        if found == 0:\n",
    "            FT.loc['Other',BAR] += attr  \n",
    "FT.loc['Total'] = [FT['CA'].sum(),FT['1T'].sum(),FT['49'].sum(),FT['T'].sum(),FT['BA Blue'].sum(),FT['BA Green'].sum(),FT['BA Orange'].sum(),FT['BA Red'].sum(),FT['BA Yellow'].sum()]\n",
    "\n",
    "FT = (FT/Scale).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5dd65e-157d-43b7-a62d-f0c0537a7fb4",
   "metadata": {},
   "source": [
    "# **inexus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c3b09d-e31d-49aa-99c1-f35bccb64cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "\n",
    "dict_project = {\n",
    "    'AC - 1TEMPO':'1T',\n",
    "    'BA - Extension and Core project':'BA',\n",
    "    'CA - Electrification Project':'CA',\n",
    "    'SF - Central Subway':'T',\n",
    "    'SF - Van Ness': '49'\n",
    "}\n",
    "\n",
    "veh_to_route_bs = pd.read_csv('outputs/routetovehicledictBaseline2018.csv')\n",
    "veh_to_route_bs = veh_to_route_bs.set_index('trip_id')['route_id'].to_dict()\n",
    "veh_to_route_TR = pd.read_csv('outputs/routetovehicledictFuture2018.csv')\n",
    "veh_to_route_TR = veh_to_route_TR.set_index('trip_id')['route_id'].to_dict()\n",
    "\n",
    "from_indexes = [\n",
    "\n",
    "                '1', '49', 'K/T', 'J', 'L', 'M', 'N', \n",
    "                'BA - Blue', 'BA - Green', 'BA - Orange', 'BA - Red', \n",
    "                'BA - Yellow', 'Car', 'CarPool','TNC', 'TNC-Pool','Walk', 'Bike', \n",
    "    'CA', 'AC - others', 'SF - others','AM','AY','CC','CE','CM',\n",
    "    'DE','EM','FF','GG','HF','MA','PE','RV', 'SB',\n",
    "    'SC','SL','SM','SO','SR','ST','TD','UC','VC','VN','VT','WC','WH',\n",
    "                'Other']\n",
    "to_indexes_dict = {'CA':['CA:12867','CA:12868','CA:12869'], '1T':'AC:1-142', '49':'SF:12327', 'T':'SF:12476', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue':'BA:11', \n",
    "              'BA Green':'BA:5', 'BA Orange':'BA:3', 'BA Red':'BA:7', 'BA Yellow':'BA:1'}\n",
    "to_indexes = ['CA', '1T', '49', 'T', \n",
    "              #'J', 'L', 'M', 'N', \n",
    "              'BA Blue', \n",
    "              'BA Green', 'BA Orange', 'BA Red', 'BA Yellow']\n",
    "FT = pd.DataFrame(0, index=from_indexes, columns=to_indexes)\n",
    "\n",
    "\n",
    "for veh_bs, veh_tr, project, mode_base, in_bs, in_tr in zip(list(df['Vehicles Used Baseline']), list(df['Vehicles Used TR']), list(df['Project Tried']), \n",
    "                                              list(df['Chosen Mode Baseline']), list(df['Potential INEXUS Baseline']), list(df['Potential INEXUS TR'])):\n",
    "    # routes_bs = veh_to_route_bs[veh_bs]\n",
    "    # routes_TR = veh_to_route_TR[veh_tr]\n",
    "    # veh_bs = ','.join(veh_bs)\n",
    "    # veh_tr = ','.join(veh_tr)\n",
    "    \n",
    "\n",
    "    found = 0\n",
    "    \n",
    "    fixed_string = veh_bs.replace(\" \", \", \")\n",
    "    veh_bs = ast.literal_eval(fixed_string)\n",
    "    fixed_string = veh_tr.replace(\" \", \", \")\n",
    "    veh_tr = ast.literal_eval(fixed_string)\n",
    "\n",
    "    routes_bs = [veh_to_route_bs.get(key, '0') for key in veh_bs]\n",
    "    routes_TR = [veh_to_route_TR.get(key, '0') for key in veh_tr]\n",
    "    \n",
    "    attr = in_tr - in_bs\n",
    "    \n",
    "    BARTS = []\n",
    "    if project != 'BA - Extension and Core project' :\n",
    "        BARTS.append(dict_project[project])\n",
    "    else:\n",
    "        \n",
    "        if 'BA:1' in routes_TR or 'BA:2' in routes_TR :\n",
    "            BARTS.append('BA Yellow')\n",
    "        if 'BA:3' in routes_TR or 'BA:4' in routes_TR :\n",
    "            BARTS.append('BA Orange')\n",
    "        if 'BA:5' in routes_TR or 'BA:6' in routes_TR :\n",
    "            BARTS.append('BA Green')\n",
    "        if 'BA:7' in routes_TR or 'BA:8' in routes_TR :\n",
    "            BARTS.append('BA Red')\n",
    "        if 'BA:11' in routes_TR or 'BA:12' in routes_TR :\n",
    "            BARTS.append('BA Blue')\n",
    "            \n",
    "    for BAR in BARTS:\n",
    "        \n",
    "        if BAR == '1T':\n",
    "            if 'AC:1-142' in routes_bs:\n",
    "                FT.loc['1',BAR] += attr\n",
    "                found+=1\n",
    "            if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in [item for item in routes_TR if item != 'AC:1T-142']) and not any('AC:1-142' in s for s in routes_bs) :\n",
    "                FT.loc['AC - others',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'CA':\n",
    "            if any('CA:' in s for s in routes_bs) :\n",
    "                FT.loc['CA',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Yellow':\n",
    "            if 'BA:1' in routes_bs:\n",
    "                FT.loc['BA - Yellow',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Orange':\n",
    "            if 'BA:3' in routes_bs:\n",
    "                FT.loc['BA - Orange',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Green':\n",
    "            if 'BA:5' in routes_bs:\n",
    "                FT.loc['BA - Green',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Red':\n",
    "            if 'BA:7' in routes_bs:\n",
    "                FT.loc['BA - Red',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'BA Blue':\n",
    "            if 'BA:11' in routes_bs:\n",
    "                FT.loc['BA - Blue',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == 'T':\n",
    "            if 'SF:12476' in routes_bs:\n",
    "                FT.loc['K/T',BAR] += attr\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:1001']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT.loc['SF - others',BAR] += attr\n",
    "                found+=1\n",
    "        if BAR == '49':\n",
    "            if 'SF:12327' in routes_bs:\n",
    "                FT.loc['49',BAR] += attr\n",
    "                found+=1\n",
    "            if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in [item for item in routes_TR if item != 'SF:18608']) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs):\n",
    "                FT.loc['SF - others',BAR] += attr\n",
    "                found+=1\n",
    "        \n",
    "\n",
    "        # if any('AC:' in s for s in routes_bs):\n",
    "        #     FT.loc['AC',BAR] += 1\n",
    "        # if any('SF:' in s for s in routes_bs):\n",
    "        #     FT.loc['SF',BAR] += 1\n",
    "        # if any('BA:' in s for s in routes_bs):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "            \n",
    "        if 'AC:1-142' in routes_bs and 'AC:1T-142' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['1',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12327' in routes_bs and 'SF:18608' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['49',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12476' in routes_bs and 'SF:1001' not in routes_TR and 'SF:1002' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['K/T',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12475' in routes_bs and 'SF:12375' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['J',BAR] += attr\n",
    "            found+=1\n",
    "            # if BAR == 'CA':\n",
    "            #     print(routes_bs, routes_TR, attr)\n",
    "        if 'SF:12477' in routes_bs and 'SF:12377' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['L',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12478' in routes_bs and 'SF:12378' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['M',BAR] += attr\n",
    "            found+=1\n",
    "        if 'SF:12479' in routes_bs and 'SF:12379' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['N',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:1' in routes_bs and 'BA:1' not in routes_TR and 'BA:2' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Yellow',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:3' in routes_bs and 'BA:3' not in routes_TR and 'BA:4' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Orange',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:5' in routes_bs and 'BA:5' not in routes_TR and 'BA:6' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Green',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:7' in routes_bs and 'BA:7' not in routes_TR and 'BA:8' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Red',BAR] += attr\n",
    "            found+=1\n",
    "        if 'BA:11' in routes_bs and 'BA:11' not in routes_TR and 'BA:12' not in routes_TR and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['BA - Blue',BAR] += attr\n",
    "            found+=1\n",
    "            \n",
    "        if mode_base =='walk' :\n",
    "            FT.loc['Walk',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail' :\n",
    "            FT.loc['TNC',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='ride_hail_pooled' :\n",
    "            FT.loc['TNC-Pool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car' :\n",
    "            FT.loc['Car',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car_hov2' :\n",
    "            FT.loc['CarPool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='car_hov3' :\n",
    "            FT.loc['CarPool',BAR] += attr\n",
    "            found+=1\n",
    "        if mode_base =='bike' :\n",
    "            FT.loc['Bike',BAR] += attr\n",
    "            found+=1\n",
    "\n",
    "            \n",
    "        if any('AC:' in s for s in routes_bs) and not any('AC:' in s for s in routes_TR) and not any('AC:1-142' in s for s in routes_bs)  and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AC - others',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SF:' in s for s in routes_bs) and not any('SF:' in s for s in routes_TR) and not any('SF:12327' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12475' in s for s in routes_bs) and not any('SF:12476' in s for s in routes_bs) and not any('SF:12477' in s for s in routes_bs) and not any('SF:12478' in s for s in routes_bs) and not any('SF:12479' in s for s in routes_bs) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SF - others',BAR] += attr\n",
    "            found+=1\n",
    "        # if any('BA:' in s for s in routes_bs) and not any('BA:' in s for s in routes_TR):\n",
    "        #     FT.loc['BA',BAR] += 1\n",
    "        #     found+=1\n",
    "        \n",
    "        if any('CA:' in s for s in routes_bs) and not any('CA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CA',BAR] += attr\n",
    "            found+=1\n",
    "        if any('AM:' in s for s in routes_bs) and not any('AM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('AY:' in s for s in routes_bs) and not any('AY:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['AY',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CC:' in s for s in routes_bs) and not any('CC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CE:' in s for s in routes_bs) and not any('CE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('CM:' in s for s in routes_bs) and not any('CM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['CM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('DE:' in s for s in routes_bs) and not any('DE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['DE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('EM:' in s for s in routes_bs) and not any('EM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['EM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('GG:' in s for s in routes_bs) and not any('GG:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['GG',BAR] += attr\n",
    "            found+=1\n",
    "        if any('HF:' in s for s in routes_bs) and not any('HF:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['HF',BAR] += attr\n",
    "            found+=1\n",
    "        if any('MA:' in s for s in routes_bs) and not any('MA:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['MA',BAR] += attr\n",
    "            found+=1\n",
    "        if any('PE:' in s for s in routes_bs) and not any('PE:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['PE',BAR] += attr\n",
    "            found+=1\n",
    "        if any('RV:' in s for s in routes_bs) and not any('RV:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['RV',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SB:' in s for s in routes_bs) and not any('SB:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SB',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SC:' in s for s in routes_bs) and not any('SC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SL:' in s for s in routes_bs) and not any('SL:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SL',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SM:' in s for s in routes_bs) and not any('SM:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SM',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SO:' in s for s in routes_bs) and not any('SO:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SO',BAR] += attr\n",
    "            found+=1\n",
    "        if any('SR:' in s for s in routes_bs) and not any('SR:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['SR',BAR] += attr\n",
    "            found+=1\n",
    "        if any('ST:' in s for s in routes_bs) and not any('ST:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['ST',BAR] += attr\n",
    "            found+=1\n",
    "        if any('TD:' in s for s in routes_bs) and not any('TD:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['TD',BAR] += attr\n",
    "            found+=1\n",
    "        if any('UC:' in s for s in routes_bs) and not any('UC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['UC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VC:' in s for s in routes_bs) and not any('VC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VN:' in s for s in routes_bs) and not any('VN:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VN',BAR] += attr\n",
    "            found+=1\n",
    "        if any('VT:' in s for s in routes_bs) and not any('VT:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['VT',BAR] += attr\n",
    "            found+=1\n",
    "        if any('WC:' in s for s in routes_bs) and not any('WC:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['WC',BAR] += attr\n",
    "            found+=1\n",
    "        if any('WH:' in s for s in routes_bs) and not any('WH:' in s for s in routes_TR) and not any(BR  in routes_bs for BR in to_indexes_dict[BAR]):\n",
    "            FT.loc['WH',BAR] += attr\n",
    "            found+=1    \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        if found == 0:\n",
    "            FT.loc['Other',BAR] += attr  \n",
    "FT.loc['Total'] = [FT['CA'].sum(),FT['1T'].sum(),FT['49'].sum(),FT['T'].sum(),FT['BA Blue'].sum(),FT['BA Green'].sum(),FT['BA Orange'].sum(),FT['BA Red'].sum(),FT['BA Yellow'].sum()]\n",
    "\n",
    "FT = (FT/Scale).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64300b2-b22d-41f1-bd64-df962ad06b30",
   "metadata": {},
   "source": [
    "# ***OTHER PLOTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72541e-fde0-477e-982c-3d2f8e3bb5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grouped_sum = df.groupby('Project Tried').agg({\n",
    "    'Trip Length Baseline': 'sum',\n",
    "    'Trip Duration Baseline': 'sum',\n",
    "    'Potential INEXUS Baseline': 'sum',\n",
    "    'Trip Length TR': 'sum',\n",
    "    'Trip Duration TR': 'sum',\n",
    "    'Potential INEXUS TR': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate averages for each 'Switch From' condition for \"Baseline\" and \"TR\"\n",
    "conditions = [\n",
    "    'Switch from another transit agency',\n",
    "    'Switch from same transit agency',\n",
    "    'Switch from another mode'\n",
    "]\n",
    "avg_incomes_baseline = [df[df['Switch From'] == condition]['Person Income'].mean() for condition in conditions]\n",
    "avg_incomes_TR = [df[df['Switch From'] == condition]['Person Income'].mean() for condition in conditions]\n",
    "\n",
    "# Display results in a table format\n",
    "average_income_df = pd.DataFrame({\n",
    "    'Switch From': conditions,\n",
    "    'Average Household Income': avg_incomes_baseline,\n",
    "    'Average Household Income': avg_incomes_TR\n",
    "})\n",
    "\n",
    "# Printing the results\n",
    "print(\"Grouped Sums:\")\n",
    "print(grouped_sum)\n",
    "\n",
    "print(\"\\nAverage Household Incomes:\")\n",
    "print(average_income_df*4160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614dec5-6a8d-4165-9f13-44de96c5750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a custom color palette for softer colors\n",
    "base_palette = sns.color_palette(\"colorblind\")\n",
    "custom_palette = sns.light_palette(base_palette[0], n_colors=len(base_palette), reverse=False, input=\"rgb\")\n",
    "\n",
    "# Group by 'Project Tried' and 'Switch From', then count occurrences\n",
    "grouped_df = df.groupby(['Project Tried', 'Switch From']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create a new DataFrame with normalized percentages\n",
    "normalized_df = grouped_df.div(grouped_df.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Create stacked bar plot with custom color palette and labels\n",
    "ax = normalized_df.plot(kind='bar', stacked=True, figsize=(18, 7), color=custom_palette)\n",
    "\n",
    "# Set plot labels and title\n",
    "# plt.xlabel('Project')\n",
    "plt.ylabel('Percentage (%)', fontsize=18)\n",
    "# plt.title('Percentage of \"Switch From\" for each project')\n",
    "# plt.legend(title='Switch From', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Rotate x-labels for better readability\n",
    "plt.xticks( ha='right')\n",
    "\n",
    "ax.legend( bbox_to_anchor=(0.5, 1.1), loc='upper center', ncol=len(normalized_df.columns))\n",
    "\n",
    "# Add labels on each stacked bar\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, label_type='center', fontsize=18, padding=2, fmt='%.1f%%')  # Show as percentages\n",
    "\n",
    "# ax.set_xticks(range(len(df.columns)))\n",
    "ax.set_xticklabels(['1Tempo BRT', 'BART', 'Caltrain', 'Central Subway', 'Van Ness BRT'], rotation=0, fontsize=18)\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "    \n",
    "# Adjust layout to fit everything nicely\n",
    "plt.tight_layout()\n",
    "plt.savefig('switch from.png', dpi=600)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8da10f8-293c-40c3-a718-c91754a1a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping for aggregation\n",
    "mapping = {\n",
    "    'car': 'Car',\n",
    "    'car_hov2': 'Car',\n",
    "    'car_hov3': 'Car',\n",
    "    'ride_hail': 'TNC',\n",
    "    'ride_hail_pooled': 'TNC',\n",
    "    'bike': 'Bike',\n",
    "    'walk': 'Walk',\n",
    "    'walk_transit': 'Walk',\n",
    "    'drive_transit': 'Car'\n",
    "}\n",
    "project_name_mapping = {\n",
    "    \"AC - 1TEMPO\": \"1Tempo BRT\",\n",
    "    \"BA - Extension and Core project\": \"BART\",\n",
    "    \"CA - Electrification Project\": \"Caltrain\",\n",
    "    \"SF - Central Subway\": \"Central Subway\",\n",
    "    \"SF - Van Ness\": \"Van Ness BRT\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to 'Chosen Mode Baseline' column\n",
    "df['Chosen Mode Baseline'] = df['Chosen Mode Baseline'].replace(mapping)\n",
    "df['Project Tried'] = df['Project Tried'].replace(project_name_mapping)\n",
    "\n",
    "# Remove rows with 'walk_transit' in 'Chosen Mode Baseline'\n",
    "# df = df[df['Chosen Mode Baseline'] != 'walk_transit']\n",
    "\n",
    "# 1. Generate the two color palettes: one blue and one orange.\n",
    "custom_palette = [\n",
    "    '#c9d9d3',  # very light green\n",
    "    '#dadaeb',  # very light purple\n",
    "    '#b2ebf2',\n",
    "    '#f5c9c9',\n",
    "    '#f0ebd8',  # very light yellow\n",
    "    '#d0d0d0',   # another light grey\n",
    "    '#e3dfd5',  # off white/greyish\n",
    "    '#d9d9d9',  # light grey\n",
    "]\n",
    "\n",
    "\n",
    "# Ensure the palette has enough colors for the data\n",
    "if len(custom_palette) < grouped_df.shape[1]:\n",
    "    custom_palette = sns.color_palette(\"husl\", n_colors=grouped_df.shape[1])  # Fallback to a diverse palette\n",
    "\n",
    "colors = {col: custom_palette[i] for i, col in enumerate(grouped_df.columns)}\n",
    "\n",
    "# Group by 'Project Tried' and 'Switch From', then count occurrences\n",
    "grouped_df = df.groupby(['Project Tried', 'Switch From']).size().unstack(fill_value=0)\n",
    "\n",
    "# Extract the rows in df where 'Switch From' is 'Switch from another mode'\n",
    "switch_rows = df[df['Switch From'] == 'Switch from another mode']\n",
    "\n",
    "# Group by 'Project Tried' and 'Chosen Mode Baseline' to get the count of each mode\n",
    "switch_mode_grouped = switch_rows.groupby(['Project Tried', 'Chosen Mode Baseline']).size().unstack(fill_value=0)\n",
    "\n",
    "# Replace the 'Switch from another mode' column in grouped_df with the columns from switch_mode_grouped\n",
    "grouped_df = grouped_df.drop(columns='Switch from another mode')\n",
    "grouped_df = pd.concat([grouped_df, switch_mode_grouped], axis=1, sort=False).fillna(0)\n",
    "\n",
    "# Create a new DataFrame with normalized percentages\n",
    "# normalized_df = grouped_df.div(grouped_df.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Reorder the rows (i.e., the projects)\n",
    "ordered_projects = ['Caltrain','1Tempo BRT', 'Van Ness BRT', 'Central Subway','BART']\n",
    "grouped_df = grouped_df.loc[ordered_projects]\n",
    "\n",
    "# Create a new DataFrame with normalized percentages\n",
    "normalized_df = grouped_df.div(grouped_df.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Plot with the custom color palette\n",
    "ax = normalized_df.plot(kind='bar', stacked=True, figsize=(18, 7), color=custom_palette)\n",
    "\n",
    "\n",
    "\n",
    "# Set plot labels and title\n",
    "# plt.xlabel('Project')\n",
    "plt.ylabel('Percentage (%)', fontsize=18)\n",
    "# plt.title('Percentage of \"Switch From\" for each project')\n",
    "# plt.legend(title='Switch From', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Rotate x-labels for better readability\n",
    "plt.xticks( ha='right')\n",
    "\n",
    "ax.legend( bbox_to_anchor=(0.5, 1.1), loc='upper center', ncol=len(normalized_df.columns), fontsize = 15)\n",
    "\n",
    "# Add labels on each stacked bar\n",
    "threshold = 3  # for example, only show numbers if the segment represents more than 5%\n",
    "\n",
    "# Adjust bar labeling\n",
    "cumulative_heights = [0] * len(normalized_df)\n",
    "\n",
    "for container in ax.containers:\n",
    "    for i, rect in enumerate(container):\n",
    "        height = rect.get_height()\n",
    "        x_pos = rect.get_x() + rect.get_width() / 2.\n",
    "        y_pos = cumulative_heights[i] + height / 2.\n",
    "        \n",
    "        cumulative_heights[i] += height  # Update the cumulative height\n",
    "        \n",
    "        # Only label if above the threshold and height is not zero\n",
    "        if height > threshold and height != 0:\n",
    "            ax.text(x_pos, y_pos, f\"{height:.1f}%\", ha='center', va='center', fontsize=18)\n",
    "            \n",
    "# ax.set_xticks(range(len(df.columns)))\n",
    "ax.set_xticklabels(['Caltrain','1Tempo BRT', 'Van Ness BRT',   'Central Subway','BART'], rotation=0, fontsize=18,ha='center')\n",
    "ax.set_xlabel(\"\")\n",
    "# ax.set_xticks([r + rect.get_width() / 2 for r in range(len(normalized_df))])  # Adjust the x-tick positions\n",
    "\n",
    "ax.xaxis.grid(False)\n",
    "# Adjust layout to fit everything nicely\n",
    "plt.tight_layout()\n",
    "plt.savefig('switch from.png', dpi=600)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08664af-df52-45b8-8ba7-43e35a749aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "project_name_mapping = {\n",
    "    \"AC - 1TEMPO\": \"1Tempo BRT\",\n",
    "    \"BA - Extension and Core project\": \"BART\",\n",
    "    \"CA - Electrification Project\": \"Caltrain\",\n",
    "    \"SF - Central Subway\": \"Central Subway\",\n",
    "    \"SF - Van Ness\": \"Van Ness BRT\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df['Project Tried'] = df['Project Tried'].replace(project_name_mapping)\n",
    "# Set overall aesthetics\n",
    "sns.set_context(\"talk\")\n",
    "sns.set(font_scale=1.2, style=\"whitegrid\")\n",
    "\n",
    "# Create 1x3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 7))\n",
    "\n",
    "# Variables to plot\n",
    "metrics = ['Diff Length', 'Diff Duration', 'Diff Potential INEXUS']\n",
    "projects = [\"Caltrain\", \"1Tempo BRT\", \"Van Ness BRT\", \"Central Subway\", \"BART\"]\n",
    "n_projects = len(projects)\n",
    "labels = ['Distance', 'Duration', 'INEXUS']\n",
    "\n",
    "mean_line_props = dict(linestyle='-', linewidth=2, color='red')\n",
    "median_line_props = dict(linestyle='-', linewidth=2, color='green')\n",
    "\n",
    "for i, (ax, metric) in enumerate(zip(axes, metrics)):\n",
    "    for j, project in enumerate(projects):\n",
    "        if metric == 'Diff Potential INEXUS':\n",
    "            subset = df[df['Project Tried'] == project]\n",
    "            ax.boxplot(subset[metric]*11.23, positions=[j], widths=0.5, patch_artist=True, showfliers=False, \n",
    "                       boxprops=dict(facecolor=sns.color_palette(\"pastel\")[j], alpha=0.6), \n",
    "                       whis=[10, 90],  # Display whiskers for 5th and 95th percentiles\n",
    "                       showmeans=True,  # Display the mean\n",
    "                       meanline=True,  # Show the mean as a line\n",
    "                       meanprops=mean_line_props,  # Custom properties for mean line\n",
    "                       medianprops=median_line_props)  # Custom properties for median line\n",
    "        else:\n",
    "            subset = df[df['Project Tried'] == project]\n",
    "            ax.boxplot(subset[metric], positions=[j], widths=0.5, patch_artist=True, showfliers=False, \n",
    "                       boxprops=dict(facecolor=sns.color_palette(\"pastel\")[j], alpha=0.6),\n",
    "                       whis=[10, 90],  # Display whiskers for 5th and 95th percentiles\n",
    "                       showmeans=True,  # Display the mean\n",
    "                       meanline=True,  # Show the mean as a line\n",
    "                       meanprops=mean_line_props,  # Custom properties for mean line\n",
    "                       medianprops=median_line_props)  # Custom properties for median line\n",
    "\n",
    "    \n",
    "    # Setting y-label for each subplot\n",
    "    if i ==0:\n",
    "        ax.set_ylabel(f'Absolute Change', fontsize=18)\n",
    "    \n",
    "    # X-axis settings\n",
    "    ax.set_xticks([n_projects/2])  # centering the metric name\n",
    "    ax.set_xticklabels([labels[i]], fontsize=18)  # using the first word of the metric name, and setting fontsize to 18\n",
    "    ax.xaxis.grid(False)  # <-- Set visible to False\n",
    "    ax.yaxis.grid(True, linestyle='--', which='major', color='gray', alpha=.25)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)  # setting the tick font size to 18\n",
    "\n",
    "# Global title\n",
    "# fig.suptitle('Absolute Change and Distribution from Baseline', fontsize=18, y=1.08)\n",
    "\n",
    "# Global legend within the plots, horizontally over the plots\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=sns.color_palette(\"pastel\")[i], edgecolor='gray', label=project) \n",
    "                   for i, project in enumerate(projects)]\n",
    "fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.02), ncol=len(projects), fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('column_plot_distribution.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a0f73-6f0c-4758-b0bc-ba3d0a0b9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Distance','Duration','INEXUS']\n",
    "metrics_bs = ['Trip Length Baseline','Trip Duration Baseline','Potential INEXUS Baseline']\n",
    "metrics_tr = ['Trip Length TR','Trip Duration TR','Potential INEXUS TR']\n",
    "labels = ['Distance', 'Duration', 'INEXUS']\n",
    "\n",
    "# Calculate percentage change for each metric and project\n",
    "percentage_changes = {}\n",
    "\n",
    "for mb, mt, m in zip(metrics_bs, metrics_tr, metrics):\n",
    "    percentage_changes[m] = []\n",
    "    for project in projects:\n",
    "\n",
    "        baseline_sum = df[df['Project Tried'] == project][mb].sum()\n",
    "        tr_sum = df[df['Project Tried'] == project][mt].sum()\n",
    "\n",
    "        change = 100 * (tr_sum - baseline_sum) / baseline_sum  # percentage change formula\n",
    "        percentage_changes[m].append(change)\n",
    "\n",
    "# Plotting\n",
    "# Assuming the percentage change for each metric and project is already calculated as per previous code in `percentage_changes`\n",
    "# We will adjust the plotting structure:\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 7))\n",
    "width = 0.15  # adjust as needed\n",
    "ind = np.arange(len(metrics))  # the x locations for the metrics\n",
    "\n",
    "# Loop to plot bars for each project under each metric\n",
    "for i, project in enumerate(projects):\n",
    "    \n",
    "    values = [percentage_changes[metric][i]  if metric != 'INEXUS' else -percentage_changes[metric][i] for metric in metrics ]\n",
    "\n",
    "\n",
    "    bars = ax.bar(ind + i*width, values, width, color=sns.color_palette(\"pastel\")[i], label=project, alpha=0.6)\n",
    "    \n",
    "    \n",
    "    # Adding values on top or below the bars based on value's sign\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height >= 0:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., 1.01*height, f'{height:.1f}%', \n",
    "                    ha='center', va='bottom', fontsize=18)\n",
    "        else:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., 1.05*height, f'{height:.1f}%', \n",
    "                    ha='center', va='top', fontsize=18)\n",
    "\n",
    "# Adjust x-axis labels and other aesthetics\n",
    "ax.set_ylabel('Percentage Change', fontsize=18)\n",
    "ax.set_xticks(ind + width * (len(projects) / 2))\n",
    "ax.set_xticklabels(labels, fontsize=18)\n",
    "# Put the legend inside the graph, the loc parameter can be adjusted to place the legend at a different position\n",
    "ax.legend(fontsize=18, loc='lower right')\n",
    "ax.grid(True, axis='y', linestyle='--', which='major', color='gray', alpha=.25)\n",
    "ax.set_ylim(-12, 12)# Adjust the upper limit as necessary\n",
    "plt.tight_layout()\n",
    "ax.xaxis.grid(False)\n",
    "plt.savefig('percentage_change_grouped3.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0970948-234b-482b-9dae-f335ee326035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample dataframe (replace this with your actual dataframe)\n",
    "# df = ...\n",
    "df = df[df['Person Race']!='American Indian and Alaska Native tribes specified; or American Indian or Alaska Native, not specified and no other races']\n",
    "# Compute the average income per project\n",
    "avg_income_per_project = df.groupby('Project Tried')['Person Income'].mean()\n",
    "\n",
    "# # Compute the proportion of each race per project\n",
    "race_proportions = df.groupby(['Project Tried', 'Person Race']).size().unstack().fillna(0)\n",
    "race_proportions_percentage = (race_proportions.divide(race_proportions.sum(axis=1), axis=0) * 100).fillna(0)\n",
    "race_proportions = race_proportions.divide(race_proportions.sum(axis=1), axis=0)\n",
    "print(avg_income_per_project)\n",
    "\n",
    "ordered_projects = ['Caltrain','1Tempo BRT', 'Van Ness BRT', 'Central Subway','BART']\n",
    "\n",
    "# Order the dataframes according to the specified order of projects\n",
    "avg_income_per_project = avg_income_per_project.loc[ordered_projects]\n",
    "race_proportions = race_proportions.loc[ordered_projects]\n",
    "race_proportions_percentage = race_proportions_percentage.loc[ordered_projects]\n",
    "\n",
    "\n",
    "\n",
    "# Compute the height of each segment of the bar\n",
    "segment_heights = race_proportions.multiply(avg_income_per_project, axis=0)\n",
    "\n",
    "# Light colors using the Pastel1 colormap\n",
    "colors = plt.cm.Pastel2.colors\n",
    "\n",
    "# Plotting\n",
    "ax = segment_heights.plot(kind='bar', stacked=True, figsize=(18, 7), color=colors)\n",
    "\n",
    "# Annotate the bars with the average income values\n",
    "for idx, value in enumerate(avg_income_per_project):\n",
    "    ax.text(idx, value, f'{value:,.0f}', ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "# Annotate with percentage values inside each sub-bar\n",
    "cum_heights = segment_heights.cumsum(axis=1)\n",
    "for col in race_proportions_percentage.columns:\n",
    "    for idx, value in enumerate(race_proportions_percentage[col]):\n",
    "        if value > 3:  # Only annotate if value is significant enough for visibility\n",
    "            height = cum_heights.at[segment_heights.index[idx], col] - 0.5 * segment_heights.at[segment_heights.index[idx], col]\n",
    "            ax.text(idx, height, f'{value:.0f}%', ha='center', va='center', fontsize=18, color='black')  # using black for visibility against light colors\n",
    "\n",
    "ax.set_ylabel('Average Person Income', fontsize = 16)\n",
    "# ax.set_title('Average Person Income by Project, Split by Race')\n",
    "\n",
    "# Replace x labels as specified\n",
    "x_labels = [\"Caltrain\", \"1Tempo BRT\", \"Van Ness BRT\", \"Central Subway\", \"BART\"]\n",
    "ax.set_xticks(range(len(x_labels)))\n",
    "ax.set_xticklabels(x_labels, rotation=0, ha=\"center\", fontsize = 18)\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "\n",
    "original_labels = ['Alaska Native alone', \n",
    "                   'American Indian alone', \n",
    "                   'Asian alone', \n",
    "                   'Black or African American alone', \n",
    "                   'White alone', \n",
    "                  'American Indian and Alaska Native tribes specified; or American Indian or Alaska Native, not specified and no other races', \n",
    "                  'Native Hawaiian and Other Pacific Islander alone',\n",
    "                   'Some Other Race alone'\n",
    "                  ]  # Assuming these are your original labels\n",
    "summarized_labels = ['Alaska Native', 'American Indian', 'Asian', \n",
    "                     'Black or African American', 'White', 'Other', 'Native Hawaiian', 'Other'\n",
    "                    ]  # Shorter labels\n",
    "overall_avg_income = df['Person Income'].mean()\n",
    "ax.axhline(y=overall_avg_income, color='black', linestyle='--', linewidth=2)\n",
    "def currency_formatter(x, pos):\n",
    "    return f\"${x:,.0f}\"\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(currency_formatter))\n",
    "\n",
    "legend_dict = dict(zip(original_labels, summarized_labels))\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels = [legend_dict[label] if label in legend_dict else label for label in labels]\n",
    "ax.legend(handles, new_labels, title='Race', fontsize=14, bbox_to_anchor=(0.30, 0.99), loc='upper center')\n",
    "ax.xaxis.grid(False)\n",
    "\n",
    "plt.savefig('income2.png', dpi=600, bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae1e5a-4b0e-4bd0-a799-7a3a3b44b645",
   "metadata": {},
   "outputs": [],
   "source": [
    " df['Person Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb7a80-e71f-438f-8d2f-2602fc448949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Sample dataframe (replace this with your actual dataframe)\n",
    "# df = ...\n",
    "df = df[df['Person Race']!='American Indian and Alaska Native tribes specified; or American Indian or Alaska Native, not specified and no other races']\n",
    "\n",
    "# Compute the average income per project\n",
    "avg_income_per_project = df.groupby('Project Tried')['Person Income'].mean()\n",
    "\n",
    "ordered_projects = ['Caltrain','1Tempo BRT', 'Van Ness BRT', 'Central Subway','BART']\n",
    "\n",
    "# Order the dataframes according to the specified order of projects\n",
    "avg_income_per_project = avg_income_per_project.loc[ordered_projects]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(18, 7))\n",
    "avg_income_per_project.plot(kind='bar', ax=ax, color='skyblue')\n",
    "\n",
    "# Annotate the bars with the average income values\n",
    "for idx, value in enumerate(avg_income_per_project):\n",
    "    ax.text(idx, value + 1000, f'${value:,.0f}', ha='center', va='bottom', fontsize=18) # adding +1000 for some space above the bar\n",
    "\n",
    "ax.set_ylabel('Average Person Income', fontsize=16)\n",
    "ax.set_title('Average Person Income by Project', fontsize=20)\n",
    "\n",
    "x_labels = [\"Caltrain\", \"1Tempo BRT\", \"Van Ness BRT\", \"Central Subway\", \"BART\"]\n",
    "ax.set_xticks(range(len(x_labels)))\n",
    "ax.set_xticklabels(x_labels, rotation=0, ha=\"center\", fontsize=18)\n",
    "\n",
    "overall_avg_income = df['Person Income'].mean()\n",
    "ax.axhline(y=overall_avg_income, color='black', linestyle='--', linewidth=2)\n",
    "\n",
    "def currency_formatter(x, pos):\n",
    "    return f\"${x:,.0f}\"\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(currency_formatter))\n",
    "ax.xaxis.grid(False)\n",
    "\n",
    "plt.savefig('income2.png', dpi=600, bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac88734-4e60-4128-94ec-2f93bfb015f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = df[df['Person Race']!='American Indian and Alaska Native tribes specified; or American Indian or Alaska Native, not specified and no other races']\n",
    "dfx = df[df['HS Income']>0]\n",
    "# Compute the average income per project\n",
    "# avg_income_per_project = dfx.groupby('Project Tried')['HS Income'].mean()\n",
    "avg_income_per_project_switch_test = dfx.pivot_table(values='HS Income', index='Project Tried', columns='Switch From', aggfunc='mean')\n",
    "\n",
    "\n",
    "ordered_projects = ['Caltrain','1Tempo BRT', 'Van Ness BRT', 'Central Subway','BART']\n",
    "\n",
    "# Order the dataframes according to the specified order of projects\n",
    "avg_income_per_project_switch_test = avg_income_per_project_switch_test.loc[ordered_projects]\n",
    "print(avg_income_per_project)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "# Bar width for grouped bars\n",
    "bar_width = 0.2\n",
    "switch_categories = df['Switch From'].unique()\n",
    "num_switches = len(switch_categories)\n",
    "positions = list(range(len(ordered_projects)))\n",
    "\n",
    "# Pastel1 palette\n",
    "colors = plt.cm.Pastel1(np.linspace(0, 1, num_switches))\n",
    "\n",
    "for index, (switch, color) in enumerate(zip(switch_categories, colors)):\n",
    "    switch_values = avg_income_per_project_switch_test[switch]\n",
    "    ax1.bar([pos + index * bar_width for pos in positions], switch_values, width=bar_width, label=switch, color=color)\n",
    "\n",
    "# Annotate bars with their values\n",
    "for index, project in enumerate(ordered_projects):\n",
    "    for switch_index, switch in enumerate(switch_categories):\n",
    "        value = avg_income_per_project_switch_test.at[project, switch]\n",
    "        ax1.text(index + switch_index * bar_width, value + 1000, f'${value:,.0f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Adjust x-axis to accommodate grouped bars\n",
    "ax1.set_xticks([pos + bar_width for pos in positions])\n",
    "ax1.set_xticklabels(ordered_projects, rotation=0, fontsize=10)\n",
    "\n",
    "# Overall average line, legend placement and formatting\n",
    "ax1.axhline(y=105854, color='gray', linestyle='--', linewidth=2)\n",
    "ax1.legend( loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=len(switch_categories))  # Adjusted these parameters\n",
    "ax1.set_ylabel('Average Household Income', fontsize=16)\n",
    "ax1.yaxis.set_major_formatter(FuncFormatter(currency_formatter))\n",
    "ax1.xaxis.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('average_income_grouped.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a72216-0f45-495b-a041-da805919a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_columns_for_switches(df, switch_categories):\n",
    "    for project in ordered_projects:\n",
    "        first, third = df.xs((project, switch_categories[0])), df.xs((project, switch_categories[2]))\n",
    "        df.loc[(project, switch_categories[0])], df.loc[(project, switch_categories[2])] = third.values, first.values\n",
    "    return df\n",
    "\n",
    "grouped_race_percentages = swap_columns_for_switches(grouped_race_percentages, df['Switch From'].unique())\n",
    "df = df[df['Person Race'] != 'American Indian and Alaska Native tribes specified; or American Indian or Alaska Native, not specified and no other races']\n",
    "\n",
    "avg_income_per_project = df.groupby('Project Tried')['Person Income'].mean().loc[ordered_projects]\n",
    "race_proportions_percentage = (df.groupby(['Project Tried', 'Person Race']).size().unstack().fillna(0).divide(df.groupby(['Project Tried', 'Person Race']).size().unstack().sum(axis=1), axis=0) * 100).loc[ordered_projects]\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "bar_width, switch_categories, positions = 0.2, df['Switch From'].unique(), list(range(len(ordered_projects)))\n",
    "\n",
    "def add_labels(data, ax, shift=0):\n",
    "    for idx, project in enumerate(ordered_projects):\n",
    "        cum_height = 0\n",
    "        for col_num, race in enumerate(data.columns):\n",
    "            value, y_position = data.loc[project, race], cum_height + 0.5 * data.loc[project, race]\n",
    "            if value > 5:\n",
    "                ax.text(idx + shift, y_position, f\"{value:.0f}%\", ha=\"center\", va=\"center\", fontsize=12, color='black')\n",
    "            cum_height += value\n",
    "\n",
    "for idx, project in enumerate(ordered_projects):\n",
    "    for switch_index, switch in enumerate(switch_categories):\n",
    "        ax2.text(idx + bar_width * (switch_index - 1) + bar_width / 2, 102, custom_titles.get(switch, switch), ha=\"center\", fontsize=12, fontweight='bold')\n",
    "\n",
    "for switch_index, switch in enumerate(switch_categories):\n",
    "    grouped_race_percentages.xs(switch, level='Switch From').reindex(ordered_projects).fillna(0).plot(kind='bar', stacked=True, ax=ax2, width=bar_width, color=colors, position=switch_index - 1)\n",
    "    add_labels(grouped_race_percentages.xs(switch, level='Switch From').reindex(ordered_projects).fillna(0), ax2, shift=bar_width * (switch_index - 1) + bar_width / 2)\n",
    "\n",
    "ax2.set_xlim(-1.5 * bar_width, len(ordered_projects) - 1.5 * bar_width)\n",
    "ax2.set_xticks(positions)\n",
    "ax2.set_xticklabels(ordered_projects, rotation=0, ha=\"center\", fontsize=13)\n",
    "ax2.legend(handles[:len(unique_labels)], [legend_dict[label] if label in legend_dict else label for label in grouped_race_proportions.columns], fontsize=12, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=4)\n",
    "ax2.yaxis.set_major_formatter(FuncFormatter(percent_formatter))\n",
    "ax2.set_xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('race_proportions_split_corrected.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34dc116-acc0-4d33-8629-d2fb112e2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Project Tried')\n",
    "\n",
    "vmt_baseline = grouped['Trip Length Baseline'].sum()\n",
    "vmt_TR = grouped['Trip Length TR'].sum()\n",
    "\n",
    "vht_baseline = grouped['Trip Duration Baseline'].sum()\n",
    "vht_TR = grouped['Trip Duration TR'].sum()\n",
    "\n",
    "plan_mode_baseline = grouped['Planned Mode Baseline'].value_counts()\n",
    "plan_mode_TR = grouped['Planned Mode TR'].value_counts()\n",
    "\n",
    "mode_baseline = grouped['Chosen Mode Baseline'].value_counts()\n",
    "mode_TR = grouped['Chosen Mode TR'].value_counts()\n",
    "\n",
    "inexus_baseline = grouped['Potential INEXUS Baseline'].sum()\n",
    "inexus_TR = grouped['Potential INEXUS TR'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eee987-b247-481e-b94b-ce459c56f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmt_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ad2c7-7d05-46cc-9bfd-7ab70f44c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmt_TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9b328-99a2-40ca-8a41-49e76859ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vht_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82c2df-93f4-427b-a139-d6a058c2b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "vht_TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719a323-1b80-4d4e-af1b-a667831eae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_mode_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc560a-8c24-40e0-9ddb-c0f8946e5996",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_mode_TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0df3b-529e-4f32-8a65-ed787c46c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d571a-9255-4d03-a466-5a5fb3ccff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a619949e-fa64-42d9-908f-7089187d5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inexus_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c602f-bf0a-469d-a8bf-8151227992c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inexus_TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da7147-c0cc-4c89-81f9-2d0b1e388219",
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = inexus_TR\n",
    "BS = inexus_baseline\n",
    "\n",
    "index_union = BS.index.union(TR.index)\n",
    "baseline_reindexed = BS.reindex(index_union, fill_value=0)\n",
    "TR_reindexed = TR.reindex(index_union, fill_value=0)\n",
    "\n",
    "# Calculate the difference between the two reindexed pivot tables\n",
    "difference_table = (TR_reindexed - baseline_reindexed)/(-baseline_reindexed)*100\n",
    "\n",
    "# The `difference_table` will contain the differences between the two original pivot tables.\n",
    "print(difference_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdce967-114f-44ba-9841-5f020e001c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = mode_TR\n",
    "BS = mode_baseline\n",
    "\n",
    "index_union = BS.index.union(TR.index)\n",
    "baseline_reindexed = BS.reindex(index_union, fill_value=0)\n",
    "TR_reindexed = TR.reindex(index_union, fill_value=0)\n",
    "\n",
    "# Calculate the difference between the two reindexed pivot tables\n",
    "difference_table = TR_reindexed - baseline_reindexed \n",
    "\n",
    "# The `difference_table` will contain the differences between the two original pivot tables.\n",
    "print(difference_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c342e08-1e76-4ed0-baf0-c9343792741c",
   "metadata": {},
   "source": [
    "# ***EVENTS STATS PUBLIC TRANSIT***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326df7b-a739-4ec5-bc2c-d68d168e2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Events = pd.read_csv(Dir_beam+'/0.events.csv.gz', nrows = None, \n",
    "                     usecols=['type', 'numPassengers', 'capacity', 'mode', 'vehicle', 'length', 'duration','arrivalTime','departureTime', 'primaryFuel', 'secondaryFuel']\n",
    "                    )\n",
    "Events = Events[(Events['type']=='PathTraversal')&(Events['mode'].isin(['bus','tram','subway','cable_car','rail', 'ferry']))]\n",
    "agencies = []\n",
    "\n",
    "for vehicle in Events['vehicle']:\n",
    "    agencies.append(vehicle.split(':')[0])\n",
    "Events['agency'] = agencies\n",
    "\n",
    "vehicle_to_routes = pd.read_csv('outputs/routetovehicledictBaseline2018.csv')\n",
    "vehicle_to_routes = vehicle_to_routes.set_index('trip_id')['route_id'].to_dict()\n",
    "Events['route_id'] = Events['vehicle'].map(vehicle_to_routes)\n",
    "print(len(Events))\n",
    "Events = Events[(~Events['route_id'].str.contains('BA:19'))]\n",
    "print(len(Events))\n",
    "\n",
    "\n",
    "Events['numPassengers'] = Events['numPassengers']/3*10\n",
    "Events['capacity'] = Events['capacity']/3*10\n",
    "\n",
    "Events['numPassengers'] = Events['numPassengers'].astype(int)\n",
    "Events['capacity'] = Events['capacity'].astype(int)\n",
    "\n",
    "# Events = Events.dropna(axis=1, how='all')\n",
    "transit_agencies = {\n",
    "    'AC': 'Alameda-Contra Costa Transit District (AC Transit)',\n",
    "    # 'AM': 'Capitol Corridor',    \n",
    "    # 'AY': 'American Canyon Transit',\n",
    "    'BA': 'BART',\n",
    "    # 'CC': 'County Connection (Central Contra Costa Transit Authority)',\n",
    "    # 'CE': 'ACE Altamont Corridor Express',\n",
    "    # 'CM': 'San Mateo County Transit',\n",
    "    # 'DE': 'Dumbarton Express',\n",
    "    # 'EM': 'Emery Go-Round',\n",
    "    # 'FF': 'Fairfield and Suisun Transit (FAST)',\n",
    "    # 'GG': 'Golden Gate Transit',\n",
    "    # 'HF': 'Alcatraz Hornblower Ferry',\n",
    "    # 'MA': 'Marin Transit',\n",
    "    # 'SB': 'San Francisco Bay Ferry',\n",
    "    # 'SC': 'Santa Cruz Metro',\n",
    "    'SF': 'San Francisco Municipal Transportation Agency (SFMTA)',\n",
    "    # 'SL': 'SolTrans',\n",
    "    # 'SM': 'Stanford Marguerite Shuttle',\n",
    "    # 'SO': 'Sonoma County Transit',\n",
    "    # 'SR': 'Santa Rosa CityBus',\n",
    "    # 'ST': 'SamTrans',\n",
    "    # 'TD': 'Tri Delta Transit',\n",
    "    # 'VC': 'Vacaville City Coach',\n",
    "    # 'VN': 'Vine Transit (Napa County)',\n",
    "    # 'VT': 'Santa Clara Valley Transportation Authority (VTA)',\n",
    "    # 'WH': 'Livermore Amador Valley Transit Authority',\n",
    "    'caltrain-ca-us': 'Caltrain',\n",
    "    # 'petalumatransit-petaluma-ca-us': 'Petaluma Transit',\n",
    "    # 'riovista-ca-us': 'Rio Vista Delta Breeze',\n",
    "    # 'unioncity-ca-us': 'Union City Transit',\n",
    "    # 'westcat-ca-us': 'Western Contra Costa Transit Authority (WestCAT)'\n",
    "}\n",
    "\n",
    "vehicle_ids = {\n",
    "    'SF:12327':'Line 49 Van Ness/Mission' ,\n",
    "    'AC:1-142':'1 AC' ,\n",
    "    # 'CA:12867':'Caltrain Bullet, Baby Bullet' ,\n",
    "    # 'CA:12867':'Caltrain Limitd' ,\n",
    "    # 'CA:12867':'Caltrain Local' ,\n",
    "    'SF:12475':'Muni Metro J' ,\n",
    "    'SF:12476':'Muni Metro K/T' ,\n",
    "    'SF:12311':'LINE 30 Stockton' ,\n",
    "    # 'SF:1106':'Muni Metro T' ,\n",
    "    # 'SF:1102':'Muni Metro K' ,\n",
    "    'SF:12477':'Muni Metro L' ,\n",
    "    'SF:12478':'Muni Metro M' ,\n",
    "    'SF:12479':'Muni Metro N' ,\n",
    "    'BA:1':'BA Yellow' ,\n",
    "    # 'BA:2':'BA Yellow 2',\n",
    "    'BA:3':'BA Orange',\n",
    "    # 'BA:4':'BA Orange 4',\n",
    "    'BA:5':'BA Green',\n",
    "    # 'BA:6':'BA Green 6',\n",
    "    'BA:7':'BA Red',\n",
    "    # 'BA:8':'BA Red 8',\n",
    "    # 'BA:10':'BA Blue',\n",
    "    'BA:11':'BA Blue',\n",
    "    ':':'All',\n",
    "}\n",
    "n_trips = []\n",
    "names = []\n",
    "pass_kms =  []\n",
    "supp_kms =  []\n",
    "modes = []\n",
    "lengths = []\n",
    "pass_durations = []\n",
    "energies = []\n",
    "durations = []\n",
    "\n",
    "for agency in transit_agencies.keys():\n",
    "    names.append(transit_agencies[agency])\n",
    "    events_agency = Events[Events['agency']==agency]\n",
    "    n_trips.append(len(events_agency['vehicle'].value_counts()))\n",
    "    pass_kms.append((events_agency['numPassengers'] * events_agency['length']).sum())\n",
    "    supp_kms.append((events_agency['capacity'] * events_agency['length']).sum())\n",
    "    modes.append(list(np.unique(events_agency['mode'])))\n",
    "    lengths.append(int(np.sum(events_agency['length'])))\n",
    "    pass_durations.append((events_agency['numPassengers'] *(events_agency['arrivalTime'] - events_agency['departureTime'])).sum())\n",
    "    energies.append((events_agency['primaryFuel'] + events_agency['secondaryFuel']).sum())\n",
    "    durations.append((events_agency['arrivalTime'] - events_agency['departureTime']).sum())\n",
    "    \n",
    "for route in vehicle_ids.keys():\n",
    "    names.append(vehicle_ids[route])\n",
    "    if route != ':':\n",
    "        events_route = Events[Events['route_id']==route]\n",
    "    else:\n",
    "        events_route = Events    \n",
    "    n_trips.append(len(events_route['vehicle'].value_counts()))\n",
    "    pass_kms.append((events_route['numPassengers'] * events_route['length']).sum())\n",
    "    supp_kms.append((events_route['capacity'] * events_route['length']).sum())\n",
    "    modes.append(list(np.unique(events_route['mode'])))\n",
    "    lengths.append(int(np.sum(events_route['length'])))\n",
    "    pass_durations.append((events_route['numPassengers'] *(events_route['arrivalTime'] - events_route['departureTime'])).sum())\n",
    "    energies.append((events_route['primaryFuel'] + events_route['secondaryFuel']).sum())\n",
    "    durations.append((events_route['arrivalTime'] - events_route['departureTime']).sum())\n",
    "    \n",
    "Events = pd.read_csv(Dir_beam_TR+'/0.events.csv.gz', nrows = None, \n",
    "                     usecols=['type', 'numPassengers', 'capacity', 'mode', 'vehicle', 'length', 'duration','arrivalTime','departureTime', 'primaryFuel', 'secondaryFuel']\n",
    "                    )\n",
    "Events = Events[(Events['type']=='PathTraversal')&(Events['mode'].isin(['bus','tram','subway','cable_car','rail', 'ferry']))]\n",
    "agencies = []\n",
    "\n",
    "vehicle_to_routes = pd.read_csv('outputs/routetovehicledictFuture2018.csv')\n",
    "vehicle_to_routes = vehicle_to_routes.set_index('trip_id')['route_id'].to_dict()\n",
    "Events['route_id'] = Events['vehicle'].map(vehicle_to_routes)\n",
    "\n",
    "for vehicle in Events['vehicle']:\n",
    "    agencies.append(vehicle.split(':')[0])\n",
    "Events['agency'] = agencies\n",
    "\n",
    "Events['numPassengers'] = Events['numPassengers']/3*10\n",
    "Events['capacity'] = Events['capacity']/3*10\n",
    "\n",
    "Events['numPassengers'] = Events['numPassengers'].astype(int)\n",
    "Events['capacity'] = Events['capacity'].astype(int)\n",
    "\n",
    "transit_agencies = {\n",
    "    'AC': 'Alameda-Contra Costa Transit District (AC Transit) - TR',\n",
    "    # 'AM': 'Capitol Corridor',    \n",
    "    # 'AY': 'American Canyon Transit',\n",
    "    'BA': 'BART - TR',\n",
    "    # 'CC': 'County Connection (Central Contra Costa Transit Authority)',\n",
    "    # 'CE': 'ACE Altamont Corridor Express',\n",
    "    # 'CM': 'San Mateo County Transit',\n",
    "    # 'DE': 'Dumbarton Express',\n",
    "    # 'EM': 'Emery Go-Round',\n",
    "    # 'FF': 'Fairfield and Suisun Transit (FAST)',\n",
    "    # 'GG': 'Golden Gate Transit',\n",
    "    # 'HF': 'Alcatraz Hornblower Ferry',\n",
    "    # 'MA': 'Marin Transit',\n",
    "    # 'SB': 'San Francisco Bay Ferry',\n",
    "    # 'SC': 'Santa Cruz Metro',\n",
    "    'SF': 'San Francisco Municipal Transportation Agency (SFMTA) - TR',\n",
    "    # 'SL': 'SolTrans',\n",
    "    # 'SM': 'Stanford Marguerite Shuttle',\n",
    "    # 'SO': 'Sonoma County Transit',\n",
    "    # 'SR': 'Santa Rosa CityBus',\n",
    "    # 'ST': 'SamTrans',\n",
    "    # 'TD': 'Tri Delta Transit',\n",
    "    # 'VC': 'Vacaville City Coach',\n",
    "    # 'VN': 'Vine Transit (Napa County)',\n",
    "    # 'VT': 'Santa Clara Valley Transportation Authority (VTA)',\n",
    "    # 'WH': 'Livermore Amador Valley Transit Authority',\n",
    "    'Caltrain': 'Caltrain - TR',\n",
    "    # 'petalumatransit-petaluma-ca-us': 'Petaluma Transit',\n",
    "    # 'riovista-ca-us': 'Rio Vista Delta Breeze',\n",
    "    # 'unioncity-ca-us': 'Union City Transit',\n",
    "    # 'westcat-ca-us': 'Western Contra Costa Transit Authority (WestCAT)'\n",
    "}\n",
    "\n",
    "vehicle_ids = {\n",
    "    'SF:18608':'Line 49 Van Ness/Mission - TR' ,\n",
    "    'AC:1T-142':'1Tempo AC' ,\n",
    "    # 'CA:12867':'Caltrain Bullet, Baby Bullet - TR' ,\n",
    "    # 'CA:12867':'Caltrain Limited - TR' ,\n",
    "    #  'CA:12867':'Caltrain Local - TR',\n",
    "    'SF:12475':'Muni Metro J - TR' ,\n",
    "    'SF:1001':'Muni Metro T - TR' ,\n",
    "    'SF:1002':'Muni Metro K - TR' ,\n",
    "    'SF:12311':'LINE 30 Stockton - TR' ,\n",
    "    'SF:12477':'Muni Metro L - TR' ,\n",
    "    'SF:12478':'Muni Metro M - TR' ,\n",
    "    'SF:12479':'Muni Metro N - TR' ,\n",
    "    'BA:1':'BA Yellow 1 - TR' ,\n",
    "    'BA:2':'BA Yellow 2 - TR',\n",
    "    'BA:3':'BA Orange 3 - TR',\n",
    "    'BA:4':'BA Orange 4 - TR',\n",
    "    'BA:5':'BA Green 5 - TR',\n",
    "    'BA:6':'BA Green 6 - TR',\n",
    "    'BA:7':'BA Red 7 - TR',\n",
    "    'BA:8':'BA Red 8 - TR',\n",
    "    'BA:11':'BA Blue 11 - TR',\n",
    "    'BA:12':'BA Blue 12 - TR',\n",
    "    ':':'All - TR',\n",
    "}\n",
    "\n",
    "for agency in transit_agencies.keys():\n",
    "    names.append(transit_agencies[agency])\n",
    "    events_agency = Events[Events['agency']==agency]\n",
    "    n_trips.append(len(events_agency['vehicle'].value_counts()))\n",
    "    pass_kms.append((events_agency['numPassengers'] * events_agency['length']).sum())\n",
    "    supp_kms.append((events_agency['capacity'] * events_agency['length']).sum())\n",
    "    modes.append(list(np.unique(events_agency['mode'])))\n",
    "    lengths.append(int(np.sum(events_agency['length'])))\n",
    "    pass_durations.append((events_agency['numPassengers'] *(events_agency['arrivalTime'] - events_agency['departureTime'])).sum())\n",
    "    energies.append((events_agency['primaryFuel'] + events_agency['secondaryFuel']).sum())\n",
    "    durations.append((events_agency['arrivalTime'] - events_agency['departureTime']).sum())\n",
    "\n",
    "for route in vehicle_ids.keys():\n",
    "    names.append(vehicle_ids[route])\n",
    "    if route != ':':\n",
    "        events_route = Events[Events['route_id']==route]\n",
    "    else:\n",
    "        events_route = Events\n",
    "    n_trips.append(len(events_route['vehicle'].value_counts()))\n",
    "    pass_kms.append((events_route['numPassengers'] * events_route['length']).sum())\n",
    "    supp_kms.append((events_route['capacity'] * events_route['length']).sum())\n",
    "    modes.append(list(np.unique(events_route['mode'])))\n",
    "    lengths.append(int(np.sum(events_route['length'])))\n",
    "    pass_durations.append((events_route['numPassengers'] *(events_route['arrivalTime'] - events_route['departureTime'])).sum())\n",
    "    energies.append((events_route['primaryFuel'] + events_route['secondaryFuel']).sum())\n",
    "    durations.append((events_route['arrivalTime'] - events_route['departureTime']).sum())\n",
    "    \n",
    "Table = pd.DataFrame()\n",
    "Table.index = names\n",
    "Table['Number of Trips per Direction'] = n_trips\n",
    "Table['VMT km M'] = np.array(lengths)/1000000\n",
    "Table['VHT km M'] = np.array(durations)/1000000\n",
    "Table['PHT M'] = np.array(pass_durations)/1000000000\n",
    "# Table['Energy GJ'] = np.array(energies)/1000000000\n",
    "Table['RPK km M'] = np.array(pass_kms)/1000000000\n",
    "Table['ASK km M'] = np.array(supp_kms)/1000000000\n",
    "# Table['Modes'] = modes\n",
    "\n",
    "# Table.loc['BART'] = Table.loc['BA Yellow'] + Table.loc['BA Green'] + Table.loc['BA Red'] + Table.loc['BA Blue'] + Table.loc['BA Orange']\n",
    "Table.loc['BA Blue - TR'] = Table.loc['BA Blue 11 - TR'] + Table.loc['BA Blue 12 - TR']\n",
    "Table.loc['BA Yellow - TR'] = Table.loc['BA Yellow 1 - TR'] + Table.loc['BA Yellow 2 - TR']\n",
    "Table.loc['BA Orange - TR'] = Table.loc['BA Orange 3 - TR'] + Table.loc['BA Orange 4 - TR']\n",
    "Table.loc['BA Green - TR'] = Table.loc['BA Green 5 - TR'] + Table.loc['BA Green 6 - TR']\n",
    "Table.loc['BA Red - TR'] = Table.loc['BA Red 7 - TR'] + Table.loc['BA Red 8 - TR']\n",
    "# Table.loc['Caltrain'] = Table.loc['Caltrain Bullet, Baby Bullet'] + Table.loc['Caltrain Limited'] + Table.loc['Caltrain Local']\n",
    "# Table.loc['Caltrain - TR'] = Table.loc['Caltrain Bullet, Baby Bullet - TR'] + Table.loc['Caltrain Limited - TR'] + Table.loc['Caltrain Local - TR']\n",
    "Table.loc['BA-CA-SF-AC'] = Table.loc['Caltrain'] + Table.loc['BART'] +Table.loc['Alameda-Contra Costa Transit District (AC Transit)'] + Table.loc['San Francisco Municipal Transportation Agency (SFMTA)']\n",
    "Table.loc['BA-CA-SF-AC - TR'] = Table.loc['Caltrain - TR'] + Table.loc['BART - TR'] +Table.loc['Alameda-Contra Costa Transit District (AC Transit) - TR'] + Table.loc['San Francisco Municipal Transportation Agency (SFMTA) - TR']\n",
    "Table.loc['Other'] = Table.loc['All'] - Table.loc['BA-CA-SF-AC'] \n",
    "Table.loc['Other - TR'] = Table.loc['All - TR'] - Table.loc['BA-CA-SF-AC - TR'] \n",
    "Table.loc['Muni Metro K/T - TR'] = Table.loc['Muni Metro K - TR'] + Table.loc['Muni Metro T - TR'] \n",
    "Table.loc['Muni Metro'] = Table.loc['Muni Metro K/T'] + Table.loc['Muni Metro J']  + Table.loc['Muni Metro L']  + Table.loc['Muni Metro M']  + Table.loc['Muni Metro N'] \n",
    "Table.loc['Muni Metro - TR'] = Table.loc['Muni Metro K/T - TR'] + Table.loc['Muni Metro J - TR']  + Table.loc['Muni Metro L - TR']  + Table.loc['Muni Metro M - TR']  + Table.loc['Muni Metro N - TR'] \n",
    "\n",
    "Table['AV Load Factor'] = Table['RPK km M']/Table['ASK km M']\n",
    "Table['AV Speed vehicles km/h'] = Table['VMT km M']/Table['VHT km M']\n",
    "Table['AV Speed pass km/h'] = Table['RPK km M']/Table['PHT M']\n",
    "\n",
    "Table = Table.drop('BA Yellow 1 - TR')\n",
    "Table = Table.drop('BA Yellow 2 - TR')\n",
    "Table = Table.drop('BA Orange 3 - TR')\n",
    "Table = Table.drop('BA Orange 4 - TR')\n",
    "Table = Table.drop('BA Green 5 - TR')\n",
    "Table = Table.drop('BA Green 6 - TR')\n",
    "Table = Table.drop('BA Red 7 - TR')\n",
    "Table = Table.drop('BA Red 8 - TR')\n",
    "Table = Table.drop('BA Blue 12 - TR')\n",
    "Table = Table.drop('BA Blue 11 - TR')\n",
    "# Table = Table.drop('Caltrain Bullet, Baby Bullet - TR')\n",
    "# Table = Table.drop('Caltrain Limited - TR')\n",
    "# Table = Table.drop('Caltrain Local - TR')\n",
    "# Table = Table.drop('Caltrain Bullet, Baby Bullet')\n",
    "# Table = Table.drop('Caltrain Limited')\n",
    "# Table = Table.drop('Caltrain Local')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500bc80d-f728-4400-971e-36126704f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c94ae-152e-4419-bb8b-ca72786a9ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RR = pd.read_csv('outputs/route_ridershipNewit5.csv', index_col = 0)\n",
    "RR = RR[(~RR.index.str.contains('BA:19'))]\n",
    "\n",
    "columns = ['AG', 'Line', 'Case', 'Ridership', '# Trips', 'VMT [M km]', 'VHT [M h]', \n",
    "           'RPK [M km]', 'PHT [M h]', 'ASK [M km]', 'Load Factor', \n",
    "           'Av Sp. Veh. [km/h]', 'Av Sp. Pas. [km/h]' ]\n",
    "\n",
    "agencies =  ['CA', 'CA', \n",
    "             'AC', 'AC', 'AC', 'AC',\n",
    "             'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA', 'BA',\n",
    "             'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF', 'SF',  \n",
    "             'All', 'All', 'BA-CA-SF-AC', 'BA-CA-SF-AC', 'Other','Other'\n",
    "            ]\n",
    "lines = ['All', 'All',\n",
    "         'All', 'All', '1', '1T',\n",
    "         'All', 'All', 'Blue', 'Blue', 'Green', 'Green', 'Orange', 'Orange', 'Red', 'Red', 'Yellow', 'Yellow',\n",
    "         'All', 'All', '49', '49', 'K/T', 'K/T', 'K', 'T', 'J', 'J', 'L', 'L', 'M', 'M', 'N', 'N', 'Metro', 'Metro',\n",
    "          'All', 'All','BA-CA-SF-AC', 'BA-CA-SF-AC', 'Other','Other'\n",
    "        ]\n",
    "cases = ['BAU', 'TR', \n",
    "         'BAU', 'TR', 'BAU', 'TR', \n",
    "         'BAU', 'TR', 'BAU', 'TR', 'BAU', 'TR', 'BAU', 'TR', 'BAU', 'TR', 'BAU', 'TR', \n",
    "         'BAU', 'TR', 'BAU', 'TR', 'BAU', 'TR', 'TR', 'TR', 'BAU', 'TR', 'BAU', 'TR', 'BAU', 'TR', 'BAU', 'TR', 'BAU', 'TR'\n",
    "         , 'BAU', 'TR', 'BAU', 'TR','BAU', 'TR'\n",
    "        ]\n",
    "         \n",
    "rrs = [['CA:'], ['CA:'],\n",
    "      ['AC:'], ['AC:'], ['AC:1-142'], ['AC:1T-142'],\n",
    "      ['BA:'], ['BA:'], ['BA:11'], ['BA:11', 'BA:12'], ['BA:5'], ['BA:5', 'BA:6'], ['BA:3'], ['BA:3', 'BA:4'], ['BA:7'], ['BA:7', 'BA:8'], ['BA:1'], ['BA:1', 'BA:2'],\n",
    "      ['SF:'], ['SF:'], ['SF:12327'], ['SF:18608'], ['SF:12476'], ['SF:1001','SF:1002'], \n",
    "       ['SF:1002'], ['SF:1001'], ['SF:12475'], ['SF:12475'], ['SF:12477'], ['SF:12477'], \n",
    "       ['SF:12478'], ['SF:12478'], ['SF:12479'], ['SF:12479'], \n",
    "       ['SF:12476','SF:12475','SF:12477','SF:12478','SF:12479'], \n",
    "       ['SF:1002','SF:1001','SF:12475','SF:12477','SF:12478','SF:12479'],\n",
    "      [':'], [':'], ['SF:','AC:' ,'BA:' ,'CA:' ], ['SF:','AC:' ,'BA:' ,'CA:'], \n",
    "      ['AM:','AY:','CC:','CE:','CM:','DE:','EM:','FF:','GG:','HF:','MA:','PE:','RV:', 'SB:','SC:','SL:','SM:','SO:','SR:','ST:','TD:','UC:','VC:','VN:','VT:','WC:','WH:'],\n",
    "      ['AM:','AY:','CC:','CE:','CM:','DE:','EM:','FF:','GG:','HF:','MA:','PE:','RV:', 'SB:','SC:','SL:','SM:','SO:','SR:','ST:','TD:','UC:','VC:','VN:','VT:','WC:','WH:']]\n",
    "\n",
    "is_contains = [True, True,\n",
    "      True, True, True, True,\n",
    "      True, True, False, False, False, False, False, False, False, False, False, False, \n",
    "      True, True, False, False, False, False, \n",
    "       False, False, False, False, False, False, \n",
    "       False, False, False, False,  \n",
    "       False,  \n",
    "       False, \n",
    "      True, True, True, True, \n",
    "      True,\n",
    "      True]\n",
    "\n",
    "Table_names = ['Caltrain', 'Caltrain - TR',\n",
    "      'Alameda-Contra Costa Transit District (AC Transit)', 'Alameda-Contra Costa Transit District (AC Transit) - TR', '1 AC', '1Tempo AC',\n",
    "      'BART', 'BART - TR', 'BA Blue', 'BA Blue - TR', 'BA Green', 'BA Green - TR', 'BA Orange', 'BA Orange - TR', 'BA Red', 'BA Red - TR', 'BA Yellow', 'BA Yellow - TR',\n",
    "      'San Francisco Municipal Transportation Agency (SFMTA)', 'San Francisco Municipal Transportation Agency (SFMTA) - TR', \n",
    "               'Line 49 Van Ness/Mission', 'Line 49 Van Ness/Mission - TR', 'Muni Metro K/T', 'Muni Metro K/T - TR', 'Muni Metro K - TR', 'Muni Metro T - TR', 'Muni Metro J', 'Muni Metro J - TR', 'Muni Metro L', 'Muni Metro L - TR', 'Muni Metro M', 'Muni Metro M - TR', 'Muni Metro N', 'Muni Metro N - TR', \n",
    "               'Muni Metro', 'Muni Metro - TR',\n",
    "      'All', 'All - TR', 'BA-CA-SF-AC', 'BA-CA-SF-AC - TR', 'Other', 'Other - TR']\n",
    "               \n",
    "print(len(Table_names))              \n",
    "print(len(rrs))              \n",
    "print(len(cases))              \n",
    "print(len(lines))              \n",
    "print(len(agencies))              \n",
    "print(len(columns))              \n",
    "print(len(is_contains))              \n",
    "Table2 = pd.DataFrame(columns= columns)\n",
    "i=0        \n",
    "for agency, line, case, rr, Table_name, is_con in zip (agencies,\n",
    "                                               lines,\n",
    "                                               cases,\n",
    "                                               rrs,\n",
    "                                               Table_names, \n",
    "                                                       is_contains):\n",
    "    ridership = 0\n",
    "    for r in rr:\n",
    "        print(r)\n",
    "        if is_con:\n",
    "            if case =='BAU':\n",
    "                ridership+= RR[RR.index.str.contains(r)]['Baseline2018'].sum()      \n",
    "            elif case =='TR':\n",
    "                ridership+= RR[RR.index.str.contains(r)]['Future2018'].sum() \n",
    "        else:\n",
    "            if case =='BAU':\n",
    "                ridership+= RR[RR.index == r]['Baseline2018'].sum()      \n",
    "            elif case =='TR':\n",
    "                ridership+= RR[RR.index == r]['Future2018'].sum()\n",
    "        \n",
    "    Table2.loc[0+i] = [agency, line, # TU\n",
    "                 case, # TU \n",
    "                 int(ridership/Scale),\n",
    "                int(Table.loc[Table_name, 'Number of Trips per Direction']),\n",
    "                Table.loc[Table_name, 'VMT km M'],\n",
    "                Table.loc[Table_name, 'VHT km M'],\n",
    "                Table.loc[Table_name, 'RPK km M']/Scale,\n",
    "                Table.loc[Table_name, 'PHT M']/Scale,\n",
    "                Table.loc[Table_name, 'ASK km M']/Scale,\n",
    "                Table.loc[Table_name, 'AV Load Factor'],\n",
    "                Table.loc[Table_name, 'AV Speed vehicles km/h'],\n",
    "                Table.loc[Table_name, 'AV Speed pass km/h']]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc02085-7937-4346-b767-9091e905a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452489a-7d01-4306-abfb-f8d947d113fc",
   "metadata": {},
   "source": [
    "# ***Upgrade person file***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f9b7fa-48ab-440c-9f6a-7155a4212325",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('outputs/person_databaseTR-part1.csv')\n",
    "df2 =  pd.read_csv('outputs/person_databaseTR-part2.csv')\n",
    "df3 =   pd.read_csv('outputs/person_databaseTR-part3.csv')\n",
    "print(len(df1))\n",
    "print(len(df2))\n",
    "print(len(df3))\n",
    "# df1 = df1[(df1['Project Tried'] != 'AC - 1TEMPO')&(df1['Project Tried'] != 'SF - Central Subway')]\n",
    "# df2 = df2[df2['Project Tried']  == 'SF - Central Subway']\n",
    "# df3 = df3[df3['Project Tried']  == 'AC - 1TEMPO']\n",
    "\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "print(len(df))\n",
    "\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320292e4-42e8-42b7-b790-b054c27fa9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Project Tried'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afeedb0-c5f0-47a6-bae5-374af0342002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21960504-3436-476b-b9c3-6b9c0d83f18e",
   "metadata": {},
   "source": [
    "# ***Validation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76be6f-7e3d-4ce5-91de-f4600449140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFMTA = pd.read_excel('inputs/TransitData/SFMTA_2020_01_25.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72156851-f03c-42ab-b77d-2dd8ccf02d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFMTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32dee54-b45f-4c88-8ff3-098a4740ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFMTA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86e5bf-7b19-4b68-96ed-5d31282a9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFMTA = SFMTA[SFMTA['ROUTE_ALPHA'] == 'KLM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bacbc-1aef-4bf5-a72b-60a59313e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(SFMTA['Stop Name'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbaf7dc-035d-49ff-a92c-395dd9bd623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFMTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc932ee-edea-439d-adb4-4ac4ef3d42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('gs://beam-core-outputs/sfbay-baseline-20230526/inexus/sfbay_baseline_default-1.0_2020__20230526.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b1c1b8-3f6a-44f3-aba2-a642f40eafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_trips_baseline = pd.read_csv('gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/inexus/sfbay_baseline_default-1.0_2018__20230709.csv', compression = 'gzip', \n",
    "                                    usecols = ['logsum_trip_Potential_INEXUS']) #to Update\n",
    "person_trips_TR = pd.read_csv('gs://beam-core-outputs/sfbay-tr-30pct-20230716/inexus/sfbay_baseline_default-1.0_2018__20230716.csv', compression = 'gzip', \n",
    "                                    usecols = ['logsum_trip_Potential_INEXUS',]) #to Update\n",
    "# logsum_trip_Potential_INEXUS\n",
    "# destination_logsum_x\n",
    "# destination_logsum_y\n",
    "# logsum_tours_mode_AS_tours\n",
    "# workplace_location_logsum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1da8d5-2d19-43b2-b6d8-3e0c018bc0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_trips_baseline.logsum_trip_Potential_INEXUS.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90eb317-aa5d-4aac-b173-63a667f47611",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_trips_TR.logsum_trip_Potential_INEXUS.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca4d43-46c8-4eed-893f-3fb4c6947d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-person_trips_baseline.logsum_trip_Potential_INEXUS.sum()/person_trips_TR.logsum_trip_Potential_INEXUS.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e835de-286c-442b-becb-701320478b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e502fc05-7669-4a28-9978-47692363dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Potential INEXUS TR'].sum()-df['Potential INEXUS Baseline'].sum())/df['Potential INEXUS Baseline'].sum()*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9868808-64a9-45e8-a189-53eed57881e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum([0, 120, 120, 240, 360, 135, 135, 135, 135, 150, 150, 105, \n",
    "                 105, 105, 105, 90, 90,90, 90, 120, 120 ,120 ])/60)\n",
    "print(sum([0, 75, 75, 75, 75, 90, 90, 210, 210, 150, 150, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30])/60)\n",
    "print(sum([0, 120, 120, 120, 90, 90, 90, 90, 105, 105, \n",
    "                105, 105, 150, 150, 135, 135, 135, 135, 360, 240, 120, 120  ])/60)\n",
    "print(sum([0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30 , 150 ,150, 210, 210, 90, 90, 75, 75 ,75 ,75 ])/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8879907e-9701-497a-9059-488583a89ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \"source\": [\n",
    "    \"stops_tsb = [7876, 7877, 7878, 7879, 7397, 7359, 7360, 7361, 7362, 7363, 7364, 7365,\\n\",\n",
    "    \"                7390, 7391, 7392, 7393, 7346, 7344, 7342, 7394, 7395, 7396]\\n\",\n",
    "    \"tt_stops_tsb = [0, 120, 120, 240, 360, 135, 135, 135, 135, 150, 150, 105, \\n\",\n",
    "    \"                105, 105, 105, 90, 90,90, 90, 120, 120 ,120 ]\\n\",\n",
    "    \"\\n\",\n",
    "    \"stops_ksb = [7217, 6994, 6995, 6997, 6996, 6998, 6991, 6993, 6739, 7058, 7125, 6503,\\n\",\n",
    "    \"                7114, 5807, 5780, 5786, 5808, 5793, 5798, 5795, 5785, 5418]\\n\",\n",
    "    \"tt_stops_ksb = [0, 75, 75, 75, 75, 90, 90, 210, 210, 150, 150, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\\n\",\n",
    "    \"\\n\",\n",
    "    \"stops_tnb  = [7398, 7399, 7400, 7347, 7343, 7345, 7401, 7402, 7403, 7404, \\n\",\n",
    "    \"                 7352, 7353, 7354, 7355, 7356, 7357, 7358, 7166, 7879, 7878, 7877, 7876]\\n\",\n",
    "    \"tt_stops_tnb = [0, 120, 120, 120, 90, 90, 90, 90, 105, 105, \\n\",\n",
    "    \"                105, 105, 150, 150, 135, 135, 135, 135, 360, 240, 120, 120 ]\\n\",\n",
    "    \"\\n\",\n",
    "    \"stops_knb = [7778, 5784, 5794, 5797, 5787, 5788, 5809, 5779, 5806, 7113, 7109, 6898, \\n\",\n",
    "    \"                6740, 5730, 5728, 5726, 5419, 5727, 5417, 5731, 6992]\\n\",\n",
    "    \"tt_stops_knb = [0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30 , 150 ,150, 210, 210, 90, 90, 75, 75 ,75 ,75]\\n\","
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

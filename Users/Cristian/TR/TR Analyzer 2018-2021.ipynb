{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd03ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cpoliziani/opt/miniconda3/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import difflib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def  processEvents(dataFilepath_sim, nrows):\n",
    "    PTs = []\n",
    "    PEVs = []\n",
    "    print('read', dataFilepath_sim)\n",
    "    for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n",
    "        if sum((chunk['type'] == 'PathTraversal')) > 0:\n",
    "            chunk['vehicle'] = chunk['vehicle'].astype(str)\n",
    "            PT = chunk.loc[(chunk['type'] == 'PathTraversal') & (chunk['length'] > 0)].dropna(how='all', axis=1)\n",
    "            PT['departureTime'] = PT['departureTime'].astype(int)\n",
    "            PT['arrivalTime'] = PT['arrivalTime'].astype(int)\n",
    "\n",
    "            PTs.append(PT[['driver', 'vehicle', 'mode', 'length', 'startX', 'startY', 'endX', 'endY', 'vehicleType',\n",
    "                           'arrivalTime', 'departureTime', 'primaryFuel', 'primaryFuelType', 'secondaryFuel',\n",
    "                           'secondaryFuelType', 'numPassengers', 'riders','time']])\n",
    "            print(chunk.type.value_counts())\n",
    "            PEV = chunk.loc[(chunk.type == \"PersonEntersVehicle\") &\n",
    "                            ~(chunk['person'].apply(str).str.contains('Agent').fillna(False)) &\n",
    "                            ~(chunk['vehicle'].str.contains('body').fillna(False)), :].dropna(how='all', axis=1)\n",
    "            if ~PEV.empty:\n",
    "                PEV['time'] = PEV['time'].astype(int)\n",
    "                PEVs.append(PEV)\n",
    "\n",
    "    Events_file_sim_PT = pd.concat(PTs)[['vehicle','time','endY','endX','startY','startX','mode']]\n",
    "    Events_file_sim_PE = pd.concat(PEVs)[['vehicle','time',]]\n",
    "    print(Events_file_sim_PE)\n",
    "\n",
    "    return Events_file_sim_PT, Events_file_sim_PE\n",
    "\n",
    "\n",
    "\n",
    "#Filter transit trips\n",
    "def filter_transit(Events_file_sim_PT,Events_file_sim_PE):\n",
    "    print(Events_file_sim_PT['mode'].value_counts())\n",
    "    Events_file_sim_PT = Events_file_sim_PT[(Events_file_sim_PT['mode'] == 'bus')|\n",
    "                                            (Events_file_sim_PT['mode'] == 'tram')|\n",
    "                                            (Events_file_sim_PT['mode'] == 'subway')|\n",
    "                                            (Events_file_sim_PT['mode'] == 'cable_car')|\n",
    "                                            (Events_file_sim_PT['mode'] == 'ferry')|\n",
    "                                            (Events_file_sim_PT['mode'] == 'rail')]\n",
    "    print(Events_file_sim_PT['mode'].value_counts())\n",
    "    Events_file_sim_PE = Events_file_sim_PE[Events_file_sim_PE['vehicle'].isin(Events_file_sim_PT['vehicle'])]\n",
    "    \n",
    "    return Events_file_sim_PE\n",
    "\n",
    "def guess_agency(Events_file_sim_PE):\n",
    "\n",
    "    agencies = []\n",
    "    for vehicleID in Events_file_sim_PE['vehicle']:\n",
    "        agency = vehicleID.split(':')[0]\n",
    "        if agency == 'petalumatransit-petaluma-ca-us':\n",
    "            agencies.append('PE')\n",
    "        elif agency == 'westcat-ca-us':\n",
    "            agencies.append('WC')\n",
    "        elif agency == 'caltrain-ca-us':\n",
    "            agencies.append('CA')\n",
    "        elif agency == 'riovista-ca-us':\n",
    "            agencies.append('RV')\n",
    "        elif agency == 'unioncity-ca-us':\n",
    "            agencies.append('UC')\n",
    "        else:\n",
    "            if len(agency) == 2:\n",
    "                agencies.append(agency)\n",
    "            elif agency == 'Caltrain':\n",
    "                agencies.append('CA')\n",
    "            else:\n",
    "                print('Warning, this agency is not recognized:', agency)\n",
    "    Events_file_sim_PE['agency'] = agencies\n",
    "\n",
    "    print(np.unique(agencies))\n",
    "    \n",
    "    return Events_file_sim_PE\n",
    "\n",
    "def guess_route(Events_file_sim_PE, GTFS_filepaths):\n",
    "\n",
    "    GTFS_trip_files = {}\n",
    "\n",
    "    for GTFS_filepath, GTFS in zip(GTFS_filepaths,GTFSs):\n",
    "        GTFS_trip_files[GTFS] = pd.read_csv(GTFS_filepath+'trips.txt')\n",
    "\n",
    "    route_ids = []\n",
    "    total_routes = len(Events_file_sim_PE['vehicle'])\n",
    "    i = 0\n",
    "    time_start = time.time()\n",
    "    for vehicle, agency in zip(Events_file_sim_PE['vehicle'],Events_file_sim_PE['agency']):\n",
    "        i+=1\n",
    "        if i%10000 ==0:\n",
    "            print(i,'/',total_routes,'. Time = ', time.time()-time_start, '. Estimated remaining time:', (time.time()-time_start)/i*total_routes-(time.time()-time_start))\n",
    "        if agency == 'SM':\n",
    "            route_ids.append(agency+':'+str(list(GTFS_trip_files[agency]['route_id'][\n",
    "                GTFS_trip_files[agency]['trip_id'].astype(str)==\n",
    "                     str(vehicle).split(':')[1]+'|'\n",
    "                     +str(vehicle).split(':')[2]+':'\n",
    "                     +str(vehicle).split(':')[3]+'|'\n",
    "                     +str(vehicle).split(':')[4]+':'\n",
    "                     +str(vehicle).split(':')[5]+':'\n",
    "                     +str(vehicle).split(':')[6]])[0]))\n",
    "        else:\n",
    "#             print(list(GTFS_trip_files[agency]['route_id'][GTFS_trip_files[agency]['trip_id'].astype(str)==str(vehicle.split(':')[1])])[0])\n",
    "            try:\n",
    "                route_ids.append(agency+':'+str(list(GTFS_trip_files[agency]['route_id'][GTFS_trip_files[agency]['trip_id'].astype(str)==str(vehicle.split(':')[1])])[0]))\n",
    "            except:\n",
    "                print('Warning, trip non found for vehicle', vehicle)\n",
    "                route_ids.append('tripID not found')\n",
    "    #     elif agency == 'GG':\n",
    "    #         route_ids.append('GG:'+str(list(GTFS_trip_files[agency]['route_id'][GTFS_trip_files[agency]['trip_id']==vehicle.split(':')[1]])[0]))\n",
    "    #     elif agency == 'SF':\n",
    "    #         route_ids.append('SF:'+str(list(GTFS_trip_files[agency]['route_id'][GTFS_trip_files[agency]['trip_id']==vehicle.split(':')[1]])[0]))\n",
    "    Events_file_sim_PE['route_id'] = route_ids\n",
    "    \n",
    "    return Events_file_sim_PE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "# dataFilepath_sim = [\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#             ]\n",
    "\n",
    "                    \n",
    "# years = ['2018','2019','2020','2021']\n",
    "#####################################################################################\n",
    "dataFilepath_sim = [\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                's3://beam-outputs/pilates-outputs/sfbay-baseline-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "                's3://beam-outputs/pilates-outputs/test_49_3/beam/year-2018-iteration-3/ITERS/it.0/0.events.csv.gz',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "            ]\n",
    "\n",
    "                    \n",
    "years = ['2018']\n",
    "\n",
    "names = []\n",
    "for year in years:\n",
    "    names.append('Baseline'+year)\n",
    "    names.append('Future'+year)\n",
    "\n",
    "output_filepath = '/Users/cpoliziani/Downloads/Transit Rich/Results/'\n",
    "\n",
    "GTFS_filepath = '/Users/cpoliziani/Downloads/Data/TR/GTFS/r5-simple-no-local/'\n",
    "GTFS_filepath2 = '/Users/cpoliziani/Downloads/Data/TR/GTFS/r5-simple-no-local-TR-49/'\n",
    "\n",
    "RA_output = 'agency_ridershipNew3.csv'\n",
    "RR_output = 'route_ridershipNew3.csv'\n",
    "\n",
    "GTFSs = ['3D','AC','AM','AY','BA','CA','CC','CE','CM','CT','DE','EM','GG','HF','MA','PE','RV', 'SB',\n",
    "        'SC','SF','SM','SO','SR','ST','TD','UC','VC','VN','VT','WC','WH']\n",
    "\n",
    "GTFS_3D = GTFS_filepath+'3D/'\n",
    "GTFS_AC = GTFS_filepath+'AC/'\n",
    "GTFS_AM = GTFS_filepath+'AM/'\n",
    "GTFS_AY = GTFS_filepath+'AY/'\n",
    "GTFS_BA = GTFS_filepath+'BA/'\n",
    "GTFS_Caltrain = GTFS_filepath+'Caltrain/'\n",
    "GTFS_CC = GTFS_filepath+'CC/'\n",
    "GTFS_CE = GTFS_filepath+'CE/'\n",
    "GTFS_CM = GTFS_filepath+'CM/'\n",
    "GTFS_CT = GTFS_filepath+'CT/'\n",
    "GTFS_DE = GTFS_filepath+'DE/'\n",
    "GTFS_EM = GTFS_filepath+'EM/'\n",
    "GTFS_GG = GTFS_filepath+'GG/'\n",
    "GTFS_HF = GTFS_filepath+'HF/'\n",
    "GTFS_MA = GTFS_filepath+'MA/'\n",
    "GTFS_PE = GTFS_filepath+'PE/'\n",
    "GTFS_RV = GTFS_filepath+'RV/'\n",
    "GTFS_SB = GTFS_filepath+'SB/'\n",
    "GTFS_SC = GTFS_filepath+'SC/'\n",
    "GTFS_SF = GTFS_filepath+'SF/'\n",
    "GTFS_SM = GTFS_filepath+'SM/'\n",
    "GTFS_SO = GTFS_filepath+'SO/'\n",
    "GTFS_SR = GTFS_filepath+'SR/'\n",
    "GTFS_ST = GTFS_filepath+'ST/'\n",
    "GTFS_TD = GTFS_filepath+'TD/'\n",
    "GTFS_UC = GTFS_filepath+'UC/'\n",
    "GTFS_VC = GTFS_filepath+'VC/'\n",
    "GTFS_VN = GTFS_filepath+'VN/'\n",
    "GTFS_VT = GTFS_filepath+'VT/'\n",
    "GTFS_WC = GTFS_filepath+'WC/'\n",
    "GTFS_WH = GTFS_filepath+'WH/'\n",
    "\n",
    "\n",
    "GTFS_3D2 = GTFS_filepath2+'3D/'\n",
    "GTFS_AC2 = GTFS_filepath2+'AC/'\n",
    "GTFS_AM2 = GTFS_filepath2+'AM/'\n",
    "GTFS_AY2 = GTFS_filepath2+'AY/'\n",
    "GTFS_BA2 = GTFS_filepath2+'BA/'\n",
    "GTFS_Caltrain2 = GTFS_filepath2+'Caltrain/'\n",
    "GTFS_CC2 = GTFS_filepath2+'CC/'\n",
    "GTFS_CE2 = GTFS_filepath2+'CE/'\n",
    "GTFS_CM2 = GTFS_filepath2+'CM/'\n",
    "GTFS_CT2 = GTFS_filepath2+'CT/'\n",
    "GTFS_DE2 = GTFS_filepath2+'DE/'\n",
    "GTFS_EM2 = GTFS_filepath2+'EM/'\n",
    "GTFS_GG2 = GTFS_filepath2+'GG/'\n",
    "GTFS_HF2 = GTFS_filepath2+'HF/'\n",
    "GTFS_MA2 = GTFS_filepath2+'MA/'\n",
    "GTFS_PE2 = GTFS_filepath2+'PE/'\n",
    "GTFS_RV2 = GTFS_filepath2+'RV/'\n",
    "GTFS_SB2 = GTFS_filepath2+'SB/'\n",
    "GTFS_SC2 = GTFS_filepath2+'SC/'\n",
    "GTFS_SF2 = GTFS_filepath2+'SF/'\n",
    "GTFS_SM2 = GTFS_filepath2+'SM/'\n",
    "GTFS_SO2 = GTFS_filepath2+'SO/'\n",
    "GTFS_SR2 = GTFS_filepath2+'SR/'\n",
    "GTFS_ST2 = GTFS_filepath2+'ST/'\n",
    "GTFS_TD2 = GTFS_filepath2+'TD/'\n",
    "GTFS_UC2 = GTFS_filepath2+'UC/'\n",
    "GTFS_VC2 = GTFS_filepath2+'VC/'\n",
    "GTFS_VN2 = GTFS_filepath2+'VN/'\n",
    "GTFS_VT2 = GTFS_filepath2+'VT/'\n",
    "GTFS_WC2 = GTFS_filepath2+'WC/'\n",
    "GTFS_WH2 = GTFS_filepath2+'WH/'\n",
    "\n",
    "GTFS_baseline = [GTFS_3D,\n",
    "                    GTFS_AC,\n",
    "                    GTFS_AM,\n",
    "                    GTFS_AY,\n",
    "                    GTFS_BA,\n",
    "                    GTFS_Caltrain,\n",
    "                    GTFS_CC,\n",
    "                    GTFS_CE,\n",
    "                    GTFS_CM,\n",
    "                    GTFS_CT,\n",
    "                    GTFS_DE,\n",
    "                    GTFS_EM,\n",
    "                    GTFS_GG,\n",
    "                    GTFS_HF,\n",
    "                    GTFS_MA,\n",
    "                    GTFS_PE,\n",
    "                    GTFS_RV,\n",
    "                    GTFS_SB,\n",
    "                    GTFS_SC,\n",
    "                    GTFS_SF,\n",
    "                    GTFS_SM,\n",
    "                    GTFS_SO,\n",
    "                    GTFS_SR,\n",
    "                    GTFS_ST,\n",
    "                    GTFS_TD,\n",
    "                    GTFS_UC,\n",
    "                    GTFS_VC,\n",
    "                    GTFS_VN,\n",
    "                    GTFS_VT,\n",
    "                    GTFS_WC,\n",
    "                    GTFS_WH]\n",
    "\n",
    "GTFS_TR = [GTFS_3D2,\n",
    "                    GTFS_AC2,\n",
    "                    GTFS_AM2,\n",
    "                    GTFS_AY2,\n",
    "                    GTFS_BA2,\n",
    "                    GTFS_Caltrain2,\n",
    "                    GTFS_CC2,\n",
    "                    GTFS_CE2,\n",
    "                    GTFS_CM2,\n",
    "                    GTFS_CT2,\n",
    "                    GTFS_DE2,\n",
    "                    GTFS_EM2,\n",
    "                    GTFS_GG2,\n",
    "                    GTFS_HF2,\n",
    "                    GTFS_MA2,\n",
    "                    GTFS_PE2,\n",
    "                    GTFS_RV2,\n",
    "                    GTFS_SB2,\n",
    "                    GTFS_SC2,\n",
    "                    GTFS_SF2,\n",
    "                    GTFS_SM2,\n",
    "                    GTFS_SO2,\n",
    "                    GTFS_SR2,\n",
    "                    GTFS_ST2,\n",
    "                    GTFS_TD2,\n",
    "                    GTFS_UC2,\n",
    "                    GTFS_VC2,\n",
    "                    GTFS_VN2,\n",
    "                    GTFS_VT2,\n",
    "                    GTFS_WC2,\n",
    "                    GTFS_WH2]\n",
    "GTFS_filepaths = [GTFS_baseline, GTFS_TR,GTFS_baseline, GTFS_TR,GTFS_baseline, GTFS_TR,GTFS_baseline, GTFS_TR]\n",
    "\n",
    "\n",
    "\n",
    "nrows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f74de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate ridership\n",
      "read s3://beam-outputs/pilates-outputs/sfbay-baseline-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,13,15,16,17,19,20,21,22,29,35,37,39,41,42,43,44,46,47,51,52,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           355896\n",
      "PersonEntersVehicle     254363\n",
      "departure               183651\n",
      "PersonLeavesVehicle     134821\n",
      "ModeChoice              101597\n",
      "actend                  101533\n",
      "LeavingParkingEvent      79407\n",
      "actstart                 75088\n",
      "arrival                  75088\n",
      "PersonCost               66631\n",
      "ParkingEvent             60125\n",
      "TeleportationEvent        9433\n",
      "ReserveRideHail           2291\n",
      "Replanning                  64\n",
      "ChargingPlugInEvent          4\n",
      "RefuelSessionEvent           4\n",
      "ChargingPlugOutEvent         4\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal          375409\n",
      "PersonEntersVehicle    188683\n",
      "PersonLeavesVehicle    153238\n",
      "ModeChoice             119235\n",
      "actend                 118915\n",
      "departure              118915\n",
      "arrival                 92021\n",
      "actstart                92017\n",
      "LeavingParkingEvent     82265\n",
      "PersonCost              73897\n",
      "ParkingEvent            64421\n",
      "TeleportationEvent      17778\n",
      "ReserveRideHail          2959\n",
      "Replanning                247\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           371352\n",
      "PersonEntersVehicle     177833\n",
      "PersonLeavesVehicle     170840\n",
      "ModeChoice              109892\n",
      "departure               108884\n",
      "actend                  108884\n",
      "actstart                103726\n",
      "arrival                 103722\n",
      "PersonCost               78520\n",
      "LeavingParkingEvent      76580\n",
      "ParkingEvent             66546\n",
      "TeleportationEvent       19400\n",
      "ReserveRideHail           2866\n",
      "Replanning                 942\n",
      "ChargingPlugInEvent          7\n",
      "RefuelSessionEvent           3\n",
      "ChargingPlugOutEvent         3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           360538\n",
      "PersonEntersVehicle     179133\n",
      "PersonLeavesVehicle     167783\n",
      "ModeChoice              113911\n",
      "actend                  112886\n",
      "departure               112886\n",
      "arrival                 102941\n",
      "actstart                102941\n",
      "LeavingParkingEvent      78607\n",
      "PersonCost               77035\n",
      "ParkingEvent             65108\n",
      "TeleportationEvent       21051\n",
      "ReserveRideHail           4033\n",
      "Replanning                1129\n",
      "RefuelSessionEvent           7\n",
      "ChargingPlugOutEvent         7\n",
      "ChargingPlugInEvent          4\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           370499\n",
      "PersonLeavesVehicle     179405\n",
      "PersonEntersVehicle     169805\n",
      "arrival                 110870\n",
      "actstart                110870\n",
      "ModeChoice              104727\n",
      "actend                  103216\n",
      "departure               103205\n",
      "PersonCost               80093\n",
      "LeavingParkingEvent      73771\n",
      "ParkingEvent             66627\n",
      "TeleportationEvent       21761\n",
      "ReserveRideHail           3810\n",
      "Replanning                1330\n",
      "ChargingPlugInEvent          5\n",
      "RefuelSessionEvent           3\n",
      "ChargingPlugOutEvent         3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           400705\n",
      "PersonLeavesVehicle     191442\n",
      "PersonEntersVehicle     164402\n",
      "arrival                 111469\n",
      "actstart                111467\n",
      "ModeChoice               92121\n",
      "departure                91585\n",
      "actend                   91574\n",
      "PersonCost               82246\n",
      "LeavingParkingEvent      74131\n",
      "ParkingEvent             68161\n",
      "TeleportationEvent       15499\n",
      "ReserveRideHail           4438\n",
      "Replanning                 748\n",
      "RefuelSessionEvent           5\n",
      "ChargingPlugOutEvent         5\n",
      "ChargingPlugInEvent          2\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           395153\n",
      "PersonEntersVehicle     175031\n",
      "PersonLeavesVehicle     174877\n",
      "arrival                 101337\n",
      "actstart                101310\n",
      "ModeChoice              101114\n",
      "actend                  100854\n",
      "departure               100854\n",
      "PersonCost               80562\n",
      "LeavingParkingEvent      80165\n",
      "ParkingEvent             68312\n",
      "TeleportationEvent       14519\n",
      "ReserveRideHail           5625\n",
      "Replanning                 277\n",
      "ChargingPlugInEvent          4\n",
      "RefuelSessionEvent           3\n",
      "ChargingPlugOutEvent         3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           389098\n",
      "PersonEntersVehicle     175192\n",
      "PersonLeavesVehicle     172723\n",
      "ModeChoice              104194\n",
      "actend                  103080\n",
      "departure               103080\n",
      "actstart                100938\n",
      "arrival                 100912\n",
      "PersonCost               80675\n",
      "LeavingParkingEvent      80344\n",
      "ParkingEvent             69079\n",
      "TeleportationEvent       14597\n",
      "ReserveRideHail           5827\n",
      "Replanning                 252\n",
      "RefuelSessionEvent           3\n",
      "ChargingPlugOutEvent         3\n",
      "ChargingPlugInEvent          3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           387465\n",
      "PersonEntersVehicle     174840\n",
      "PersonLeavesVehicle     172339\n",
      "actend                  103768\n",
      "departure               103768\n",
      "ModeChoice              103134\n",
      "arrival                 102465\n",
      "actstart                102465\n",
      "LeavingParkingEvent      80719\n",
      "PersonCost               79245\n",
      "ParkingEvent             68683\n",
      "TeleportationEvent       15103\n",
      "ReserveRideHail           5798\n",
      "Replanning                 203\n",
      "RefuelSessionEvent           2\n",
      "ChargingPlugOutEvent         2\n",
      "ChargingPlugInEvent          1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           383346\n",
      "PersonEntersVehicle     175816\n",
      "PersonLeavesVehicle     171648\n",
      "ModeChoice              105965\n",
      "departure               105744\n",
      "actend                  105744\n",
      "actstart                101544\n",
      "arrival                 101542\n",
      "LeavingParkingEvent      79828\n",
      "PersonCost               79434\n",
      "ParkingEvent             68312\n",
      "TeleportationEvent       14724\n",
      "ReserveRideHail           6055\n",
      "Replanning                 288\n",
      "ChargingPlugInEvent          6\n",
      "RefuelSessionEvent           2\n",
      "ChargingPlugOutEvent         2\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           380421\n",
      "PersonEntersVehicle     175058\n",
      "PersonLeavesVehicle     172008\n",
      "ModeChoice              105279\n",
      "departure               104945\n",
      "actend                  104945\n",
      "arrival                 102146\n",
      "actstart                102146\n",
      "PersonCost               80763\n",
      "LeavingParkingEvent      80351\n",
      "ParkingEvent             70431\n",
      "TeleportationEvent       15855\n",
      "ReserveRideHail           5412\n",
      "Replanning                 228\n",
      "RefuelSessionEvent           5\n",
      "ChargingPlugOutEvent         5\n",
      "ChargingPlugInEvent          2\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           380431\n",
      "PersonLeavesVehicle     173197\n",
      "PersonEntersVehicle     172615\n",
      "ModeChoice              104905\n",
      "departure               104800\n",
      "actend                  104800\n",
      "arrival                 104537\n",
      "actstart                104523\n",
      "PersonCost               79804\n",
      "LeavingParkingEvent      78316\n",
      "ParkingEvent             69081\n",
      "TeleportationEvent       17119\n",
      "ReserveRideHail           5702\n",
      "Replanning                 166\n",
      "ChargingPlugInEvent          2\n",
      "RefuelSessionEvent           1\n",
      "ChargingPlugOutEvent         1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           379263\n",
      "PersonEntersVehicle     171411\n",
      "PersonLeavesVehicle     169973\n",
      "ModeChoice              107439\n",
      "actend                  106726\n",
      "departure               106726\n",
      "actstart                105753\n",
      "arrival                 105749\n",
      "PersonCost               78108\n",
      "LeavingParkingEvent      76377\n",
      "ParkingEvent             66778\n",
      "TeleportationEvent       19677\n",
      "ReserveRideHail           5796\n",
      "Replanning                 219\n",
      "RefuelSessionEvent           2\n",
      "ChargingPlugOutEvent         2\n",
      "ChargingPlugInEvent          1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           368416\n",
      "PersonEntersVehicle     172739\n",
      "PersonLeavesVehicle     166430\n",
      "actend                  112218\n",
      "departure               112217\n",
      "ModeChoice              112102\n",
      "actstart                106387\n",
      "arrival                 106376\n",
      "PersonCost               76621\n",
      "LeavingParkingEvent      73809\n",
      "ParkingEvent             64239\n",
      "TeleportationEvent       21972\n",
      "ReserveRideHail           6241\n",
      "Replanning                 229\n",
      "ChargingPlugInEvent          2\n",
      "RefuelSessionEvent           1\n",
      "ChargingPlugOutEvent         1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           374403\n",
      "PersonEntersVehicle     175148\n",
      "PersonLeavesVehicle     168178\n",
      "ModeChoice              109598\n",
      "departure               109501\n",
      "actend                  109500\n",
      "arrival                 105505\n",
      "actstart                105505\n",
      "PersonCost               76373\n",
      "LeavingParkingEvent      75085\n",
      "ParkingEvent             64240\n",
      "TeleportationEvent       20861\n",
      "ReserveRideHail           5839\n",
      "Replanning                 253\n",
      "RefuelSessionEvent           4\n",
      "ChargingPlugOutEvent         4\n",
      "ChargingPlugInEvent          3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           382615\n",
      "PersonLeavesVehicle     173897\n",
      "PersonEntersVehicle     173412\n",
      "arrival                 105206\n",
      "actstart                105203\n",
      "ModeChoice              104764\n",
      "actend                  104437\n",
      "departure               104437\n",
      "PersonCost               79592\n",
      "LeavingParkingEvent      75778\n",
      "ParkingEvent             67448\n",
      "TeleportationEvent       17742\n",
      "ReserveRideHail           5288\n",
      "Replanning                 179\n",
      "RefuelSessionEvent           1\n",
      "ChargingPlugOutEvent         1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           372562\n",
      "PersonEntersVehicle     185190\n",
      "PersonLeavesVehicle     166337\n",
      "ModeChoice              111378\n",
      "actend                  111237\n",
      "departure               111237\n",
      "actstart                 98754\n",
      "arrival                  98752\n",
      "LeavingParkingEvent      80376\n",
      "PersonCost               77182\n",
      "ParkingEvent             65939\n",
      "TeleportationEvent       15713\n",
      "ReserveRideHail           5074\n",
      "Replanning                 256\n",
      "ChargingPlugInEvent          7\n",
      "RefuelSessionEvent           3\n",
      "ChargingPlugOutEvent         3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           382599\n",
      "PersonLeavesVehicle     177967\n",
      "PersonEntersVehicle     175365\n",
      "arrival                 103876\n",
      "actstart                103850\n",
      "ModeChoice              102082\n",
      "departure               101811\n",
      "actend                  101811\n",
      "PersonCost               82619\n",
      "LeavingParkingEvent      76967\n",
      "ParkingEvent             70219\n",
      "TeleportationEvent       15671\n",
      "ReserveRideHail           4836\n",
      "Replanning                 312\n",
      "RefuelSessionEvent           6\n",
      "ChargingPlugOutEvent         6\n",
      "ChargingPlugInEvent          3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           373399\n",
      "PersonEntersVehicle     182085\n",
      "PersonLeavesVehicle     174131\n",
      "ModeChoice              108073\n",
      "actend                  107169\n",
      "departure               107168\n",
      "actstart                101334\n",
      "arrival                 101330\n",
      "PersonCost               79763\n",
      "LeavingParkingEvent      78284\n",
      "ParkingEvent             67674\n",
      "TeleportationEvent       14008\n",
      "ReserveRideHail           5041\n",
      "Replanning                 528\n",
      "ChargingPlugInEvent          7\n",
      "RefuelSessionEvent           3\n",
      "ChargingPlugOutEvent         3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,37,39,41,42,43,44,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           382406\n",
      "PersonLeavesVehicle     180533\n",
      "PersonEntersVehicle     174571\n",
      "actstart                105111\n",
      "arrival                 105088\n",
      "ModeChoice              101257\n",
      "departure               100247\n",
      "actend                  100246\n",
      "PersonCost               82211\n",
      "LeavingParkingEvent      76907\n",
      "ParkingEvent             70026\n",
      "TeleportationEvent       15053\n",
      "ReserveRideHail           5571\n",
      "Replanning                 757\n",
      "RefuelSessionEvent           6\n",
      "ChargingPlugOutEvent         6\n",
      "ChargingPlugInEvent          4\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           401938\n",
      "PersonLeavesVehicle     195988\n",
      "PersonEntersVehicle     161799\n",
      "arrival                 112532\n",
      "actstart                112531\n",
      "ModeChoice               89273\n",
      "departure                88925\n",
      "actend                   88925\n",
      "PersonCost               85517\n",
      "ParkingEvent             72622\n",
      "LeavingParkingEvent      71219\n",
      "TeleportationEvent       12890\n",
      "ReserveRideHail           5241\n",
      "Replanning                 582\n",
      "RefuelSessionEvent           7\n",
      "ChargingPlugOutEvent         7\n",
      "ChargingPlugInEvent          4\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           390804\n",
      "PersonLeavesVehicle     183231\n",
      "PersonEntersVehicle     170248\n",
      "arrival                 107157\n",
      "actstart                107146\n",
      "ModeChoice               98326\n",
      "actend                   98186\n",
      "departure                98186\n",
      "PersonCost               81959\n",
      "LeavingParkingEvent      74601\n",
      "ParkingEvent             69642\n",
      "TeleportationEvent       14087\n",
      "ReserveRideHail           5891\n",
      "Replanning                 532\n",
      "ChargingPlugInEvent          2\n",
      "RefuelSessionEvent           1\n",
      "ChargingPlugOutEvent         1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           380665\n",
      "PersonLeavesVehicle     180471\n",
      "PersonEntersVehicle     171643\n",
      "actstart                107837\n",
      "arrival                 107829\n",
      "ModeChoice              101663\n",
      "actend                  100808\n",
      "departure               100808\n",
      "PersonCost               81755\n",
      "LeavingParkingEvent      74437\n",
      "ParkingEvent             69326\n",
      "TeleportationEvent       15723\n",
      "ReserveRideHail           6294\n",
      "Replanning                 736\n",
      "RefuelSessionEvent           2\n",
      "ChargingPlugOutEvent         2\n",
      "ChargingPlugInEvent          1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (0,17,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal          372269\n",
      "PersonLeavesVehicle    169341\n",
      "PersonEntersVehicle    126578\n",
      "actstart                99821\n",
      "arrival                 99817\n",
      "PersonCost              71172\n",
      "ModeChoice              67136\n",
      "actend                  66849\n",
      "departure               66849\n",
      "ParkingEvent            62993\n",
      "LeavingParkingEvent     60659\n",
      "TeleportationEvent       9329\n",
      "ReserveRideHail          3699\n",
      "Replanning                397\n",
      "Name: type, dtype: int64\n",
      "         vehicle    time\n",
      "172383    229730   18000\n",
      "172388    398535   18003\n",
      "172391     30873   18003\n",
      "172402    663474   18000\n",
      "172414    172651   18003\n",
      "...          ...     ...\n",
      "35776802  202477  211586\n",
      "35776822  202477  212315\n",
      "35776838  202477  212631\n",
      "35776862   92528  214507\n",
      "35776882   92528  215007\n",
      "\n",
      "[2061889 rows x 2 columns]\n",
      "car          2770060\n",
      "walk         1957021\n",
      "bus          1337343\n",
      "car_hov2      405068\n",
      "car_hov3      286232\n",
      "tram           54924\n",
      "bike           34471\n",
      "cable_car      17836\n",
      "subway         14358\n",
      "rail            1702\n",
      "ferry             73\n",
      "Name: mode, dtype: int64\n",
      "bus          1337343\n",
      "tram           54924\n",
      "cable_car      17836\n",
      "subway         14358\n",
      "rail            1702\n",
      "ferry             73\n",
      "Name: mode, dtype: int64\n",
      "['3D' 'AC' 'AM' 'AY' 'BA' 'CA' 'CC' 'CE' 'CM' 'CT' 'DE' 'EM' 'GG' 'MA'\n",
      " 'PE' 'RV' 'SB' 'SC' 'SF' 'SM' 'SO' 'SR' 'ST' 'TD' 'UC' 'VC' 'VN' 'VT'\n",
      " 'WC' 'WH']\n",
      "10000 / 296235 . Time =  49.56320309638977 . Estimated remaining time: 1418.6723416837453\n",
      "20000 / 296235 . Time =  96.70227813720703 . Estimated remaining time: 1335.6276888694763\n",
      "30000 / 296235 . Time =  140.44179821014404 . Estimated remaining time: 1246.3507447719576\n",
      "40000 / 296235 . Time =  183.60449314117432 . Estimated remaining time: 1176.1474315470457\n",
      "50000 / 296235 . Time =  226.26219606399536 . Estimated remaining time: 1114.2734404608248\n",
      "60000 / 296235 . Time =  268.92954325675964 . Estimated remaining time: 1058.8428460501434\n",
      "70000 / 296235 . Time =  312.93390417099 . Estimated remaining time: 1011.3800237131459\n",
      "80000 / 296235 . Time =  355.14318227767944 . Estimated remaining time: 959.9298233403267\n",
      "90000 / 296235 . Time =  397.81200408935547 . Estimated remaining time: 911.5862081950902\n",
      "100000 / 296235 . Time =  444.7370080947876 . Estimated remaining time: 872.7296656890392\n",
      "110000 / 296235 . Time =  493.780757188797 . Estimated remaining time: 835.9932662077711\n",
      "120000 / 296235 . Time =  543.7718892097473 . Estimated remaining time: 798.5969902839065\n",
      "130000 / 296235 . Time =  594.1179530620575 . Estimated remaining time: 759.7169071602546\n",
      "140000 / 296235 . Time =  645.3711450099945 . Estimated remaining time: 720.2111487338627\n",
      "150000 / 296235 . Time =  696.6712870597839 . Estimated remaining time: 679.184837009406\n",
      "160000 / 296235 . Time =  746.1548302173615 . Estimated remaining time: 635.3275204499885\n",
      "170000 / 296235 . Time =  793.1164679527283 . Estimated remaining time: 588.9356312963052\n",
      "180000 / 296235 . Time =  838.6701602935791 . Estimated remaining time: 541.5712549564837\n",
      "190000 / 296235 . Time =  885.8418161869049 . Estimated remaining time: 495.3021329617436\n",
      "200000 / 296235 . Time =  933.2369921207428 . Estimated remaining time: 449.0503077763499\n",
      "210000 / 296235 . Time =  980.5556871891022 . Estimated remaining time: 402.65818706766186\n",
      "220000 / 296235 . Time =  1025.943034172058 . Estimated remaining time: 355.51257736613525\n",
      "230000 / 296235 . Time =  1071.5069591999054 . Estimated remaining time: 308.5707084742578\n",
      "240000 / 296235 . Time =  1117.6068029403687 . Estimated remaining time: 261.86924333961315\n",
      "250000 / 296235 . Time =  1162.9801359176636 . Estimated remaining time: 215.0815456034038\n",
      "260000 / 296235 . Time =  1207.3885822296143 . Estimated remaining time: 168.26817356030756\n",
      "270000 / 296235 . Time =  1253.4316611289978 . Estimated remaining time: 121.79177435326574\n",
      "280000 / 296235 . Time =  1300.9215052127838 . Estimated remaining time: 75.43021560750276\n",
      "290000 / 296235 . Time =  1350.4650812149048 . Estimated remaining time: 29.03499712085727\n",
      "evaluate ridership\n",
      "read s3://beam-outputs/pilates-outputs/test_49_3/beam/year-2018-iteration-3/ITERS/it.0/0.events.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,4,5,6,12,15,17,18,19,20,32,34,35,36,40,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           356650\n",
      "PersonEntersVehicle     254021\n",
      "departure               183362\n",
      "PersonLeavesVehicle     135477\n",
      "ModeChoice              100853\n",
      "actend                  100805\n",
      "LeavingParkingEvent      79232\n",
      "arrival                  75379\n",
      "actstart                 75377\n",
      "PersonCost               66837\n",
      "ParkingEvent             60344\n",
      "TeleportationEvent        9339\n",
      "ReserveRideHail           2273\n",
      "Replanning                  45\n",
      "ChargingPlugInEvent          2\n",
      "RefuelSessionEvent           2\n",
      "ChargingPlugOutEvent         2\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           377351\n",
      "PersonEntersVehicle     186896\n",
      "PersonLeavesVehicle     155501\n",
      "ModeChoice              117312\n",
      "departure               117083\n",
      "actend                  117082\n",
      "arrival                  93263\n",
      "actstart                 93242\n",
      "LeavingParkingEvent      81344\n",
      "PersonCost               74859\n",
      "ParkingEvent             65074\n",
      "TeleportationEvent       17824\n",
      "ReserveRideHail           2930\n",
      "Replanning                 234\n",
      "ChargingPlugInEvent          3\n",
      "RefuelSessionEvent           1\n",
      "ChargingPlugOutEvent         1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           368583\n",
      "PersonEntersVehicle     180281\n",
      "PersonLeavesVehicle     167778\n",
      "ModeChoice              112751\n",
      "actend                  111504\n",
      "departure               111504\n",
      "actstart                102031\n",
      "arrival                 102008\n",
      "PersonCost               77338\n",
      "LeavingParkingEvent      77167\n",
      "ParkingEvent             65490\n",
      "TeleportationEvent       19518\n",
      "ReserveRideHail           3034\n",
      "Replanning                1000\n",
      "ChargingPlugInEvent          5\n",
      "RefuelSessionEvent           4\n",
      "ChargingPlugOutEvent         4\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           365333\n",
      "PersonEntersVehicle     175469\n",
      "PersonLeavesVehicle     171976\n",
      "ModeChoice              109714\n",
      "actend                  108851\n",
      "departure               108848\n",
      "arrival                 105780\n",
      "actstart                105764\n",
      "PersonCost               78742\n",
      "LeavingParkingEvent      76729\n",
      "ParkingEvent             66255\n",
      "TeleportationEvent       21545\n",
      "ReserveRideHail           3883\n",
      "Replanning                1095\n",
      "RefuelSessionEvent           6\n",
      "ChargingPlugOutEvent         6\n",
      "ChargingPlugInEvent          4\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           365042\n",
      "PersonLeavesVehicle     174589\n",
      "PersonEntersVehicle     173890\n",
      "ModeChoice              110233\n",
      "departure               107759\n",
      "actend                  107756\n",
      "actstart                107541\n",
      "arrival                 107525\n",
      "PersonCost               78132\n",
      "LeavingParkingEvent      75823\n",
      "ParkingEvent             65343\n",
      "TeleportationEvent       21370\n",
      "ReserveRideHail           3902\n",
      "Replanning                1089\n",
      "RefuelSessionEvent           2\n",
      "ChargingPlugOutEvent         2\n",
      "ChargingPlugInEvent          2\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           401809\n",
      "PersonLeavesVehicle     192189\n",
      "PersonEntersVehicle     164477\n",
      "arrival                 111845\n",
      "actstart                111841\n",
      "departure                91021\n",
      "actend                   91021\n",
      "ModeChoice               90330\n",
      "PersonCost               82604\n",
      "LeavingParkingEvent      74029\n",
      "ParkingEvent             68094\n",
      "TeleportationEvent       15448\n",
      "ReserveRideHail           4593\n",
      "Replanning                 682\n",
      "RefuelSessionEvent           6\n",
      "ChargingPlugOutEvent         6\n",
      "ChargingPlugInEvent          5\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal          394551\n",
      "PersonEntersVehicle    175253\n",
      "PersonLeavesVehicle    174604\n",
      "actstart               101671\n",
      "arrival                101668\n",
      "ModeChoice             101661\n",
      "actend                 101199\n",
      "departure              101199\n",
      "LeavingParkingEvent     80232\n",
      "PersonCost              79838\n",
      "ParkingEvent            68039\n",
      "TeleportationEvent      14431\n",
      "ReserveRideHail          5382\n",
      "Replanning                272\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           390541\n",
      "PersonEntersVehicle     174585\n",
      "PersonLeavesVehicle     173241\n",
      "ModeChoice              102718\n",
      "actend                  102713\n",
      "departure               102713\n",
      "actstart                101184\n",
      "arrival                 101184\n",
      "PersonCost               80730\n",
      "LeavingParkingEvent      80209\n",
      "ParkingEvent             69381\n",
      "TeleportationEvent       14730\n",
      "ReserveRideHail           5849\n",
      "Replanning                 209\n",
      "ChargingPlugInEvent          7\n",
      "RefuelSessionEvent           3\n",
      "ChargingPlugOutEvent         3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           387561\n",
      "PersonEntersVehicle     173802\n",
      "PersonLeavesVehicle     173279\n",
      "ModeChoice              103223\n",
      "departure               103041\n",
      "actend                  103041\n",
      "arrival                 102890\n",
      "actstart                102861\n",
      "LeavingParkingEvent      80019\n",
      "PersonCost               79954\n",
      "ParkingEvent             69040\n",
      "TeleportationEvent       15159\n",
      "ReserveRideHail           5914\n",
      "Replanning                 197\n",
      "RefuelSessionEvent           7\n",
      "ChargingPlugOutEvent         7\n",
      "ChargingPlugInEvent          5\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           383331\n",
      "PersonEntersVehicle     176434\n",
      "PersonLeavesVehicle     170638\n",
      "ModeChoice              106587\n",
      "actend                  106335\n",
      "departure               106334\n",
      "actstart                101048\n",
      "arrival                 101018\n",
      "LeavingParkingEvent      80242\n",
      "PersonCost               78907\n",
      "ParkingEvent             68010\n",
      "TeleportationEvent       14922\n",
      "ReserveRideHail           5996\n",
      "Replanning                 184\n",
      "ChargingPlugInEvent          6\n",
      "RefuelSessionEvent           4\n",
      "ChargingPlugOutEvent         4\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           382731\n",
      "PersonEntersVehicle     174730\n",
      "PersonLeavesVehicle     171537\n",
      "ModeChoice              104587\n",
      "departure               104321\n",
      "actend                  104320\n",
      "arrival                 102094\n",
      "actstart                102094\n",
      "PersonCost               80773\n",
      "LeavingParkingEvent      80642\n",
      "ParkingEvent             70355\n",
      "TeleportationEvent       16079\n",
      "ReserveRideHail           5486\n",
      "Replanning                 236\n",
      "RefuelSessionEvent           6\n",
      "ChargingPlugOutEvent         6\n",
      "ChargingPlugInEvent          3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           377001\n",
      "PersonLeavesVehicle     173331\n",
      "PersonEntersVehicle     172833\n",
      "ModeChoice              105951\n",
      "actend                  105806\n",
      "departure               105801\n",
      "actstart                104666\n",
      "arrival                 104666\n",
      "PersonCost               79947\n",
      "LeavingParkingEvent      77989\n",
      "ParkingEvent             69164\n",
      "TeleportationEvent       16976\n",
      "ReserveRideHail           5668\n",
      "Replanning                 197\n",
      "ChargingPlugInEvent          2\n",
      "RefuelSessionEvent           1\n",
      "ChargingPlugOutEvent         1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           379959\n",
      "PersonEntersVehicle     172612\n",
      "PersonLeavesVehicle     169367\n",
      "ModeChoice              107487\n",
      "departure               107035\n",
      "actend                  107030\n",
      "arrival                 104875\n",
      "actstart                104869\n",
      "PersonCost               78084\n",
      "LeavingParkingEvent      76464\n",
      "ParkingEvent             66648\n",
      "TeleportationEvent       19313\n",
      "ReserveRideHail           5999\n",
      "Replanning                 251\n",
      "RefuelSessionEvent           3\n",
      "ChargingPlugOutEvent         3\n",
      "ChargingPlugInEvent          1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal          369026\n",
      "PersonEntersVehicle    172447\n",
      "PersonLeavesVehicle    166499\n",
      "ModeChoice             112186\n",
      "actend                 112185\n",
      "departure              112185\n",
      "actstart               106134\n",
      "arrival                106132\n",
      "PersonCost              76522\n",
      "LeavingParkingEvent     74094\n",
      "ParkingEvent            64302\n",
      "TeleportationEvent      22037\n",
      "ReserveRideHail          6005\n",
      "Replanning                246\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           375654\n",
      "PersonEntersVehicle     174504\n",
      "PersonLeavesVehicle     169033\n",
      "ModeChoice              108506\n",
      "departure               108255\n",
      "actend                  108255\n",
      "arrival                 105931\n",
      "actstart                105910\n",
      "PersonCost               76807\n",
      "LeavingParkingEvent      75521\n",
      "ParkingEvent             64558\n",
      "TeleportationEvent       20927\n",
      "ReserveRideHail           5878\n",
      "Replanning                 253\n",
      "ChargingPlugInEvent          4\n",
      "RefuelSessionEvent           2\n",
      "ChargingPlugOutEvent         2\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           381286\n",
      "PersonEntersVehicle     173728\n",
      "PersonLeavesVehicle     173348\n",
      "ModeChoice              105579\n",
      "actend                  105288\n",
      "departure               105287\n",
      "actstart                105267\n",
      "arrival                 105242\n",
      "PersonCost               78942\n",
      "LeavingParkingEvent      75801\n",
      "ParkingEvent             66893\n",
      "TeleportationEvent       17774\n",
      "ReserveRideHail           5304\n",
      "Replanning                 257\n",
      "RefuelSessionEvent           2\n",
      "ChargingPlugOutEvent         2\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           374843\n",
      "PersonEntersVehicle     185016\n",
      "PersonLeavesVehicle     166243\n",
      "ModeChoice              110783\n",
      "departure               110402\n",
      "actend                  110401\n",
      "arrival                  98805\n",
      "actstart                 98804\n",
      "LeavingParkingEvent      80351\n",
      "PersonCost               77138\n",
      "ParkingEvent             65854\n",
      "TeleportationEvent       15949\n",
      "ReserveRideHail           5159\n",
      "Replanning                 248\n",
      "ChargingPlugInEvent          2\n",
      "RefuelSessionEvent           1\n",
      "ChargingPlugOutEvent         1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           380337\n",
      "PersonLeavesVehicle     177009\n",
      "PersonEntersVehicle     176720\n",
      "ModeChoice              103552\n",
      "actend                  103330\n",
      "departure               103330\n",
      "arrival                 102566\n",
      "actstart                102559\n",
      "PersonCost               82864\n",
      "LeavingParkingEvent      76645\n",
      "ParkingEvent             70269\n",
      "TeleportationEvent       15445\n",
      "ReserveRideHail           4942\n",
      "Replanning                 419\n",
      "ChargingPlugInEvent          5\n",
      "RefuelSessionEvent           4\n",
      "ChargingPlugOutEvent         4\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           375171\n",
      "PersonEntersVehicle     179969\n",
      "PersonLeavesVehicle     176101\n",
      "ModeChoice              106332\n",
      "actend                  105655\n",
      "departure               105654\n",
      "actstart                103293\n",
      "arrival                 103285\n",
      "PersonCost               79551\n",
      "LeavingParkingEvent      77706\n",
      "ParkingEvent             67635\n",
      "TeleportationEvent       14079\n",
      "ReserveRideHail           5132\n",
      "Replanning                 423\n",
      "ChargingPlugInEvent          8\n",
      "RefuelSessionEvent           3\n",
      "ChargingPlugOutEvent         3\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           382661\n",
      "PersonLeavesVehicle     180720\n",
      "PersonEntersVehicle     174670\n",
      "arrival                 104432\n",
      "actstart                104431\n",
      "ModeChoice              100695\n",
      "departure                99963\n",
      "actend                   99962\n",
      "PersonCost               83447\n",
      "LeavingParkingEvent      76556\n",
      "ParkingEvent             71154\n",
      "TeleportationEvent       15160\n",
      "ReserveRideHail           5419\n",
      "Replanning                 705\n",
      "RefuelSessionEvent           9\n",
      "ChargingPlugOutEvent         9\n",
      "ChargingPlugInEvent          7\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,20,41,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           400006\n",
      "PersonLeavesVehicle     195781\n",
      "PersonEntersVehicle     162216\n",
      "arrival                 112640\n",
      "actstart                112638\n",
      "ModeChoice               90345\n",
      "actend                   89981\n",
      "departure                89981\n",
      "PersonCost               84367\n",
      "LeavingParkingEvent      72010\n",
      "ParkingEvent             71818\n",
      "TeleportationEvent       12580\n",
      "ReserveRideHail           5035\n",
      "Replanning                 591\n",
      "RefuelSessionEvent           5\n",
      "ChargingPlugOutEvent         5\n",
      "ChargingPlugInEvent          1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           393038\n",
      "PersonLeavesVehicle     182217\n",
      "PersonEntersVehicle     170639\n",
      "arrival                 106483\n",
      "actstart                106478\n",
      "ModeChoice               98066\n",
      "departure                97561\n",
      "actend                   97561\n",
      "PersonCost               82341\n",
      "LeavingParkingEvent      75016\n",
      "ParkingEvent             69745\n",
      "TeleportationEvent       14126\n",
      "ReserveRideHail           6134\n",
      "Replanning                 581\n",
      "RefuelSessionEvent           5\n",
      "ChargingPlugOutEvent         5\n",
      "ChargingPlugInEvent          4\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (3,15,49,51,53,54,55,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal           380366\n",
      "PersonLeavesVehicle     181078\n",
      "PersonEntersVehicle     171288\n",
      "arrival                 108263\n",
      "actstart                108260\n",
      "ModeChoice              101534\n",
      "actend                  100745\n",
      "departure               100744\n",
      "PersonCost               81432\n",
      "LeavingParkingEvent      74421\n",
      "ParkingEvent             69225\n",
      "TeleportationEvent       15795\n",
      "ReserveRideHail           6200\n",
      "Replanning                 646\n",
      "ChargingPlugInEvent          1\n",
      "RefuelSessionEvent           1\n",
      "ChargingPlugOutEvent         1\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/3554254780.py:13: DtypeWarning: Columns (15,20,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathTraversal          375085\n",
      "PersonLeavesVehicle    170049\n",
      "PersonEntersVehicle    127710\n",
      "actstart               100308\n",
      "arrival                100297\n",
      "PersonCost              71523\n",
      "ModeChoice              67903\n",
      "departure               67492\n",
      "actend                  67491\n",
      "ParkingEvent            63317\n",
      "LeavingParkingEvent     61207\n",
      "TeleportationEvent       9341\n",
      "ReserveRideHail          3781\n",
      "Replanning                511\n",
      "Name: type, dtype: int64\n",
      "         vehicle    time\n",
      "173810    620727   18007\n",
      "174050    740481   18021\n",
      "174057    229418   18050\n",
      "174068     29974   18064\n",
      "174079    133521   18003\n",
      "...          ...     ...\n",
      "35785469   39198  182176\n",
      "35785836  528903  205746\n",
      "35785913  528903  209876\n",
      "35785932  202477  211277\n",
      "35786008   92528  215806\n",
      "\n",
      "[2062981 rows x 2 columns]\n",
      "car          2770165\n",
      "walk         1958263\n",
      "bus          1341993\n",
      "car_hov2      404751\n",
      "car_hov3      286217\n",
      "tram           54924\n",
      "bike           34530\n",
      "cable_car      17836\n",
      "subway         15118\n",
      "rail            1947\n",
      "ferry             73\n",
      "Name: mode, dtype: int64\n",
      "bus          1341993\n",
      "tram           54924\n",
      "cable_car      17836\n",
      "subway         15118\n",
      "rail            1947\n",
      "ferry             73\n",
      "Name: mode, dtype: int64\n",
      "['3D' 'AC' 'AM' 'AY' 'BA' 'CA' 'CC' 'CE' 'CM' 'CT' 'DE' 'EM' 'GG' 'MA'\n",
      " 'PE' 'RV' 'SB' 'SC' 'SF' 'SM' 'SO' 'SR' 'ST' 'TD' 'UC' 'VC' 'VN' 'VT'\n",
      " 'WC' 'WH']\n",
      "10000 / 297312 . Time =  51.137309074401855 . Estimated remaining time: 1469.2362809249878\n",
      "20000 / 297312 . Time =  100.4305911064148 . Estimated remaining time: 1392.5304163146973\n",
      "30000 / 297312 . Time =  144.2644407749176 . Estimated remaining time: 1285.4538817955017\n",
      "40000 / 297312 . Time =  189.0248899459839 . Estimated remaining time: 1215.9593310289383\n",
      "50000 / 297312 . Time =  233.80921411514282 . Estimated remaining time: 1156.4764909883118\n",
      "60000 / 297312 . Time =  278.240581035614 . Estimated remaining time: 1100.4971479766846\n",
      "70000 / 297312 . Time =  329.2480719089508 . Estimated remaining time: 1069.1719703712463\n",
      "80000 / 297312 . Time =  371.26340889930725 . Estimated remaining time: 1008.499926218605\n",
      "90000 / 297312 . Time =  413.4064898490906 . Estimated remaining time: 952.2680699896496\n",
      "100000 / 297312 . Time =  459.561203956604 . Estimated remaining time: 906.7694006050874\n",
      "110000 / 297312 . Time =  506.23456597328186 . Estimated remaining time: 862.0346281392533\n",
      "120000 / 297312 . Time =  554.4099140167236 . Estimated remaining time: 819.1960884529112\n",
      "130000 / 297312 . Time =  602.4985628128052 . Estimated remaining time: 775.4249191756323\n",
      "140000 / 297312 . Time =  652.3207790851593 . Estimated remaining time: 732.9849032095226\n",
      "150000 / 297312 . Time =  700.3481709957123 . Estimated remaining time: 687.7979312732698\n",
      "160000 / 297312 . Time =  747.7838170528412 . Estimated remaining time: 641.7480716595173\n",
      "170000 / 297312 . Time =  796.0761549472809 . Estimated remaining time: 596.1767491612154\n",
      "180000 / 297312 . Time =  841.8506891727448 . Estimated remaining time: 548.6621553359985\n",
      "190000 / 297312 . Time =  886.7748079299927 . Estimated remaining time: 500.85040991172787\n",
      "200000 / 297312 . Time =  932.1692750453949 . Estimated remaining time: 453.5562810227584\n",
      "210000 / 297312 . Time =  980.3355929851532 . Estimated remaining time: 407.5955291792734\n",
      "220000 / 297312 . Time =  1026.3102560043335 . Estimated remaining time: 360.6640835278597\n",
      "230000 / 297312 . Time =  1074.4079740047455 . Estimated remaining time: 314.4371700326835\n",
      "240000 / 297312 . Time =  1120.645940065384 . Estimated remaining time: 267.61024976167687\n",
      "250000 / 297312 . Time =  1167.704304933548 . Estimated remaining time: 220.9857032884522\n",
      "260000 / 297312 . Time =  1213.3205308914185 . Estimated remaining time: 174.12082727200436\n",
      "270000 / 297312 . Time =  1259.3230941295624 . Estimated remaining time: 127.38752632929481\n",
      "280000 / 297312 . Time =  1307.5989730358124 . Estimated remaining time: 80.84697459692279\n",
      "290000 / 297312 . Time =  1359.443029165268 . Estimated remaining time: 34.276713628413745\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Ridership route\n",
    "RR = pd.DataFrame()\n",
    "#Ridership agency\n",
    "RA = pd.DataFrame()\n",
    "\n",
    "for fp, name, GTFS_filepath in zip(dataFilepath_sim,names, GTFS_filepaths):\n",
    "    print('evaluate ridership')\n",
    "    #import pathtraversal and person enter vehicles\n",
    "    PT, PE = processEvents(fp, nrows)\n",
    "    #filter PE transit trips from PT\n",
    "    PE = filter_transit(PT, PE)\n",
    "    #Guess transit agency for each PE\n",
    "    PE = guess_agency(PE)\n",
    "    #Guess transit route for each PE\n",
    "    PE = guess_route(PE, GTFS_filepath)\n",
    "    #Route Ridership\n",
    "    rr = PE['route_id'].value_counts()\n",
    "    sum_agency = 0\n",
    "    sum_agency_bsva = 0\n",
    "    sum_route = 0\n",
    "    for route, count in zip(rr.keys(), rr):\n",
    "        RR.at[route, name] = count\n",
    "        sum_route += count\n",
    "    ra = PE['agency'].value_counts()\n",
    "    for agency, count in zip(ra.keys(), ra):\n",
    "        RA.at[agency, name] = count\n",
    "        sum_agency += count\n",
    "        if agency in ['BA', 'SF', 'VT', 'AC']:\n",
    "            RA.at[agency, name+' BA-SF-VT-AC'] = count\n",
    "            sum_agency_bsva += count\n",
    "    for route, count in zip(rr.keys(), rr):\n",
    "        RR.at[route, name+' shares'] = count/sum_route\n",
    "    ra = PE['agency'].value_counts()\n",
    "    for agency, count in zip(ra.keys(), ra):\n",
    "        RA.at[agency, name+' shares'] = count/sum_agency\n",
    "        if agency in ['BA', 'SF', 'VT', 'AC']:\n",
    "            RA.at[agency, name+' shares BA-SF-VT-AC'] = count/sum_agency_bsva\n",
    "    RA.to_csv(output_filepath+RA_output)\n",
    "    RR.to_csv(output_filepath+RR_output)\n",
    "\n",
    "for year in years:\n",
    "    diff = []\n",
    "    diff_abs = []\n",
    "    for baseline, future in zip(RA['Baseline'+year],RA['Future'+year]):\n",
    "        diff.append((future-baseline)/baseline)\n",
    "        diff_abs.append((future-baseline))\n",
    "    RA['Diff %'+year] = diff\n",
    "    RA['Diff'+year] = diff_abs\n",
    "\n",
    "tot_NTD = 1756364558 + 15283299+5703705+49795740+110802986+7386518+49247910+27027693 + 8437926+50222832 + 2818648\n",
    "    \n",
    "RA.at['BA', 'clipper BA-SF-VT-AC 2016 share target'] = 350485/773719\n",
    "RA.at['BA', 'MTC BA-SF-VT-AC 2016 share target'] = 458900/1564500\n",
    "RA.at['BA', 'NTD BA-SF-VT-AC 2019 share target'] = (1756364558 + 15283299)/tot_NTD\n",
    "\n",
    "RA.at['SF', 'clipper BA-SF-VT-AC 2016 share target'] = 293991/773719\n",
    "RA.at['SF', 'MTC BA-SF-VT-AC 2016 share target'] = 777000/1564500\n",
    "RA.at['SF', 'NTD BA-SF-VT-AC 2019 share target'] = (5703705+49795740+110802986+7386518+49247910)/tot_NTD\n",
    "\n",
    "RA.at['VT', 'clipper BA-SF-VT-AC 2016 share target'] = 43950/773719\n",
    "RA.at['VT', 'MTC BA-SF-VT-AC 2016 share target'] = 146700/1564500\n",
    "RA.at['VT', 'NTD BA-SF-VT-AC 2019 share target'] = (27027693 + 8437926)/tot_NTD\n",
    "\n",
    "RA.at['AC', 'clipper BA-SF-VT-AC 2016 share target'] = 85293/773719\n",
    "RA.at['AC', 'MTC BA-SF-VT-AC 2016 share target'] = 181900/1564500\n",
    "RA.at['AC', 'NTD BA-SF-VT-AC 2019 share target'] = (50222832 + 2818648)/tot_NTD\n",
    "\n",
    "RA.at['BA', 'clipper BA-SF-VT-AC 2020 Jan av ridership target'] = 350485\n",
    "RA.at['BA', 'MTC BA-SF-VT-AC 2016 av ridership target'] = 458900\n",
    "RA.at['BA', 'NTD BA-SF-VT-AC 2019 ridership target'] = (1756364558 + 15283299)\n",
    "\n",
    "RA.at['SF', 'clipper BA-SF-VT-AC 2020 Jan av ridership target'] = 293991\n",
    "RA.at['SF', 'MTC BA-SF-VT-AC 2016 av ridership target'] = 777000\n",
    "RA.at['SF', 'NTD BA-SF-VT-AC 2019 ridership target'] = (5703705+49795740+110802986+7386518+49247910)\n",
    "\n",
    "RA.at['VT', 'clipper BA-SF-VT-AC 2020 Jan av ridership target'] = 43950\n",
    "RA.at['VT', 'MTC BA-SF-VT-AC 2016 av ridership target'] = 146700\n",
    "RA.at['VT', 'NTD BA-SF-VT-AC 2019 ridership target'] =  (27027693 + 8437926)\n",
    "\n",
    "RA.at['AC', 'clipper BA-SF-VT-AC 2020 Jan av ridership target'] = 85293\n",
    "RA.at['AC', 'MTC BA-SF-VT-AC 2016 av ridership target'] = 181900\n",
    "RA.at['AC', 'NTD BA-SF-VT-AC 2019 ridership target'] = (50222832 + 2818648)\n",
    "\n",
    "RA.to_csv(output_filepath+RA_output)\n",
    "RR.to_csv(output_filepath+RR_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64807f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 BA-SF-VT-AC</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Baseline2018 shares BA-SF-VT-AC</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 BA-SF-VT-AC</th>\n",
       "      <th>Future2018 shares</th>\n",
       "      <th>Future2018 shares BA-SF-VT-AC</th>\n",
       "      <th>Diff %2018</th>\n",
       "      <th>Diff2018</th>\n",
       "      <th>clipper BA-SF-VT-AC 2016 share target</th>\n",
       "      <th>MTC BA-SF-VT-AC 2016 share target</th>\n",
       "      <th>NTD BA-SF-VT-AC 2019 share target</th>\n",
       "      <th>clipper BA-SF-VT-AC 2020 Jan av ridership target</th>\n",
       "      <th>MTC BA-SF-VT-AC 2016 av ridership target</th>\n",
       "      <th>NTD BA-SF-VT-AC 2019 ridership target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>96467.0</td>\n",
       "      <td>96467.0</td>\n",
       "      <td>0.325643</td>\n",
       "      <td>0.404498</td>\n",
       "      <td>97766.0</td>\n",
       "      <td>97766.0</td>\n",
       "      <td>0.328833</td>\n",
       "      <td>0.408297</td>\n",
       "      <td>0.013466</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.379971</td>\n",
       "      <td>0.496644</td>\n",
       "      <td>0.107022</td>\n",
       "      <td>293991.0</td>\n",
       "      <td>777000.0</td>\n",
       "      <td>2.229369e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AC</th>\n",
       "      <td>56183.0</td>\n",
       "      <td>56183.0</td>\n",
       "      <td>0.189657</td>\n",
       "      <td>0.235582</td>\n",
       "      <td>56226.0</td>\n",
       "      <td>56226.0</td>\n",
       "      <td>0.189114</td>\n",
       "      <td>0.234815</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.110238</td>\n",
       "      <td>0.116267</td>\n",
       "      <td>0.025463</td>\n",
       "      <td>85293.0</td>\n",
       "      <td>181900.0</td>\n",
       "      <td>5.304148e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VT</th>\n",
       "      <td>52724.0</td>\n",
       "      <td>52724.0</td>\n",
       "      <td>0.177980</td>\n",
       "      <td>0.221078</td>\n",
       "      <td>52508.0</td>\n",
       "      <td>52508.0</td>\n",
       "      <td>0.176609</td>\n",
       "      <td>0.219288</td>\n",
       "      <td>-0.004097</td>\n",
       "      <td>-216.0</td>\n",
       "      <td>0.056804</td>\n",
       "      <td>0.093768</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>43950.0</td>\n",
       "      <td>146700.0</td>\n",
       "      <td>3.546562e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>33112.0</td>\n",
       "      <td>33112.0</td>\n",
       "      <td>0.111776</td>\n",
       "      <td>0.138843</td>\n",
       "      <td>32948.0</td>\n",
       "      <td>32948.0</td>\n",
       "      <td>0.110820</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>-0.004953</td>\n",
       "      <td>-164.0</td>\n",
       "      <td>0.452987</td>\n",
       "      <td>0.293321</td>\n",
       "      <td>0.850490</td>\n",
       "      <td>350485.0</td>\n",
       "      <td>458900.0</td>\n",
       "      <td>1.771648e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>16540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16209.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020012</td>\n",
       "      <td>-331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GG</th>\n",
       "      <td>7370.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006920</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>5693.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053048</td>\n",
       "      <td>302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WH</th>\n",
       "      <td>3007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D</th>\n",
       "      <td>2918.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039411</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>2871.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2842.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.010101</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SO</th>\n",
       "      <td>2452.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.033442</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA</th>\n",
       "      <td>2385.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>2224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2576.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>352.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD</th>\n",
       "      <td>2118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010387</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CT</th>\n",
       "      <td>1886.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.143690</td>\n",
       "      <td>-271.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VN</th>\n",
       "      <td>1847.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009204</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WC</th>\n",
       "      <td>1602.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1601.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000624</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM</th>\n",
       "      <td>974.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069815</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UC</th>\n",
       "      <td>822.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>814.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009732</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC</th>\n",
       "      <td>705.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>709.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>647.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>651.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EM</th>\n",
       "      <td>513.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066277</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>342.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.204678</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AM</th>\n",
       "      <td>317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.100946</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.075758</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CE</th>\n",
       "      <td>138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.144928</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RV</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.360000</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SB</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Baseline2018  Baseline2018 BA-SF-VT-AC  Baseline2018 shares  \\\n",
       "SF       96467.0                   96467.0             0.325643   \n",
       "AC       56183.0                   56183.0             0.189657   \n",
       "VT       52724.0                   52724.0             0.177980   \n",
       "BA       33112.0                   33112.0             0.111776   \n",
       "ST       16540.0                       NaN             0.055834   \n",
       "GG        7370.0                       NaN             0.024879   \n",
       "CC        5693.0                       NaN             0.019218   \n",
       "WH        3007.0                       NaN             0.010151   \n",
       "3D        2918.0                       NaN             0.009850   \n",
       "SR        2871.0                       NaN             0.009692   \n",
       "SO        2452.0                       NaN             0.008277   \n",
       "MA        2385.0                       NaN             0.008051   \n",
       "CA        2224.0                       NaN             0.007508   \n",
       "TD        2118.0                       NaN             0.007150   \n",
       "CT        1886.0                       NaN             0.006367   \n",
       "VN        1847.0                       NaN             0.006235   \n",
       "WC        1602.0                       NaN             0.005408   \n",
       "SM         974.0                       NaN             0.003288   \n",
       "UC         822.0                       NaN             0.002775   \n",
       "VC         705.0                       NaN             0.002380   \n",
       "PE         647.0                       NaN             0.002184   \n",
       "EM         513.0                       NaN             0.001732   \n",
       "CM         342.0                       NaN             0.001154   \n",
       "AM         317.0                       NaN             0.001070   \n",
       "SC         198.0                       NaN             0.000668   \n",
       "CE         138.0                       NaN             0.000466   \n",
       "DE         127.0                       NaN             0.000429   \n",
       "RV          25.0                       NaN             0.000084   \n",
       "SB          19.0                       NaN             0.000064   \n",
       "AY           9.0                       NaN             0.000030   \n",
       "\n",
       "    Baseline2018 shares BA-SF-VT-AC  Future2018  Future2018 BA-SF-VT-AC  \\\n",
       "SF                         0.404498     97766.0                 97766.0   \n",
       "AC                         0.235582     56226.0                 56226.0   \n",
       "VT                         0.221078     52508.0                 52508.0   \n",
       "BA                         0.138843     32948.0                 32948.0   \n",
       "ST                              NaN     16209.0                     NaN   \n",
       "GG                              NaN      7319.0                     NaN   \n",
       "CC                              NaN      5995.0                     NaN   \n",
       "WH                              NaN      3050.0                     NaN   \n",
       "3D                              NaN      3033.0                     NaN   \n",
       "SR                              NaN      2842.0                     NaN   \n",
       "SO                              NaN      2370.0                     NaN   \n",
       "MA                              NaN      2393.0                     NaN   \n",
       "CA                              NaN      2576.0                     NaN   \n",
       "TD                              NaN      2140.0                     NaN   \n",
       "CT                              NaN      1615.0                     NaN   \n",
       "VN                              NaN      1864.0                     NaN   \n",
       "WC                              NaN      1601.0                     NaN   \n",
       "SM                              NaN      1042.0                     NaN   \n",
       "UC                              NaN       814.0                     NaN   \n",
       "VC                              NaN       709.0                     NaN   \n",
       "PE                              NaN       651.0                     NaN   \n",
       "EM                              NaN       547.0                     NaN   \n",
       "CM                              NaN       272.0                     NaN   \n",
       "AM                              NaN       285.0                     NaN   \n",
       "SC                              NaN       183.0                     NaN   \n",
       "CE                              NaN       118.0                     NaN   \n",
       "DE                              NaN       182.0                     NaN   \n",
       "RV                              NaN        16.0                     NaN   \n",
       "SB                              NaN        26.0                     NaN   \n",
       "AY                              NaN        12.0                     NaN   \n",
       "\n",
       "    Future2018 shares  Future2018 shares BA-SF-VT-AC  Diff %2018  Diff2018  \\\n",
       "SF           0.328833                       0.408297    0.013466    1299.0   \n",
       "AC           0.189114                       0.234815    0.000765      43.0   \n",
       "VT           0.176609                       0.219288   -0.004097    -216.0   \n",
       "BA           0.110820                       0.137600   -0.004953    -164.0   \n",
       "ST           0.054518                            NaN   -0.020012    -331.0   \n",
       "GG           0.024617                            NaN   -0.006920     -51.0   \n",
       "CC           0.020164                            NaN    0.053048     302.0   \n",
       "WH           0.010259                            NaN    0.014300      43.0   \n",
       "3D           0.010201                            NaN    0.039411     115.0   \n",
       "SR           0.009559                            NaN   -0.010101     -29.0   \n",
       "SO           0.007971                            NaN   -0.033442     -82.0   \n",
       "MA           0.008049                            NaN    0.003354       8.0   \n",
       "CA           0.008664                            NaN    0.158273     352.0   \n",
       "TD           0.007198                            NaN    0.010387      22.0   \n",
       "CT           0.005432                            NaN   -0.143690    -271.0   \n",
       "VN           0.006270                            NaN    0.009204      17.0   \n",
       "WC           0.005385                            NaN   -0.000624      -1.0   \n",
       "SM           0.003505                            NaN    0.069815      68.0   \n",
       "UC           0.002738                            NaN   -0.009732      -8.0   \n",
       "VC           0.002385                            NaN    0.005674       4.0   \n",
       "PE           0.002190                            NaN    0.006182       4.0   \n",
       "EM           0.001840                            NaN    0.066277      34.0   \n",
       "CM           0.000915                            NaN   -0.204678     -70.0   \n",
       "AM           0.000959                            NaN   -0.100946     -32.0   \n",
       "SC           0.000616                            NaN   -0.075758     -15.0   \n",
       "CE           0.000397                            NaN   -0.144928     -20.0   \n",
       "DE           0.000612                            NaN    0.433071      55.0   \n",
       "RV           0.000054                            NaN   -0.360000      -9.0   \n",
       "SB           0.000087                            NaN    0.368421       7.0   \n",
       "AY           0.000040                            NaN    0.333333       3.0   \n",
       "\n",
       "    clipper BA-SF-VT-AC 2016 share target  MTC BA-SF-VT-AC 2016 share target  \\\n",
       "SF                               0.379971                           0.496644   \n",
       "AC                               0.110238                           0.116267   \n",
       "VT                               0.056804                           0.093768   \n",
       "BA                               0.452987                           0.293321   \n",
       "ST                                    NaN                                NaN   \n",
       "GG                                    NaN                                NaN   \n",
       "CC                                    NaN                                NaN   \n",
       "WH                                    NaN                                NaN   \n",
       "3D                                    NaN                                NaN   \n",
       "SR                                    NaN                                NaN   \n",
       "SO                                    NaN                                NaN   \n",
       "MA                                    NaN                                NaN   \n",
       "CA                                    NaN                                NaN   \n",
       "TD                                    NaN                                NaN   \n",
       "CT                                    NaN                                NaN   \n",
       "VN                                    NaN                                NaN   \n",
       "WC                                    NaN                                NaN   \n",
       "SM                                    NaN                                NaN   \n",
       "UC                                    NaN                                NaN   \n",
       "VC                                    NaN                                NaN   \n",
       "PE                                    NaN                                NaN   \n",
       "EM                                    NaN                                NaN   \n",
       "CM                                    NaN                                NaN   \n",
       "AM                                    NaN                                NaN   \n",
       "SC                                    NaN                                NaN   \n",
       "CE                                    NaN                                NaN   \n",
       "DE                                    NaN                                NaN   \n",
       "RV                                    NaN                                NaN   \n",
       "SB                                    NaN                                NaN   \n",
       "AY                                    NaN                                NaN   \n",
       "\n",
       "    NTD BA-SF-VT-AC 2019 share target  \\\n",
       "SF                           0.107022   \n",
       "AC                           0.025463   \n",
       "VT                           0.017025   \n",
       "BA                           0.850490   \n",
       "ST                                NaN   \n",
       "GG                                NaN   \n",
       "CC                                NaN   \n",
       "WH                                NaN   \n",
       "3D                                NaN   \n",
       "SR                                NaN   \n",
       "SO                                NaN   \n",
       "MA                                NaN   \n",
       "CA                                NaN   \n",
       "TD                                NaN   \n",
       "CT                                NaN   \n",
       "VN                                NaN   \n",
       "WC                                NaN   \n",
       "SM                                NaN   \n",
       "UC                                NaN   \n",
       "VC                                NaN   \n",
       "PE                                NaN   \n",
       "EM                                NaN   \n",
       "CM                                NaN   \n",
       "AM                                NaN   \n",
       "SC                                NaN   \n",
       "CE                                NaN   \n",
       "DE                                NaN   \n",
       "RV                                NaN   \n",
       "SB                                NaN   \n",
       "AY                                NaN   \n",
       "\n",
       "    clipper BA-SF-VT-AC 2020 Jan av ridership target  \\\n",
       "SF                                          293991.0   \n",
       "AC                                           85293.0   \n",
       "VT                                           43950.0   \n",
       "BA                                          350485.0   \n",
       "ST                                               NaN   \n",
       "GG                                               NaN   \n",
       "CC                                               NaN   \n",
       "WH                                               NaN   \n",
       "3D                                               NaN   \n",
       "SR                                               NaN   \n",
       "SO                                               NaN   \n",
       "MA                                               NaN   \n",
       "CA                                               NaN   \n",
       "TD                                               NaN   \n",
       "CT                                               NaN   \n",
       "VN                                               NaN   \n",
       "WC                                               NaN   \n",
       "SM                                               NaN   \n",
       "UC                                               NaN   \n",
       "VC                                               NaN   \n",
       "PE                                               NaN   \n",
       "EM                                               NaN   \n",
       "CM                                               NaN   \n",
       "AM                                               NaN   \n",
       "SC                                               NaN   \n",
       "CE                                               NaN   \n",
       "DE                                               NaN   \n",
       "RV                                               NaN   \n",
       "SB                                               NaN   \n",
       "AY                                               NaN   \n",
       "\n",
       "    MTC BA-SF-VT-AC 2016 av ridership target  \\\n",
       "SF                                  777000.0   \n",
       "AC                                  181900.0   \n",
       "VT                                  146700.0   \n",
       "BA                                  458900.0   \n",
       "ST                                       NaN   \n",
       "GG                                       NaN   \n",
       "CC                                       NaN   \n",
       "WH                                       NaN   \n",
       "3D                                       NaN   \n",
       "SR                                       NaN   \n",
       "SO                                       NaN   \n",
       "MA                                       NaN   \n",
       "CA                                       NaN   \n",
       "TD                                       NaN   \n",
       "CT                                       NaN   \n",
       "VN                                       NaN   \n",
       "WC                                       NaN   \n",
       "SM                                       NaN   \n",
       "UC                                       NaN   \n",
       "VC                                       NaN   \n",
       "PE                                       NaN   \n",
       "EM                                       NaN   \n",
       "CM                                       NaN   \n",
       "AM                                       NaN   \n",
       "SC                                       NaN   \n",
       "CE                                       NaN   \n",
       "DE                                       NaN   \n",
       "RV                                       NaN   \n",
       "SB                                       NaN   \n",
       "AY                                       NaN   \n",
       "\n",
       "    NTD BA-SF-VT-AC 2019 ridership target  \n",
       "SF                           2.229369e+08  \n",
       "AC                           5.304148e+07  \n",
       "VT                           3.546562e+07  \n",
       "BA                           1.771648e+09  \n",
       "ST                                    NaN  \n",
       "GG                                    NaN  \n",
       "CC                                    NaN  \n",
       "WH                                    NaN  \n",
       "3D                                    NaN  \n",
       "SR                                    NaN  \n",
       "SO                                    NaN  \n",
       "MA                                    NaN  \n",
       "CA                                    NaN  \n",
       "TD                                    NaN  \n",
       "CT                                    NaN  \n",
       "VN                                    NaN  \n",
       "WC                                    NaN  \n",
       "SM                                    NaN  \n",
       "UC                                    NaN  \n",
       "VC                                    NaN  \n",
       "PE                                    NaN  \n",
       "EM                                    NaN  \n",
       "CM                                    NaN  \n",
       "AM                                    NaN  \n",
       "SC                                    NaN  \n",
       "CE                                    NaN  \n",
       "DE                                    NaN  \n",
       "RV                                    NaN  \n",
       "SB                                    NaN  \n",
       "AY                                    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "RA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bde3697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF:18608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4216.0</td>\n",
       "      <td>0.01418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "SF:18608           NaN                  NaN      4216.0            0.01418"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR[RR.index=='SF:18608']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "767bfe89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC:1-142</th>\n",
       "      <td>2182.0</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "AC:1-142        2182.0             0.007366         NaN                NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "RR[RR.index.str.contains('AC:1-142')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30422d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AC:1T-142</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>0.008866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "AC:1T-142           NaN                  NaN      2636.0           0.008866"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "RR[RR.index.str.contains('AC:1T-142')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b5b429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CA:12868</th>\n",
       "      <td>1157.0</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>1293.0</td>\n",
       "      <td>0.004349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA:12869</th>\n",
       "      <td>679.0</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>872.0</td>\n",
       "      <td>0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA:12867</th>\n",
       "      <td>388.0</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>411.0</td>\n",
       "      <td>0.001382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "CA:12868        1157.0             0.003906      1293.0           0.004349\n",
       "CA:12869         679.0             0.002292       872.0           0.002933\n",
       "CA:12867         388.0             0.001310       411.0           0.001382"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "RR[RR.index.str.contains('CA:')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630c2979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF:1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1626.0</td>\n",
       "      <td>0.005469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "SF:1000           NaN                  NaN      1626.0           0.005469"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "RR[RR.index.str.contains('SF:1000')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21ac6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF:12475</th>\n",
       "      <td>2368.0</td>\n",
       "      <td>0.007994</td>\n",
       "      <td>2347.0</td>\n",
       "      <td>0.007894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "SF:12475        2368.0             0.007994      2347.0           0.007894"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#The Central Subway Project will improve public transportation in San Francisco by extending the Muni Metro T Third Line through SoMa\n",
    "\n",
    "#J\n",
    "RR[RR.index.str.contains('SF:12475')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4285dbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF:12476</th>\n",
       "      <td>4202.0</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>0.01416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "SF:12476        4202.0             0.014185      4210.0            0.01416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#K/T\n",
    "RR[RR.index.str.contains('SF:12476')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11556a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF:12477</th>\n",
       "      <td>3148.0</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>0.010629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "SF:12477        3148.0             0.010627      3160.0           0.010629"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#L\n",
    "RR[RR.index.str.contains('SF:12477')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a0d28f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF:12478</th>\n",
       "      <td>3147.0</td>\n",
       "      <td>0.010623</td>\n",
       "      <td>3204.0</td>\n",
       "      <td>0.010777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "SF:12478        3147.0             0.010623      3204.0           0.010777"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#M\n",
    "RR[RR.index.str.contains('SF:12478')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5367c92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline2018</th>\n",
       "      <th>Baseline2018 shares</th>\n",
       "      <th>Future2018</th>\n",
       "      <th>Future2018 shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF:12479</th>\n",
       "      <td>4310.0</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>4414.0</td>\n",
       "      <td>0.014846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Baseline2018  Baseline2018 shares  Future2018  Future2018 shares\n",
       "SF:12479        4310.0             0.014549      4414.0           0.014846"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#N\n",
    "RR[RR.index.str.contains('SF:12479')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95215ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total SF light rail baseline2018 17175.0\n",
      "total SF light rail future2018 18961.0\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    \n",
    "    print('total SF light rail baseline'+year,\n",
    "         (list(RR[RR.index.str.contains('SF:12475')]['Baseline'+year])[0]+\n",
    "          list(RR[RR.index.str.contains('SF:12476')]['Baseline'+year])[0]+\n",
    "          list(RR[RR.index.str.contains('SF:12477')]['Baseline'+year])[0]+\n",
    "          list(RR[RR.index.str.contains('SF:12478')]['Baseline'+year])[0]+\n",
    "          list(RR[RR.index.str.contains('SF:12479')]['Baseline'+year])[0])\n",
    "         )\n",
    "    print('total SF light rail future'+year,\n",
    "         (list(RR[RR.index.str.contains('SF:12475')]['Future'+year])[0]+\n",
    "          list(RR[RR.index.str.contains('SF:12476')]['Future'+year])[0]+\n",
    "          list(RR[RR.index.str.contains('SF:12477')]['Future'+year])[0]+\n",
    "          list(RR[RR.index.str.contains('SF:12478')]['Future'+year])[0]+\n",
    "          list(RR[RR.index.str.contains('SF:12479')]['Future'+year])[0]+\n",
    "          list(RR[RR.index.str.contains('SF:1000')]['Future'+year])[0])\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b6fb7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/700297135.py:15: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PtoPTss_baseline = pd.read_csv(fp_PtoPTss_baseline)\n",
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_71528/700297135.py:17: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  PtoPTss_TR = pd.read_csv(fp_PtoPTss_future)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m PtoPTss_TR \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fp_PtoPTss_future)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print('read plans baseline',dataFilepath_sim[index_baseline][:-13]+'plans.csv.gz')\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m plans_baseline \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mdataFilepath_sim\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex_baseline\u001b[49m\u001b[43m]\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m13\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplans.csv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print('read plans TR', dataFilepath_sim[index_future][:-13]+'plans.csv.gz')\u001b[39;00m\n\u001b[1;32m     21\u001b[0m plans_TR \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(dataFilepath_sim[index_future][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m13\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplans.csv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "#########Analysis of what agents used in the baseline\n",
    "index_baseline =6 \n",
    "index_future =7\n",
    "fp_PtoPTss_baseline = '/Users/cpoliziani/Downloads/personToVehicles.csv.gz'\n",
    "fp_PtoPTss_future = '/Users/cpoliziani/Downloads/personToVehicles (1).csv.gz'\n",
    "\n",
    "# print('read PtoPTss baseline',fp_PtoPTss_baseline)\n",
    "PtoPTss_baseline = pd.read_csv(fp_PtoPTss_baseline)\n",
    "# print('read PtoPTss TR', fp_PtoPTss_future)\n",
    "PtoPTss_TR = pd.read_csv(fp_PtoPTss_future)\n",
    "# print('read plans baseline',dataFilepath_sim[index_baseline][:-13]+'plans.csv.gz')\n",
    "plans_baseline = pd.read_csv(dataFilepath_sim[index_baseline][:-13]+'plans.csv.gz')\n",
    "# print('read plans TR', dataFilepath_sim[index_future][:-13]+'plans.csv.gz')\n",
    "plans_TR = pd.read_csv(dataFilepath_sim[index_future][:-13]+'plans.csv.gz')\n",
    "# print('read GTFS trips fpr AC, SF and CA')\n",
    "line_1T_trips_TR = pd.read_csv(GTFS_AC2+'trips.txt')\n",
    "line_1T_trips_TR = line_1T_trips_TR[line_1T_trips_TR['route_id'].str.contains('1T-142')]\n",
    "line_CS_trips_TR = pd.read_csv(GTFS_SF2+'trips.txt')\n",
    "line_CS_trips_TR = line_CS_trips_TR[line_CS_trips_TR['route_id']==1000]\n",
    "line_CA_trips_TR = pd.read_csv(GTFS_Caltrain2+'trips.txt')\n",
    "# print('read mode choice')\n",
    "mode_choice_baseline = pd.read_csv(dataFilepath_sim[index_baseline])\n",
    "mode_choice_TR = pd.read_csv(dataFilepath_sim[index_future])\n",
    "mode_choice_baseline = mode_choice_baseline[mode_choice_baseline['type']=='ModeChoice']\n",
    "mode_choice_TR = mode_choice_TR[mode_choice_TR['type']=='ModeChoice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "PtoPTss_AC_TR = PtoPTss_TR[PtoPTss_TR['vehicle2'].str.contains('AC', na=False)]\n",
    "PtoPTss_SF_TR = PtoPTss_TR[PtoPTss_TR['vehicle2'].str.contains('SF', na=False)]\n",
    "PtoPTss_CA_TR = PtoPTss_TR[PtoPTss_TR['vehicle2'].str.contains('Ca', na=False)]\n",
    "\n",
    "#Filter SF trips - CS only\n",
    "is_CS = []\n",
    "vehicles = list(line_CS_trips_TR['trip_id'])\n",
    "for vehicle in PtoPTss_SF_TR['vehicleID']:\n",
    "    if int(vehicle[3:]) in vehicles:\n",
    "        is_CS.append(True)\n",
    "    else:\n",
    "        is_CS.append(False)\n",
    "print('Filter CS trips [tot, remained]',len(is_CS),sum(is_CS))\n",
    "PtoPTss_SF_TR['is_CS'] = is_CS\n",
    "PtoPTss_SF_TR = PtoPTss_SF_TR[PtoPTss_SF_TR['is_CS']==True]\n",
    "\n",
    "\n",
    "is_AC = []\n",
    "vehicles = list(line_1T_trips_TR['trip_id'])\n",
    "for vehicle in PtoPTss_AC_TR['vehicleID']:\n",
    "    if int(vehicle[3:]) in vehicles:\n",
    "        is_AC.append(True)\n",
    "    else:\n",
    "        is_AC.append(False)\n",
    "print('Filter 1T trips [tot, remained]',len(is_AC),sum(is_AC))\n",
    "PtoPTss_AC_TR['is_AC'] = is_AC\n",
    "PtoPTss_AC_TR = PtoPTss_AC_TR[PtoPTss_AC_TR['is_AC']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_baseline = pd.DataFrame()\n",
    "i = 0\n",
    "trips_TR = pd.concat([line_CA_trips_TR['trip_id'],line_CS_trips_TR['trip_id'],line_1T_trips_TR['trip_id']])\n",
    "##############################\n",
    "# PtoPTss_TR2=pd.concat([PtoPTss_AC_TR,PtoPTss_SF_TR,PtoPTss_CA_TR])\n",
    "# PtoPTss_TR2_dict = PtoPTss.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "#                                                     sum(x.duration)]).to_dict()\n",
    "# print(len(PtoPTss_CA_TR))\n",
    "PtoPTss_TR_CA_dict = PtoPTss_CA_TR.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "                                                    sum(x.duration)]).to_dict()\n",
    "# print(len(PtoPTss_TR_CA_dict.keys()))\n",
    "# print(len(PtoPTss_SF_TR))\n",
    "PtoPTss_TR_SF_dict = PtoPTss_SF_TR.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "                                                    sum(x.duration)]).to_dict()\n",
    "# print(len(PtoPTss_TR_SF_dict.keys()))\n",
    "# print(len(PtoPTss_AC_TR))\n",
    "PtoPTss_TR_AC_dict = PtoPTss_AC_TR.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "                                                    sum(x.duration)]).to_dict()\n",
    "# print(len(PtoPTss_TR_AC_dict.keys()))\n",
    "# print(len(PtoPTss_baseline))\n",
    "PtoPTss_baseline_dict = PtoPTss_baseline.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "                                                    sum(x.duration)]).to_dict()\n",
    "# print(len(PtoPTss_baseline_dict.keys()))\n",
    "# print(len(PtoPTss_TR))\n",
    "PtoPTss_TR_dict = PtoPTss_TR.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "                                                sum(x.duration)]).to_dict()\n",
    "print(len(PtoPTss_TR_dict.keys()))\n",
    "\n",
    "\n",
    "#Add logsum\n",
    "person_trips_baseline = pd.read_csv('/Users/cpoliziani/Downloads/tourTripsMerged_Baseline.csv')\n",
    "person_trips_baseline['trip_num']=person_trips_baseline['trip_num']*2-1\n",
    "person_trips_TR = pd.read_csv('/Users/cpoliziani/Downloads/tourTripsMerged_TR.csv')\n",
    "person_trips_TR['trip_num']=person_trips_TR['trip_num']*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ed8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addGeometryIdToDataFrame(df, gdf, xcol, ycol, idColumn=\"geometry\", df_geom='epsg:32610'): \n",
    "    gdf.set_crs(epsg = \"3310\", inplace = True)\n",
    "    gdf_data = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[xcol], df[ycol]))\n",
    "    gdf_data.set_crs(epsg = \"32610\", inplace = True)\n",
    "    joined = gpd.sjoin(gdf_data.to_crs('epsg:26910'), gdf.to_crs('epsg:26910'))\n",
    "    gdf_data = gdf_data.merge(joined['ZCTA'], left_index=True, right_index=True, how=\"left\")\n",
    "    gdf_data.rename(columns={'ZCTA': idColumn}, inplace=True)\n",
    "    df = pd.DataFrame(gdf_data.drop(columns='geometry'))\n",
    "#     df.drop(columns=[xcol, ycol], inplace=True)\n",
    "    return df.loc[~df.index.duplicated(keep='first'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30faf0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_baseline = pd.DataFrame(columns = ['Person',\n",
    "                                           'Plan Index',\n",
    "                                           'Planned Depart Time Baseline',\n",
    "                                           'Planned Depart Time TR',\n",
    "                                           'Activity From Baseline',\n",
    "                                           'Activity To Baseline',\n",
    "                                           'Activity From TR',\n",
    "                                           'Activity To TR',\n",
    "                                           'Project Tried',\n",
    "                                           'Vehicles Used Baseline',\n",
    "                                           'Vehicle Types Used Baseline',                                          \n",
    "                                           'Bus agencies Used Baseline',\n",
    "                                           'First Bus agency Used Baseline',\n",
    "                                           'Vehicles Used TR',\n",
    "                                           'Vehicle Types Used TR',                                          \n",
    "                                           'Bus agencies Used TR',\n",
    "                                           'First Bus agency Used TR',\n",
    "                                           'Switch From',\n",
    "                                           'Trip Length Baseline',                       \n",
    "                                           'Trip Duration Baseline',\n",
    "                                           'Trip Length TR',\n",
    "                                           'Trip Duration TR',\n",
    "                                           'Diff Length',\n",
    "                                           'Diff Duration',\n",
    "                                           'Planned Mode Baseline',                                         \n",
    "                                           'Planned Mode TR',                                          \n",
    "                                           'Chosen Mode Baseline',                                          \n",
    "                                           'Chosen Mode TR',\n",
    "                                           'X Activity From TR',\n",
    "                                           'Y Activity From TR',\n",
    "                                           'X Activity To TR',\n",
    "                                           'Y Activity To TR',\n",
    "                                           'X Activity From Baseline',\n",
    "                                           'Y Activity From Baseline',\n",
    "                                           'X Activity To Baseline',\n",
    "                                           'Y Activity To Baseline',\n",
    "                                           'Log Sum Baseline',\n",
    "                                           'Log Sum TR',\n",
    "                                           'Diff Log Sum',\n",
    "#                                            'ZIP Departure TR',                                          \n",
    "#                                            'ZIP Arrival TR',                                          \n",
    "#                                            'ZIP Departure Baseline',                                          \n",
    "#                                            'ZIP Arrival Baseline',                                          \n",
    "                                          ])\n",
    "\n",
    "PtoPTss_baseline_bus =  PtoPTss_baseline[(PtoPTss_baseline['mode'] =='bus')|\n",
    "                                         (PtoPTss_baseline['mode'] =='subway')|\n",
    "                                         (PtoPTss_baseline['mode'] =='tram')|\n",
    "                                         (PtoPTss_baseline['mode'] =='rail')|\n",
    "                                         (PtoPTss_baseline['mode'] =='cable_car')|\n",
    "                                         (PtoPTss_baseline['mode'] =='ferry')]\n",
    "PtoPTss_TR_bus =  PtoPTss_TR[(PtoPTss_TR['mode'] =='bus')|\n",
    "                                         (PtoPTss_TR['mode'] =='subway')|\n",
    "                                         (PtoPTss_TR['mode'] =='tram')|\n",
    "                                         (PtoPTss_TR['mode'] =='rail')|\n",
    "                                         (PtoPTss_TR['mode'] =='cable_car')|\n",
    "                                         (PtoPTss_TR['mode'] =='ferry')]   \n",
    "print(len(PtoPTss_TR_SF_dict))\n",
    "print(len(PtoPTss_TR_CA_dict))\n",
    "print(len(PtoPTss_TR_AC_dict))\n",
    "\n",
    "\n",
    "i=0      \n",
    "for row in PtoPTss_TR_SF_dict.keys():\n",
    "    i+=1\n",
    "    if i%50==0:\n",
    "        print(i)\n",
    "        \n",
    "    try:\n",
    "        persons_baseline.at[i,'Person'] = row[0]\n",
    "    except:\n",
    "        print('Warning', row, 'person')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Plan Index'] = int(row[1])\n",
    "    except:\n",
    "        print('Warning', row, 'plan_index')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity From Baseline'] = list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity From Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity To Baseline'] = list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity To Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity From TR'] = list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity From TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity To TR'] = list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity To TR')  \n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Depart Time Baseline'] = int(list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0])\n",
    "    except:\n",
    "        print('Warning', row, 'plan_dep_time_baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Depart Time TR'] = int(list(plans_TR['activityEndTime'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0])\n",
    "    except:\n",
    "        print('Warning', row, 'plan_dep_time_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Project Tried'] = 'SF - Central Subway'\n",
    "    except:\n",
    "        print('Warning', row, 'project tried')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Log Sum Baseline'] = np.mean(list(person_trips_baseline['mode_choice_logsum_y'][(person_trips_baseline['person_id']==row[0])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Log Sum Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Log Sum TR'] = np.mean(list(person_trips_TR['mode_choice_logsum_y'][(person_trips_TR['person_id']==row[0])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Log Sum TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Diff Log Sum'] = persons_baseline.at[i,'Log Sum TR']-persons_baseline.at[i,'Log Sum Baseline']\n",
    "    except:\n",
    "        print('Warning', row, 'Diff Log Sum')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicles Used Baseline'] = np.unique(list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicles Used Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicles Used TR'] = np.unique(list(PtoPTss_TR['vehicleID'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicles Used TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Bus agencies Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Bus agencies Used Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Bus agencies Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Bus agencies Used TR') \n",
    "    try:\n",
    "        persons_baseline.at[i,'First Bus agency Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))[0]\n",
    "    except:\n",
    "        print('Warning', row, 'First Bus agency Used Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'First Bus agency Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))[0]\n",
    "    except:\n",
    "        print('Warning', row, 'First Bus agency Used TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Length TR'] = int(PtoPTss_TR_dict[row][0])\n",
    "    except:\n",
    "        print('Warning', row, 'TR_length')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Duration TR'] = int(PtoPTss_TR_dict[row][1])\n",
    "    except:\n",
    "        print('Warning', row, 'TR_duration')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Length Baseline'] = int(PtoPTss_baseline_dict[row][0])\n",
    "    except:\n",
    "        print('Warning', row, 'baseline_length')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Duration Baseline'] = int(PtoPTss_baseline_dict[row][1])\n",
    "    except:\n",
    "        print('Warning', row, 'baseline_duration')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Diff Length'] = int(persons_baseline.at[i,'Trip Length TR']-persons_baseline.at[i,'Trip Length Baseline'])\n",
    "    except:\n",
    "        print('Warning', row, 'diff_length')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Diff Duration'] = int(persons_baseline.at[i,'Trip Duration TR']-persons_baseline.at[i,'Trip Duration Baseline'])\n",
    "    except:\n",
    "        print('Warning', row, 'diff_duration')\n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity From TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_from_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity From TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_From_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity To TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_To_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity To TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_To_TR')   \n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity From Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_from_Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity From Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_From_Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity To Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_To_Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity To Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_To_Baseline')   \n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicle Types Used Baseline'] = np.unique(list(PtoPTss_baseline['mode'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicle Types Used baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicle Types Used TR'] = np.unique(list(PtoPTss_TR['mode'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicle Types Used TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Mode Baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Baseline planned mode')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Mode TR'] = list(plans_TR['legMode'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1])])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'TR planned mode')\n",
    "    try:\n",
    "        plan_dep_time_baseline = list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "        persons_baseline.at[i,'Chosen Mode Baseline'] = list(mode_choice_baseline['mode'][(mode_choice_baseline['person']==row[0])&(mode_choice_baseline['time']>=plan_dep_time_baseline-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'mode_choice_baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Chosen Mode TR'] = list(mode_choice_TR['mode'][(mode_choice_TR['person']==row[0])&(mode_choice_TR['time']>=persons_baseline.at[i,'Planned Depart Time TR']-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'mode_choice_TR')\n",
    "        \n",
    "####################################\n",
    "for row in PtoPTss_TR_CA_dict.keys():\n",
    "    i+=1\n",
    "    if i%10==0:\n",
    "        print(i)\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        persons_baseline.at[i,'Person'] = row[0]\n",
    "    except:\n",
    "        print('Warning', row, 'person')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Plan Index'] = int(row[1])\n",
    "    except:\n",
    "        print('Warning', row, 'plan_index')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity From Baseline'] = list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity From Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity To Baseline'] = list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity To Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity From TR'] = list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity From TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity To TR'] = list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity To TR')  \n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Depart Time Baseline'] = int(list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0])\n",
    "    except:\n",
    "        print('Warning', row, 'plan_dep_time_baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Depart Time TR'] = int(list(plans_TR['activityEndTime'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0])\n",
    "    except:\n",
    "        print('Warning', row, 'plan_dep_time_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Project Tried'] = 'CA - Electrification Project'\n",
    "    except:\n",
    "        print('Warning', row, 'project tried')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Log Sum Baseline'] = np.mean(list(person_trips_baseline['mode_choice_logsum_y'][(person_trips_baseline['person_id']==row[0])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Log Sum Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Log Sum TR'] = np.mean(list(person_trips_TR['mode_choice_logsum_y'][(person_trips_TR['person_id']==row[0])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Log Sum TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Diff Log Sum'] = persons_baseline.at[i,'Log Sum TR']-persons_baseline.at[i,'Log Sum Baseline']\n",
    "    except:\n",
    "        print('Warning', row, 'Diff Log Sum')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicles Used Baseline'] = np.unique(list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicles Used Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicles Used TR'] = np.unique(list(PtoPTss_TR['vehicleID'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicles Used TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Bus agencies Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Bus agencies Used Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Bus agencies Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Bus agencies Used TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'First Bus agency Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))[0]\n",
    "    except:\n",
    "        print('Warning', row, 'First Bus agency Used Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'First Bus agency Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))[0]\n",
    "    except:\n",
    "        print('Warning', row, 'First Bus agency Used TR')  \n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Length TR'] = int(PtoPTss_TR_dict[row][0])\n",
    "    except:\n",
    "        print('Warning', row, 'TR_length')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Duration TR'] = int(PtoPTss_TR_dict[row][1])\n",
    "    except:\n",
    "        print('Warning', row, 'TR_duration')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Length Baseline'] = int(PtoPTss_baseline_dict[row][0])\n",
    "    except:\n",
    "        print('Warning', row, 'baseline_length')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Duration Baseline'] = int(PtoPTss_baseline_dict[row][1])\n",
    "    except:\n",
    "        print('Warning', row, 'baseline_duration')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Diff Length'] = int(persons_baseline.at[i,'Trip Length TR']-persons_baseline.at[i,'Trip Length Baseline'])\n",
    "    except:\n",
    "        print('Warning', row, 'diff_length')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Diff Duration'] = int(persons_baseline.at[i,'Trip Duration TR']-persons_baseline.at[i,'Trip Duration Baseline'])\n",
    "    except:\n",
    "        print('Warning', row, 'diff_duration')\n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity From TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_from_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity From TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_From_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity To TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_To_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity To TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_To_TR')   \n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity From Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_from_Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity From Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_From_Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity To Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_To_Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity To Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_To_Baseline')   \n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicle Types Used Baseline'] = np.unique(list(PtoPTss_baseline['mode'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicle Types Used baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicle Types Used TR'] = np.unique(list(PtoPTss_TR['mode'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicle Types Used TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Mode Baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Baseline planned mode')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Mode TR'] = list(plans_TR['legMode'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1])])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'TR planned mode')\n",
    "    try:\n",
    "        plan_dep_time_baseline = list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "        persons_baseline.at[i,'Chosen Mode Baseline'] = list(mode_choice_baseline['mode'][(mode_choice_baseline['person']==row[0])&(mode_choice_baseline['time']>=plan_dep_time_baseline-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'mode_choice_baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Chosen Mode TR'] = list(mode_choice_TR['mode'][(mode_choice_TR['person']==row[0])&(mode_choice_TR['time']>=persons_baseline.at[i,'Planned Depart Time TR']-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'mode_choice_TR')\n",
    "        \n",
    "####################################\n",
    "for row in PtoPTss_TR_AC_dict.keys():\n",
    "    i+=1\n",
    "    if i%10==0:\n",
    "        print(i) \n",
    "        \n",
    "        \n",
    "    try:\n",
    "        persons_baseline.at[i,'Person'] = row[0]\n",
    "    except:\n",
    "        print('Warning', row, 'person')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Plan Index'] = int(row[1])\n",
    "    except:\n",
    "        print('Warning', row, 'plan_index')    \n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity From Baseline'] = list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity From Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity To Baseline'] = list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity To Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity From TR'] = list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity From TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Activity To TR'] = list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Activity To TR')   \n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Depart Time Baseline'] = int(list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0])\n",
    "    except:\n",
    "        print('Warning', row, 'plan_dep_time_baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Depart Time TR'] = int(list(plans_TR['activityEndTime'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0])\n",
    "    except:\n",
    "        print('Warning', row, 'plan_dep_time_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Project Tried'] = 'AC - 1TEMPO'\n",
    "    except:\n",
    "        print('Warning', row, 'project tried')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Log Sum Baseline'] = np.mean(list(person_trips_baseline['mode_choice_logsum_y'][(person_trips_baseline['person_id']==row[0])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Log Sum Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Log Sum TR'] = np.mean(list(person_trips_TR['mode_choice_logsum_y'][(person_trips_TR['person_id']==row[0])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Log Sum TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Diff Log Sum'] = persons_baseline.at[i,'Log Sum TR']-persons_baseline.at[i,'Log Sum Baseline']\n",
    "    except:\n",
    "        print('Warning', row, 'Diff Log Sum')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicles Used Baseline'] = np.unique(list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicles Used Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicles Used TR'] = np.unique(list(PtoPTss_TR['vehicleID'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicles Used TR')    \n",
    "    try:\n",
    "        persons_baseline.at[i,'Bus agencies Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Bus agencies Used Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Bus agencies Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Bus agencies Used TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'First Bus agency Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))[0]\n",
    "    except:\n",
    "        print('Warning', row, 'First Bus agency Used Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'First Bus agency Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))[0]\n",
    "    except:\n",
    "        print('Warning', row, 'First Bus agency Used TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Length TR'] = int(PtoPTss_TR_dict[row][0])\n",
    "    except:\n",
    "        print('Warning', row, 'TR_length')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Duration TR'] = int(PtoPTss_TR_dict[row][1])\n",
    "    except:\n",
    "        print('Warning', row, 'TR_duration')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Length Baseline'] = int(PtoPTss_baseline_dict[row][0])\n",
    "    except:\n",
    "        print('Warning', row, 'baseline_length')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Trip Duration Baseline'] = int(PtoPTss_baseline_dict[row][1])\n",
    "    except:\n",
    "        print('Warning', row, 'baseline_duration')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Diff Length'] = int(persons_baseline.at[i,'Trip Length TR']-persons_baseline.at[i,'Trip Length Baseline'])\n",
    "    except:\n",
    "        print('Warning', row, 'diff_length')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Diff Duration'] = int(persons_baseline.at[i,'Trip Duration TR']-persons_baseline.at[i,'Trip Duration Baseline'])\n",
    "    except:\n",
    "        print('Warning', row, 'diff_duration')\n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity From TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_from_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity From TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_From_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity To TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_To_TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity To TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_To_TR')   \n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity From Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_from_Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity From Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_From_Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'X Activity To Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'x_activity_To_Baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Y Activity To Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'y_activity_To_Baseline')   \n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicle Types Used Baseline'] = np.unique(list(PtoPTss_baseline['mode'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicle Types Used baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Vehicle Types Used TR'] = np.unique(list(PtoPTss_TR['mode'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "    except:\n",
    "        print('Warning', row, 'Vehicle Types Used TR')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Mode Baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'Baseline planned mode')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Planned Mode TR'] = list(plans_TR['legMode'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1])])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'TR planned mode')\n",
    "    try:\n",
    "        plan_dep_time_baseline = list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "        persons_baseline.at[i,'Chosen Mode Baseline'] = list(mode_choice_baseline['mode'][(mode_choice_baseline['person']==row[0])&(mode_choice_baseline['time']>=plan_dep_time_baseline-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'mode_choice_baseline')\n",
    "    try:\n",
    "        persons_baseline.at[i,'Chosen Mode TR'] = list(mode_choice_TR['mode'][(mode_choice_TR['person']==row[0])&(mode_choice_TR['time']>=persons_baseline.at[i,'Planned Depart Time TR']-1)])[0]\n",
    "    except:\n",
    "        print('Warning', row, 'mode_choice_TR')\n",
    "\n",
    "        \n",
    "zipcode = gpd.read_file('/Users/cpoliziani/Downloads/TAZ to ZIP/ZCTA2010.shp')\n",
    "persons_baseline = addGeometryIdToDataFrame(persons_baseline, zipcode, 'X Activity From TR', 'Y Activity From TR', 'ZIP Departure TR')\n",
    "persons_baseline = addGeometryIdToDataFrame(persons_baseline, zipcode, 'X Activity To TR', 'Y Activity To TR', 'ZIP Arrival TR')\n",
    "persons_baseline = addGeometryIdToDataFrame(persons_baseline, zipcode, 'X Activity From Baseline', 'Y Activity From Baseline', 'ZIP Departure Baseline')\n",
    "persons_baseline = addGeometryIdToDataFrame(persons_baseline, zipcode, 'X Activity To Baseline', 'Y Activity To Baseline', 'ZIP Arrival Baseline')\n",
    "\n",
    "\n",
    "#Add Switch From Column\n",
    "switch_type = []\n",
    "for agencies_baseline, project in zip(persons_baseline['Bus agencies Used Baseline'],persons_baseline['Project Tried']):\n",
    "    if len(agencies_baseline) == 0:\n",
    "        switch_type.append('Switch from another mode')\n",
    "    elif project == 'SF - Central Subway' and 'SF' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    elif project == 'AC - 1TEMPO' and 'AC' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    elif project == 'CA - Electrification Project' and 'ca' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    else:\n",
    "        switch_type.append('Switch from another transit agency')\n",
    "\n",
    "persons_baseline['Switch From'] = switch_type\n",
    "\n",
    "persons_baseline.to_csv('/Users/cpoliziani/Downloads/person_database.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcac523",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_type = []\n",
    "for agencies_baseline, project in zip(persons_baseline['Bus agencies Used Baseline'],persons_baseline['Project Tried']):\n",
    "    if len(agencies_baseline) == 0:\n",
    "        switch_type.append('Switch from another mode')\n",
    "    elif project == 'SF - Central Subway' and 'SF' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    elif project == 'AC - 1TEMPO' and 'AC' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    elif project == 'CA - Electrification Project' and 'ca' in agencies_baseline:\n",
    "        switch_type.append('Switch from same transit agency')\n",
    "    else:\n",
    "        switch_type.append('Switch from another transit agency')\n",
    "\n",
    "persons_baseline['Switch From'] = switch_type\n",
    "\n",
    "persons_baseline.to_csv('/Users/cpoliziani/Downloads/person_database.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951faecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_trips_baseline = pd.read_csv('/Users/cpoliziani/Downloads/tourTripsMerged_Baseline.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_trips_baseline['trip_num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_trips_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca89725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaa2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7d02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610561b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a013ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd689c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6528bad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77b3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02282ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv('s3://beam-outputs/output/newyork/nyc-2-ridehail-200k__2022-09-29_11-44-14_esl/ITERS/it.0/0.events.csv.gz')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c88ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "veh = events[['vehicle','type']].dropna()\n",
    "veh = veh[(veh['vehicle'].str.contains('rideHail'))&(veh['type']=='PathTraversal')]\n",
    "vei = []\n",
    "for ve in veh['vehicle']:\n",
    "    vei.append(ve[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b51fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(vei, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9926c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/Users/cpoliziani/Downloads/0.skimsRidehail (1).csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b4400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b82a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871230b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb9ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c398f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b92e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for row in PtoPTss_TR_CA_dict.keys():\n",
    "#     i+=1\n",
    "#     if i%1000==0:\n",
    "#         print(i)\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'person'] = row[0]\n",
    "#         persons_baseline.at[i,'plan_index'] = row[1]\n",
    "#         persons_baseline.at[i,'project tried'] = 'CA - Electrification Project'\n",
    "#         persons_baseline.at[i,'TR_length'] = PtoPTss_TR_dict[row][0]\n",
    "#         persons_baseline.at[i,'TR_duration'] = PtoPTss_TR_dict[row][1]\n",
    "#         persons_baseline.at[i,'baseline_length'] = PtoPTss_baseline_dict[row][0]\n",
    "#         persons_baseline.at[i,'baseline_duration'] = PtoPTss_baseline_dict[row][1]\n",
    "#         persons_baseline.at[i,'diff_length'] = persons_baseline.at[i,'TR_length']-persons_baseline.at[i,'baseline_length']\n",
    "#         persons_baseline.at[i,'diff_duration'] = persons_baseline.at[i,'TR_duration']-persons_baseline.at[i,'baseline_duration']\n",
    "#         persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "#     except:\n",
    "#         persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "#         persons_baseline.at[i,'person'] = row[0]\n",
    "#         persons_baseline.at[i,'plan_index'] = row[1]\n",
    "#         persons_baseline.at[i,'project tried'] = 'CA - Electrification Project'\n",
    "#         print('WARNING:',row[0], row[1]) \n",
    "\n",
    "\n",
    "# for row in PtoPTss_TR_AC_dict.keys():\n",
    "#     i+=1\n",
    "#     if i%1000==0:\n",
    "#         print(i)\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'person'] = row[0]\n",
    "#         persons_baseline.at[i,'plan_index'] = row[1]\n",
    "#         persons_baseline.at[i,'project tried'] = 'AC - 1 Tempo BRT Line'\n",
    "#         persons_baseline.at[i,'TR_length'] = PtoPTss_TR_dict[row][0]\n",
    "#         persons_baseline.at[i,'TR_duration'] = PtoPTss_TR_dict[row][1]\n",
    "#         persons_baseline.at[i,'baseline_length'] = PtoPTss_baseline_dict[row][0]\n",
    "#         persons_baseline.at[i,'baseline_duration'] = PtoPTss_baseline_dict[row][1]\n",
    "#         persons_baseline.at[i,'diff_length'] = persons_baseline.at[i,'TR_length']-persons_baseline.at[i,'baseline_length']\n",
    "#         persons_baseline.at[i,'diff_duration'] = persons_baseline.at[i,'TR_duration']-persons_baseline.at[i,'baseline_duration']\n",
    "#         persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "#     except:\n",
    "#         persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "#         persons_baseline.at[i,'person'] = row[0]\n",
    "#         persons_baseline.at[i,'plan_index'] = row[1]\n",
    "#         persons_baseline.at[i,'project tried'] = 'AC - 1 Tempo BRT Line'\n",
    "#         print('WARNING:',row[0], row[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############\n",
    "# trips_TR = pd.concat([line_CA_trips_TR['trip_id'],line_CS_trips_TR['trip_id'],line_1T_trips_TR['trip_id']])\n",
    "# for vehicle, person, plan_index, vehicle2 in zip(PtoPTss['vehicleID'],PtoPTss['personID'],PtoPTss['planIndex'],PtoPTss['vehicle2'] ):\n",
    "#     if int(vehicle.split(':')[1]) in list(trips_TR):\n",
    "#         i+=1\n",
    "#         if i%1000==0:\n",
    "#             print(i)\n",
    "#         try:\n",
    "\n",
    "#             persons_baseline.at[i,'person'] = person\n",
    "#             persons_baseline.at[i,'plan_index'] = plan_index\n",
    "#             persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==person)&(plans_baseline['planElementIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "#             persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "#             persons_baseline.at[i,'vehicle_now'] = vehicle\n",
    "#             if vehicle2 == 'SF':\n",
    "#                 persons_baseline.at[i,'project'] = 'CS'\n",
    "#             if vehicle2 == 'Ca':\n",
    "#                 persons_baseline.at[i,'project'] = 'CA'\n",
    "#             if vehicle2 == 'AC':\n",
    "#                 persons_baseline.at[i,'project'] = '1T'\n",
    "\n",
    "#             persons_baseline.at[i,'vehicle_baseline'] = list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'agency_baseline'] = list(PtoPTss_baseline['vehicle2'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'length_baseline'] = list(PtoPTss_baseline['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'length_TR'] = list(PtoPTss_TR['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'duration_baseline'] = list(PtoPTss_baseline['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'duration_TR'] = list(PtoPTss_TR['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'speed_baseline'] = persons_baseline.loc[i,'length_baseline']/persons_baseline.loc[i,'duration_baseline']\n",
    "#             persons_baseline.at[i,'speed_TR'] = persons_baseline.loc[i,'length_TR']/persons_baseline.loc[i,'duration_TR']\n",
    "#             persons_baseline.at[i,'diff_length'] = persons_baseline.loc[i,'length_TR']-persons_baseline.loc[i,'length_baseline'] \n",
    "#             persons_baseline.at[i,'diff_duration'] = persons_baseline.loc[i,'duration_TR']-persons_baseline.loc[i,'duration_baseline'] \n",
    "#             persons_baseline.at[i,'diff_speed'] = persons_baseline.loc[i,'speed_TR']-persons_baseline.loc[i,'speed_baseline'] \n",
    "#         except:\n",
    "#             persons_baseline.at[i,'person'] = person\n",
    "#             persons_baseline.at[i,'plan_index'] = plan_index\n",
    "#             persons_baseline.at[i,'vehicle_now'] = vehicle\n",
    "#             if vehicle2 == 'SF':\n",
    "#                 persons_baseline.at[i,'project'] = 'CS'\n",
    "#             if vehicle2 == 'Ca':\n",
    "#                 persons_baseline.at[i,'project'] = 'CA'\n",
    "#             if vehicle2 == 'AC':\n",
    "#                 persons_baseline.at[i,'project'] = '1T'\n",
    "\n",
    "#             print('PtoPTss_baseline not found person and plan index',person,plan_index, vehicle)\n",
    "#     print('Warning')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# persons_baseline = pd.DataFrame(['person','plan_index','mode_baseline','vehicle_baseline','agency_baseline',\n",
    "#                                  'x_activity_TR','y_activity_TR','vehicle_now'])\n",
    "# i = 0\n",
    "# PtoPTss=pd.concat(PtoPTss_AC_TR,PtoPTss_SF_TR,PtoPTss_CA_TR)\n",
    "# for vehicle, person, plan_index in zip(PtoPTss['vehicleID'],PtoPTss['personID'],PtoPTss['planIndex'] ):\n",
    "#     if int(vehicle.split(':')[1]) in list(line_1T_trips_TR):\n",
    "#         i+=1\n",
    "#         persons_baseline.loc[i,'person'] = person\n",
    "#         persons_baseline.loc[i,'plan_index'] = plan_index\n",
    "#         persons_baseline.loc[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==person)&(plans_baseline['planElementIndex']==plan_index)])[0]\n",
    "#         persons_baseline.loc[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "#         persons_baseline.loc[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "#         persons_baseline.loc[i,'vehicle_now'] = '1T'\n",
    "#         try:\n",
    "#             persons_baseline.loc[i,'vehicle_baseline'] = list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.loc[i,'agency_baseline'] = list(PtoPTss_baseline['vehicle2'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.loc[i,'length_baseline'] = list(PtoPTss_baseline['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.loc[i,'length_TR'] = list(PtoPTss_TR['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.loc[i,'duration_baseline'] = list(PtoPTss_baseline['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.loc[i,'duration_TR'] = list(PtoPTss_TR['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.loc[i,'speed_baseline'] = persons_baseline.loc[i,'length_baseline']/persons_baseline.loc[i,'duration_baseline']\n",
    "#             persons_baseline.loc[i,'speed_TR'] = persons_baseline.loc[i,'length_TR']/persons_baseline.loc[i,'duration_TR']\n",
    "#             persons_baseline.loc[i,'diff_length'] = persons_baseline.loc[i,'length_TR']-persons_baseline.loc[i,'length_baseline'] \n",
    "#             persons_baseline.loc[i,'diff_duration'] = persons_baseline.loc[i,'duration_TR']-persons_baseline.loc[i,'duration_baseline'] \n",
    "#             persons_baseline.loc[i,'speed_length'] = persons_baseline.loc[i,'speed_TR']-persons_baseline.loc[i,'speed_baseline'] \n",
    "#         except:\n",
    "#             persons_baseline.loc[i,'vehicle_baseline'] = None\n",
    "#             persons_baseline.loc[i,'agency_baseline'] = None\n",
    "#             print('PtoPTss_baseline not found person and plan index',person,plan_index, vehicle)\n",
    "\n",
    "\n",
    "# persons_baseline.to_csv('/Users/cpoliziani/Downloads/person_database.csv')\n",
    "\n",
    "# PtoPTss_baseline\n",
    "\n",
    "\n",
    "# persons_baseline = pd.DataFrame()\n",
    "# i = 0\n",
    "# PtoPTss=pd.concat([PtoPTss_AC_TR,PtoPTss_SF_TR,PtoPTss_CA_TR])\n",
    "# for vehicle, person, plan_index, vehicle2 in zip(PtoPTss['vehicleID'],PtoPTss['personID'],PtoPTss['planIndex'],PtoPTss['vehicle2'] ):\n",
    "#     if int(vehicle.split(':')[1]) in list(line_1T_trips_TR):\n",
    "#         i+=1\n",
    "\n",
    "#             persons_baseline.at[i,'person'] = person\n",
    "#             persons_baseline.at[i,'plan_index'] = plan_index\n",
    "#             persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==person)&(plans_baseline['planElementIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "#             persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "#             persons_baseline.at[i,'vehicle_now'] = vehicle\n",
    "#             if vehicle2 == 'SF':\n",
    "#                 persons_baseline.at[i,'project'] = 'CS'\n",
    "#             if vehicle2 == 'Ca':\n",
    "#                 persons_baseline.at[i,'project'] = 'CA'\n",
    "#             if vehicle2 == 'AC':\n",
    "#                 persons_baseline.at[i,'project'] = '1T'\n",
    "#         try:\n",
    "\n",
    "#             persons_baseline.at[i,'vehicle_baseline'] = list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'agency_baseline'] = list(PtoPTss_baseline['vehicle2'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'length_baseline'] = list(PtoPTss_baseline['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'length_TR'] = list(PtoPTss_TR['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'duration_baseline'] = list(PtoPTss_baseline['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'duration_TR'] = list(PtoPTss_TR['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "#             persons_baseline.at[i,'speed_baseline'] = persons_baseline.loc[i,'length_baseline']/persons_baseline.loc[i,'duration_baseline']\n",
    "#             persons_baseline.at[i,'speed_TR'] = persons_baseline.loc[i,'length_TR']/persons_baseline.loc[i,'duration_TR']\n",
    "#             persons_baseline.at[i,'diff_length'] = persons_baseline.loc[i,'length_TR']-persons_baseline.loc[i,'length_baseline'] \n",
    "#             persons_baseline.at[i,'diff_duration'] = persons_baseline.loc[i,'duration_TR']-persons_baseline.loc[i,'duration_baseline'] \n",
    "#             persons_baseline.at[i,'diff_speed'] = persons_baseline.loc[i,'speed_TR']-persons_baseline.loc[i,'speed_baseline'] \n",
    "#         except:\n",
    "#             persons_baseline.at[i,'person'] = person\n",
    "#             persons_baseline.at[i,'plan_index'] = plan_index\n",
    "#             persons_baseline.at[i,'vehicle_now'] = vehicle\n",
    "#             if vehicle2 == 'SF':\n",
    "#                 persons_baseline.at[i,'project'] = 'CS'\n",
    "#             if vehicle2 == 'Ca':\n",
    "#                 persons_baseline.at[i,'project'] = 'CA'\n",
    "#             if vehicle2 == 'AC':\n",
    "#                 persons_baseline.at[i,'project'] = '1T'\n",
    "\n",
    "#             print('PtoPTss_baseline not found person and plan index',person,plan_index, vehicle)\n",
    "\n",
    "\n",
    "# persons_baseline.to_csv('/Users/cpoliziani/Downloads/person_database.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b2641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1fdf17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354d159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a48840",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIRR_capacities_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/apr2020LIRR.csv')\n",
    "LIRR_capacities_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/aug2020LIRR.csv')\n",
    "LIRR_capacities_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/aug2021LIRR.csv')\n",
    "LIRR_capacities_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/jan2022LIRR.csv')\n",
    "LIRR_capacities_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/apr2022LIRR.csv')\n",
    "\n",
    "MNR_capacities_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/apr2020MNR.csv')\n",
    "MNR_capacities_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/aug2020MNR.csv')\n",
    "MNR_capacities_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/aug2021MNR.csv')\n",
    "MNR_capacities_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/jan2022MNR.csv')\n",
    "MNR_capacities_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/apr2022MNR.csv')\n",
    "\n",
    "# LIRR_capacities_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/LIRR_capacities.csv')\n",
    "# MNR_capacities = MNR_capacities.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "# LIRR_capacities = LIRR_capacities.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "\n",
    "\n",
    "capacities_data = [LIRR_capacities_apr2020,\n",
    "        LIRR_capacities_aug2020,\n",
    "        LIRR_capacities_aug2021,\n",
    "        LIRR_capacities_jan2022,\n",
    "        LIRR_capacities_may2022,\n",
    "        MNR_capacities_apr2020,\n",
    "        MNR_capacities_aug2020,\n",
    "        MNR_capacities_aug2021,\n",
    "        MNR_capacities_jan2022,\n",
    "        MNR_capacities_may2022,\n",
    "        ]\n",
    "\n",
    "for capacity_data in capacities_data:\n",
    "    trains = []\n",
    "    for train in capacity_data['Train']:\n",
    "        try:\n",
    "            trains.append(int(train))\n",
    "        except:\n",
    "            trains.append(train)\n",
    "    capacity_data['Train'] = trains\n",
    "    \n",
    "\n",
    "\n",
    "LIRR_capacities_apr2020 = LIRR_capacities_apr2020.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "LIRR_capacities_aug2020 = LIRR_capacities_aug2020.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "LIRR_capacities_aug2021 = LIRR_capacities_aug2021.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "LIRR_capacities_jan2022 = LIRR_capacities_jan2022.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "LIRR_capacities_may2022 = LIRR_capacities_may2022.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "\n",
    "MNR_capacities_apr2020 = MNR_capacities_apr2020.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "MNR_capacities_aug2020 = MNR_capacities_aug2020.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "MNR_capacities_aug2021 = MNR_capacities_aug2021.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "MNR_capacities_jan2022 = MNR_capacities_jan2022.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "MNR_capacities_may2022 = MNR_capacities_may2022.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "\n",
    "\n",
    "LIRR_trips_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-1april2020/Long_Island_Rail_20200318/trips.txt')\n",
    "LIRR_trips_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5august2020/Long_Island_Rail_20200629/trips.txt')\n",
    "LIRR_trips_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-4august2021/Long_Island_Rail_20210726/trips.txt')\n",
    "LIRR_trips_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5january2022/Long_Island_Rail_20211216/trips.txt')\n",
    "LIRR_trips_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-11may2022/Long_Island_Rail_20220430/trips.txt')\n",
    "\n",
    "LIRR_trips_apr2020['agency_id']='LI'\n",
    "LIRR_trips_aug2020['agency_id']='LI'\n",
    "LIRR_trips_aug2021['agency_id']='LI'\n",
    "LIRR_trips_jan2022['agency_id']='LI'\n",
    "LIRR_trips_may2022['agency_id']='LI'\n",
    "\n",
    "MNR_trips_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-1april2020/Metro-North_Railroad_20200325/trips.txt')\n",
    "MNR_trips_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5august2020/Metro-North_Railroad_20200731/trips.txt')\n",
    "MNR_trips_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-4august2021/Metro-North_Railroad_20210721/trips.txt')\n",
    "MNR_trips_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5january2022/Metro-North_Railroad_20211222/trips.txt')\n",
    "MNR_trips_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-11may2022/Metro-North_Railroad_20220429/trips.txt')\n",
    "\n",
    "MNR_trips_apr2020['agency_id']='1'\n",
    "MNR_trips_aug2020['agency_id']='1'\n",
    "MNR_trips_aug2021['agency_id']='1'\n",
    "MNR_trips_jan2022['agency_id']='1'\n",
    "MNR_trips_may2022['agency_id']='1'\n",
    "\n",
    "# MNR_routes_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-1april2020/Metro-North_Railroad_20200325/routes.txt')\n",
    "# MNR_routes_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5august2020/Metro-North_Railroad_20200731/routes.txt')\n",
    "# MNR_routes_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-4august2021/Metro-North_Railroad_20210721/routes.txt')\n",
    "# MNR_routes_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5january2022/Metro-North_Railroad_20211222/routes.txt')\n",
    "# MNR_routes_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-11may2022/Metro-North_Railroad_20220429/routes.txt')\n",
    "\n",
    "# trips_data_MNR = [MNR_trips_apr2020,\n",
    "#         MNR_trips_aug2020,\n",
    "#         MNR_trips_aug2021,\n",
    "#         MNR_trips_jan2022,\n",
    "#         MNR_trips_may2022,\n",
    "#         ]\n",
    "\n",
    "# routes_data_MNR = [MNR_routes_apr2020,\n",
    "#         MNR_routes_aug2020,\n",
    "#         MNR_routes_aug2021,\n",
    "#         MNR_routes_jan2022,\n",
    "#         MNR_routes_may2022,\n",
    "#         ]\n",
    "\n",
    "# for trip_data_MNR, route_data_MNR, i  in zip(trips_data_MNR,routes_data_MNR, range(len(trips_data))):\n",
    "#     agencies =[]\n",
    "#     for route in trip_data_MNR['route_id']:\n",
    "#         agencies.append(list(route_data_MNR['agency_id'][route_data_MNR['route_id']==route])[0])\n",
    "#     trip_data_MNR['agency_id']=agencies\n",
    "\n",
    "\n",
    "# MNR_trips_apr2020 = trips_data_MNR[0]\n",
    "# MNR_trips_aug2020 = trips_data_MNR[1]\n",
    "# MNR_trips_aug2021 = trips_data_MNR[2]\n",
    "# MNR_trips_jan2022 = trips_data_MNR[3]\n",
    "# MNR_trips_may2022 = trips_data_MNR[4]\n",
    "\n",
    "trips_data = [LIRR_trips_apr2020,\n",
    "        LIRR_trips_aug2020,\n",
    "        LIRR_trips_aug2021,\n",
    "        LIRR_trips_jan2022,\n",
    "        LIRR_trips_may2022,\n",
    "        MNR_trips_apr2020,\n",
    "        MNR_trips_aug2020,\n",
    "        MNR_trips_aug2021,\n",
    "        MNR_trips_jan2022,\n",
    "        MNR_trips_may2022,\n",
    "        ]\n",
    "\n",
    "capacities_data = [LIRR_capacities_apr2020,\n",
    "        LIRR_capacities_aug2020,\n",
    "        LIRR_capacities_aug2021,\n",
    "        LIRR_capacities_jan2022,\n",
    "        LIRR_capacities_may2022,\n",
    "        MNR_capacities_apr2020,\n",
    "        MNR_capacities_aug2020,\n",
    "        MNR_capacities_aug2021,\n",
    "        MNR_capacities_jan2022,\n",
    "        MNR_capacities_may2022,\n",
    "        ]\n",
    "\n",
    "for trip_data, capacity_data in zip(trips_data, capacities_data):\n",
    "\n",
    "    capacities = []\n",
    "    wrong_ids = []\n",
    "    print('number of trip', len(trip_data),'number of capacities', len(capacity_data))\n",
    "    print('number of unique trip', len(np.unique(trip_data['trip_short_name'])))\n",
    "    for trip_short_name in trip_data['trip_short_name']:\n",
    "        try:\n",
    "            capacities.append(capacity_data[trip_short_name][0][0])\n",
    "        except:\n",
    "            try:\n",
    "                capacities.append(capacity_data[float(trip_short_name)][0][0])\n",
    "            except:\n",
    "                wrong_ids.append(trip_short_name)\n",
    "                capacities.append(np.nan)\n",
    "    trip_data['capacity'] = capacities\n",
    "    print('Warning!! Not found',len(wrong_ids))\n",
    "#     print(trip_data)\n",
    "    print('######################')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trip_data in trips_data:\n",
    "    max_cap = max(list(trip_data['capacity'].dropna()))\n",
    "    print(max_cap)\n",
    "    trip_data['capacity'] = trip_data['capacity'].fillna(max_cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c30339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trips_data_apr2020 = [trips_data[0],trips_data[5]]\n",
    "trips_data_aug2020 = [trips_data[1],trips_data[6]]\n",
    "trips_data_aug2021 = [trips_data[2],trips_data[7]]\n",
    "trips_data_jan2022 = [trips_data[3],trips_data[8]]\n",
    "trips_data_may2022 = [trips_data[4],trips_data[9]]\n",
    "\n",
    "transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "                                           'routeId',\n",
    "                                           'tripId',\n",
    "                                           'capacity',\n",
    "                                            'vehicleTypeId',\n",
    "                                          ])\n",
    "i=0      \n",
    "for trip_data, j in zip(trips_data_apr2020,[0,1]):\n",
    "    for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "        i+=1\n",
    "        if i%5000==0:\n",
    "            print(i)\n",
    "        transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "        transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "        if j == 0:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20200318:'+str(tripID)\n",
    "        elif j == 1:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20200325:'+str(tripID)\n",
    "        transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "        transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_apr2020.csv')\n",
    "\n",
    "\n",
    "transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "                                           'routeId',\n",
    "                                           'tripId',\n",
    "                                           'capacity',\n",
    "                                            'vehicleTypeId',\n",
    "                                          ])\n",
    "i=0      \n",
    "for trip_data, j in zip(trips_data_aug2020,[0,1]):\n",
    "    for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "        i+=1\n",
    "        if i%5000==0:\n",
    "            print(i)\n",
    "        transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "        transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "        if j == 0:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20200629:'+str(tripID)\n",
    "        elif j == 1:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20200731:'+str(tripID)\n",
    "        transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "        transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_aug2020.csv')\n",
    "\n",
    "\n",
    "\n",
    "transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "                                           'routeId',\n",
    "                                           'tripId',\n",
    "                                           'capacity',\n",
    "                                            'vehicleTypeId',\n",
    "                                          ])\n",
    "i=0      \n",
    "for trip_data, j in zip(trips_data_aug2021,[0,1]):\n",
    "    for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "        i+=1\n",
    "        if i%5000==0:\n",
    "            print(i)\n",
    "        transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "        transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "        if j == 0:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20210726:'+str(tripID)\n",
    "        elif j == 1:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20210721:'+str(tripID)\n",
    "        transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "        transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_aug2021.csv')\n",
    "\n",
    "\n",
    "\n",
    "transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "                                           'routeId',\n",
    "                                           'tripId',\n",
    "                                           'capacity',\n",
    "                                            'vehicleTypeId',\n",
    "                                          ])\n",
    "i=0      \n",
    "for trip_data, j in zip(trips_data_jan2022,[0,1]):\n",
    "    for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "        i+=1\n",
    "        if i%5000==0:\n",
    "            print(i)\n",
    "        transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "        transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "        if j == 0:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20211216:'+str(tripID)\n",
    "        elif j == 1:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20211222:'+str(tripID)\n",
    "        transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "        transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_jan2022.csv')\n",
    "\n",
    "\n",
    "\n",
    "transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "                                           'routeId',\n",
    "                                           'tripId',\n",
    "                                            'capacity',\n",
    "                                           'vehicleTypeId',\n",
    "                                          ])\n",
    "i=0      \n",
    "for trip_data, j in zip(trips_data_may2022,[0,1]):\n",
    "    for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "        i+=1\n",
    "        if i%5000==0:\n",
    "            print(i)\n",
    "        transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "        transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "        if j == 0:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20220430:'+str(tripID)\n",
    "        elif j == 1:\n",
    "            transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20220429:'+str(tripID)\n",
    "        transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "        transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_may2022.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae191ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_data_apr2020[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('s3://beam-outputs/output/newyork/new-york-jan2022-0-of-10__2022-09-21_17-07-49_qdx/ITERS/it.10/10.events.csv.gz', nrows = 90000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4046bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Imports\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import geopandas as gpd\n",
    "# import difflib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import time\n",
    "\n",
    "# def  processEvents(dataFilepath_sim, nrows):\n",
    "#     PTs = []\n",
    "#     PEVs = []\n",
    "#     print('read', dataFilepath_sim)\n",
    "#     for chunk in pd.read_csv(dataFilepath_sim, compression = 'gzip',chunksize=1500000, nrows = nrows):\n",
    "#         if sum((chunk['type'] == 'PathTraversal')) > 0:\n",
    "#             chunk['vehicle'] = chunk['vehicle'].astype(str)\n",
    "#             PT = chunk.loc[(chunk['type'] == 'PathTraversal') & (chunk['length'] > 0)].dropna(how='all', axis=1)\n",
    "#             PT['departureTime'] = PT['departureTime'].astype(int)\n",
    "#             PT['arrivalTime'] = PT['arrivalTime'].astype(int)\n",
    "\n",
    "#             PTs.append(PT[['driver', 'vehicle', 'mode', 'length', 'startX', 'startY', 'endX', 'endY', 'vehicleType',\n",
    "#                            'arrivalTime', 'departureTime', 'primaryFuel', 'primaryFuelType', 'secondaryFuel',\n",
    "#                            'secondaryFuelType', 'numPassengers', 'riders','time']])\n",
    "#             print(chunk.type.value_counts())\n",
    "#             PEV = chunk.loc[(chunk.type == \"PersonEntersVehicle\") &\n",
    "#                             ~(chunk['person'].apply(str).str.contains('Agent').fillna(False)) &\n",
    "#                             ~(chunk['vehicle'].str.contains('body').fillna(False)), :].dropna(how='all', axis=1)\n",
    "#             if ~PEV.empty:\n",
    "#                 PEV['time'] = PEV['time'].astype(int)\n",
    "#                 PEVs.append(PEV)\n",
    "\n",
    "#     Events_file_sim_PT = pd.concat(PTs)[['vehicle','time','endY','endX','startY','startX','mode']]\n",
    "#     Events_file_sim_PE = pd.concat(PEVs)[['vehicle','time',]]\n",
    "#     print(Events_file_sim_PE)\n",
    "\n",
    "#     return Events_file_sim_PT, Events_file_sim_PE\n",
    "\n",
    "\n",
    "\n",
    "# #Filter transit trips\n",
    "# def filter_transit(Events_file_sim_PT,Events_file_sim_PE):\n",
    "#     print(Events_file_sim_PT['mode'].value_counts())\n",
    "#     Events_file_sim_PT = Events_file_sim_PT[(Events_file_sim_PT['mode'] == 'bus')|\n",
    "#                                             (Events_file_sim_PT['mode'] == 'tram')|\n",
    "#                                             (Events_file_sim_PT['mode'] == 'subway')|\n",
    "#                                             (Events_file_sim_PT['mode'] == 'cable_car')|\n",
    "#                                             (Events_file_sim_PT['mode'] == 'ferry')|\n",
    "#                                             (Events_file_sim_PT['mode'] == 'rail')]\n",
    "#     print(Events_file_sim_PT['mode'].value_counts())\n",
    "#     Events_file_sim_PE = Events_file_sim_PE[Events_file_sim_PE['vehicle'].isin(Events_file_sim_PT['vehicle'])]\n",
    "    \n",
    "#     return Events_file_sim_PE\n",
    "\n",
    "# def guess_agency(Events_file_sim_PE):\n",
    "\n",
    "#     agencies = []\n",
    "#     for vehicleID in Events_file_sim_PE['vehicle']:\n",
    "#         agency = vehicleID.split(':')[0]\n",
    "#         if agency == 'petalumatransit-petaluma-ca-us':\n",
    "#             agencies.append('PE')\n",
    "#         elif agency == 'westcat-ca-us':\n",
    "#             agencies.append('WC')\n",
    "#         elif agency == 'caltrain-ca-us':\n",
    "#             agencies.append('CA')\n",
    "#         elif agency == 'riovista-ca-us':\n",
    "#             agencies.append('RV')\n",
    "#         elif agency == 'unioncity-ca-us':\n",
    "#             agencies.append('UC')\n",
    "#         else:\n",
    "#             if len(agency) == 2:\n",
    "#                 agencies.append(agency)\n",
    "#             elif agency == 'Caltrain':\n",
    "#                 agencies.append('CA')\n",
    "#             else:\n",
    "#                 print('Warning, this agency is not recognized:', agency)\n",
    "#     Events_file_sim_PE['agency'] = agencies\n",
    "\n",
    "#     print(np.unique(agencies))\n",
    "    \n",
    "#     return Events_file_sim_PE\n",
    "\n",
    "# def guess_route(Events_file_sim_PE, GTFS_filepaths):\n",
    "\n",
    "#     GTFS_trip_files = {}\n",
    "\n",
    "#     for GTFS_filepath, GTFS in zip(GTFS_filepaths,GTFSs):\n",
    "#         GTFS_trip_files[GTFS] = pd.read_csv(GTFS_filepath+'trips.txt')\n",
    "\n",
    "#     route_ids = []\n",
    "#     total_routes = len(Events_file_sim_PE['vehicle'])\n",
    "#     i = 0\n",
    "#     time_start = time.time()\n",
    "#     for vehicle, agency in zip(Events_file_sim_PE['vehicle'],Events_file_sim_PE['agency']):\n",
    "#         i+=1\n",
    "#         if i%10000 ==0:\n",
    "#             print(i,'/',total_routes,'. Time = ', time.time()-time_start, '. Estimated remaining time:', (time.time()-time_start)/i*total_routes-(time.time()-time_start))\n",
    "#         if agency == 'SM':\n",
    "#             route_ids.append(agency+':'+str(list(GTFS_trip_files[agency]['route_id'][\n",
    "#                 GTFS_trip_files[agency]['trip_id'].astype(str)==\n",
    "#                      str(vehicle).split(':')[1]+'|'\n",
    "#                      +str(vehicle).split(':')[2]+':'\n",
    "#                      +str(vehicle).split(':')[3]+'|'\n",
    "#                      +str(vehicle).split(':')[4]+':'\n",
    "#                      +str(vehicle).split(':')[5]+':'\n",
    "#                      +str(vehicle).split(':')[6]])[0]))\n",
    "#         else:\n",
    "# #             print(list(GTFS_trip_files[agency]['route_id'][GTFS_trip_files[agency]['trip_id'].astype(str)==str(vehicle.split(':')[1])])[0])\n",
    "#             try:\n",
    "#                 route_ids.append(agency+':'+str(list(GTFS_trip_files[agency]['route_id'][GTFS_trip_files[agency]['trip_id'].astype(str)==str(vehicle.split(':')[1])])[0]))\n",
    "#             except:\n",
    "#                 print('Warning, trip non found for vehicle', vehicle)\n",
    "#                 route_ids.append('tripID not found')\n",
    "#     #     elif agency == 'GG':\n",
    "#     #         route_ids.append('GG:'+str(list(GTFS_trip_files[agency]['route_id'][GTFS_trip_files[agency]['trip_id']==vehicle.split(':')[1]])[0]))\n",
    "#     #     elif agency == 'SF':\n",
    "#     #         route_ids.append('SF:'+str(list(GTFS_trip_files[agency]['route_id'][GTFS_trip_files[agency]['trip_id']==vehicle.split(':')[1]])[0]))\n",
    "#     Events_file_sim_PE['route_id'] = route_ids\n",
    "    \n",
    "#     return Events_file_sim_PE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dataFilepath_sim = [\n",
    "# #                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "# #                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "# #                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "# #                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "# #                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "# #                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "# #                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220801/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "# #                 's3://beam-outputs/pilates-outputs/sfbay-AC-SF-CA-20220801/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz',\n",
    "#             ]\n",
    "\n",
    "                    \n",
    "# years = ['2018','2019','2020','2021']\n",
    "\n",
    "# names = []\n",
    "# for year in years:\n",
    "#     names.append('Baseline'+year)\n",
    "#     names.append('Future'+year)\n",
    "\n",
    "# output_filepath = '/Users/cpoliziani/Downloads/Transit Rich/Results/'\n",
    "\n",
    "# GTFS_filepath = '/Users/cpoliziani/Downloads/Data/TR/GTFS/r5-simple-no-local/'\n",
    "# GTFS_filepath2 = '/Users/cpoliziani/Downloads/Data/TR/GTFS/r5-simple-no-local-TR/'\n",
    "\n",
    "# RA_output = 'agency_ridershipNew3.csv'\n",
    "# RR_output = 'route_ridershipNew3.csv'\n",
    "\n",
    "# GTFSs = ['3D','AC','AM','AY','BA','CA','CC','CE','CM','CT','DE','EM','GG','HF','MA','PE','RV', 'SB',\n",
    "#         'SC','SF','SM','SO','SR','ST','TD','UC','VC','VN','VT','WC','WH']\n",
    "\n",
    "# GTFS_3D = GTFS_filepath+'3D/'\n",
    "# GTFS_AC = GTFS_filepath+'AC/'\n",
    "# GTFS_AM = GTFS_filepath+'AM/'\n",
    "# GTFS_AY = GTFS_filepath+'AY/'\n",
    "# GTFS_BA = GTFS_filepath+'BA/'\n",
    "# GTFS_Caltrain = GTFS_filepath+'Caltrain/'\n",
    "# GTFS_CC = GTFS_filepath+'CC/'\n",
    "# GTFS_CE = GTFS_filepath+'CE/'\n",
    "# GTFS_CM = GTFS_filepath+'CM/'\n",
    "# GTFS_CT = GTFS_filepath+'CT/'\n",
    "# GTFS_DE = GTFS_filepath+'DE/'\n",
    "# GTFS_EM = GTFS_filepath+'EM/'\n",
    "# GTFS_GG = GTFS_filepath+'GG/'\n",
    "# GTFS_HF = GTFS_filepath+'HF/'\n",
    "# GTFS_MA = GTFS_filepath+'MA/'\n",
    "# GTFS_PE = GTFS_filepath+'PE/'\n",
    "# GTFS_RV = GTFS_filepath+'RV/'\n",
    "# GTFS_SB = GTFS_filepath+'SB/'\n",
    "# GTFS_SC = GTFS_filepath+'SC/'\n",
    "# GTFS_SF = GTFS_filepath+'SF/'\n",
    "# GTFS_SM = GTFS_filepath+'SM/'\n",
    "# GTFS_SO = GTFS_filepath+'SO/'\n",
    "# GTFS_SR = GTFS_filepath+'SR/'\n",
    "# GTFS_ST = GTFS_filepath+'ST/'\n",
    "# GTFS_TD = GTFS_filepath+'TD/'\n",
    "# GTFS_UC = GTFS_filepath+'UC/'\n",
    "# GTFS_VC = GTFS_filepath+'VC/'\n",
    "# GTFS_VN = GTFS_filepath+'VN/'\n",
    "# GTFS_VT = GTFS_filepath+'VT/'\n",
    "# GTFS_WC = GTFS_filepath+'WC/'\n",
    "# GTFS_WH = GTFS_filepath+'WH/'\n",
    "\n",
    "\n",
    "# GTFS_3D2 = GTFS_filepath2+'3D/'\n",
    "# GTFS_AC2 = GTFS_filepath2+'AC/'\n",
    "# GTFS_AM2 = GTFS_filepath2+'AM/'\n",
    "# GTFS_AY2 = GTFS_filepath2+'AY/'\n",
    "# GTFS_BA2 = GTFS_filepath2+'BA/'\n",
    "# GTFS_Caltrain2 = GTFS_filepath2+'Caltrain/'\n",
    "# GTFS_CC2 = GTFS_filepath2+'CC/'\n",
    "# GTFS_CE2 = GTFS_filepath2+'CE/'\n",
    "# GTFS_CM2 = GTFS_filepath2+'CM/'\n",
    "# GTFS_CT2 = GTFS_filepath2+'CT/'\n",
    "# GTFS_DE2 = GTFS_filepath2+'DE/'\n",
    "# GTFS_EM2 = GTFS_filepath2+'EM/'\n",
    "# GTFS_GG2 = GTFS_filepath2+'GG/'\n",
    "# GTFS_HF2 = GTFS_filepath2+'HF/'\n",
    "# GTFS_MA2 = GTFS_filepath2+'MA/'\n",
    "# GTFS_PE2 = GTFS_filepath2+'PE/'\n",
    "# GTFS_RV2 = GTFS_filepath2+'RV/'\n",
    "# GTFS_SB2 = GTFS_filepath2+'SB/'\n",
    "# GTFS_SC2 = GTFS_filepath2+'SC/'\n",
    "# GTFS_SF2 = GTFS_filepath2+'SF/'\n",
    "# GTFS_SM2 = GTFS_filepath2+'SM/'\n",
    "# GTFS_SO2 = GTFS_filepath2+'SO/'\n",
    "# GTFS_SR2 = GTFS_filepath2+'SR/'\n",
    "# GTFS_ST2 = GTFS_filepath2+'ST/'\n",
    "# GTFS_TD2 = GTFS_filepath2+'TD/'\n",
    "# GTFS_UC2 = GTFS_filepath2+'UC/'\n",
    "# GTFS_VC2 = GTFS_filepath2+'VC/'\n",
    "# GTFS_VN2 = GTFS_filepath2+'VN/'\n",
    "# GTFS_VT2 = GTFS_filepath2+'VT/'\n",
    "# GTFS_WC2 = GTFS_filepath2+'WC/'\n",
    "# GTFS_WH2 = GTFS_filepath2+'WH/'\n",
    "\n",
    "# GTFS_baseline = [GTFS_3D,\n",
    "#                     GTFS_AC,\n",
    "#                     GTFS_AM,\n",
    "#                     GTFS_AY,\n",
    "#                     GTFS_BA,\n",
    "#                     GTFS_Caltrain,\n",
    "#                     GTFS_CC,\n",
    "#                     GTFS_CE,\n",
    "#                     GTFS_CM,\n",
    "#                     GTFS_CT,\n",
    "#                     GTFS_DE,\n",
    "#                     GTFS_EM,\n",
    "#                     GTFS_GG,\n",
    "#                     GTFS_HF,\n",
    "#                     GTFS_MA,\n",
    "#                     GTFS_PE,\n",
    "#                     GTFS_RV,\n",
    "#                     GTFS_SB,\n",
    "#                     GTFS_SC,\n",
    "#                     GTFS_SF,\n",
    "#                     GTFS_SM,\n",
    "#                     GTFS_SO,\n",
    "#                     GTFS_SR,\n",
    "#                     GTFS_ST,\n",
    "#                     GTFS_TD,\n",
    "#                     GTFS_UC,\n",
    "#                     GTFS_VC,\n",
    "#                     GTFS_VN,\n",
    "#                     GTFS_VT,\n",
    "#                     GTFS_WC,\n",
    "#                     GTFS_WH]\n",
    "\n",
    "# GTFS_TR = [GTFS_3D2,\n",
    "#                     GTFS_AC2,\n",
    "#                     GTFS_AM2,\n",
    "#                     GTFS_AY2,\n",
    "#                     GTFS_BA2,\n",
    "#                     GTFS_Caltrain2,\n",
    "#                     GTFS_CC2,\n",
    "#                     GTFS_CE2,\n",
    "#                     GTFS_CM2,\n",
    "#                     GTFS_CT2,\n",
    "#                     GTFS_DE2,\n",
    "#                     GTFS_EM2,\n",
    "#                     GTFS_GG2,\n",
    "#                     GTFS_HF2,\n",
    "#                     GTFS_MA2,\n",
    "#                     GTFS_PE2,\n",
    "#                     GTFS_RV2,\n",
    "#                     GTFS_SB2,\n",
    "#                     GTFS_SC2,\n",
    "#                     GTFS_SF2,\n",
    "#                     GTFS_SM2,\n",
    "#                     GTFS_SO2,\n",
    "#                     GTFS_SR2,\n",
    "#                     GTFS_ST2,\n",
    "#                     GTFS_TD2,\n",
    "#                     GTFS_UC2,\n",
    "#                     GTFS_VC2,\n",
    "#                     GTFS_VN2,\n",
    "#                     GTFS_VT2,\n",
    "#                     GTFS_WC2,\n",
    "#                     GTFS_WH2]\n",
    "# GTFS_filepaths = [GTFS_baseline, GTFS_TR,GTFS_baseline, GTFS_TR,GTFS_baseline, GTFS_TR,GTFS_baseline, GTFS_TR]\n",
    "\n",
    "\n",
    "\n",
    "# nrows = None\n",
    "\n",
    "\n",
    "\n",
    "# #Ridership route\n",
    "# RR = pd.DataFrame()\n",
    "# #Ridership agency\n",
    "# RA = pd.DataFrame()\n",
    "\n",
    "# for fp, name, GTFS_filepath in zip(dataFilepath_sim,names, GTFS_filepaths):\n",
    "#     print('evaluate ridership')\n",
    "#     #import pathtraversal and person enter vehicles\n",
    "#     PT, PE = processEvents(fp, nrows)\n",
    "#     #filter PE transit trips from PT\n",
    "#     PE = filter_transit(PT, PE)\n",
    "#     #Guess transit agency for each PE\n",
    "#     PE = guess_agency(PE)\n",
    "#     #Guess transit route for each PE\n",
    "#     PE = guess_route(PE, GTFS_filepath)\n",
    "#     #Route Ridership\n",
    "#     rr = PE['route_id'].value_counts()\n",
    "#     sum_agency = 0\n",
    "#     sum_agency_bsva = 0\n",
    "#     sum_route = 0\n",
    "#     for route, count in zip(rr.keys(), rr):\n",
    "#         RR.at[route, name] = count\n",
    "#         sum_route += count\n",
    "#     ra = PE['agency'].value_counts()\n",
    "#     for agency, count in zip(ra.keys(), ra):\n",
    "#         RA.at[agency, name] = count\n",
    "#         sum_agency += count\n",
    "#         if agency in ['BA', 'SF', 'VT', 'AC']:\n",
    "#             RA.at[agency, name+' BA-SF-VT-AC'] = count\n",
    "#             sum_agency_bsva += count\n",
    "#     for route, count in zip(rr.keys(), rr):\n",
    "#         RR.at[route, name+' shares'] = count/sum_route\n",
    "#     ra = PE['agency'].value_counts()\n",
    "#     for agency, count in zip(ra.keys(), ra):\n",
    "#         RA.at[agency, name+' shares'] = count/sum_agency\n",
    "#         if agency in ['BA', 'SF', 'VT', 'AC']:\n",
    "#             RA.at[agency, name+' shares BA-SF-VT-AC'] = count/sum_agency_bsva\n",
    "#     RA.to_csv(output_filepath+RA_output)\n",
    "#     RR.to_csv(output_filepath+RR_output)\n",
    "\n",
    "# for year in years:\n",
    "#     diff = []\n",
    "#     diff_abs = []\n",
    "#     for baseline, future in zip(RA['Baseline'+year],RA['Future'+year]):\n",
    "#         diff.append((future-baseline)/baseline)\n",
    "#         diff_abs.append((future-baseline))\n",
    "#     RA['Diff %'+year] = diff\n",
    "#     RA['Diff'+year] = diff_abs\n",
    "\n",
    "# tot_NTD = 1756364558 + 15283299+5703705+49795740+110802986+7386518+49247910+27027693 + 8437926+50222832 + 2818648\n",
    "    \n",
    "# RA.at['BA', 'clipper BA-SF-VT-AC 2016 share target'] = 350485/773719\n",
    "# RA.at['BA', 'MTC BA-SF-VT-AC 2016 share target'] = 458900/1564500\n",
    "# RA.at['BA', 'NTD BA-SF-VT-AC 2019 share target'] = (1756364558 + 15283299)/tot_NTD\n",
    "\n",
    "# RA.at['SF', 'clipper BA-SF-VT-AC 2016 share target'] = 293991/773719\n",
    "# RA.at['SF', 'MTC BA-SF-VT-AC 2016 share target'] = 777000/1564500\n",
    "# RA.at['SF', 'NTD BA-SF-VT-AC 2019 share target'] = (5703705+49795740+110802986+7386518+49247910)/tot_NTD\n",
    "\n",
    "# RA.at['VT', 'clipper BA-SF-VT-AC 2016 share target'] = 43950/773719\n",
    "# RA.at['VT', 'MTC BA-SF-VT-AC 2016 share target'] = 146700/1564500\n",
    "# RA.at['VT', 'NTD BA-SF-VT-AC 2019 share target'] = (27027693 + 8437926)/tot_NTD\n",
    "\n",
    "# RA.at['AC', 'clipper BA-SF-VT-AC 2016 share target'] = 85293/773719\n",
    "# RA.at['AC', 'MTC BA-SF-VT-AC 2016 share target'] = 181900/1564500\n",
    "# RA.at['AC', 'NTD BA-SF-VT-AC 2019 share target'] = (50222832 + 2818648)/tot_NTD\n",
    "\n",
    "# RA.at['BA', 'clipper BA-SF-VT-AC 2020 Jan av ridership target'] = 350485\n",
    "# RA.at['BA', 'MTC BA-SF-VT-AC 2016 av ridership target'] = 458900\n",
    "# RA.at['BA', 'NTD BA-SF-VT-AC 2019 ridership target'] = (1756364558 + 15283299)\n",
    "\n",
    "# RA.at['SF', 'clipper BA-SF-VT-AC 2020 Jan av ridership target'] = 293991\n",
    "# RA.at['SF', 'MTC BA-SF-VT-AC 2016 av ridership target'] = 777000\n",
    "# RA.at['SF', 'NTD BA-SF-VT-AC 2019 ridership target'] = (5703705+49795740+110802986+7386518+49247910)\n",
    "\n",
    "# RA.at['VT', 'clipper BA-SF-VT-AC 2020 Jan av ridership target'] = 43950\n",
    "# RA.at['VT', 'MTC BA-SF-VT-AC 2016 av ridership target'] = 146700\n",
    "# RA.at['VT', 'NTD BA-SF-VT-AC 2019 ridership target'] =  (27027693 + 8437926)\n",
    "\n",
    "# RA.at['AC', 'clipper BA-SF-VT-AC 2020 Jan av ridership target'] = 85293\n",
    "# RA.at['AC', 'MTC BA-SF-VT-AC 2016 av ridership target'] = 181900\n",
    "# RA.at['AC', 'NTD BA-SF-VT-AC 2019 ridership target'] = (50222832 + 2818648)\n",
    "\n",
    "# RA.to_csv(output_filepath+RA_output)\n",
    "# RR.to_csv(output_filepath+RR_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RA\n",
    "\n",
    "\n",
    "\n",
    "# RR[RR.index.str.contains('AC:1-142')]\n",
    "\n",
    "\n",
    "\n",
    "# RR[RR.index.str.contains('AC:1T-142')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RR[RR.index.str.contains('CA:')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RR[RR.index.str.contains('SF:1000')]\n",
    "\n",
    "\n",
    "\n",
    "# #The Central Subway Project will improve public transportation in San Francisco by extending the Muni Metro T Third Line through SoMa\n",
    "\n",
    "# #J\n",
    "# RR[RR.index.str.contains('SF:12475')]\n",
    "\n",
    "\n",
    "\n",
    "# #K/T\n",
    "# RR[RR.index.str.contains('SF:12476')]\n",
    "\n",
    "\n",
    "\n",
    "# #L\n",
    "# RR[RR.index.str.contains('SF:12477')]\n",
    "\n",
    "\n",
    "\n",
    "# #M\n",
    "# RR[RR.index.str.contains('SF:12478')]\n",
    "\n",
    "\n",
    "\n",
    "# #N\n",
    "# RR[RR.index.str.contains('SF:12479')]\n",
    "\n",
    "\n",
    "\n",
    "# for year in years:\n",
    "    \n",
    "#     print('total SF light rail baseline'+year,\n",
    "#          (list(RR[RR.index.str.contains('SF:12475')]['Baseline'+year])[0]+\n",
    "#           list(RR[RR.index.str.contains('SF:12476')]['Baseline'+year])[0]+\n",
    "#           list(RR[RR.index.str.contains('SF:12477')]['Baseline'+year])[0]+\n",
    "#           list(RR[RR.index.str.contains('SF:12478')]['Baseline'+year])[0]+\n",
    "#           list(RR[RR.index.str.contains('SF:12479')]['Baseline'+year])[0])\n",
    "#          )\n",
    "#     print('total SF light rail future'+year,\n",
    "#          (list(RR[RR.index.str.contains('SF:12475')]['Future'+year])[0]+\n",
    "#           list(RR[RR.index.str.contains('SF:12476')]['Future'+year])[0]+\n",
    "#           list(RR[RR.index.str.contains('SF:12477')]['Future'+year])[0]+\n",
    "#           list(RR[RR.index.str.contains('SF:12478')]['Future'+year])[0]+\n",
    "#           list(RR[RR.index.str.contains('SF:12479')]['Future'+year])[0]+\n",
    "#           list(RR[RR.index.str.contains('SF:1000')]['Future'+year])[0])\n",
    "#          )\n",
    "\n",
    "# #Imports\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import difflib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import time\n",
    "\n",
    "# #########Analysis of what agents used in the baseline\n",
    "# index_baseline =6 \n",
    "# index_future =7\n",
    "# fp_PtoPTss_baseline = '/Users/cpoliziani/Downloads/personToVehicles.csv.gz'\n",
    "# fp_PtoPTss_future = '/Users/cpoliziani/Downloads/personToVehicles (1).csv.gz'\n",
    "\n",
    "# # print('read PtoPTss baseline',fp_PtoPTss_baseline)\n",
    "# PtoPTss_baseline = pd.read_csv(fp_PtoPTss_baseline)\n",
    "# # print('read PtoPTss TR', fp_PtoPTss_future)\n",
    "# PtoPTss_TR = pd.read_csv(fp_PtoPTss_future)\n",
    "# # print('read plans baseline',dataFilepath_sim[index_baseline][:-13]+'plans.csv.gz')\n",
    "# plans_baseline = pd.read_csv(dataFilepath_sim[index_baseline][:-13]+'plans.csv.gz')\n",
    "# # print('read plans TR', dataFilepath_sim[index_future][:-13]+'plans.csv.gz')\n",
    "# plans_TR = pd.read_csv(dataFilepath_sim[index_future][:-13]+'plans.csv.gz')\n",
    "# # print('read GTFS trips fpr AC, SF and CA')\n",
    "# line_1T_trips_TR = pd.read_csv(GTFS_AC2+'trips.txt')\n",
    "# line_1T_trips_TR = line_1T_trips_TR[line_1T_trips_TR['route_id'].str.contains('1T-142')]\n",
    "# line_CS_trips_TR = pd.read_csv(GTFS_SF2+'trips.txt')\n",
    "# line_CS_trips_TR = line_CS_trips_TR[line_CS_trips_TR['route_id']==1000]\n",
    "# line_CA_trips_TR = pd.read_csv(GTFS_Caltrain2+'trips.txt')\n",
    "# # print('read mode choice')\n",
    "# mode_choice_baseline = pd.read_csv(dataFilepath_sim[index_baseline])\n",
    "# mode_choice_TR = pd.read_csv(dataFilepath_sim[index_future])\n",
    "# mode_choice_baseline = mode_choice_baseline[mode_choice_baseline['type']=='ModeChoice']\n",
    "# mode_choice_TR = mode_choice_TR[mode_choice_TR['type']=='ModeChoice']\n",
    "\n",
    "# PtoPTss_AC_TR = PtoPTss_TR[PtoPTss_TR['vehicle2'].str.contains('AC', na=False)]\n",
    "# PtoPTss_SF_TR = PtoPTss_TR[PtoPTss_TR['vehicle2'].str.contains('SF', na=False)]\n",
    "# PtoPTss_CA_TR = PtoPTss_TR[PtoPTss_TR['vehicle2'].str.contains('Ca', na=False)]\n",
    "\n",
    "# #Filter SF trips - CS only\n",
    "# is_CS = []\n",
    "# vehicles = list(line_CS_trips_TR['trip_id'])\n",
    "# for vehicle in PtoPTss_SF_TR['vehicleID']:\n",
    "#     if int(vehicle[3:]) in vehicles:\n",
    "#         is_CS.append(True)\n",
    "#     else:\n",
    "#         is_CS.append(False)\n",
    "# print('Filter CS trips [tot, remained]',len(is_CS),sum(is_CS))\n",
    "# PtoPTss_SF_TR['is_CS'] = is_CS\n",
    "# PtoPTss_SF_TR = PtoPTss_SF_TR[PtoPTss_SF_TR['is_CS']==True]\n",
    "\n",
    "\n",
    "# is_AC = []\n",
    "# vehicles = list(line_1T_trips_TR['trip_id'])\n",
    "# for vehicle in PtoPTss_AC_TR['vehicleID']:\n",
    "#     if int(vehicle[3:]) in vehicles:\n",
    "#         is_AC.append(True)\n",
    "#     else:\n",
    "#         is_AC.append(False)\n",
    "# print('Filter 1T trips [tot, remained]',len(is_AC),sum(is_AC))\n",
    "# PtoPTss_AC_TR['is_AC'] = is_AC\n",
    "# PtoPTss_AC_TR = PtoPTss_AC_TR[PtoPTss_AC_TR['is_AC']==True]\n",
    "\n",
    "# persons_baseline = pd.DataFrame()\n",
    "# i = 0\n",
    "# trips_TR = pd.concat([line_CA_trips_TR['trip_id'],line_CS_trips_TR['trip_id'],line_1T_trips_TR['trip_id']])\n",
    "# ##############################\n",
    "# # PtoPTss_TR2=pd.concat([PtoPTss_AC_TR,PtoPTss_SF_TR,PtoPTss_CA_TR])\n",
    "# # PtoPTss_TR2_dict = PtoPTss.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "# #                                                     sum(x.duration)]).to_dict()\n",
    "# # print(len(PtoPTss_CA_TR))\n",
    "# PtoPTss_TR_CA_dict = PtoPTss_CA_TR.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "#                                                     sum(x.duration)]).to_dict()\n",
    "# # print(len(PtoPTss_TR_CA_dict.keys()))\n",
    "# # print(len(PtoPTss_SF_TR))\n",
    "# PtoPTss_TR_SF_dict = PtoPTss_SF_TR.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "#                                                     sum(x.duration)]).to_dict()\n",
    "# # print(len(PtoPTss_TR_SF_dict.keys()))\n",
    "# # print(len(PtoPTss_AC_TR))\n",
    "# PtoPTss_TR_AC_dict = PtoPTss_AC_TR.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "#                                                     sum(x.duration)]).to_dict()\n",
    "# # print(len(PtoPTss_TR_AC_dict.keys()))\n",
    "# # print(len(PtoPTss_baseline))\n",
    "# PtoPTss_baseline_dict = PtoPTss_baseline.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "#                                                     sum(x.duration)]).to_dict()\n",
    "# # print(len(PtoPTss_baseline_dict.keys()))\n",
    "# # print(len(PtoPTss_TR))\n",
    "# PtoPTss_TR_dict = PtoPTss_TR.groupby(['personID', 'planIndex']).apply(lambda x: [sum(x.length),\n",
    "#                                                 sum(x.duration)]).to_dict()\n",
    "# print(len(PtoPTss_TR_dict.keys()))\n",
    "\n",
    "\n",
    "# #Add logsum\n",
    "# person_trips_baseline = pd.read_csv('/Users/cpoliziani/Downloads/tourTripsMerged_Baseline.csv')\n",
    "# person_trips_baseline['trip_num']=person_trips_baseline['trip_num']*2-1\n",
    "# person_trips_TR = pd.read_csv('/Users/cpoliziani/Downloads/tourTripsMerged_TR.csv')\n",
    "# person_trips_TR['trip_num']=person_trips_TR['trip_num']*2-1\n",
    "\n",
    "\n",
    "# def addGeometryIdToDataFrame(df, gdf, xcol, ycol, idColumn=\"geometry\", df_geom='epsg:32610'): \n",
    "#     gdf.set_crs(epsg = \"3310\", inplace = True)\n",
    "#     gdf_data = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[xcol], df[ycol]))\n",
    "#     gdf_data.set_crs(epsg = \"32610\", inplace = True)\n",
    "#     joined = gpd.sjoin(gdf_data.to_crs('epsg:26910'), gdf.to_crs('epsg:26910'))\n",
    "#     gdf_data = gdf_data.merge(joined['ZCTA'], left_index=True, right_index=True, how=\"left\")\n",
    "#     gdf_data.rename(columns={'ZCTA': idColumn}, inplace=True)\n",
    "#     df = pd.DataFrame(gdf_data.drop(columns='geometry'))\n",
    "# #     df.drop(columns=[xcol, ycol], inplace=True)\n",
    "#     return df.loc[~df.index.duplicated(keep='first'), :]\n",
    "\n",
    "# persons_baseline = pd.DataFrame(columns = ['Person',\n",
    "#                                            'Plan Index',\n",
    "#                                            'Planned Depart Time Baseline',\n",
    "#                                            'Planned Depart Time TR',\n",
    "#                                            'Activity From Baseline',\n",
    "#                                            'Activity To Baseline',\n",
    "#                                            'Activity From TR',\n",
    "#                                            'Activity To TR',\n",
    "#                                            'Project Tried',\n",
    "#                                            'Vehicles Used Baseline',\n",
    "#                                            'Vehicle Types Used Baseline',                                          \n",
    "#                                            'Bus agencies Used Baseline',\n",
    "#                                            'First Bus agency Used Baseline',\n",
    "#                                            'Vehicles Used TR',\n",
    "#                                            'Vehicle Types Used TR',                                          \n",
    "#                                            'Bus agencies Used TR',\n",
    "#                                            'First Bus agency Used TR',\n",
    "#                                            'Switch From',\n",
    "#                                            'Trip Length Baseline',                       \n",
    "#                                            'Trip Duration Baseline',\n",
    "#                                            'Trip Length TR',\n",
    "#                                            'Trip Duration TR',\n",
    "#                                            'Diff Length',\n",
    "#                                            'Diff Duration',\n",
    "#                                            'Planned Mode Baseline',                                         \n",
    "#                                            'Planned Mode TR',                                          \n",
    "#                                            'Chosen Mode Baseline',                                          \n",
    "#                                            'Chosen Mode TR',\n",
    "#                                            'X Activity From TR',\n",
    "#                                            'Y Activity From TR',\n",
    "#                                            'X Activity To TR',\n",
    "#                                            'Y Activity To TR',\n",
    "#                                            'X Activity From Baseline',\n",
    "#                                            'Y Activity From Baseline',\n",
    "#                                            'X Activity To Baseline',\n",
    "#                                            'Y Activity To Baseline',\n",
    "#                                            'Log Sum Baseline',\n",
    "#                                            'Log Sum TR',\n",
    "#                                            'Diff Log Sum TR',\n",
    "# #                                            'ZIP Departure TR',                                          \n",
    "# #                                            'ZIP Arrival TR',                                          \n",
    "# #                                            'ZIP Departure Baseline',                                          \n",
    "# #                                            'ZIP Arrival Baseline',                                          \n",
    "#                                           ])\n",
    "\n",
    "# PtoPTss_baseline_bus =  PtoPTss_baseline[(PtoPTss_baseline['mode'] =='bus')|\n",
    "#                                          (PtoPTss_baseline['mode'] =='subway')|\n",
    "#                                          (PtoPTss_baseline['mode'] =='tram')|\n",
    "#                                          (PtoPTss_baseline['mode'] =='rail')|\n",
    "#                                          (PtoPTss_baseline['mode'] =='cable_car')|\n",
    "#                                          (PtoPTss_baseline['mode'] =='ferry')]\n",
    "# PtoPTss_TR_bus =  PtoPTss_TR[(PtoPTss_TR['mode'] =='bus')|\n",
    "#                                          (PtoPTss_TR['mode'] =='subway')|\n",
    "#                                          (PtoPTss_TR['mode'] =='tram')|\n",
    "#                                          (PtoPTss_TR['mode'] =='rail')|\n",
    "#                                          (PtoPTss_TR['mode'] =='cable_car')|\n",
    "#                                          (PtoPTss_TR['mode'] =='ferry')]   \n",
    "# print(len(PtoPTss_TR_SF_dict))\n",
    "# print(len(PtoPTss_TR_CA_dict))\n",
    "# print(len(PtoPTss_TR_AC_dict))\n",
    "\n",
    "\n",
    "# i=0      \n",
    "# for row in PtoPTss_TR_SF_dict.keys():\n",
    "#     i+=1\n",
    "#     if i%50==0:\n",
    "#         print(i)\n",
    "#         break\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Person'] = row[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'person')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Plan Index'] = int(row[1])\n",
    "#     except:\n",
    "#         print('Warning', row, 'plan_index')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity From Baseline'] = int(list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity From Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity To Baseline'] = int(list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity To Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity From TR'] = int(list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity From TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity To TR'] = int(list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity To TR')  \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Depart Time Baseline'] = int(list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'plan_dep_time_baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Depart Time TR'] = int(list(plans_TR['activityEndTime'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'plan_dep_time_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Project Tried'] = 'SF - Central Subway'\n",
    "#     except:\n",
    "#         print('Warning', row, 'project tried')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Log Sum Baseline'] = np.unique(list(person_trips_baseline['mode_choice_logsum_y'][(person_trips_baseline['person_id']==row[0])&(person_trips_baseline['trip_num']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Log Sum Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Log Sum TR'] = np.unique(list(person_TR['mode_choice_logsum_y'][(person_TR['person_id']==row[0])&(person_TR['trip_num']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Log Sum TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Diff Log Sum'] = persons_baseline.at[i,'Log Sum TR']-persons_baseline.at[i,'Log Sum Baseline']\n",
    "#     except:\n",
    "#         print('Warning', row, 'Diff Log Sum TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicles Used Baseline'] = np.unique(list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicles Used Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicles Used TR'] = np.unique(list(PtoPTss_TR['vehicleID'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicles Used TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Bus agencies Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Bus agencies Used Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Bus agencies Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Bus agencies Used TR') \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'First Bus agency Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'First Bus agency Used Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'First Bus agency Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'First Bus agency Used TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Length TR'] = int(PtoPTss_TR_dict[row][0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'TR_length')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Duration TR'] = int(PtoPTss_TR_dict[row][1])\n",
    "#     except:\n",
    "#         print('Warning', row, 'TR_duration')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Length Baseline'] = int(PtoPTss_baseline_dict[row][0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'baseline_length')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Duration Baseline'] = int(PtoPTss_baseline_dict[row][1])\n",
    "#     except:\n",
    "#         print('Warning', row, 'baseline_duration')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Diff Length'] = int(persons_baseline.at[i,'Trip Length TR']-persons_baseline.at[i,'Trip Length Baseline'])\n",
    "#     except:\n",
    "#         print('Warning', row, 'diff_length')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Diff Duration'] = int(persons_baseline.at[i,'Trip Duration TR']-persons_baseline.at[i,'Trip Duration Baseline'])\n",
    "#     except:\n",
    "#         print('Warning', row, 'diff_duration')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity From TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_from_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity From TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_From_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity To TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_To_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity To TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_To_TR')   \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity From Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_from_Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity From Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_From_Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity To Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_To_Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity To Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_To_Baseline')   \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicle Types Used Baseline'] = np.unique(list(PtoPTss_baseline['mode'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicle Types Used baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicle Types Used TR'] = np.unique(list(PtoPTss_TR['mode'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicle Types Used TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Mode Baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'Baseline planned mode')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Mode TR'] = list(plans_TR['legMode'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1])])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'TR planned mode')\n",
    "#     try:\n",
    "#         plan_dep_time_baseline = list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'Chosen Mode Baseline'] = list(mode_choice_baseline['mode'][(mode_choice_baseline['person']==row[0])&(mode_choice_baseline['time']>=plan_dep_time_baseline-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'mode_choice_baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Chosen Mode TR'] = list(mode_choice_TR['mode'][(mode_choice_TR['person']==row[0])&(mode_choice_TR['time']>=persons_baseline.at[i,'Planned Depart Time TR']-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'mode_choice_TR')\n",
    "        \n",
    "# ####################################\n",
    "# for row in PtoPTss_TR_CA_dict.keys():\n",
    "#     i+=1\n",
    "#     if i%50==0:\n",
    "#         print(i)\n",
    "#         break\n",
    "        \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Person'] = row[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'person')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Plan Index'] = int(row[1])\n",
    "#     except:\n",
    "#         print('Warning', row, 'plan_index')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity From Baseline'] = int(list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity From Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity To Baseline'] = int(list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity To Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity From TR'] = int(list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity From TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity To TR'] = int(list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity To TR')  \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Depart Time Baseline'] = int(list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'plan_dep_time_baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Depart Time TR'] = int(list(plans_TR['activityEndTime'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'plan_dep_time_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Project Tried'] = 'CA - Electrification Project'\n",
    "#     except:\n",
    "#         print('Warning', row, 'project tried')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Log Sum Baseline'] = np.unique(list(person_trips_baseline['mode_choice_logsum_y'][(person_trips_baseline['person_id']==row[0])&(person_trips_baseline['trip_num']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Log Sum Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Log Sum TR'] = np.unique(list(person_TR['mode_choice_logsum_y'][(person_TR['person_id']==row[0])&(person_TR['trip_num']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Log Sum TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Diff Log Sum'] = persons_baseline.at[i,'Log Sum TR']-persons_baseline.at[i,'Log Sum Baseline']\n",
    "#     except:\n",
    "#         print('Warning', row, 'Diff Log Sum TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicles Used Baseline'] = np.unique(list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicles Used Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicles Used TR'] = np.unique(list(PtoPTss_TR['vehicleID'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicles Used TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Bus agencies Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Bus agencies Used Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Bus agencies Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Bus agencies Used TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'First Bus agency Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'First Bus agency Used Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'First Bus agency Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'First Bus agency Used TR')  \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Length TR'] = int(PtoPTss_TR_dict[row][0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'TR_length')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Duration TR'] = int(PtoPTss_TR_dict[row][1])\n",
    "#     except:\n",
    "#         print('Warning', row, 'TR_duration')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Length Baseline'] = int(PtoPTss_baseline_dict[row][0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'baseline_length')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Duration Baseline'] = int(PtoPTss_baseline_dict[row][1])\n",
    "#     except:\n",
    "#         print('Warning', row, 'baseline_duration')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Diff Length'] = int(persons_baseline.at[i,'Trip Length TR']-persons_baseline.at[i,'Trip Length Baseline'])\n",
    "#     except:\n",
    "#         print('Warning', row, 'diff_length')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Diff Duration'] = int(persons_baseline.at[i,'Trip Duration TR']-persons_baseline.at[i,'Trip Duration Baseline'])\n",
    "#     except:\n",
    "#         print('Warning', row, 'diff_duration')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity From TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_from_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity From TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_From_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity To TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_To_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity To TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_To_TR')   \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity From Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_from_Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity From Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_From_Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity To Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_To_Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity To Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_To_Baseline')   \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicle Types Used Baseline'] = np.unique(list(PtoPTss_baseline['mode'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicle Types Used baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicle Types Used TR'] = np.unique(list(PtoPTss_TR['mode'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicle Types Used TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Mode Baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'Baseline planned mode')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Mode TR'] = list(plans_TR['legMode'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1])])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'TR planned mode')\n",
    "#     try:\n",
    "#         plan_dep_time_baseline = list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'Chosen Mode Baseline'] = list(mode_choice_baseline['mode'][(mode_choice_baseline['person']==row[0])&(mode_choice_baseline['time']>=plan_dep_time_baseline-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'mode_choice_baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Chosen Mode TR'] = list(mode_choice_TR['mode'][(mode_choice_TR['person']==row[0])&(mode_choice_TR['time']>=persons_baseline.at[i,'Planned Depart Time TR']-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'mode_choice_TR')\n",
    "        \n",
    "# ####################################\n",
    "# for row in PtoPTss_TR_AC_dict.keys():\n",
    "#     i+=1\n",
    "#     if i%50==0:\n",
    "#         print(i) \n",
    "#         break\n",
    "        \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Person'] = row[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'person')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Plan Index'] = int(row[1])\n",
    "#     except:\n",
    "#         print('Warning', row, 'plan_index')    \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity From Baseline'] = int(list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity From Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity To Baseline'] = int(list(plans_baseline['activityType'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity To Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity From TR'] = int(list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity From TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Activity To TR'] = int(list(plans_TR['activityType'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'Activity To TR')   \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Depart Time Baseline'] = int(list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'plan_dep_time_baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Depart Time TR'] = int(list(plans_TR['activityEndTime'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'plan_dep_time_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Project Tried'] = 'AC - 1TEMPO'\n",
    "#     except:\n",
    "#         print('Warning', row, 'project tried')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Log Sum Baseline'] = np.unique(list(person_trips_baseline['mode_choice_logsum_y'][(person_trips_baseline['person_id']==row[0])&(person_trips_baseline['trip_num']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Log Sum Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Log Sum TR'] = np.unique(list(person_TR['mode_choice_logsum_y'][(person_TR['person_id']==row[0])&(person_TR['trip_num']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Log Sum TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Diff Log Sum'] = persons_baseline.at[i,'Log Sum TR']-persons_baseline.at[i,'Log Sum Baseline']\n",
    "#     except:\n",
    "#         print('Warning', row, 'Diff Log Sum TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicles Used Baseline'] = np.unique(list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicles Used Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicles Used TR'] = np.unique(list(PtoPTss_TR['vehicleID'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicles Used TR')    \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Bus agencies Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Bus agencies Used Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Bus agencies Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Bus agencies Used TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'First Bus agency Used Baseline'] = np.unique(list(PtoPTss_baseline_bus['vehicle2'][(PtoPTss_baseline_bus['personID']==row[0])&(PtoPTss_baseline_bus['planIndex']==row[1])]))[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'First Bus agency Used Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'First Bus agency Used TR'] = np.unique(list(PtoPTss_TR_bus['vehicle2'][(PtoPTss_TR_bus['personID']==row[0])&(PtoPTss_TR_bus['planIndex']==row[1])]))[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'First Bus agency Used TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Length TR'] = int(PtoPTss_TR_dict[row][0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'TR_length')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Duration TR'] = int(PtoPTss_TR_dict[row][1])\n",
    "#     except:\n",
    "#         print('Warning', row, 'TR_duration')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Length Baseline'] = int(PtoPTss_baseline_dict[row][0])\n",
    "#     except:\n",
    "#         print('Warning', row, 'baseline_length')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Trip Duration Baseline'] = int(PtoPTss_baseline_dict[row][1])\n",
    "#     except:\n",
    "#         print('Warning', row, 'baseline_duration')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Diff Length'] = int(persons_baseline.at[i,'Trip Length TR']-persons_baseline.at[i,'Trip Length Baseline'])\n",
    "#     except:\n",
    "#         print('Warning', row, 'diff_length')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Diff Duration'] = int(persons_baseline.at[i,'Trip Duration TR']-persons_baseline.at[i,'Trip Duration Baseline'])\n",
    "#     except:\n",
    "#         print('Warning', row, 'diff_duration')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity From TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_from_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity From TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_From_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity To TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_To_TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity To TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_To_TR')   \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity From Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_from_Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity From Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_From_Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'X Activity To Baseline'] = list(plans_baseline['activityLocationX'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'x_activity_To_Baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Y Activity To Baseline'] = list(plans_baseline['activityLocationY'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]+1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'y_activity_To_Baseline')   \n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicle Types Used Baseline'] = np.unique(list(PtoPTss_baseline['mode'][(PtoPTss_baseline['personID']==row[0])&(PtoPTss_baseline['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicle Types Used baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Vehicle Types Used TR'] = np.unique(list(PtoPTss_TR['mode'][(PtoPTss_TR['personID']==row[0])&(PtoPTss_TR['planIndex']==row[1])]))\n",
    "#     except:\n",
    "#         print('Warning', row, 'Vehicle Types Used TR')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Mode Baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'Baseline planned mode')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Planned Mode TR'] = list(plans_TR['legMode'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1])])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'TR planned mode')\n",
    "#     try:\n",
    "#         plan_dep_time_baseline = list(plans_baseline['activityEndTime'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1]-1)])[0]\n",
    "#         persons_baseline.at[i,'Chosen Mode Baseline'] = list(mode_choice_baseline['mode'][(mode_choice_baseline['person']==row[0])&(mode_choice_baseline['time']>=plan_dep_time_baseline-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'mode_choice_baseline')\n",
    "#     try:\n",
    "#         persons_baseline.at[i,'Chosen Mode TR'] = list(mode_choice_TR['mode'][(mode_choice_TR['person']==row[0])&(mode_choice_TR['time']>=persons_baseline.at[i,'Planned Depart Time TR']-1)])[0]\n",
    "#     except:\n",
    "#         print('Warning', row, 'mode_choice_TR')\n",
    "\n",
    "        \n",
    "# zipcode = gpd.read_file('/Users/cpoliziani/Downloads/TAZ to ZIP/ZCTA2010.shp')\n",
    "# persons_baseline = addGeometryIdToDataFrame(persons_baseline, zipcode, 'X Activity From TR', 'Y Activity From TR', 'ZIP Departure TR')\n",
    "# persons_baseline = addGeometryIdToDataFrame(persons_baseline, zipcode, 'X Activity To TR', 'Y Activity To TR', 'ZIP Arrival TR')\n",
    "# persons_baseline = addGeometryIdToDataFrame(persons_baseline, zipcode, 'X Activity From Baseline', 'Y Activity From Baseline', 'ZIP Departure Baseline')\n",
    "# persons_baseline = addGeometryIdToDataFrame(persons_baseline, zipcode, 'X Activity To Baseline', 'Y Activity To Baseline', 'ZIP Arrival Baseline')\n",
    "\n",
    "\n",
    "# #Add Switch From Column\n",
    "# switch_type = []\n",
    "# for agencies_baseline, project in zip(persons_baseline['Bus agencies Used Baseline'],persons_baseline['Project Tried']):\n",
    "#     if len(agencies_baseline) == 0:\n",
    "#         switch_type.append('Switch from another mode')\n",
    "#     elif project == 'SF - Central Subway' and 'SF' in agencies_baseline:\n",
    "#         switch_type.append('Switch from same transit agency')\n",
    "#     elif project == 'AC - 1TEMPO' and 'AC' in agencies_baseline:\n",
    "#         switch_type.append('Switch from same transit agency')\n",
    "#     elif project == 'CA - Electrification Project' and 'ca' in agencies_baseline:\n",
    "#         switch_type.append('Switch from same transit agency')\n",
    "#     else:\n",
    "#         switch_type.append('Switch from another transit agency')\n",
    "\n",
    "# persons_baseline['Switch From'] = switch_type\n",
    "\n",
    "# persons_baseline.to_csv('/Users/cpoliziani/Downloads/person_database.csv')\n",
    "\n",
    "\n",
    "# person_trips_baseline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# persons_baseline_AC = persons_baseline[persons_baseline['Project Tried']=='AC - 1TEMPO']\n",
    "\n",
    "# persons_baseline_AC.dropna(axis=0)\n",
    "\n",
    "# sum(persons_baseline_AC['Diff Duration'])\n",
    "\n",
    "# sum(persons_baseline_AC['Diff Length'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# events = pd.read_csv('s3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz', nrows = 900000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# veh = events[['vehicle','type']].dropna()\n",
    "# veh = veh[(veh['vehicle'].str.contains('rideHail'))&(veh['type']=='PathTraversal')]\n",
    "# vei = []\n",
    "# for ve in veh['vehicle']:\n",
    "#     vei.append(ve[-10:])\n",
    "\n",
    "# np.unique(vei, return_counts=True)\n",
    "\n",
    "# pd.read_csv('/Users/cpoliziani/Downloads/0.skimsRidehail (1).csv.gz')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # for row in PtoPTss_TR_CA_dict.keys():\n",
    "# #     i+=1\n",
    "# #     if i%1000==0:\n",
    "# #         print(i)\n",
    "# #     try:\n",
    "# #         persons_baseline.at[i,'person'] = row[0]\n",
    "# #         persons_baseline.at[i,'plan_index'] = row[1]\n",
    "# #         persons_baseline.at[i,'project tried'] = 'CA - Electrification Project'\n",
    "# #         persons_baseline.at[i,'TR_length'] = PtoPTss_TR_dict[row][0]\n",
    "# #         persons_baseline.at[i,'TR_duration'] = PtoPTss_TR_dict[row][1]\n",
    "# #         persons_baseline.at[i,'baseline_length'] = PtoPTss_baseline_dict[row][0]\n",
    "# #         persons_baseline.at[i,'baseline_duration'] = PtoPTss_baseline_dict[row][1]\n",
    "# #         persons_baseline.at[i,'diff_length'] = persons_baseline.at[i,'TR_length']-persons_baseline.at[i,'baseline_length']\n",
    "# #         persons_baseline.at[i,'diff_duration'] = persons_baseline.at[i,'TR_duration']-persons_baseline.at[i,'baseline_duration']\n",
    "# #         persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "# #         persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "# #         persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "# #     except:\n",
    "# #         persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "# #         persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "# #         persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "# #         persons_baseline.at[i,'person'] = row[0]\n",
    "# #         persons_baseline.at[i,'plan_index'] = row[1]\n",
    "# #         persons_baseline.at[i,'project tried'] = 'CA - Electrification Project'\n",
    "# #         print('WARNING:',row[0], row[1]) \n",
    "\n",
    "\n",
    "# # for row in PtoPTss_TR_AC_dict.keys():\n",
    "# #     i+=1\n",
    "# #     if i%1000==0:\n",
    "# #         print(i)\n",
    "# #     try:\n",
    "# #         persons_baseline.at[i,'person'] = row[0]\n",
    "# #         persons_baseline.at[i,'plan_index'] = row[1]\n",
    "# #         persons_baseline.at[i,'project tried'] = 'AC - 1 Tempo BRT Line'\n",
    "# #         persons_baseline.at[i,'TR_length'] = PtoPTss_TR_dict[row][0]\n",
    "# #         persons_baseline.at[i,'TR_duration'] = PtoPTss_TR_dict[row][1]\n",
    "# #         persons_baseline.at[i,'baseline_length'] = PtoPTss_baseline_dict[row][0]\n",
    "# #         persons_baseline.at[i,'baseline_duration'] = PtoPTss_baseline_dict[row][1]\n",
    "# #         persons_baseline.at[i,'diff_length'] = persons_baseline.at[i,'TR_length']-persons_baseline.at[i,'baseline_length']\n",
    "# #         persons_baseline.at[i,'diff_duration'] = persons_baseline.at[i,'TR_duration']-persons_baseline.at[i,'baseline_duration']\n",
    "# #         persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "# #         persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "# #         persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "# #     except:\n",
    "# #         persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "# #         persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==row[0])&(plans_TR['planElementIndex']==row[1]-1)])[0]\n",
    "# #         persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==row[0])&(plans_baseline['planElementIndex']==row[1])])[0]\n",
    "# #         persons_baseline.at[i,'person'] = row[0]\n",
    "# #         persons_baseline.at[i,'plan_index'] = row[1]\n",
    "# #         persons_baseline.at[i,'project tried'] = 'AC - 1 Tempo BRT Line'\n",
    "# #         print('WARNING:',row[0], row[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##############\n",
    "# # trips_TR = pd.concat([line_CA_trips_TR['trip_id'],line_CS_trips_TR['trip_id'],line_1T_trips_TR['trip_id']])\n",
    "# # for vehicle, person, plan_index, vehicle2 in zip(PtoPTss['vehicleID'],PtoPTss['personID'],PtoPTss['planIndex'],PtoPTss['vehicle2'] ):\n",
    "# #     if int(vehicle.split(':')[1]) in list(trips_TR):\n",
    "# #         i+=1\n",
    "# #         if i%1000==0:\n",
    "# #             print(i)\n",
    "# #         try:\n",
    "\n",
    "# #             persons_baseline.at[i,'person'] = person\n",
    "# #             persons_baseline.at[i,'plan_index'] = plan_index\n",
    "# #             persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==person)&(plans_baseline['planElementIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "# #             persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "# #             persons_baseline.at[i,'vehicle_now'] = vehicle\n",
    "# #             if vehicle2 == 'SF':\n",
    "# #                 persons_baseline.at[i,'project'] = 'CS'\n",
    "# #             if vehicle2 == 'Ca':\n",
    "# #                 persons_baseline.at[i,'project'] = 'CA'\n",
    "# #             if vehicle2 == 'AC':\n",
    "# #                 persons_baseline.at[i,'project'] = '1T'\n",
    "\n",
    "# #             persons_baseline.at[i,'vehicle_baseline'] = list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'agency_baseline'] = list(PtoPTss_baseline['vehicle2'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'length_baseline'] = list(PtoPTss_baseline['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'length_TR'] = list(PtoPTss_TR['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'duration_baseline'] = list(PtoPTss_baseline['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'duration_TR'] = list(PtoPTss_TR['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'speed_baseline'] = persons_baseline.loc[i,'length_baseline']/persons_baseline.loc[i,'duration_baseline']\n",
    "# #             persons_baseline.at[i,'speed_TR'] = persons_baseline.loc[i,'length_TR']/persons_baseline.loc[i,'duration_TR']\n",
    "# #             persons_baseline.at[i,'diff_length'] = persons_baseline.loc[i,'length_TR']-persons_baseline.loc[i,'length_baseline'] \n",
    "# #             persons_baseline.at[i,'diff_duration'] = persons_baseline.loc[i,'duration_TR']-persons_baseline.loc[i,'duration_baseline'] \n",
    "# #             persons_baseline.at[i,'diff_speed'] = persons_baseline.loc[i,'speed_TR']-persons_baseline.loc[i,'speed_baseline'] \n",
    "# #         except:\n",
    "# #             persons_baseline.at[i,'person'] = person\n",
    "# #             persons_baseline.at[i,'plan_index'] = plan_index\n",
    "# #             persons_baseline.at[i,'vehicle_now'] = vehicle\n",
    "# #             if vehicle2 == 'SF':\n",
    "# #                 persons_baseline.at[i,'project'] = 'CS'\n",
    "# #             if vehicle2 == 'Ca':\n",
    "# #                 persons_baseline.at[i,'project'] = 'CA'\n",
    "# #             if vehicle2 == 'AC':\n",
    "# #                 persons_baseline.at[i,'project'] = '1T'\n",
    "\n",
    "# #             print('PtoPTss_baseline not found person and plan index',person,plan_index, vehicle)\n",
    "# #     print('Warning')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # persons_baseline = pd.DataFrame(['person','plan_index','mode_baseline','vehicle_baseline','agency_baseline',\n",
    "# #                                  'x_activity_TR','y_activity_TR','vehicle_now'])\n",
    "# # i = 0\n",
    "# # PtoPTss=pd.concat(PtoPTss_AC_TR,PtoPTss_SF_TR,PtoPTss_CA_TR)\n",
    "# # for vehicle, person, plan_index in zip(PtoPTss['vehicleID'],PtoPTss['personID'],PtoPTss['planIndex'] ):\n",
    "# #     if int(vehicle.split(':')[1]) in list(line_1T_trips_TR):\n",
    "# #         i+=1\n",
    "# #         persons_baseline.loc[i,'person'] = person\n",
    "# #         persons_baseline.loc[i,'plan_index'] = plan_index\n",
    "# #         persons_baseline.loc[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==person)&(plans_baseline['planElementIndex']==plan_index)])[0]\n",
    "# #         persons_baseline.loc[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "# #         persons_baseline.loc[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "# #         persons_baseline.loc[i,'vehicle_now'] = '1T'\n",
    "# #         try:\n",
    "# #             persons_baseline.loc[i,'vehicle_baseline'] = list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.loc[i,'agency_baseline'] = list(PtoPTss_baseline['vehicle2'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.loc[i,'length_baseline'] = list(PtoPTss_baseline['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.loc[i,'length_TR'] = list(PtoPTss_TR['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.loc[i,'duration_baseline'] = list(PtoPTss_baseline['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.loc[i,'duration_TR'] = list(PtoPTss_TR['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.loc[i,'speed_baseline'] = persons_baseline.loc[i,'length_baseline']/persons_baseline.loc[i,'duration_baseline']\n",
    "# #             persons_baseline.loc[i,'speed_TR'] = persons_baseline.loc[i,'length_TR']/persons_baseline.loc[i,'duration_TR']\n",
    "# #             persons_baseline.loc[i,'diff_length'] = persons_baseline.loc[i,'length_TR']-persons_baseline.loc[i,'length_baseline'] \n",
    "# #             persons_baseline.loc[i,'diff_duration'] = persons_baseline.loc[i,'duration_TR']-persons_baseline.loc[i,'duration_baseline'] \n",
    "# #             persons_baseline.loc[i,'speed_length'] = persons_baseline.loc[i,'speed_TR']-persons_baseline.loc[i,'speed_baseline'] \n",
    "# #         except:\n",
    "# #             persons_baseline.loc[i,'vehicle_baseline'] = None\n",
    "# #             persons_baseline.loc[i,'agency_baseline'] = None\n",
    "# #             print('PtoPTss_baseline not found person and plan index',person,plan_index, vehicle)\n",
    "\n",
    "\n",
    "# # persons_baseline.to_csv('/Users/cpoliziani/Downloads/person_database.csv')\n",
    "\n",
    "# # PtoPTss_baseline\n",
    "\n",
    "\n",
    "# # persons_baseline = pd.DataFrame()\n",
    "# # i = 0\n",
    "# # PtoPTss=pd.concat([PtoPTss_AC_TR,PtoPTss_SF_TR,PtoPTss_CA_TR])\n",
    "# # for vehicle, person, plan_index, vehicle2 in zip(PtoPTss['vehicleID'],PtoPTss['personID'],PtoPTss['planIndex'],PtoPTss['vehicle2'] ):\n",
    "# #     if int(vehicle.split(':')[1]) in list(line_1T_trips_TR):\n",
    "# #         i+=1\n",
    "\n",
    "# #             persons_baseline.at[i,'person'] = person\n",
    "# #             persons_baseline.at[i,'plan_index'] = plan_index\n",
    "# #             persons_baseline.at[i,'mode_baseline'] = list(plans_baseline['legMode'][(plans_baseline['personId']==person)&(plans_baseline['planElementIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'x_activity_TR'] = list(plans_TR['activityLocationX'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "# #             persons_baseline.at[i,'y_activity_TR'] = list(plans_TR['activityLocationY'][(plans_TR['personId']==person)&(plans_TR['planElementIndex']==plan_index-1)])[0]\n",
    "# #             persons_baseline.at[i,'vehicle_now'] = vehicle\n",
    "# #             if vehicle2 == 'SF':\n",
    "# #                 persons_baseline.at[i,'project'] = 'CS'\n",
    "# #             if vehicle2 == 'Ca':\n",
    "# #                 persons_baseline.at[i,'project'] = 'CA'\n",
    "# #             if vehicle2 == 'AC':\n",
    "# #                 persons_baseline.at[i,'project'] = '1T'\n",
    "# #         try:\n",
    "\n",
    "# #             persons_baseline.at[i,'vehicle_baseline'] = list(PtoPTss_baseline['vehicleID'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'agency_baseline'] = list(PtoPTss_baseline['vehicle2'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'length_baseline'] = list(PtoPTss_baseline['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'length_TR'] = list(PtoPTss_TR['length'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'duration_baseline'] = list(PtoPTss_baseline['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'duration_TR'] = list(PtoPTss_TR['duration'][(PtoPTss_baseline['personID']==person)&(PtoPTss_baseline['planIndex']==plan_index)])[0]\n",
    "# #             persons_baseline.at[i,'speed_baseline'] = persons_baseline.loc[i,'length_baseline']/persons_baseline.loc[i,'duration_baseline']\n",
    "# #             persons_baseline.at[i,'speed_TR'] = persons_baseline.loc[i,'length_TR']/persons_baseline.loc[i,'duration_TR']\n",
    "# #             persons_baseline.at[i,'diff_length'] = persons_baseline.loc[i,'length_TR']-persons_baseline.loc[i,'length_baseline'] \n",
    "# #             persons_baseline.at[i,'diff_duration'] = persons_baseline.loc[i,'duration_TR']-persons_baseline.loc[i,'duration_baseline'] \n",
    "# #             persons_baseline.at[i,'diff_speed'] = persons_baseline.loc[i,'speed_TR']-persons_baseline.loc[i,'speed_baseline'] \n",
    "# #         except:\n",
    "# #             persons_baseline.at[i,'person'] = person\n",
    "# #             persons_baseline.at[i,'plan_index'] = plan_index\n",
    "# #             persons_baseline.at[i,'vehicle_now'] = vehicle\n",
    "# #             if vehicle2 == 'SF':\n",
    "# #                 persons_baseline.at[i,'project'] = 'CS'\n",
    "# #             if vehicle2 == 'Ca':\n",
    "# #                 persons_baseline.at[i,'project'] = 'CA'\n",
    "# #             if vehicle2 == 'AC':\n",
    "# #                 persons_baseline.at[i,'project'] = '1T'\n",
    "\n",
    "# #             print('PtoPTss_baseline not found person and plan index',person,plan_index, vehicle)\n",
    "\n",
    "\n",
    "# # persons_baseline.to_csv('/Users/cpoliziani/Downloads/person_database.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LIRR_capacities_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/apr2020LIRR.csv')\n",
    "# LIRR_capacities_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/aug2020LIRR.csv')\n",
    "# LIRR_capacities_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/aug2021LIRR.csv')\n",
    "# LIRR_capacities_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/jan2022LIRR.csv')\n",
    "# LIRR_capacities_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/apr2022LIRR.csv')\n",
    "\n",
    "# MNR_capacities_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/apr2020MNR.csv')\n",
    "# MNR_capacities_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/aug2020MNR.csv')\n",
    "# MNR_capacities_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/aug2021MNR.csv')\n",
    "# MNR_capacities_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/jan2022MNR.csv')\n",
    "# MNR_capacities_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/apr2022MNR.csv')\n",
    "\n",
    "# # LIRR_capacities_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/LIRR_capacities.csv')\n",
    "# # MNR_capacities = MNR_capacities.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "# # LIRR_capacities = LIRR_capacities.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "\n",
    "\n",
    "# capacities_data = [LIRR_capacities_apr2020,\n",
    "#         LIRR_capacities_aug2020,\n",
    "#         LIRR_capacities_aug2021,\n",
    "#         LIRR_capacities_jan2022,\n",
    "#         LIRR_capacities_may2022,\n",
    "#         MNR_capacities_apr2020,\n",
    "#         MNR_capacities_aug2020,\n",
    "#         MNR_capacities_aug2021,\n",
    "#         MNR_capacities_jan2022,\n",
    "#         MNR_capacities_may2022,\n",
    "#         ]\n",
    "\n",
    "# for capacity_data in capacities_data:\n",
    "#     trains = []\n",
    "#     for train in capacity_data['Train']:\n",
    "#         try:\n",
    "#             trains.append(int(train))\n",
    "#         except:\n",
    "#             trains.append(train)\n",
    "#     capacity_data['Train'] = trains\n",
    "    \n",
    "\n",
    "\n",
    "# LIRR_capacities_apr2020 = LIRR_capacities_apr2020.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "# LIRR_capacities_aug2020 = LIRR_capacities_aug2020.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "# LIRR_capacities_aug2021 = LIRR_capacities_aug2021.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "# LIRR_capacities_jan2022 = LIRR_capacities_jan2022.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "# LIRR_capacities_may2022 = LIRR_capacities_may2022.groupby(['Train']).apply(lambda x: [list(x['Total Seats'])]).to_dict()\n",
    "\n",
    "# MNR_capacities_apr2020 = MNR_capacities_apr2020.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "# MNR_capacities_aug2020 = MNR_capacities_aug2020.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "# MNR_capacities_aug2021 = MNR_capacities_aug2021.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "# MNR_capacities_jan2022 = MNR_capacities_jan2022.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "# MNR_capacities_may2022 = MNR_capacities_may2022.groupby(['Train']).apply(lambda x: [list(x['Total Seat'])]).to_dict()\n",
    "\n",
    "\n",
    "# LIRR_trips_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-1april2020/Long_Island_Rail_20200318/trips.txt')\n",
    "# LIRR_trips_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5august2020/Long_Island_Rail_20200629/trips.txt')\n",
    "# LIRR_trips_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-4august2021/Long_Island_Rail_20210726/trips.txt')\n",
    "# LIRR_trips_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5january2022/Long_Island_Rail_20211216/trips.txt')\n",
    "# LIRR_trips_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-11may2022/Long_Island_Rail_20220430/trips.txt')\n",
    "\n",
    "# LIRR_trips_apr2020['agency_id']='LI'\n",
    "# LIRR_trips_aug2020['agency_id']='LI'\n",
    "# LIRR_trips_aug2021['agency_id']='LI'\n",
    "# LIRR_trips_jan2022['agency_id']='LI'\n",
    "# LIRR_trips_may2022['agency_id']='LI'\n",
    "\n",
    "# MNR_trips_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-1april2020/Metro-North_Railroad_20200325/trips.txt')\n",
    "# MNR_trips_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5august2020/Metro-North_Railroad_20200731/trips.txt')\n",
    "# MNR_trips_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-4august2021/Metro-North_Railroad_20210721/trips.txt')\n",
    "# MNR_trips_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5january2022/Metro-North_Railroad_20211222/trips.txt')\n",
    "# MNR_trips_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-11may2022/Metro-North_Railroad_20220429/trips.txt')\n",
    "\n",
    "# MNR_trips_apr2020['agency_id']='1'\n",
    "# MNR_trips_aug2020['agency_id']='1'\n",
    "# MNR_trips_aug2021['agency_id']='1'\n",
    "# MNR_trips_jan2022['agency_id']='1'\n",
    "# MNR_trips_may2022['agency_id']='1'\n",
    "\n",
    "# # MNR_routes_apr2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-1april2020/Metro-North_Railroad_20200325/routes.txt')\n",
    "# # MNR_routes_aug2020 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5august2020/Metro-North_Railroad_20200731/routes.txt')\n",
    "# # MNR_routes_aug2021 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-4august2021/Metro-North_Railroad_20210721/routes.txt')\n",
    "# # MNR_routes_jan2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-5january2022/Metro-North_Railroad_20211222/routes.txt')\n",
    "# # MNR_routes_may2022 = pd.read_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/r5-prod-11may2022/Metro-North_Railroad_20220429/routes.txt')\n",
    "\n",
    "# # trips_data_MNR = [MNR_trips_apr2020,\n",
    "# #         MNR_trips_aug2020,\n",
    "# #         MNR_trips_aug2021,\n",
    "# #         MNR_trips_jan2022,\n",
    "# #         MNR_trips_may2022,\n",
    "# #         ]\n",
    "\n",
    "# # routes_data_MNR = [MNR_routes_apr2020,\n",
    "# #         MNR_routes_aug2020,\n",
    "# #         MNR_routes_aug2021,\n",
    "# #         MNR_routes_jan2022,\n",
    "# #         MNR_routes_may2022,\n",
    "# #         ]\n",
    "\n",
    "# # for trip_data_MNR, route_data_MNR, i  in zip(trips_data_MNR,routes_data_MNR, range(len(trips_data))):\n",
    "# #     agencies =[]\n",
    "# #     for route in trip_data_MNR['route_id']:\n",
    "# #         agencies.append(list(route_data_MNR['agency_id'][route_data_MNR['route_id']==route])[0])\n",
    "# #     trip_data_MNR['agency_id']=agencies\n",
    "\n",
    "\n",
    "# # MNR_trips_apr2020 = trips_data_MNR[0]\n",
    "# # MNR_trips_aug2020 = trips_data_MNR[1]\n",
    "# # MNR_trips_aug2021 = trips_data_MNR[2]\n",
    "# # MNR_trips_jan2022 = trips_data_MNR[3]\n",
    "# # MNR_trips_may2022 = trips_data_MNR[4]\n",
    "\n",
    "# trips_data = [LIRR_trips_apr2020,\n",
    "#         LIRR_trips_aug2020,\n",
    "#         LIRR_trips_aug2021,\n",
    "#         LIRR_trips_jan2022,\n",
    "#         LIRR_trips_may2022,\n",
    "#         MNR_trips_apr2020,\n",
    "#         MNR_trips_aug2020,\n",
    "#         MNR_trips_aug2021,\n",
    "#         MNR_trips_jan2022,\n",
    "#         MNR_trips_may2022,\n",
    "#         ]\n",
    "\n",
    "# capacities_data = [LIRR_capacities_apr2020,\n",
    "#         LIRR_capacities_aug2020,\n",
    "#         LIRR_capacities_aug2021,\n",
    "#         LIRR_capacities_jan2022,\n",
    "#         LIRR_capacities_may2022,\n",
    "#         MNR_capacities_apr2020,\n",
    "#         MNR_capacities_aug2020,\n",
    "#         MNR_capacities_aug2021,\n",
    "#         MNR_capacities_jan2022,\n",
    "#         MNR_capacities_may2022,\n",
    "#         ]\n",
    "\n",
    "# for trip_data, capacity_data in zip(trips_data, capacities_data):\n",
    "\n",
    "#     capacities = []\n",
    "#     wrong_ids = []\n",
    "#     print('number of trip', len(trip_data),'number of capacities', len(capacity_data))\n",
    "#     print('number of unique trip', len(np.unique(trip_data['trip_short_name'])))\n",
    "#     for trip_short_name in trip_data['trip_short_name']:\n",
    "#         try:\n",
    "#             capacities.append(capacity_data[trip_short_name][0][0])\n",
    "#         except:\n",
    "#             try:\n",
    "#                 capacities.append(capacity_data[float(trip_short_name)][0][0])\n",
    "#             except:\n",
    "#                 wrong_ids.append(trip_short_name)\n",
    "#                 capacities.append(np.nan)\n",
    "#     trip_data['capacity'] = capacities\n",
    "#     print('Warning!! Not found',len(wrong_ids))\n",
    "# #     print(trip_data)\n",
    "#     print('######################')\n",
    "\n",
    "\n",
    "\n",
    "# for trip_data in trips_data:\n",
    "#     max_cap = max(list(trip_data['capacity'].dropna()))\n",
    "#     print(max_cap)\n",
    "#     trip_data['capacity'] = trip_data['capacity'].fillna(max_cap)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# trips_data_apr2020 = [trips_data[0],trips_data[5]]\n",
    "# trips_data_aug2020 = [trips_data[1],trips_data[6]]\n",
    "# trips_data_aug2021 = [trips_data[2],trips_data[7]]\n",
    "# trips_data_jan2022 = [trips_data[3],trips_data[8]]\n",
    "# trips_data_may2022 = [trips_data[4],trips_data[9]]\n",
    "\n",
    "# transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "#                                            'routeId',\n",
    "#                                            'tripId',\n",
    "#                                            'capacity',\n",
    "#                                             'vehicleTypeId',\n",
    "#                                           ])\n",
    "# i=0      \n",
    "# for trip_data, j in zip(trips_data_apr2020,[0,1]):\n",
    "#     for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "#         i+=1\n",
    "#         if i%5000==0:\n",
    "#             print(i)\n",
    "#         transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "#         transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "#         if j == 0:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20200318:'+str(tripID)\n",
    "#         elif j == 1:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20200325:'+str(tripID)\n",
    "#         transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "#         transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "# transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_apr2020.csv')\n",
    "\n",
    "\n",
    "# transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "#                                            'routeId',\n",
    "#                                            'tripId',\n",
    "#                                            'capacity',\n",
    "#                                             'vehicleTypeId',\n",
    "#                                           ])\n",
    "# i=0      \n",
    "# for trip_data, j in zip(trips_data_aug2020,[0,1]):\n",
    "#     for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "#         i+=1\n",
    "#         if i%5000==0:\n",
    "#             print(i)\n",
    "#         transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "#         transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "#         if j == 0:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20200629:'+str(tripID)\n",
    "#         elif j == 1:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20200731:'+str(tripID)\n",
    "#         transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "#         transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "# transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_aug2020.csv')\n",
    "\n",
    "\n",
    "\n",
    "# transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "#                                            'routeId',\n",
    "#                                            'tripId',\n",
    "#                                            'capacity',\n",
    "#                                             'vehicleTypeId',\n",
    "#                                           ])\n",
    "# i=0      \n",
    "# for trip_data, j in zip(trips_data_aug2021,[0,1]):\n",
    "#     for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "#         i+=1\n",
    "#         if i%5000==0:\n",
    "#             print(i)\n",
    "#         transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "#         transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "#         if j == 0:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20210726:'+str(tripID)\n",
    "#         elif j == 1:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20210721:'+str(tripID)\n",
    "#         transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "#         transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "# transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_aug2021.csv')\n",
    "\n",
    "\n",
    "\n",
    "# transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "#                                            'routeId',\n",
    "#                                            'tripId',\n",
    "#                                            'capacity',\n",
    "#                                             'vehicleTypeId',\n",
    "#                                           ])\n",
    "# i=0      \n",
    "# for trip_data, j in zip(trips_data_jan2022,[0,1]):\n",
    "#     for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "#         i+=1\n",
    "#         if i%5000==0:\n",
    "#             print(i)\n",
    "#         transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "#         transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "#         if j == 0:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20211216:'+str(tripID)\n",
    "#         elif j == 1:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20211222:'+str(tripID)\n",
    "#         transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "#         transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "# transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_jan2022.csv')\n",
    "\n",
    "\n",
    "\n",
    "# transitVehicleTypesbyTrip = pd.DataFrame(columns = ['agencyId',\n",
    "#                                            'routeId',\n",
    "#                                            'tripId',\n",
    "#                                             'capacity',\n",
    "#                                            'vehicleTypeId',\n",
    "#                                           ])\n",
    "# i=0      \n",
    "# for trip_data, j in zip(trips_data_may2022,[0,1]):\n",
    "#     for agencyID, tripID, routeID, capacity in zip(trip_data['agency_id'], trip_data['trip_id'],trip_data['route_id'],trip_data['capacity']):\n",
    "#         i+=1\n",
    "#         if i%5000==0:\n",
    "#             print(i)\n",
    "#         transitVehicleTypesbyTrip.at[i,'agencyId'] = agencyID\n",
    "#         transitVehicleTypesbyTrip.at[i,'routeId'] = routeID\n",
    "#         if j == 0:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Long_Island_Rail_20220430:'+str(tripID)\n",
    "#         elif j == 1:\n",
    "#             transitVehicleTypesbyTrip.at[i,'tripId'] = 'Metro-North_Railroad_20220429:'+str(tripID)\n",
    "#         transitVehicleTypesbyTrip.at[i,'capacity'] = capacity\n",
    "#         transitVehicleTypesbyTrip.at[i,'vehicleTypeId'] = 'RAIL-DEFAULT'\n",
    "\n",
    "# transitVehicleTypesbyTrip.to_csv('/Users/cpoliziani/Downloads/Data/EPI/Capacities/transitVehicleTypesbyTrip_may2022.csv')\n",
    "\n",
    "\n",
    "\n",
    "# trips_data_apr2020[1]\n",
    "\n",
    "# pd.read_csv('s3://beam-outputs/output/newyork/new-york-jan2022-0-of-10__2022-09-21_17-07-49_qdx/ITERS/it.10/10.events.csv.gz', nrows = 90000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

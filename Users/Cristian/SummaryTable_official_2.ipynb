{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f4d318-29e8-4b98-8b77-935b6eb7c70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db285d87-fbe8-4e70-8b6d-bea93f197ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectAllData(outDirectory, year_it,\n",
    "                  trips, activities, PTs, PtoPTs, LT, PLT, VLT, ST, name):\n",
    "\n",
    "\n",
    "    storage_client = storage.Client.from_service_account_json('outputs/beam-core-b829a9287f0e.json')\n",
    "    bucket_name = 'beam-core-outputs'\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    if is_GEO:\n",
    "        \n",
    "        BGs = gpd.read_file('/vsicurl/https://github.com/LBNL-UCB-STI/beam-core-analysis/raw/main/Users/Zach/scenario/sfbay-blockgroups-2010/641aa0d4-ce5b-4a81-9c30-8790c4ab8cfb202047-1-wkkklf.j5ouj.shp')\n",
    "        \n",
    "        trips = addGeometryIdToDataFrame(trips, BGs, 'originX', 'originY', 'startBlockGroup')\n",
    "        trips = addGeometryIdToDataFrame(trips, BGs, 'destinationX', 'destinationY', 'endBlockGroup')\n",
    "        activities = addGeometryIdToDataFrame(activities, BGs, 'activityLocationX', 'activityLocationY', 'activityBlockGroup')\n",
    "        \n",
    "        print('Add block ID infos')\n",
    "        # block_info = pd.read_csv('local_files/bg_w_geog_labels.csv')\n",
    "        block_info = pd.read_csv('https://github.com/LBNL-UCB-STI/beam-core-analysis/raw/main/Users/Nazanin/bg_w_geog_labels.csv')\n",
    "        trips['startBlockGroup'] = trips['startBlockGroup'].fillna(0).astype(int)\n",
    "        trips['endBlockGroup'] = trips['endBlockGroup'].fillna(0).astype(int)\n",
    "        activities['activityBlockGroup'] = activities['activityBlockGroup'].fillna(0).astype(int)\n",
    "        PTs['startBlockGroup'] = PTs['startBlockGroup'].fillna(0).astype(int)\n",
    "        PTs['endBlockGroup'] = PTs['endBlockGroup'].fillna(0).astype(int)\n",
    "        PtoPTs['startBlockGroup'] = PtoPTs['startBlockGroup'].fillna(0).astype(int)\n",
    "        PtoPTs['endBlockGroup'] = PtoPTs['endBlockGroup'].fillna(0).astype(int)\n",
    "        if is_LT:\n",
    "            LT['BlockGroup'] = LT['BlockGroup'].fillna(0).astype(int)\n",
    "            PLT['BlockGroup'] = PLT['BlockGroup'].fillna(0).astype(int)\n",
    "            VLT['BlockGroup'] = VLT['BlockGroup'].fillna(0).astype(int)\n",
    "        \n",
    "        trips = pd.merge(trips, block_info,  how='left',  left_on = 'startBlockGroup',right_on = 'bgid')\n",
    "        trips = pd.merge(trips, block_info,  how='left',  left_on = 'endBlockGroup',right_on = 'bgid',suffixes = ['_start','_end'])\n",
    "        activities = pd.merge(activities, block_info,  how='left',  left_on = 'activityBlockGroup',right_on = 'bgid',)\n",
    "        PTs = pd.merge(PTs, block_info,  how='left',  left_on = 'startBlockGroup',right_on = 'bgid',)\n",
    "        PTs = pd.merge(PTs, block_info,  how='left',  left_on = 'endBlockGroup',right_on = 'bgid',suffixes = ['_start','_end'])\n",
    "        PtoPTs = pd.merge(PtoPTs, block_info,  how='left',  left_on = 'startBlockGroup',right_on = 'bgid',)\n",
    "        PtoPTs = pd.merge(PtoPTs, block_info,  how='left',  left_on = 'endBlockGroup',right_on = 'bgid',suffixes = ['_start','_end'])\n",
    "        if is_LT:\n",
    "            LT = pd.merge(LT, block_info,  how='left',  left_on = 'BlockGroup',right_on = 'bgid',)\n",
    "            PLT = pd.merge(PLT, block_info,  how='left',  left_on = 'BlockGroup',right_on = 'bgid',)\n",
    "            VLT = pd.merge(VLT, block_info,  how='left',  left_on = 'BlockGroup',right_on = 'bgid',)\n",
    "\n",
    "    # PTs = addGeometryIdToDataFrame(PTs, BGs, 'startX', 'startY', 'startBlockGroup')\n",
    "    # PTs = addGeometryIdToDataFrame(PTs, BGs, 'endX', 'endY', 'endBlockGroup')\n",
    "    PTs.index.set_names('PathTraversalID', inplace=True)\n",
    "    \n",
    "    \n",
    "    print('writing results on', outDirectory+ 'postprocessOutputs/'+year_it)\n",
    "    \n",
    "    bucket.blob(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/trips.csv.gz').upload_from_string(trips.to_csv(index=True), content_type='text/csv')\n",
    "    bucket.blob(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/vehicles.csv.gz').upload_from_string(PTs.to_csv(index=True), content_type='text/csv')\n",
    "    bucket.blob(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/activities.csv.gz').upload_from_string(activities.to_csv(index=True), content_type='text/csv')\n",
    "    bucket.blob(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/personToVehicles.csv.gz').upload_from_string(PtoPTs.to_csv(index=True), content_type='text/csv')\n",
    "    if is_LT:\n",
    "        bucket.blob(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/linkTable.csv.gz').upload_from_string(LT.to_csv(index=True), content_type='text/csv')\n",
    "        bucket.blob(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/personLinkTable.csv.gz').upload_from_string(PLT.to_csv(index=True), content_type='text/csv')\n",
    "        bucket.blob(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/vehicleLinkTable.csv.gz').upload_from_string(VLT.to_csv(index=True), content_type='text/csv')\n",
    "    \n",
    "    bucket.blob(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/summaryTable.csv.gz').upload_from_string(ST.to_csv(index=True), content_type='text/csv')\n",
    "    \n",
    "\n",
    "#     trips.to_csv(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/trips.csv.gz', index=True)\n",
    "#     PTs.to_csv(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/vehicles.csv.gz', index=True)\n",
    "#     activities.to_csv(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/activities.csv.gz', index=True)\n",
    "#     PtoPTs.to_csv(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/personToVehicles.csv.gz', index=True)\n",
    "#     if is_LT:\n",
    "#         LT.to_csv(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/linkTable.csv.gz', index=True)\n",
    "#         PLT.to_csv(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/personLinkTable.csv.gz', index=True)\n",
    "#         VLT.to_csv(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/vehicleLinkTable.csv.gz', index=True) \n",
    "#     ST.to_csv(outDirectory[23:]+ 'postprocessOutputs/'+year_it+'/summaryTable.csv.gz', index=True)\n",
    "    \n",
    "#     if is_plot:\n",
    "#         plot_and_save_figures(outDirectory+ 'postprocessOutputs/'+year_it+'/figures/', ST, name)\n",
    "    \n",
    "    print('File uploaded successfully.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60917bae-9d99-42f8-b03e-f296010ceac5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/conda/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: pyproj>=2.6.1.post1 in /opt/conda/lib/python3.10/site-packages (from geopandas) (3.4.1)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.5.3)\n",
      "Requirement already satisfied: fiona>=1.8 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.8.22)\n",
      "Requirement already satisfied: shapely>=1.7 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas) (23.0)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: six>=1.7 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (1.16.0)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (8.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (66.1.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8->geopandas) (22.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->geopandas) (1.23.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: pygeos in /opt/conda/lib/python3.10/site-packages (0.14)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.10/site-packages (from pygeos) (1.23.5)\n",
      "Requirement already satisfied: boto in /opt/conda/lib/python3.10/site-packages (2.49.0)\n",
      "Requirement already satisfied: s3fs in /opt/conda/lib/python3.10/site-packages (2023.1.0)\n",
      "Requirement already satisfied: aiobotocore~=2.4.2 in /opt/conda/lib/python3.10/site-packages (from s3fs) (2.4.2)\n",
      "Requirement already satisfied: fsspec==2023.1.0 in /opt/conda/lib/python3.10/site-packages (from s3fs) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from s3fs) (3.8.3)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /opt/conda/lib/python3.10/site-packages (from aiobotocore~=2.4.2->s3fs) (0.11.0)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.10/site-packages (from aiobotocore~=2.4.2->s3fs) (1.14.1)\n",
      "Requirement already satisfied: botocore<1.27.60,>=1.27.59 in /opt/conda/lib/python3.10/site-packages (from aiobotocore~=2.4.2->s3fs) (1.27.59)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (22.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (2.8.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (1.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (1.26.14)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (1.16.0)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.10/site-packages (from shapely) (1.23.5)\n",
      "Requirement already satisfied: gcsfs in /opt/conda/lib/python3.10/site-packages (2023.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.10/site-packages (from gcsfs) (0.8.0)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (from gcsfs) (2.7.0)\n",
      "Requirement already satisfied: fsspec==2023.1.0 in /opt/conda/lib/python3.10/site-packages (from gcsfs) (2023.1.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from gcsfs) (2.28.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from gcsfs) (3.8.3)\n",
      "Requirement already satisfied: decorator>4.1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs) (5.1.1)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/conda/lib/python3.10/site-packages (from gcsfs) (2.16.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs) (5.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs) (2.3.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs) (2.11.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage->gcsfs) (2.4.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->gcsfs) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->gcsfs) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->gcsfs) (3.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.58.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (4.21.12)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage->gcsfs) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2041613/2848130802.py:14: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "! pip install geopandas\n",
    "! pip install pandas\n",
    "! pip install pygeos\n",
    "! pip install boto\n",
    "! pip install s3fs\n",
    "! pip install shapely\n",
    "! pip install gcsfs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import time\n",
    "from itertools import groupby\n",
    "import geopandas as gpd\n",
    "from google.cloud import storage\n",
    "# import seaborn as sns\n",
    "# %matplotlib inline\n",
    "# from io import BytesIO\n",
    "# from google.cloud import storage\n",
    "\n",
    "# import os\n",
    "# client = language.LanguageServiceClient.from_service_account_json(\"/path/to/file.json\")\n",
    "# storage_client = storage.Client()\n",
    "# bucket = storage_client.get_bucket('beam-core-outputs')\n",
    "# path = \"gs://beam-core-outputs/\"\n",
    "# df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1aa1bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Inputs filepath, data_names, names\n",
    "\n",
    "nrows = None #None for all rows\n",
    "is_leg_mode = True\n",
    "is_SMART = True\n",
    "is_NYC = None\n",
    "\n",
    "\n",
    "# #######################################################################################################################\n",
    "# #############NYC##############\n",
    "if is_NYC:\n",
    "    fp = \"s3://beam-outputs/output/newyork/\"\n",
    "    output_nm = 'SummaryTable_NYC_baseline17.csv'\n",
    "    len_id_transit = 10\n",
    "    fp_res = 'outputs/'\n",
    "    is_NYC = True\n",
    "    is_WC = False\n",
    "    is_LT = False\n",
    "    is_GEO = False\n",
    "    is_collect_data = False\n",
    "    is_plot = False\n",
    "    data = {\n",
    "        #           'new-york-split_scenario-part-1__2022-06-03_17-21-39_iqs/ITERS/it.0/0.events.csv.gz':'Baseline Part1', \n",
    "        #           'new-york-split_scenario-part-2__2022-06-15_14-26-18_cuu/ITERS/it.0/0.events.csv.gz':'Baseline Part2', \n",
    "        #           'new-york-split_scenario-part-3__2022-06-15_14-26-18_dmi/ITERS/it.0/0.events.csv.gz':'Baseline Part3',\n",
    "        #           'new-york-300k-calibration-7__2022-06-25_17-40-03_aui/ITERS/it.10/10.events.csv.gz':'Run7',\n",
    "        #           'new-york-300k-calibration-11__2022-06-28_21-55-14_hbf/ITERS/it.10/10.events.csv.gz':'Run11',\n",
    "        #           'new-york-300k-calibration-12__2022-06-28_21-54-34_tav/ITERS/it.10/10.events.csv.gz':'Run12',\n",
    "        #           'new-york-300k-calibration-13__2022-06-29_17-21-34_psu/ITERS/it.10/10.events.csv.gz':'Run13',\n",
    "        #           'new-york-300k-calibration-15__2022-06-30_15-57-54_zqu/ITERS/it.10/10.events.csv.gz':'Run15',\n",
    "        #           'new-york-300k-calibration-16__2022-07-04_14-46-10_wvt/ITERS/it.10/10.events.csv.gz':'Run16',\n",
    "        #           'new-york-300k-calibration-17__2022-07-05_20-44-02_ccs/ITERS/it.10/10.events.csv.gz':'Run17',\n",
    "        #           'new-york-450k-calibration-18__2022-07-08_15-39-57_pxy/ITERS/it.10/10.events.csv.gz':'Run18',\n",
    "        #           'new-york-450k-calibration-19__2022-07-12_17-14-44_esm/ITERS/it.10/10.events.csv.gz':'Run19',\n",
    "        #           'new-york-450k-calibration-20__2022-07-12_22-31-28_czx/ITERS/it.10/10.events.csv.gz':'Run20',\n",
    "        #           'new-york-baseline-0-of-10__2022-07-17_01-19-13_fgz/ITERS/it.5/5.events.csv.gz':'Run21-0/10-fullpop',\n",
    "        #           'new-york-baseline-3-of-10__2022-07-17_01-19-21_soy/ITERS/it.5/5.events.csv.gz':'Run21-3/10-fullpop',\n",
    "        #           'new-york-baseline-4-of-10__2022-07-17_01-19-20_qig/ITERS/it.5/5.events.csv.gz':'Run21-4/10-fullpop',\n",
    "        #           'new-york-baseline-5-of-10__2022-07-17_01-19-12_yyt/ITERS/it.5/5.events.csv.gz':'Run21-5/10-fullpop',\n",
    "        #           'new-york-baseline-6-of-10__2022-07-17_01-19-12_dgi/ITERS/it.5/5.events.csv.gz':'Run21-6/10-fullpop',\n",
    "        #           'new-york-baseline-7-of-10__2022-07-17_01-19-14_qip/ITERS/it.5/5.events.csv.gz':'Run21-7/10-fullpop',\n",
    "        #           'new-york-baseline-8-of-10__2022-07-17_01-19-11_oko/ITERS/it.5/5.events.csv.gz':'Run21-8/10-fullpop',\n",
    "        #           'new-york-baseline-2-of-10__2022-07-19_01-38-47_ryr/ITERS/it.0/0.events.csv.gz':'Run21-2/10-fullpop',\n",
    "        #           'new-york-baseline-9-of-10__2022-07-19_01-38-46_hfm/ITERS/it.0/0.events.csv.gz':'Run21-9/10-fullpop',\n",
    "        #           'new-york-baseline-1-of-10__2022-07-19_15-06-02_ewc/ITERS/it.0/0.events.csv.gz':'Run21-1/10-fullpop',\n",
    "        #           'new-york-300k-may2020-calibration-1__2022-07-23_00-00-16_plu/ITERS/it.10/10.events.csv.gz':'Future-Run1',\n",
    "        #           'new-york-300k-may2020-calibration-1__2022-07-23_00-02-02_esg/ITERS/it.10/10.events.csv.gz':'Future-Run2',\n",
    "        #           'new-york-300k-may2020-calibration-1__2022-07-23_00-02-03_gzm/ITERS/it.10/10.events.csv.gz':'Future-Run4',\n",
    "        #           'new-york-300k-may2020-calibration-5__2022-07-25_19-38-26_fjs/ITERS/it.10/10.events.csv.gz':'Future-Run5',\n",
    "        #           'new-york-300k-may2020-calibration-6__2022-07-25_19-38-18_wqn/ITERS/it.10/10.events.csv.gz':'Future-Run6',\n",
    "        #           'new-york-300k-may2020-calibration-7__2022-07-25_19-38-21_gri/ITERS/it.10/10.events.csv.gz':'Future-Run7',\n",
    "        #           'new-york-300k-may2020-calibration-8__2022-07-25_19-40-44_xde/ITERS/it.10/10.events.csv.gz':'Future-Run8',\n",
    "        #           'new-york-300k-may2020-calibration-6__2022-08-06_00-15-58_tzw/ITERS/it.10/10.events.csv.gz':'Future-Run6_2',\n",
    "        #           'new-york-300k-may2020-calibration-9__2022-08-06_00-16-00_fmo/ITERS/it.10/10.events.csv.gz':'Future-Run9',\n",
    "        #           'new-york-300k-may2020-calibration-10__2022-08-06_00-15-54_zlo/ITERS/it.10/10.events.csv.gz':'Future-Run10',\n",
    "        #           'new-york-300k-may2020-calibration-12__2022-08-13_10-30-40_cvt/ITERS/it.10/10.events.csv.gz':'may2020-12',\n",
    "        #           'new-york-300k-may2020-calibration-13__2022-08-13_10-30-40_rkc/ITERS/it.10/10.events.csv.gz':'may2020-13',\n",
    "        #           'new-york-300k-august2020-calibration-1__2022-08-13_10-57-13_nig/ITERS/it.10/10.events.csv.gz':'aug2020-1',\n",
    "        #           'new-york-300k-august2020-calibration-2__2022-08-13_10-57-12_cap/ITERS/it.10/10.events.csv.gz':'aug2020-2',\n",
    "        #           'new-york-300k-jan2022-calibration-1__2022-08-13_10-57-17_xey/ITERS/it.10/10.events.csv.gz':'jan2022-1',\n",
    "        #           'new-york-300k-jan2022-calibration-2__2022-08-13_10-57-14_zuc/ITERS/it.10/10.events.csv.gz':'jan2022-2',\n",
    "        #           'new-york-300k-june2022-calibration-1__2022-08-13_10-57-14_osw/ITERS/it.10/10.events.csv.gz':'jun2022-1',\n",
    "        #           'new-york-300k-june2022-calibration-2__2022-08-13_10-57-14_lqo/ITERS/it.10/10.events.csv.gz':'jun2022-2',\n",
    "        #           'new-york-300k-august2021-calibration-1__2022-08-13_10-57-15_wpa/ITERS/it.10/10.events.csv.gz':'aug2021-1',\n",
    "        #           'new-york-300k-august2021-calibration-2__2022-08-13_10-57-12_pds/ITERS/it.10/10.events.csv.gz':'aug2021-2',\n",
    "        # 'new-york-600k-may2020-calibration-14__2022-08-18_20-20-25_ynh/ITERS/it.10/10.events.csv.gz':'may2020-3',\n",
    "        # 'new-york-600k-august2020-calibration-3__2022-08-18_20-20-33_qid/ITERS/it.10/10.events.csv.gz':'aug2020-3',\n",
    "        # 'new-york-600k-august2021-calibration-3__2022-08-18_20-20-22_ylh/ITERS/it.10/10.events.csv.gz':'aug2021-3',\n",
    "        # 'new-york-600k-jan2022-calibration-3__2022-08-18_20-20-23_eun/ITERS/it.10/10.events.csv.gz':'jan2022-3',\n",
    "        # 'new-york-600k-june2022-calibration-3__2022-08-18_20-20-33_uov/ITERS/it.10/10.events.csv.gz':'june2022-3'\n",
    "        #     'new-york-june2022-0-of-10__2022-09-07_04-43-41_eoc/ITERS/it.5/5.events.csv.gz':'june2022-4',\n",
    "        #     'new-york-august2021-0-of-10__2022-09-07_04-41-33_wmw/ITERS/it.5/5.events.csv.gz':'aug2021-4',\n",
    "        #     'new-york-august2020-0-of-10__2022-09-07_04-41-27_hgn/ITERS/it.5/5.events.csv.gz':'aug2020-4',\n",
    "        #     'new-york-may2020-0-of-10__2022-09-07_04-41-31_dku/ITERS/it.5/5.events.csv.gz':'may2020-4',\n",
    "        # 'new-york-may2020-0-of-10__2022-09-21_17-07-17_aon/ITERS/it.10/10.events.csv.gz':'may2020-5',\n",
    "        # 'new-york-august2020-0-of-10__2022-09-21_17-07-13_pug/ITERS/it.10/10.events.csv.gz':'august2020-5',\n",
    "        # 'new-york-august2021-0-of-10__2022-09-21_17-07-09_yan/ITERS/it.10/10.events.csv.gz':'august2021-5',\n",
    "        # 'new-york-june2022-0-of-10__2022-09-21_17-07-28_ojg/ITERS/it.10/10.events.csv.gz':'june2022-5',\n",
    "        # 'new-york-jan2022-0-of-10__2022-09-21_17-07-49_qdx/ITERS/it.10/10.events.csv.gz':'jan2022-5',\n",
    "        # 'new-york-baseline-0-of-10__2022-12-06_04-19-22_kra/ITERS/it.5/5.events.csv.gz':'baseline-GTFS-Capacities-it5',\n",
    "        # 'new-york-may2020-0-of-10__2022-12-05_20-53-27_plq/ITERS/it.10/10.events.csv.gz':'may2020-GTFS-Capacities-it10',\n",
    "        # 'new-york-august2020-0-of-10__2022-12-06_00-48-35_czx/ITERS/it.10/10.events.csv.gz':'august2020-GTFS-Capacities-it10',\n",
    "        # 'new-york-august2021-0-of-10__2022-12-05_06-08-36_lne/ITERS/it.5/5.events.csv.gz':'august2021-GTFS-Capacities-it5',\n",
    "        # 'new-york-jan2022-0-of-10__2022-12-06_04-19-20_pub/ITERS/it.10/10.events.csv.gz':'jan2022-GTFS-Capacities-it10',\n",
    "        # 'new-york-june2022-0-of-10__2022-12-08_06-41-28_yhp/ITERS/it.0/0.events.csv.gz':'june2022-GTFS-Capacities-it0'\n",
    "    # 'new-york-baseline-0-of-10__2022-12-13_06-39-57_mua/ITERS/it.5/5.events.csv.gz':'baseline-GTFS-Capacities4-it5',\n",
    "    #             # 'new-york-baseline-0-of-10__2022-12-13_06-42-03_uyo/ITERS/it.5/5.events.csv.gz':'baseline-GTFS-Capacities-it5',\n",
    "    #             # 'new-york-baseline-0-of-10__2022-12-13_06-41-05_kcb/ITERS/it.5/5.events.csv.gz':'baseline-GTFS-Capacities2-it5',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-13_06-40-14_tqf/ITERS/it.5/5.events.csv.gz':'baseline-GTFS-Capacities3-it5',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-12_18-04-01_zgo/ITERS/it.10/10.events.csv.gz':'may2020-GTFS-Capacities-it10',\n",
    "    # # 'new-york-may2020-0-of-10__2022-12-12_18-04-01_zgo/ITERS/it.5/5.events.csv.gz':'may2020-GTFS-Capacities-it5',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-13_06-41-05_sat/ITERS/it.10/10.events.csv.gz':'may2020-GTFS-Capacities2-it10',\n",
    "    # # 'new-york-may2020-0-of-10__2022-12-13_06-41-05_sat/ITERS/it.5/5.events.csv.gz':'may2020-GTFS-Capacities2-it5',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-13_06-40-55_fwv/ITERS/it.10/10.events.csv.gz':'may2020-GTFS-Capacities3-it10',\n",
    "    # # 'new-york-may2020-0-of-10__2022-12-13_06-40-55_fwv/ITERS/it.5/5.events.csv.gz':'may2020-GTFS-Capacities3-it5',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-13_06-39-44_ije/ITERS/it.10/10.events.csv.gz':'may2020-GTFS-Capacities4-it10',\n",
    "    # # 'new-york-may2020-0-of-10__2022-12-13_06-39-44_ije/ITERS/it.5/5.events.csv.gz':'may2020-GTFS-Capacities4-it5',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-12_18-03-58_xrx/ITERS/it.10/10.events.csv.gz':'august2020-GTFS-Capacities-it10',\n",
    "    # # 'new-york-august2020-0-of-10__2022-12-12_18-03-58_xrx/ITERS/it.5/5.events.csv.gz':'august2020-GTFS-Capacities-it15',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-13_06-36-10_qre/ITERS/it.10/10.events.csv.gz':'august2020-GTFS-Capacities2-it10',\n",
    "    # # 'new-york-august2020-0-of-10__2022-12-13_06-36-10_qre/ITERS/it.5/5.events.csv.gz':'august2020-GTFS-Capacities2-it5',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-13_06-36-08_mpe/ITERS/it.10/10.events.csv.gz':'august2020-GTFS-Capacities3-it10',\n",
    "    # # 'new-york-august2020-0-of-10__2022-12-13_06-36-08_mpe/ITERS/it.5/5.events.csv.gz':'august2020-GTFS-Capacities3-it15',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-12_18-03-59_mbq/ITERS/it.10/10.events.csv.gz':'august2021-GTFS-Capacities-it10',\n",
    "    # # 'new-york-august2021-0-of-10__2022-12-12_18-03-59_mbq/ITERS/it.5/5.events.csv.gz':'august2021-GTFS-Capacities-it5',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-13_06-36-08_ldo/ITERS/it.10/10.events.csv.gz':'august2021-GTFS-Capacities2-it10',\n",
    "    # # 'new-york-august2021-0-of-10__2022-12-13_06-36-08_ldo/ITERS/it.5/5.events.csv.gz':'august2021-GTFS-Capacities2-it5',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-13_06-36-53_dwe/ITERS/it.10/10.events.csv.gz':'august2021-GTFS-Capacities4-it10',\n",
    "    # # 'new-york-august2021-0-of-10__2022-12-13_06-36-53_dwe/ITERS/it.5/5.events.csv.gz':'august2021-GTFS-Capacities4-it5',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-12_18-04-01_bua/ITERS/it.10/10.events.csv.gz':'jan2022-GTFS-Capacities-it10',\n",
    "    # # 'new-york-jan2022-0-of-10__2022-12-12_18-04-01_bua/ITERS/it.5/5.events.csv.gz':'jan2022-GTFS-Capacities-it5',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-13_06-36-09_kzo/ITERS/it.10/10.events.csv.gz':'jan2022-GTFS-Capacities2-it10',\n",
    "    # # 'new-york-jan2022-0-of-10__2022-12-13_06-36-09_kzo/ITERS/it.5/5.events.csv.gz':'jan2022-GTFS-Capacities2-it5',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-13_06-36-18_udd/ITERS/it.10/10.events.csv.gz':'jan2022-GTFS-Capacities3-it10',\n",
    "    # # 'new-york-jan2022-0-of-10__2022-12-13_06-36-18_udd/ITERS/it.5/5.events.csv.gz':'jan2022-GTFS-Capacities3-it5',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-13_06-36-47_jux/ITERS/it.10/10.events.csv.gz':'jan2022-GTFS-Capacities4-it10',\n",
    "    # # 'new-york-jan2022-0-of-10__2022-12-13_06-36-47_jux/ITERS/it.5/5.events.csv.gz':'jan2022-GTFS-Capacities4-it15',\n",
    "        \n",
    "    # '/ITERS/it.5/5.events.csv.gz':'baseline_5',\n",
    "    # '/ITERS/it.5/5.events.csv.gz':'baseline_6',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-18_08-02-54_wwu/ITERS/it.5/5.events.csv.gz':'may2020_5',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-18_08-02-58_sdt/ITERS/it.5/5.events.csv.gz':'may2020_6',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-18_07-59-31_hac/ITERS/it.5/5.events.csv.gz':'aug2020_5',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-18_07-59-36_vkr/ITERS/it.5/5.events.csv.gz':'aug2020_6',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-18_08-03-04_dwz/ITERS/it.5/5.events.csv.gz':'aug2021_5',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-18_08-03-07_mib/ITERS/it.5/5.events.csv.gz':'aug2021_6',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-18_07-59-32_fzx/ITERS/it.5/5.events.csv.gz':'jan2022_5',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-18_07-59-36_dmm/ITERS/it.5/5.events.csv.gz':'jan2022_6',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-18_07-59-38_qdi/ITERS/it.5/5.events.csv.gz':'jun2022_1',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-18_07-59-34_zfe/ITERS/it.5/5.events.csv.gz':'jun2022_2',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-18_07-59-33_qqx/ITERS/it.5/5.events.csv.gz':'jun2022_3',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-18_07-59-31_muj/ITERS/it.5/5.events.csv.gz':'jun2022_4',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-18_17-38-08_gfm/ITERS/it.5/5.events.csv.gz':'may2020_5',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-18_17-38-04_hfs/ITERS/it.5/5.events.csv.gz':'may2020_6',\n",
    "    # # '/ITERS/it.5/5.events.csv.gz':'aug2020_5',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-18_17-38-04_phk/ITERS/it.5/5.events.csv.gz':'aug2020_6',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-18_17-38-01_fuq/ITERS/it.5/5.events.csv.gz':'aug2021_5',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-18_17-38-11_adj/ITERS/it.5/5.events.csv.gz':'aug2021_6',\n",
    "    # # '/ITERS/it.5/5.events.csv.gz':'jan2022_5',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-18_17-38-05_bel/ITERS/it.5/5.events.csv.gz':'jan2022_6',\n",
    "    # # '/ITERS/it.5/5.events.csv.gz':'jun2022_1',\n",
    "    # # '/ITERS/it.5/5.events.csv.gz':'jun2022_2',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-18_17-38-08_yzn/ITERS/it.5/5.events.csv.gz':'jun2022_3',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-18_17-38-04_dcx/ITERS/it.5/5.events.csv.gz':'jun2022_4',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-19_23-42-50_zlc/ITERS/it.5/5.events.csv.gz':'baseline7',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-19_23-42-51_nvw/ITERS/it.5/5.events.csv.gz':'baseline8',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-19_23-42-53_uyr/ITERS/it.5/5.events.csv.gz':'baseline9',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-19_23-42-52_frv/ITERS/it.5/5.events.csv.gz':'may2020_7',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-19_23-42-55_dbm/ITERS/it.5/5.events.csv.gz':'may2020_8',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-19_23-42-54_nmv/ITERS/it.5/5.events.csv.gz':'may2020_9',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-19_23-42-59_wkn/ITERS/it.5/5.events.csv.gz':'aug2020_7',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-19_23-42-53_bkp/ITERS/it.5/5.events.csv.gz':'aug2020_8',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-19_23-42-49_zpt/ITERS/it.5/5.events.csv.gz':'aug2020_9',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-19_23-42-50_xif/ITERS/it.5/5.events.csv.gz':'aug2021_7',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-19_23-42-52_dsq/ITERS/it.5/5.events.csv.gz':'aug2021_8',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-19_23-42-52_keu/ITERS/it.5/5.events.csv.gz':'aug2021_9',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-19_23-42-51_hxu/ITERS/it.5/5.events.csv.gz':'jan2022_7',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-19_23-42-49_pkq/ITERS/it.5/5.events.csv.gz':'jan2022_8',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-19_23-42-51_hrx/ITERS/it.5/5.events.csv.gz':'jan2022_9',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-19_23-42-50_mtd/ITERS/it.5/5.events.csv.gz':'jun2022_7',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-19_23-42-53_qol/ITERS/it.5/5.events.csv.gz':'jun2022_8',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-19_23-42-48_caq/ITERS/it.5/5.events.csv.gz':'jun2022_9',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-21_09-42-56_idw/ITERS/it.5/5.events.csv.gz':'aug2020_10',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-21_09-42-57_fgn/ITERS/it.5/5.events.csv.gz':'aug2020_11',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-21_01-14-46_xiy/ITERS/it.5/5.events.csv.gz':'aug2020_12',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-21_01-42-00_tli/ITERS/it.5/5.events.csv.gz':'aug2020_13',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-21_09-42-54_txi/ITERS/it.5/5.events.csv.gz':'aug2020_14',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-21_01-14-45_rsd/ITERS/it.5/5.events.csv.gz':'aug2021_10',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-21_01-14-44_pct/ITERS/it.5/5.events.csv.gz':'aug2021_11',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-21_01-14-46_ilu/ITERS/it.5/5.events.csv.gz':'aug2021_12',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-21_01-42-02_ifx/ITERS/it.5/5.events.csv.gz':'aug2021_13',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-21_01-40-11_sdu/ITERS/it.5/5.events.csv.gz':'aug2021_14',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-21_01-14-46_pfw/ITERS/it.5/5.events.csv.gz':'Baseline_10',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-21_01-14-48_arn/ITERS/it.5/5.events.csv.gz':'Baseline_11',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-21_01-14-55_zfx/ITERS/it.5/5.events.csv.gz':'Baseline_12',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-21_01-41-59_aat/ITERS/it.5/5.events.csv.gz':'Baseline_13',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-21_01-40-07_esl/ITERS/it.5/5.events.csv.gz':'Baseline_14',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-21_01-40-10_lrg/ITERS/it.5/5.events.csv.gz':'Baseline_15',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-21_01-40-16_irv/ITERS/it.5/5.events.csv.gz':'jan2022_11',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-21_01-42-02_fvl/ITERS/it.5/5.events.csv.gz':'jan2022_12',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-21_01-42-08_gvz/ITERS/it.5/5.events.csv.gz':'jan2022_13',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-21_01-14-46_cjo/ITERS/it.5/5.events.csv.gz':'may2020_10',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-21_01-14-44_axx/ITERS/it.5/5.events.csv.gz':'may2020_11',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-21_01-14-46_ize/ITERS/it.5/5.events.csv.gz':'may2020_12',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-21_01-14-45_pqr/ITERS/it.5/5.events.csv.gz':'may2020_13',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-21_01-14-51_nuc/ITERS/it.5/5.events.csv.gz':'may2020_14',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-21_01-14-50_gyp/ITERS/it.5/5.events.csv.gz':'jan2022_10',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-21_01-14-49_tkf/ITERS/it.5/5.events.csv.gz':'jun2022_10',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-27_22-27-09_unl/ITERS/it.5/5.events.csv.gz':'baseline_16',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-27_22-28-53_lrk/ITERS/it.5/5.events.csv.gz':'baseline_17',\n",
    "    # 'new-york-baseline-0-of-10__2022-12-27_22-27-09_mfg/ITERS/it.5/5.events.csv.gz':'baseline_18',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-27_22-27-12_jkl/ITERS/it.5/5.events.csv.gz':'may2020_15',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-27_22-27-19_onq/ITERS/it.0/0.events.csv.gz':'may2020_16-it0',\n",
    "    # 'new-york-may2020-0-of-10__2022-12-27_22-27-12_gxt/ITERS/it.5/5.events.csv.gz':'may2020_17',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-27_22-27-09_bvj/ITERS/it.0/0.events.csv.gz':'aug2020_15-it0',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-27_22-27-08_qyq/ITERS/it.5/5.events.csv.gz':'aug2020_16',\n",
    "    # 'new-york-august2020-0-of-10__2022-12-27_22-27-11_gql/ITERS/it.5/5.events.csv.gz':'aug2020_17',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-27_22-27-07_cqe/ITERS/it.5/5.events.csv.gz':'aug2021_15',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-27_22-27-08_drl/ITERS/it.0/0.events.csv.gz':'aug2021_16-it0',\n",
    "    # 'new-york-august2021-0-of-10__2022-12-27_22-28-50_otm/ITERS/it.5/5.events.csv.gz':'aug2021_17',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-27_22-28-53_rxs/ITERS/it.5/5.events.csv.gz':'jan2022_14',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-27_22-28-52_cfs/ITERS/it.5/5.events.csv.gz':'jan2022_15',\n",
    "    # 'new-york-jan2022-0-of-10__2022-12-27_22-27-10_mht/ITERS/it.5/5.events.csv.gz':'jan2022_16',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-28_03-33-09_hek/ITERS/it.5/5.events.csv.gz':'may2022_11',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-28_03-33-06_yvi/ITERS/it.5/5.events.csv.gz':'may2022_12',\n",
    "    # 'new-york-june2022-0-of-10__2022-12-28_03-33-06_psr/ITERS/it.5/5.events.csv.gz':'may2022_13',\n",
    "    # 'new-york-baseline-0-of-10__2023-01-03_19-59-12_nwn/ITERS/it.5/5.events.csv.gz':'baseline-0',\n",
    "    # # '/ITERS/it.5/5.events.csv.gz':'baseline-1',\n",
    "    # 'new-york-baseline-2-of-10__2023-01-03_19-59-06_brm/ITERS/it.5/5.events.csv.gz':'baseline-2',\n",
    "    # 'new-york-baseline-3-of-10__2023-01-03_19-59-07_kqr/ITERS/it.5/5.events.csv.gz':'baseline-3',\n",
    "    # 'new-york-baseline-4-of-10__2023-01-03_19-59-09_fbb/ITERS/it.5/5.events.csv.gz':'baseline-4',\n",
    "    # 'new-york-baseline-5-of-10__2023-01-03_19-59-11_tjh/ITERS/it.5/5.events.csv.gz':'baseline-5',\n",
    "    # 'new-york-baseline-6-of-10__2023-01-03_19-59-12_zwm/ITERS/it.5/5.events.csv.gz':'baseline-6',\n",
    "    # 'new-york-baseline-7-of-10__2023-01-03_19-59-19_bcr/ITERS/it.5/5.events.csv.gz':'baseline-7',\n",
    "    # 'new-york-baseline-8-of-10__2023-01-03_19-59-14_olx/ITERS/it.5/5.events.csv.gz':'baseline-8',\n",
    "    # 'new-york-baseline-9-of-10__2023-01-03_19-59-07_xcc/ITERS/it.5/5.events.csv.gz':'baseline-9',\n",
    "    # 'new-york-jan2022-0-of-10__2023-01-04_00-19-31_leg/ITERS/it.5/5.events.csv.gz':'jan2022-0',\n",
    "    # 'new-york-jan2022-1-of-10__2023-01-04_00-19-31_bus/ITERS/it.5/5.events.csv.gz':'jan2022-1',\n",
    "    # 'new-york-jan2022-2-of-10__2023-01-04_00-19-30_bqw/ITERS/it.5/5.events.csv.gz':'jan2022-2',\n",
    "    # 'new-york-jan2022-3-of-10__2023-01-04_00-19-36_noe/ITERS/it.5/5.events.csv.gz':'jan2022-3',\n",
    "    # 'new-york-jan2022-4-of-10__2023-01-04_00-19-33_nop/ITERS/it.5/5.events.csv.gz':'jan2022-4',\n",
    "    # 'new-york-jan2022-5-of-10__2023-01-04_00-19-37_pnp/ITERS/it.5/5.events.csv.gz':'jan2022-5',\n",
    "    # 'new-york-jan2022-6-of-10__2023-01-04_00-19-29_kny/ITERS/it.5/5.events.csv.gz':'jan2022-6',\n",
    "    # 'new-york-jan2022-7-of-10__2023-01-04_00-19-39_qwt/ITERS/it.5/5.events.csv.gz':'jan2022-7',\n",
    "    # 'new-york-jan2022-8-of-10__2023-01-04_00-19-35_fzq/ITERS/it.5/5.events.csv.gz':'jan2022-8',\n",
    "    # 'new-york-jan2022-9-of-10__2023-01-04_00-19-31_dgg/ITERS/it.5/5.events.csv.gz':'jan2022-9',\n",
    "    # 'new-york-august2020-0-of-10__2023-01-04_02-12-28_pqo/ITERS/it.5/5.events.csv.gz':'aug2020-18',\n",
    "    # 'new-york-august2020-0-of-10__2023-01-04_02-12-35_ftf/ITERS/it.5/5.events.csv.gz':'aug2020-19',\n",
    "    # 'new-york-august2020-0-of-10__2023-01-04_02-12-31_sfq/ITERS/it.0/0.events.csv.gz':'aug2020-20-it0',\n",
    "    # 'new-york-august2021-0-of-10__2023-01-04_02-12-37_qvi/ITERS/it.5/5.events.csv.gz':'aug2021-18',\n",
    "    # 'new-york-august2021-0-of-10__2023-01-04_02-12-35_ial/ITERS/it.5/5.events.csv.gz':'aug2021-19',\n",
    "    # 'new-york-august2021-0-of-10__2023-01-04_02-12-38_bet/ITERS/it.5/5.events.csv.gz':'aug2021-20',\n",
    "    # 'new-york-may2020-0-of-10__2023-01-04_00-45-47_ipb/ITERS/it.5/5.events.csv.gz':'may2020-18',\n",
    "    # 'new-york-may2020-0-of-10__2023-01-04_00-45-48_hfx/ITERS/it.5/5.events.csv.gz':'may2020-19',\n",
    "    # 'new-york-june2022-0-of-10__2023-01-03_23-31-41_eiq/ITERS/it.5/5.events.csv.gz':'may2022-14',\n",
    "    # 'new-york-june2022-0-of-10__2023-01-03_23-31-41_ciy/ITERS/it.5/5.events.csv.gz':'may2022-15',\n",
    "    # 'new-york-june2022-0-of-10__2023-01-03_23-31-42_zmm/ITERS/it.5/5.events.csv.gz':'may2022-16',\n",
    "    # 'new-york-may2020-0-of-10__2023-01-10_16-54-32_cmn/ITERS/it.5/5.events.csv.gz':'may2020-20',\n",
    "    # 'new-york-may2020-0-of-10__2023-01-10_16-54-35_qsu/ITERS/it.5/5.events.csv.gz':'may2020-21',\n",
    "    # 'new-york-may2020-0-of-10__2023-01-10_16-54-50_ckx/ITERS/it.5/5.events.csv.gz':'may2020-22',\n",
    "    # 'new-york-may2020-0-of-10__2023-01-10_16-54-50_qmq/ITERS/it.5/5.events.csv.gz':'may2020-23',\n",
    "    # 'new-york-may2020-0-of-10__2023-01-10_16-55-09_oal/ITERS/it.5/5.events.csv.gz':'may2020-24',\n",
    "    # 'new-york-may2020-0-of-10__2023-01-10_16-55-11_foj/ITERS/it.5/5.events.csv.gz':'may2020-25',\n",
    "    # 'new-york-may2020-0-of-10__2023-01-10_16-55-36_lvz/ITERS/it.5/5.events.csv.gz':'may2020-26',\n",
    "    'new-york-baseline-0-of-10__2023-01-03_19-59-12_nwn/ITERS/it.5/5.events.csv.gz':'baseline-0',\n",
    "    'new-york-baseline-1-of-10__2023-01-03_19-59-13_jgp/ITERS/it.5/5.events.csv.gz':'baseline-1',\n",
    "    'new-york-baseline-2-of-10__2023-01-03_19-59-06_brm/ITERS/it.5/5.events.csv.gz':'baseline-2',\n",
    "    'new-york-baseline-3-of-10__2023-01-03_19-59-07_kqr/ITERS/it.5/5.events.csv.gz':'baseline-3',\n",
    "    'new-york-baseline-4-of-10__2023-01-03_19-59-09_fbb/ITERS/it.5/5.events.csv.gz':'baseline-4',\n",
    "    'new-york-baseline-5-of-10__2023-01-03_19-59-11_tjh/ITERS/it.5/5.events.csv.gz':'baseline-5',\n",
    "    'new-york-baseline-6-of-10__2023-01-03_19-59-12_zwm/ITERS/it.5/5.events.csv.gz':'baseline-6',\n",
    "    'new-york-baseline-7-of-10__2023-01-03_19-59-19_bcr/ITERS/it.5/5.events.csv.gz':'baseline-7',\n",
    "    'new-york-baseline-8-of-10__2023-01-03_19-59-14_olx/ITERS/it.5/5.events.csv.gz':'baseline-8',\n",
    "    'new-york-baseline-9-of-10__2023-01-03_19-59-07_xcc/ITERS/it.5/5.events.csv.gz':'baseline-9',\n",
    "    'new-york-may2020-0-of-10__2023-01-12_18-51-34_sju/ITERS/it.5/5.events.csv.gz':'may2020-0',\n",
    "    'new-york-may2020-1-of-10__2023-01-12_18-51-33_nyd/ITERS/it.5/5.events.csv.gz':'may2020-1',\n",
    "    'new-york-may2020-2-of-10__2023-01-12_18-51-29_yow/ITERS/it.5/5.events.csv.gz':'may2020-2',\n",
    "    'new-york-may2020-3-of-10__2023-01-12_18-51-36_inx/ITERS/it.5/5.events.csv.gz':'may2020-3',\n",
    "    'new-york-may2020-4-of-10__2023-01-12_18-51-31_iwm/ITERS/it.5/5.events.csv.gz':'may2020-4',\n",
    "    'new-york-may2020-5-of-10__2023-01-12_18-51-34_jui/ITERS/it.5/5.events.csv.gz':'may2020-5',\n",
    "    'new-york-may2020-6-of-10__2023-01-12_18-51-34_gqr/ITERS/it.5/5.events.csv.gz':'may2020-6',\n",
    "    'new-york-may2020-7-of-10__2023-01-12_18-51-28_juu/ITERS/it.5/5.events.csv.gz':'may2020-7',\n",
    "    'new-york-may2020-8-of-10__2023-01-12_18-51-36_ehv/ITERS/it.5/5.events.csv.gz':'may2020-8',\n",
    "    'new-york-may2020-9-of-10__2023-01-12_18-51-54_bas/ITERS/it.5/5.events.csv.gz':'may2020-9',\n",
    "    'new-york-august2020-0-of-10__2023-01-10_16-52-48_lgr/ITERS/it.5/5.events.csv.gz':'aug2020-0',\n",
    "    'new-york-august2020-1-of-10__2023-01-10_16-52-46_gib/ITERS/it.5/5.events.csv.gz':'aug2020-1',\n",
    "    'new-york-august2020-2-of-10__2023-01-14_21-19-35_flk/ITERS/it.5/5.events.csv.gz':'aug2020-2',\n",
    "    'new-york-august2020-3-of-10__2023-01-15_01-54-44_txq/ITERS/it.5/5.events.csv.gz':'aug2020-3',\n",
    "    'new-york-august2020-4-of-10__2023-01-10_16-52-43_rio/ITERS/it.5/5.events.csv.gz':'aug2020-4',\n",
    "    'new-york-august2020-5-of-10__2023-01-10_16-53-00_vjr/ITERS/it.5/5.events.csv.gz':'aug2020-5',\n",
    "    'new-york-august2020-6-of-10__2023-01-10_16-52-53_bhh/ITERS/it.5/5.events.csv.gz':'aug2020-6',\n",
    "    'new-york-august2020-7-of-10__2023-01-10_16-53-01_drt/ITERS/it.5/5.events.csv.gz':'aug2020-7',\n",
    "    'new-york-august2020-8-of-10__2023-01-10_16-53-15_qgy/ITERS/it.5/5.events.csv.gz':'aug2020-8',\n",
    "    'new-york-august2020-9-of-10__2023-01-10_16-53-14_pdt/ITERS/it.5/5.events.csv.gz':'aug2020-9',\n",
    "    'new-york-august2021-0-of-10__2023-01-12_18-51-43_rxk/ITERS/it.5/5.events.csv.gz':'aug2021-0',\n",
    "    'new-york-august2021-1-of-10__2023-01-12_18-51-29_aza/ITERS/it.5/5.events.csv.gz':'aug2021-1',\n",
    "    'new-york-august2021-2-of-10__2023-01-12_18-51-33_xqs/ITERS/it.5/5.events.csv.gz':'aug2021-2',\n",
    "    'new-york-august2021-3-of-10__2023-01-12_18-51-29_abg/ITERS/it.5/5.events.csv.gz':'aug2021-3',\n",
    "    'new-york-august2021-4-of-10__2023-01-12_18-51-34_lwg/ITERS/it.5/5.events.csv.gz':'aug2021-4',\n",
    "    'new-york-august2021-5-of-10__2023-01-12_18-51-34_air/ITERS/it.5/5.events.csv.gz':'aug2021-5',\n",
    "    'new-york-august2021-6-of-10__2023-01-12_18-51-28_vbj/ITERS/it.5/5.events.csv.gz':'aug2021-6',\n",
    "    'new-york-august2021-7-of-10__2023-01-12_18-51-29_dnu/ITERS/it.5/5.events.csv.gz':'aug2021-7',\n",
    "    'new-york-august2021-8-of-10__2023-01-12_18-51-29_uzv/ITERS/it.5/5.events.csv.gz':'aug2021-8',\n",
    "    'new-york-august2021-9-of-10__2023-01-19_00-58-43_fwc/ITERS/it.5/5.events.csv.gz':'aug2021-9',\n",
    "    'new-york-jan2022-0-of-10__2023-01-04_00-19-31_leg/ITERS/it.5/5.events.csv.gz':'jan2022-0',\n",
    "    'new-york-jan2022-1-of-10__2023-01-14_04-04-57_ztd/ITERS/it.5/5.events.csv.gz':'jan2022-1',\n",
    "    'new-york-jan2022-2-of-10__2023-01-04_00-19-30_bqw/ITERS/it.5/5.events.csv.gz':'jan2022-2',\n",
    "    'new-york-jan2022-3-of-10__2023-01-04_00-19-36_noe/ITERS/it.5/5.events.csv.gz':'jan2022-3',\n",
    "    'new-york-jan2022-4-of-10__2023-01-04_00-19-33_nop/ITERS/it.5/5.events.csv.gz':'jan2022-4',\n",
    "    'new-york-jan2022-5-of-10__2023-01-04_00-19-37_pnp/ITERS/it.5/5.events.csv.gz':'jan2022-5',\n",
    "    'new-york-jan2022-6-of-10__2023-01-04_00-19-29_kny/ITERS/it.5/5.events.csv.gz':'jan2022-6',\n",
    "    'new-york-jan2022-7-of-10__2023-01-04_00-19-39_qwt/ITERS/it.5/5.events.csv.gz':'jan2022-7',\n",
    "    'new-york-jan2022-8-of-10__2023-01-04_00-19-35_fzq/ITERS/it.5/5.events.csv.gz':'jan2022-8',\n",
    "    'new-york-jan2022-9-of-10__2023-01-04_00-19-31_dgg/ITERS/it.5/5.events.csv.gz':'jan2022-9',\n",
    "    'new-york-june2022-0-of-10__2023-01-10_16-53-18_iir/ITERS/it.5/5.events.csv.gz':'may2022-0',\n",
    "    'new-york-june2022-1-of-10__2023-01-10_16-53-23_mrs/ITERS/it.0/0.events.csv.gz':'may2022-1',\n",
    "    'new-york-june2022-2-of-10__2023-01-10_16-53-36_log/ITERS/it.5/5.events.csv.gz':'may2022-2',\n",
    "    'new-york-june2022-3-of-10__2023-01-10_16-53-36_lvd/ITERS/it.0/0.events.csv.gz':'may2022-3',\n",
    "    'new-york-june2022-4-of-10__2023-01-10_16-53-44_afe/ITERS/it.0/0.events.csv.gz':'may2022-4',\n",
    "    'new-york-june2022-5-of-10__2023-01-10_16-53-58_gry/ITERS/it.5/5.events.csv.gz':'may2022-5',\n",
    "    'new-york-june2022-6-of-10__2023-01-10_16-53-59_qdi/ITERS/it.5/5.events.csv.gz':'may2022-6',\n",
    "    'new-york-june2022-7-of-10__2023-01-10_16-54-13_fwj/ITERS/it.0/0.events.csv.gz':'may2022-7',\n",
    "    'new-york-june2022-8-of-10__2023-01-10_16-54-18_okl/ITERS/it.5/5.events.csv.gz':'may2022-8',\n",
    "    'new-york-june2022-9-of-10__2023-01-10_16-54-38_jvb/ITERS/it.5/5.events.csv.gz':'may2022-9',\n",
    "\n",
    "                }\n",
    "    shares_pop = [\n",
    "                0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1\n",
    "        # 0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333,0.033333            \n",
    "        # 0.1,0.1,0.1,0.1,0.1,\n",
    "                 #0.059,0.059,0.059,0.059,0.059\n",
    "                # 0.0295,0.0295,0.0295,0.0295,\n",
    "                    ]\n",
    "    data_names = data.keys()\n",
    "    plan_names = []\n",
    "    for data_name in data_names:\n",
    "        plan_names.append(data_name[:-13]+'plans.csv.gz')\n",
    "\n",
    "    names = data.values()\n",
    "############################################RH###########################################################################\n",
    "# fp = \"\"\n",
    "# output_nm = 'SummaryTable_Pilates_RHM5.csv'\n",
    "# len_id_transit = 3\n",
    "# fp_res = 'outputs/'\n",
    "# is_NYC = False\n",
    "# is_WC = False\n",
    "# is_LT = False\n",
    "# is_GEO = False\n",
    "# is_collect_data = True\n",
    "# is_plot = False\n",
    "# data = {\n",
    "# Dima            \n",
    "# # 's3://beam-outputs/output/newyork/nyc-ridehail-200k__2022-09-29_11-25-35_sor/ITERS/it.0/0.events.csv.gz':'Develop',\n",
    "# # 's3://beam-outputs/output/newyork/nyc-ridehail-200k__2022-09-29_11-36-23_zux/ITERS/it.0/0.events.csv.gz':'RHM1',\n",
    "# # 's3://beam-outputs/output/newyork/nyc-2-ridehail-200k__2022-09-29_11-44-14_esl/ITERS/it.0/0.events.csv.gz':'RHM2',\n",
    "# # 's3://beam-outputs/output/newyork/nyc-2-ridehail-200k__2022-10-20_09-07-49_fii/ITERS/it.0/0.events.csv.gz':'RHM2-2',\n",
    "# # Cri\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-2rh-calibr__2022-10-24_02-03-37_ism/ITERS/it.0/0.events.csv.gz':'2RH',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr__2022-10-23_21-30-34_jxx/ITERS/it.0/0.events.csv.gz':'1RH',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-default__2022-10-23_21-30-32_gzm/ITERS/it.0/0.events.csv.gz':'Default',\n",
    "#                 's3://beam-outputs/output/sfbay/sfbay-smart2-default__2022-10-25_19-09-11_vgb/ITERS/it.0/0.events.csv.gz':'Default',\n",
    "#                 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr__2022-10-25_19-09-17_bcy/ITERS/it.0/0.events.csv.gz':'1RH',\n",
    "#                 's3://beam-outputs/output/sfbay/sfbay-smart2-2rh-calibr__2022-10-25_19-09-17_rup/ITERS/it.0/0.events.csv.gz':'2RH',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr1__2022-10-26_06-11-56_wjs/ITERS/it.0/0.events.csv.gz':'Calibration1',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr2__2022-10-26_06-11-55_etk/ITERS/it.0/0.events.csv.gz':'Calibration2',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr3__2022-10-26_06-11-59_hee/ITERS/it.0/0.events.csv.gz':'Calibration3',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr4__2022-10-26_06-11-56_suk/ITERS/it.0/0.events.csv.gz':'Calibration4',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr5__2022-10-26_06-12-04_vfy/ITERS/it.0/0.events.csv.gz':'Calibration5',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr6__2022-10-26_06-12-15_cum/ITERS/it.0/0.events.csv.gz':'Calibration6',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr7__2022-10-26_06-12-44_xox/ITERS/it.0/0.events.csv.gz':'Calibration7',\n",
    "#                 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr1__2022-10-27_03-00-05_whk/ITERS/it.0/0.events.csv.gz':'Calibration1',\n",
    "#                 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr2__2022-10-27_03-00-05_czg/ITERS/it.0/0.events.csv.gz':'Calibration2',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr3__2022-10-27_03-00-01_zto/ITERS/it.0/0.events.csv.gz':'Calibration3',\n",
    "#                 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr4__2022-10-27_02-59-56_dzh/ITERS/it.0/0.events.csv.gz':'Calibration4',\n",
    "#                 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr5__2022-10-27_02-59-56_eyc/ITERS/it.0/0.events.csv.gz':'Calibration5',\n",
    "#                 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr6__2022-10-27_03-00-03_xin/ITERS/it.0/0.events.csv.gz':'Calibration6',\n",
    "#                 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr7__2022-10-27_02-59-55_bgo/ITERS/it.0/0.events.csv.gz':'Calibration7',\n",
    "\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr8__2022-11-03_16-41-48_mni/ITERS/it.0/0.events.csv.gz':'Calibration8',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr9__2022-11-03_16-41-50_fxk/ITERS/it.0/0.events.csv.gz':'Calibration9',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr10__2022-11-03_16-41-53_jgw/ITERS/it.0/0.events.csv.gz':'Calibration10',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-02_23-39-15_veq/ITERS/it.0/0.events.csv.gz':'Calibration11',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr12__2022-11-03_16-41-51_kgv/ITERS/it.0/0.events.csv.gz':'Calibration12',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr13__2022-11-03_16-41-59_ovy/ITERS/it.0/0.events.csv.gz':'Calibration13',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr14__2022-11-03_16-42-01_hpf/ITERS/it.0/0.events.csv.gz':'Calibration14',\n",
    "\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-14_twf/ITERS/it.0/0.events.csv.gz':'Calibration15',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-16_xdb/ITERS/it.0/0.events.csv.gz':'Calibration16',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-54-51_nwf/ITERS/it.0/0.events.csv.gz':'Calibration17',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-11_wtq/ITERS/it.0/0.events.csv.gz':'Calibration18',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr14__2022-11-03_16-42-01_hpf/ITERS/it.0/0.events.csv.gz':'Calibration19',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr14__2022-11-03_16-42-01_hpf/ITERS/it.0/0.events.csv.gz':'Calibration20',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-00_hdd/ITERS/it.0/0.events.csv.gz':'Calibration21',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-54-54_hzv/ITERS/it.0/0.events.csv.gz':'Calibration22',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-02_vaf/ITERS/it.0/0.events.csv.gz':'Calibration23',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr14__2022-11-03_16-42-01_hpf/ITERS/it.0/0.events.csv.gz':'Calibration24',\n",
    "# # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr14__2022-11-03_16-42-01_hpf/ITERS/it.0/0.events.csv.gz':'Calibration25',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-08_hhb/ITERS/it.0/0.events.csv.gz':'Calibration26',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-34_bom/ITERS/it.0/0.events.csv.gz':'Calibration27',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr28__2022-11-08_19-27-44_ycf/ITERS/it.0/0.events.csv.gz':'Calibration28',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr29__2022-11-08_03-21-25_dax/ITERS/it.0/0.events.csv.gz':'Calibration29',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr30__2022-11-08_03-21-06_pcm/ITERS/it.0/0.events.csv.gz':'Calibration30',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr31__2022-11-08_03-21-16_uqn/ITERS/it.0/0.events.csv.gz':'Calibration31',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr32__2022-11-08_03-21-05_nhu/ITERS/it.0/0.events.csv.gz':'Calibration32',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr33__2022-11-08_03-21-02_kmt/ITERS/it.0/0.events.csv.gz':'Calibration33',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr34__2022-11-08_03-20-56_glv/ITERS/it.0/0.events.csv.gz':'Calibration34',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr35__2022-11-08_03-20-57_acx/ITERS/it.0/0.events.csv.gz':'Calibration35',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr36__2022-11-08_03-20-57_kld/ITERS/it.0/0.events.csv.gz':'Calibration36',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr37__2022-11-08_03-21-04_qyn/ITERS/it.0/0.events.csv.gz':'Calibration37',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr38__2022-11-08_03-20-57_jyd/ITERS/it.0/0.events.csv.gz':'Calibration38',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr39__2022-11-08_03-21-00_ktd/ITERS/it.0/0.events.csv.gz':'Calibration39',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr40__2022-11-08_03-21-28_kvn/ITERS/it.0/0.events.csv.gz':'Calibration40',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr41__2022-11-08_03-21-26_pkc/ITERS/it.0/0.events.csv.gz':'Calibration41',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr41__2022-11-08_19-27-34_kyc/ITERS/it.0/0.events.csv.gz':'Calibration42',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr41__2022-11-08_19-27-27_iwq/ITERS/it.0/0.events.csv.gz':'Calibration43',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-34_bom/ITERS/it.0/0.events.csv.gz':'Calibration44',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-34_bom/ITERS/it.0/0.events.csv.gz':'Calibration45',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-34_bom/ITERS/it.0/0.events.csv.gz':'Calibration46',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-34_bom/ITERS/it.0/0.events.csv.gz':'Calibration47',\n",
    "                # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr11__2022-11-04_20-55-34_bom/ITERS/it.0/0.events.csv.gz':'Calibration48',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr49__2022-11-10_01-36-45_ufm/ITERS/it.0/0.events.csv.gz':'Calibration49',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr50__2022-11-10_01-36-41_rgz/ITERS/it.0/0.events.csv.gz':'Calibration50',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr51__2022-11-10_01-36-37_uvi/ITERS/it.0/0.events.csv.gz':'Calibration51',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr52__2022-11-10_01-36-38_zpx/ITERS/it.0/0.events.csv.gz':'Calibration52',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr53__2022-11-10_01-37-05_wpe/ITERS/it.0/0.events.csv.gz':'Calibration53',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr54__2022-11-10_01-37-07_mze/ITERS/it.0/0.events.csv.gz':'Calibration54',\n",
    "    # # 's3://beam-outputs/output/sfbay//ITERS/it.0/0.events.csv.gz':'Calibration55',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr56__2022-11-10_01-38-04_avo/ITERS/it.0/0.events.csv.gz':'Calibration56',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr57__2022-11-10_01-37-54_qmz/ITERS/it.0/0.events.csv.gz':'Calibration57',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr58__2022-11-10_01-38-00_zbn/ITERS/it.0/0.events.csv.gz':'Calibration58',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr59__2022-11-10_01-38-18_oiv/ITERS/it.0/0.events.csv.gz':'Calibration59',\n",
    "    # 's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr60__2022-11-10_01-39-04_bzm/ITERS/it.0/0.events.csv.gz':'Calibration60',\n",
    "#     's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr41__2022-11-15_02-54-11_rex/ITERS/it.0/0.events.csv.gz':'Calibration44',\n",
    "#     's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr61__2022-11-15_03-52-29_qjw/ITERS/it.0/0.events.csv.gz':'Calibration61',\n",
    "#     's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr62__2022-11-15_03-52-30_ckn/ITERS/it.0/0.events.csv.gz':'Calibration62',\n",
    "#     's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr63__2022-11-15_03-52-30_ylj/ITERS/it.0/0.events.csv.gz':'Calibration63',\n",
    "#     's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr64__2022-11-15_03-52-28_hub/ITERS/it.0/0.events.csv.gz':'Calibration64',\n",
    "#     's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr65__2022-11-15_03-52-28_ikv/ITERS/it.0/0.events.csv.gz':'Calibration65',\n",
    "#     's3://beam-outputs/output/sfbay/sfbay-smart2-rh-calibr60__2022-11-15_03-52-29_bkb/ITERS/it.0/0.events.csv.gz':'Calibration66',\n",
    "# }\n",
    "# data_names = data.keys()\n",
    "# plan_names = []\n",
    "# for data_name in data_names:\n",
    "#     plan_names.append(data_name[:-13]+'plans.csv.gz')\n",
    "\n",
    "# names = data.values()\n",
    "############################################SMART###########################################################################\n",
    "if is_SMART:\n",
    "    fp = \"\"\n",
    "    output_nm = 'ST-smart2_35.csv'\n",
    "    len_id_transit = 3\n",
    "    fp_res = 'outputs/'\n",
    "    is_NYC = False\n",
    "    is_WC = False\n",
    "    is_LT = False\n",
    "    is_GEO = False\n",
    "    is_collect_data = False\n",
    "    is_plot = False\n",
    "    is_filter_by_region = False\n",
    "    region_filter = 'SF'\n",
    "    data = {\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-base-20220409/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'Baseline/year-2018-iteration-5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-RH_fleetsz_0.125-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_0.125',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-RH_fleetsz_0.25-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_0.25',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-RH_fleetsz_0.5-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_0.50',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-RH_fleetsz_1.75-20220408/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_1.75',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-transit_frequencies_0.5-20220528/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-transit_frequencies_0.5',\n",
    "                    # 's3://beam-outputs/s3://beam-outputs/pilates-outputs/sfbay-transit_frequencies_1.5-20220529/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-transit_frequencies_1.5',\n",
    "                    # 'pilates-outputs/sfbay-transit_frequencies_2.0-20220529/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-transit_frequencies_2.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_repo_0.0-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_repo_0.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_repo_0.5-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_repo_0.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_repo_1.5-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_repo_1.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_repo_3.0-20220613/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_repo_3.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_radius_0.2-20220610/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_radius_0.2',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_radius_0.5-20220610/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_radius_0.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_radius_1.5-20220614/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_radius_1.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_radius_5.0-20220616/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_radius_5.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_wt_0.2-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_wt_0.2',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_wt_0.5-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_wt_0.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_wt_0.8-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_wt_0.8',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_wt_1.6-20220617/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_wt_1.6',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_detour_0.0-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_detour_0.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_detour_0.5-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_detour_0.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_detour_0.75-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_detour_0.75',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_detour_1.5-20220618/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_detour_1.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-pilates_june_test-20220616/beam/year-2010-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-cp_pilatesJune2022',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_price_0.5-20220616/beam/year-2010-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_price_0.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_invrepo_dem_0.0_dist_0.0-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_invrepo_dem_0.0_dist_0.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_invrepo_dem_0.2_dist_0.9-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_invrepo_dem_0.2_dist_0.9',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_invrepo_dem_0.4_dist_0.3-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_invrepo_dem_0.4_dist_0.3',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_invrepo_dem_0.4_dist_0.6-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_invrepo_dem_0.4_dist_0.6',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_invrepo_dem_0.4_dist_1.0-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_invrepo_dem_0.4_dist_1.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_invrepo_dem_0.6_dist_0.9-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_invrepo_dem_0.6_dist_0.9',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_invrepo_dem_1.0_dist_0.9-20220627/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_invrepo_dem_1.0_dist_0.9',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rh_invrepo_dem_1.0_dist_1.0-20220628/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-rh_invrepo_dem_1.0_dist_1.0',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-5veh__2022-07-20_21-48-51_yti/ITERS/it.2/2.events.csv.gz':'Disabilities 5% RH WC 50% RH fleet',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-10veh__2022-07-20_21-48-52_ucj/ITERS/it.2/2.events.csv.gz':'Disabilities 10% RH WC 50% RH fleet',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-20veh__2022-07-20_21-48-54_xwf/ITERS/it.2/2.events.csv.gz':'Disabilities 20% RH WC 50% RH fleet',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-50veh__2022-07-20_21-49-07_oyq/ITERS/it.2/2.events.csv.gz':'Disabilities 50% RH WC 50% RH fleet',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-100veh__2022-07-20_21-49-00_lgi/ITERS/it.2/2.events.csv.gz':'Disabilities 100% RH WC 50% RH fleet',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-5veh__2022-07-15_04-13-50_ntn/ITERS/it.2/2.events.csv.gz':'Disabilities 5% RH WC 100% RH fleet',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-10veh__2022-07-15_04-13-44_okn/ITERS/it.2/2.events.csv.gz':'Disabilities 10% RH WC 100% RH fleet',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-20veh__2022-07-15_04-13-46_szz/ITERS/it.2/2.events.csv.gz':'Disabilities 20% RH WC 100% RH fleet',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-50veh__2022-07-15_04-13-48_qbr/ITERS/it.2/2.events.csv.gz':'Disabilities 50% RH WC 100% RH fleet',\n",
    "                    # 's3://beam-outputs/output/sfbay/sfbay-pilates-50pop-100veh__2022-07-15_04-13-44_apr/ITERS/it.2/2.events.csv.gz':'Disabilities 100% RH WC 100% RH fleet',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-base-20220409/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'Baseline-july2022',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice-0.0-20220814/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_0.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice-0.5-20220814/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_0.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice-1.5-20220815/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_1.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice-2.0-20220815/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_2.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'Baseline-august2022',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhfleet-0.125-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_0.125',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhfleet-0.25-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_0.25',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhfleet-0.50-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_0.50',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhfleet-1.75-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_1.75',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhfleet-2.25-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_2.25',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhfleet-3.0-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_fleetsz_3.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice0.0-rhfleet1.0-20220904/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_0.0_fleetsz_1.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice0.05-rhfleet2.25-20220905/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_0.05_fleetsz_2.25',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice0.25-rhfleet1.0-20220903/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_0.25_fleetsz_1.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice0.25-rhfleet2.25-20220904/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_0.25_fleetsz_2.25',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice0.5-rhfleet0.5-20220903/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_0.5_fleetsz_0.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice0.5-rhfleet1.0-20220903/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_0.5_fleetsz_1.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice0.5-rhfleet2.25-20220903/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_0.5_fleetsz_2.25',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice1.5-rhfleet0.125-20220903/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_1.5_fleetsz_0.125',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice1.5-rhfleet0.25-20220904/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_1.5_fleetsz_0.25',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice1.5-rhfleet0.5-20220904/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_1.5_fleetsz_0.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice1.5-rhfleet1.0-20220904/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_1.5_fleetsz_1.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice1.5-rhfleet2.25-20220905/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_1.5_fleetsz_2.25',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice2.0-rhfleet0.5-20220905/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_2.0_fleetsz_0.5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice2.0-rhfleet1.0-20220905/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_2.0_fleetsz_1.0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice2.5-rhfleet0.125-20220905/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_2.5_fleetsz_0.125',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-rhprice2.5-rhfleet0.25-20220905/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'sfbay-RH_price_2.5_fleetsz_0.25',\n",
    "                    # 'gs://beam-core-outputs/sfbay-2010-accessibility-fleetpct-0.05-wheelchair-0.5-20220917/beam/year-2012-iteration-3/ITERS/it.0/0.events.csv.gz':'5% RH WC 50% RH fleet',\n",
    "                    # 'gs://beam-core-outputs/sfbay-2010-accessibility-fleetpct0.1wheelchair-0.5-20220917/beam/year-2012-iteration-3/ITERS/it.0/0.events.csv.gz':'10% RH WC 50% RH fleet',\n",
    "                    # 'gs://beam-core-outputs/sfbay-2010-accessibility-fleetpct-0.2-wheelchair-0.5-20220917/beam/year-2012-iteration-3/ITERS/it.0/0.events.csv.gz':'20% RH WC 50% RH fleet',\n",
    "                    # 'gs://beam-core-outputs/beam-core-outputs/sfbay-2010-accessibility-fleetpct-0.5-wheelchair-0.5-20220917/beam/year-2012-iteration-3/ITERS/it.0/0.events.csv.gz':'50% RH WC 50% RH fleet',\n",
    "                    # 'gs://beam-core-outputs/sfbay-2010-accessibility-fleetpct-1.0-wheelchair-0.5-20220917/beam/year-2012-iteration-3/ITERS/it.0/0.events.csv.gz':'100% RH WC 50% RH fleet',\n",
    "                    # Ambarish\n",
    "                    # 's3://beam-outputs/pilates-outputs/15thSep2019/baseline/beam/sfbay-smart-base-pilates__2019-09-13_17-22-29/ITERS/it.15/15.events.csv.gz':'2010 Baseline',\n",
    "                    # Telecommute\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-telecommute-baseline-2022-10-8/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'Telecommuting_Baseline-year2018-it5',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-telecommute-baseline-2022-10-8/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz':'Telecommuting_Baseline-year2021-it5',\n",
    "                    # TR\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz':'Baseline TR 2021',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz':'Future TR 2021',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-baseline-asis-20221209/beam/year-2010-iteration-4/ITERS/it.0/0.events.csv.gz':'Baseline-asis0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-baseline-beam_rh_calibration-20221209/beam/year-2010-iteration-4/ITERS/it.0/0.events.csv.gz':'Baseline-rh_beam0',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-pilates-baseline-asis-20221213/beam/year-2010-iteration-4/ITERS/it.0/0.events.csv.gz':'Baseline-asis1',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-pilates-baseline-rh_beam-20221213/beam/year-2010-iteration-4/ITERS/it.0/0.events.csv.gz':'Baseline-rh_beam1',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-pilates-baseline-rh_beam_asim1-20221213/beam/year-2010-iteration-4/ITERS/it.0/0.events.csv.gz':'Baseline-rh_beam_asim1',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-pilates-baseline-rh_beam_asim2-20221213/beam/year-2010-iteration-4/ITERS/it.0/0.events.csv.gz':'Baseline-rh_beam_asim2',\n",
    "                    # 's3://beam-outputs/pilates-outputs/sfbay-pilates-baseline-rh_beam_asim3-20221213/beam/year-2010-iteration-4/ITERS/it.0/0.events.csv.gz':'Baseline-rh_beam_asim3',\n",
    "\n",
    "\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_1fleet_100price_100fleet_30pct_20230222/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'1Fl 1Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_baseline_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl 1Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_100price_100fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 1Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_100price_164fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 1Pr 1.64Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_100price_200fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 1Pr 2Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_100price_400fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 1Pr 4Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_100price_1000fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 1Pr 10Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_2fleets_100price_164fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl 1Pr 1.64Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_2fleets_100price_200fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl 1Pr 2Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_2fleets_100price_400fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl 1Pr 4Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_2fleets_100price_1000fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl 1Pr 10Flz',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_2fleets_47price_100fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl 0.47Pr 1Flz',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_47price_100fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.47Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_47price_164fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.47Pr 1.64Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_47price_200fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.47Pr 2Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_47price_400fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.47Pr 4Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_47price_1000fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.47Pr 10Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_2fleets_27price_100fleet_30pct_20230221/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl 0.27Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_27price_100fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.27Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_27price_164fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.27Pr 1.64Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_27price_200fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.27Pr 2Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_27price_400fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.27Pr 4Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_27price_1000fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.27Pr 10Flz',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_2fleets_12_5price_100fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl 0.125Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_12_5price_100fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.125Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_12_5price_164fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.125Pr 1.64Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_12_5price_200fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.125Pr 2Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_12_5price_400fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.125Pr 4Flz',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_12_5price_1000fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.125Pr 10Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_2fleets_6_25_price_100fleet_30pct_20230223/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl 0.0625Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_6_25price_100fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.0625Pr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_6_25price_164fleet_30pct_20230218/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.0625Pr 1.64Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_6_25price_200fleet_30pct_20230223/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.0625Pr 2Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_6_25_price_400fleet_30pct_20230223/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.0625Pr 4Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_6_25_price_1000fleet_30pct_20230223/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl 0.0625Pr 10Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_1fleet_mix_price_100fleet_30pct_20230223/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'1Fl MixPr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_2fleets_mix_price_100fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'2Fl MixPr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_mixprice_100fleet_30pct_20230223/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl MixPr 1Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_mix_price_164fleet_30pct_20230226/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl MixPr 1.64Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_mixprice_200fleet_30pct_20230223/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl MixPr 2Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_mixprice_400fleet_30pct_20230223/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl MixPr 4Flz',\n",
    "        # 's3://beam-outputs/pilates-outputs/sfbay_5fleets_mixprice_1000fleet_30pct_20230223/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'5Fl MixPr 10Flz',\n",
    "                # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230331/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'Base-20230331', # BART ridership\n",
    "                            # 'gs://beam-core-outputs/sfbay-baseline-20230410-omx/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'OMX-Baseline-20.2', # Test OMX\n",
    "                    # 'gs://beam-core-outputs/sfbay-baseline-20230416-omx/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'OMX-Baseline2-20.2', # Test OMX\n",
    "                            # 'gs://beam-core-outputs/sfbay-baseline-20230418-omx-tr/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'OMX-Baseline2-tr-20.2', # Test OMX\n",
    "                    # 'gs://beam-core-outputs/sfbay-baseline-20230425-omx/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'OMX-Baseline3-tr-18.2', # Test OMX\n",
    "                    # 'gs://beam-core-outputs/sfbay-baseline-20230425-omx/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'OMX-Baseline3-tr-19.2', # Test OMX\n",
    "                    # 'gs://beam-core-outputs/sfbay-baseline-20230425-omx/beam/year-2020-iteration--1/ITERS/it.0/0.events.csv.gz':'OMX-Baseline3-tr-20.0', # Test OMX\n",
    "                    # 'gs://beam-core-outputs/sfbay-baseline-20230425-omx/beam/year-2020-iteration-1/ITERS/it.0/0.events.csv.gz':'OMX-Baseline3-tr-20.1', # Test OMX\n",
    "                    # 'gs://beam-core-outputs/sfbay-baseline-20230425-omx/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'OMX-Baseline3-tr-20.2', # Test OMX\n",
    "                # 'gs://beam-core-outputs/sfbay-baseline-TR-testBA-20230427/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'TR-testBA', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2018-iteration--1/ITERS/it.0/0.events.csv.gz':'Base-18.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2018-iteration-1/ITERS/it.0/0.events.csv.gz':'Base-18.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'Base-18.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2018-iteration-3/ITERS/it.0/0.events.csv.gz':'Base-18.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2018-iteration-4/ITERS/it.0/0.events.csv.gz':'Base-18.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2019-iteration--1/ITERS/it.0/0.events.csv.gz':'Base-19.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2019-iteration-1/ITERS/it.0/0.events.csv.gz':'Base-19.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'Base-19.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2019-iteration-3/ITERS/it.0/0.events.csv.gz':'Base-19.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2019-iteration-4/ITERS/it.0/0.events.csv.gz':'Base-19.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2020-iteration--1/ITERS/it.0/0.events.csv.gz':'Base-20.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2020-iteration-1/ITERS/it.0/0.events.csv.gz':'Base-20.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'Base-20.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2020-iteration-3/ITERS/it.0/0.events.csv.gz':'Base-20.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230427/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Base-20.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2018-iteration--1/ITERS/it.0/0.events.csv.gz':'TR-18.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2018-iteration-1/ITERS/it.0/0.events.csv.gz':'TR-18.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'TR-18.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2018-iteration-3/ITERS/it.0/0.events.csv.gz':'TR-18.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2018-iteration-4/ITERS/it.0/0.events.csv.gz':'TR-18.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2019-iteration--1/ITERS/it.0/0.events.csv.gz':'TR-19.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2019-iteration-1/ITERS/it.0/0.events.csv.gz':'TR-19.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'TR-19.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2019-iteration-3/ITERS/it.0/0.events.csv.gz':'TR-19.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2019-iteration-4/ITERS/it.0/0.events.csv.gz':'TR-19.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2020-iteration--1/ITERS/it.0/0.events.csv.gz':'TR-20.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2020-iteration-1/ITERS/it.0/0.events.csv.gz':'TR-20.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'TR-20.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2020-iteration-3/ITERS/it.0/0.events.csv.gz':'TR-20.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-20230427/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TR-20.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2018-iteration--1/ITERS/it.0/0.events.csv.gz':'Base2-18.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2018-iteration-1/ITERS/it.0/0.events.csv.gz':'Base2-18.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'Base2-18.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2018-iteration-3/ITERS/it.0/0.events.csv.gz':'Base2-18.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2018-iteration-4/ITERS/it.0/0.events.csv.gz':'Base2-18.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2019-iteration--1/ITERS/it.0/0.events.csv.gz':'Base2-19.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2019-iteration-1/ITERS/it.0/0.events.csv.gz':'Base2-19.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'Base2-19.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2019-iteration-3/ITERS/it.0/0.events.csv.gz':'Base2-19.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2019-iteration-4/ITERS/it.0/0.events.csv.gz':'Base2-19.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2020-iteration--1/ITERS/it.0/0.events.csv.gz':'Base2-20.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2020-iteration-1/ITERS/it.0/0.events.csv.gz':'Base2-20.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'Base2-20.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2020-iteration-3/ITERS/it.0/0.events.csv.gz':'Base2-20.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230503-omx/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Base2-20.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2018-iteration--1/ITERS/it.0/0.events.csv.gz':'TR-18.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2018-iteration-1/ITERS/it.0/0.events.csv.gz':'TR-18.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'TR-18.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2018-iteration-3/ITERS/it.0/0.events.csv.gz':'TR-18.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2018-iteration-4/ITERS/it.0/0.events.csv.gz':'TR-18.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2019-iteration--1/ITERS/it.0/0.events.csv.gz':'TR-19.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2019-iteration-1/ITERS/it.0/0.events.csv.gz':'TR-19.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'TR-19.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2019-iteration-3/ITERS/it.0/0.events.csv.gz':'TR-19.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2019-iteration-4/ITERS/it.0/0.events.csv.gz':'TR-19.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2020-iteration--1/ITERS/it.0/0.events.csv.gz':'TR-20.0', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2020-iteration-1/ITERS/it.0/0.events.csv.gz':'TR-20.1', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'TR-20.2', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2020-iteration-3/ITERS/it.0/0.events.csv.gz':'TR-20.3', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230505/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TR-20.4', # Test OMX\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230510/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Base4-20.4', # Test OMX -Solo correct\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230511/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Poolfree4-20.4', # Test OMX- Pool free solo correct\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-atlas/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Base5-20.4', # Test ATLAS\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230517/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Base6-20.4', # Test TRN correction\n",
    "            # 'gs://beam-core-outputs/sfbay-TR-20230519/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TR6-20.4', # TR compared to Base 6\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-20230523/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Base7-20.4', # other corrections to TRN Zach did\n",
    "\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/beam/year-2018-iteration--1/ITERS/it.0/0.events.csv.gz':'Base18.0',\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-30pct-20230716/beam/year-2018-iteration--1/ITERS/it.0/0.events.csv.gz':'TR18.0',\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/beam/year-2018-iteration-1/ITERS/it.0/0.events.csv.gz':'Base18.1',\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-30pct-20230716/beam/year-2018-iteration-1/ITERS/it.0/0.events.csv.gz':'TR18.1',\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'Base18.2',\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-30pct-20230716/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'TR18.2',\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'Base18.5',\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-30pct-20230716/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'TR18.5',\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/beam/year-2018-iteration-7/ITERS/it.0/0.events.csv.gz':'Base18.7',\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-30pct-20230716/beam/year-2018-iteration-7/ITERS/it.0/0.events.csv.gz':'TR18.7',\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/beam/year-2018-iteration-9/ITERS/it.0/0.events.csv.gz':'Base18.9',\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-30pct-20230716/beam/year-2018-iteration-9/ITERS/it.0/0.events.csv.gz':'TR18.9',\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline2018-30pct-20230710/beam/year-2018-iteration-10/ITERS/it.0/0.events.csv.gz':'Base18.10',\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-30pct-20230716/beam/year-2018-iteration-10/ITERS/it.0/0.events.csv.gz':'TR18.10',\n",
    "#             'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2019-iteration--1/ITERS/it.0/0.events.csv.gz':'Base19.0',\n",
    "#             'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2019-iteration--1/ITERS/it.0/0.events.csv.gz':'TR19.0',\n",
    "#             'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2019-iteration-1/ITERS/it.0/0.events.csv.gz':'Base19.1',\n",
    "#             'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2019-iteration-1/ITERS/it.0/0.events.csv.gz':'TR19.1',\n",
    "#             'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'Base19.2',\n",
    "#             'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'TR19.2',\n",
    "#             'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2019-iteration-3/ITERS/it.0/0.events.csv.gz':'Base19.3',\n",
    "#             'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2019-iteration-3/ITERS/it.0/0.events.csv.gz':'TR19.3',\n",
    "#             'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2019-iteration-4/ITERS/it.0/0.events.csv.gz':'Base19.4',\n",
    "#             'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2019-iteration-4/ITERS/it.0/0.events.csv.gz':'TR19.4',\n",
    "        \n",
    "#             'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2020-iteration--1/ITERS/it.0/0.events.csv.gz':'Base20.0',\n",
    "#             'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2020-iteration--1/ITERS/it.0/0.events.csv.gz':'TR20.0',\n",
    "#             'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2020-iteration-1/ITERS/it.0/0.events.csv.gz':'Base20.1',\n",
    "#             'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2020-iteration-1/ITERS/it.0/0.events.csv.gz':'TR20.1',\n",
    "#             'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'Base20.2',\n",
    "#             'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2020-iteration-2/ITERS/it.0/0.events.csv.gz':'TR20.2',\n",
    "#             'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2020-iteration-3/ITERS/it.0/0.events.csv.gz':'Base20.3',\n",
    "#             'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2020-iteration-3/ITERS/it.0/0.events.csv.gz':'TR20.3',\n",
    "            # 'gs://beam-core-outputs/sfbay-baseline-30pct-20230603/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Base20.4',\n",
    "            # 'gs://beam-core-outputs/sfbay-tr-30pct-20230603/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TR20.4',\n",
    "                    \n",
    "        'gs://beam-core-outputs/sfbay-baseline-20230526/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Baseline', # other corrections...BEAM 0.9.5\n",
    "        # 'gs://beam-core-outputs/sfbay-incentives-20230609/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'incentives', \n",
    "        # 'gs://beam-core-outputs/sfbay-incentives-20230618/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'incentives', # include walk transit and bike transit\n",
    "        # 'gs://beam-core-outputs/sfbay-cordon-20230609/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Cordon', \n",
    "        # 'gs://beam-core-outputs/sfbay-incentives-20230612/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'incentives', \n",
    "        # 'gs://beam-core-outputs/sfbay-cordon-20230612/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Cordon',\n",
    "        # 'gs://beam-core-outputs/sfbay-detour0125-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Detour-0.125', \n",
    "        # 'gs://beam-core-outputs/sfbay-detour05-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Detour-0.5', \n",
    "        # 'gs://beam-core-outputs/sfbay-detour3-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Detour-3', \n",
    "        # 'gs://beam-core-outputs/sfbay-detour10-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Detour-10', \n",
    "        # 'gs://beam-core-outputs/sfbay-repo_0_125-20230603/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Repo-0.125',\n",
    "        # 'gs://beam-core-outputs/sfbay-repo_0_5-20230603/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Repo-0.5',\n",
    "        # 'gs://beam-core-outputs/sfbay-repo_3-20230603/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Repo-3',\n",
    "        # 'gs://beam-core-outputs/sfbay-repo_10-20230603/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Repo-10',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr_capacity_0_25-20230608/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'capacity-0.25',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr_capacity_0_5-20230608/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'capacity-0.5',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr_capacity_1_5-20230608/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'capacity-1.5',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr_capacity_2-20230607/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'capacity-2',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-frequency_0_25-20230614/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'freq-0.25',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-frequency_0_50-20230614/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'freq-0.5',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-frequency_1_5-20230614/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'freq-1.5',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-frequency_2-20230616/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'freq-2',\n",
    "        # 'gs://beam-core-outputs/sfbay-rh-price_0_125-20230614/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHprice-0.125',\n",
    "        # 'gs://beam-core-outputs/sfbay-rh-price_0_5-20230614/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHprice-0.5',\n",
    "        # 'gs://beam-core-outputs/sfbay-rh-price_2-20230614/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHprice-2',\n",
    "        # 'gs://beam-core-outputs/sfbay-rh-price_5-20230614/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHprice-5',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-speed0_25-20230626/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TRspeed-0_25',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-speed0_5-20230626/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TRspeed-0_5',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-speed1_5-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TRspeed-1_5',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-speed2_0-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TRspeed-2_0',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-discount-100-20230703/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TRdisc-100',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-discount-75-20230703/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TRdisc-75',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-discount-50-20230703/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TRdisc-50',\n",
    "        # 'gs://beam-core-outputs/sfbay-tr-discount-25-20230703/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'TRdisc-25',\n",
    "        # 'gs://beam-core-outputs/sfbay-fleetsz_0_125-20230609/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHfltsz-0_125',\n",
    "        # 'gs://beam-core-outputs/sfbay-fleetsz_0_5-20230607/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHfltsz-0_5',\n",
    "        # 'gs://beam-core-outputs/sfbay-fleetsz_3-20230607/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHfltsz-3',\n",
    "        # 'gs://beam-core-outputs/sfbay-fleetsz_10-20230607/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHfltsz-10',\n",
    "        # 'gs://beam-core-outputs/sfbay-rh-detour0125-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHdetour-0_125',\n",
    "        # 'gs://beam-core-outputs/sfbay-rh-detour05-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHdetour-0_5',\n",
    "        # 'gs://beam-core-outputs/sfbay-rh-detour3-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHdetour-3',\n",
    "        # 'gs://beam-core-outputs/sfbay-rh-detour10-20230623/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'RHdetour-10',\n",
    "        # 'gs://beam-core-outputs/sfbay-wb-incentives-25-20230705/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'WBincent-25',\n",
    "        # 'gs://beam-core-outputs/sfbay-wb-incentives-50-20230703/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'WBincent-50',\n",
    "        # 'gs://beam-core-outputs/sfbay-wb-incentives-100-20230630/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'WBincent-100',\n",
    "        # 'gs://beam-core-outputs/sfbay-wb-incentives-200-20230630/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'WBincent-200',\n",
    "        # 'gs://beam-core-outputs/sfbay-telecommuting-baseline-20230616/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Baseline',\n",
    "        # 'gs://beam-core-outputs/sfbay-telecommuting-0p36-20230620/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Tele-036',\n",
    "        # 'gs://beam-core-outputs/sfbay-telecommuting-0p76-20230621/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Tele-076',\n",
    "        # 'gs://beam-core-outputs/sfbay-telecommuting-1p56-20230617/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Tele-156',\n",
    "        # 'gs://beam-core-outputs/sfbay-telecommuting-3p32-20230621/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Tele-332',\n",
    "        # 'gs://beam-core-outputs/sfbay-telecommuting-5p24-20230617/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Tele-524',\n",
    "        # 'gs://beam-core-outputs/sfbay-telecommuting-8p60-20230620/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'Tele-860'\n",
    "        # 'gs://beam-core-outputs/sfbay-cordon-MTA-20230703/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'MTA-Cordon',\n",
    "        # 'gs://beam-core-outputs/sfbay-cordon-MTA-nobeamtoll-20230703/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz':'MTA-Cordon-noBEAM'\n",
    "        \n",
    "        \n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_01-22-35_vjo/ITERS/it.0/0.events.csv.gz': '0.3pop-baseline',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_01-22-34_ufh/ITERS/it.0/0.events.csv.gz': '0.3pop-fewerdocks',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_01-22-57_uyl/ITERS/it.0/0.events.csv.gz': '0.3pop-moredocks',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_01-22-47_grg/ITERS/it.0/0.events.csv.gz': '0.3pop-fewerbikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_01-23-11_avr/ITERS/it.0/0.events.csv.gz': '0.3pop-morebikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_07-19-25_ioy/ITERS/it.0/0.events.csv.gz': '0.3pop-nocar400',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_07-19-25_xiw/ITERS/it.0/0.events.csv.gz': '0.3pop-nocar1600',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_07-44-20_wkt/ITERS/it.0/0.events.csv.gz': '0.3pop-cheaperbikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_07-58-25_dst/ITERS/it.0/0.events.csv.gz': '0.3pop-nosharedbikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_07-50-06_dta/ITERS/it.0/0.events.csv.gz': '0.3pop-freebikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_01-36-53_pkp/ITERS/it.0/0.events.csv.gz': '0.3pop-twicebikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_02-42-45_unm/ITERS/it.0/0.events.csv.gz': '0.3pop-twicebikes-nocar400',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_08-08-48_htd/ITERS/it.0/0.events.csv.gz': '0.3pop-twicebikes-nocar1600',\n",
    "        \n",
    "\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-12_05-21-47_yib/ITERS/it.0/0.events.csv.gz': '0.1pop-neweline',\n",
    "\n",
    "\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_17-14-51_fdd/ITERS/it.0/0.events.csv.gz': '0.1pop-baseline',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_17-14-40_xaa/ITERS/it.0/0.events.csv.gz': '0.1pop-fewerdocks',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_17-14-39_wfo/ITERS/it.0/0.events.csv.gz': '0.1pop-moredocks',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_17-14-52_kok/ITERS/it.0/0.events.csv.gz': '0.1pop-fewerbikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_17-14-52_gvj/ITERS/it.0/0.events.csv.gz': '0.1pop-morebikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-05_04-21-06_quo/ITERS/it.0/0.events.csv.gz': '0.1pop-nocar400',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-05_04-21-45_iev/ITERS/it.0/0.events.csv.gz': '0.1pop-nocar1600',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-05_06-15-59_hov/ITERS/it.0/0.events.csv.gz': '0.1pop-cheaperbikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_23-12-58_mii/ITERS/it.0/0.events.csv.gz': '0.1pop-noshared',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-05_06-39-27_kjk/ITERS/it.0/0.events.csv.gz': '0.1pop-freebikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-11_17-14-54_mkb/ITERS/it.0/0.events.csv.gz': '0.1pop-twicebikes',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-05_06-39-50_iqq/ITERS/it.0/0.events.csv.gz': '0.1pop-twicebikes-nocar400',\n",
    "#     'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-05_06-39-27_urc/ITERS/it.0/0.events.csv.gz': '0.1pop-twicebikes-nocar1600',\n",
    "    \n",
    "        # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-06-30_14-55-00_qsk/ITERS/it.0/0.events.csv.gz': '0.1pop-baseline-highBaseCost',\n",
    "\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_02-25-59_jqi/ITERS/it.0/0.events.csv.gz': '0.3pop-baseline',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_02-27-49_znc/ITERS/it.0/0.events.csv.gz': '0.3pop-fewerdocks',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_02-29-11_ybc/ITERS/it.0/0.events.csv.gz': '0.3pop-moredocks',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_21-01-43_vnv/ITERS/it.0/0.events.csv.gz': '0.3pop-fewerbikes',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_08-13-08_rmx/ITERS/it.0/0.events.csv.gz': '0.3pop-morebikes',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_08-57-44_qlv/ITERS/it.0/0.events.csv.gz': '0.3pop-nocar400',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_02-29-41_jwh/ITERS/it.0/0.events.csv.gz': '0.3pop-nocar1600',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_14-44-12_hwy/ITERS/it.0/0.events.csv.gz': '0.3pop-cheaperbikes',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_07-45-36_aep/ITERS/it.0/0.events.csv.gz': '0.3pop-noshared',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_21-09-07_xhl/ITERS/it.0/0.events.csv.gz': '0.3pop-freebikes',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_08-46-59_nmr/ITERS/it.0/0.events.csv.gz': '0.3pop-twicebikes',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_15-23-32_bmh/ITERS/it.0/0.events.csv.gz': '0.3pop-twicebikes-nocar400',\n",
    "    # 'gs://beam-core-outputs/output/sfbay/sfbay-pilates-base__2023-07-16_15-23-42_omr/ITERS/it.0/0.events.csv.gz': '0.3pop-twicebikes-nocar1600',\n",
    "\n",
    "        \n",
    "\n",
    "    }\n",
    "    data_names = data.keys()\n",
    "    plan_names = []\n",
    "    for data_name in data_names:\n",
    "        plan_names.append(data_name[:-13]+'plans.csv.gz')\n",
    "\n",
    "    names = data.values()\n",
    "\n",
    "##########################################GOOGLE CLOUD#############################################################################\n",
    "# fp = \"\"\n",
    "# output_nm = 'SummaryTable_Pilates_GoogleCloud2.csv'\n",
    "# len_id_transit = 3\n",
    "# fp_res = 'outputs/'\n",
    "# is_NYC = False\n",
    "# is_LT = False\n",
    "# is_WC = True\n",
    "# is_GEO = False\n",
    "# is_collect_data = False\n",
    "# is_plot = False\n",
    "\n",
    "# data = {               's3://beam-outputs/pilates-outputs/sfbay-base-20220409/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'Baseline/year-2018-iteration-5',\n",
    "#                 'gs://beam-core-outputs/sfbay-2010-base-20220810/beam/year-2011-iteration-3/ITERS/it.0/0.events.csv.gz':'Baseline - google cloud - year 2011 iter 3',\n",
    "#                 'gs://beam-core-outputs/fbay-2010-TR-20220810/beam/year-2011-iteration-3/ITERS/it.0/0.events.csv.gz':'TR - google cloud - year 2010 iter 3',\n",
    "\n",
    "#                 }\n",
    "# data_names = data.keys()\n",
    "# plan_names = []\n",
    "# for data_name in data_names:\n",
    "#     plan_names.append(data_name[:-13]+'plans.csv.gz')\n",
    "\n",
    "# names = data.values()\n",
    "\n",
    "#######################################################################################################################\n",
    "# Transi Rich Scenarios\n",
    "#######################################################################################################################\n",
    "# fp = \"\"\n",
    "# output_nm = 'SummaryTable_Pilates_TR.csv'\n",
    "# len_id_transit = 3\n",
    "# fp_res = 'outputs/'\n",
    "# is_NYC = False\n",
    "# is_WC = False\n",
    "# is_LT = False\n",
    "# is_GEO = False\n",
    "# is_collect_data = True\n",
    "# is_plot = False\n",
    "\n",
    "# data = {\n",
    "                # 's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'Baseline 2018',\n",
    "                # 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'Future 2018',\n",
    "                #     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz':'Baseline 2019',\n",
    "                # 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz':'Future 2019',\n",
    "                #     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz':'Baseline 2020',\n",
    "                # 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2020-iteration-5/ITERS/it.0/0.events.csv.gz':'Future 2020',\n",
    "#                     's3://beam-outputs/pilates-outputs/sfbay-baseline-20220816/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz':'Baseline 2021',\n",
    "#                 's3://beam-outputs/pilates-outputs/sfbay-TR-20220812/beam/year-2021-iteration-5/ITERS/it.0/0.events.csv.gz':'Future 2021',\n",
    "#             \n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2018-iteration-1/ITERS/it.0/0.events.csv.gz':'BS 2018-1',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2018-iteration-1/ITERS/it.0/0.events.csv.gz':'TR 2018-1',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'BS 2018-2',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2018-iteration-2/ITERS/it.0/0.events.csv.gz':'TR 2018-2',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2018-iteration-3/ITERS/it.0/0.events.csv.gz':'BS 2018-3',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2018-iteration-3/ITERS/it.0/0.events.csv.gz':'TR 2018-3',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2018-iteration-4/ITERS/it.0/0.events.csv.gz':'BS 2018-4',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2018-iteration-4/ITERS/it.0/0.events.csv.gz':'TR 2018-4',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'BS 2018-5',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz':'TR 2018-5',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2018-iteration-6/ITERS/it.0/0.events.csv.gz':'BS 2018-6',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2018-iteration-6/ITERS/it.0/0.events.csv.gz':'TR 2018-6',\n",
    "        \n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2019-iteration-1/ITERS/it.0/0.events.csv.gz':'BS 2019-1',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2019-iteration-1/ITERS/it.0/0.events.csv.gz':'TR 2019-1',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'BS 2019-2',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2019-iteration-2/ITERS/it.0/0.events.csv.gz':'TR 2019-2',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2019-iteration-3/ITERS/it.0/0.events.csv.gz':'BS 2019-3',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2019-iteration-3/ITERS/it.0/0.events.csv.gz':'TR 2019-3',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2019-iteration-4/ITERS/it.0/0.events.csv.gz':'BS 2019-4',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2019-iteration-4/ITERS/it.0/0.events.csv.gz':'TR 2019-4',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz':'BS 2019-5',\n",
    "    # 's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2019-iteration-5/ITERS/it.0/0.events.csv.gz':'TR 2019-5',\n",
    "#     's3://beam-outputs/pilates-outputs/sfbay_baseline_20230224/beam/year-2019-iteration-6/ITERS/it.0/0.events.csv.gz':'BS 2019-6',\n",
    "#     's3://beam-outputs/pilates-outputs/sfbay_baseline_TR_20230224/beam/year-2019-iteration-6/ITERS/it.0/0.events.csv.gz':'TR 2019-6',\n",
    "        \n",
    "# }\n",
    "                    \n",
    "# data_names = data.keys()\n",
    "# plan_names = []\n",
    "# for data_name in data_names:\n",
    "#     plan_names.append(data_name[:-13]+'plans.csv.gz')\n",
    "\n",
    "# names = data.values()\n",
    "#######################################################################################################################\n",
    "\n",
    "if is_GEO:\n",
    "    BGs = gpd.read_file('inputs/641aa0d4-ce5b-4a81-9c30-8790c4ab8cfb202047-1-wkkklf.j5ouj.shp')\n",
    "\n",
    "\n",
    "# Nomenclature\n",
    "\n",
    "# mode share per distance\n",
    "binnames = {1: \"0-1\", 2: \"1-2\", 3: \"2-5\", 4: \"5-15\", 5: \"15+\"}\n",
    "distanceBinsMiles = np.array([0, 1, 2, 5, 15, 500])\n",
    "    \n",
    "PTsColumns = [\n",
    "    'vehicle','time','type','mode','length','vehicleType','arrivalTime','departureTime',\n",
    "        'capacity','secondaryFuel','primaryFuelType','secondaryFuelType','numPassengers','primaryFuel', 'startX', 'startY', 'endX', 'endY'\n",
    "        ]\n",
    "if is_LT:\n",
    "    PTsColumns.append('links')\n",
    "    \n",
    "MCsColumns = ['person','time','type','mode','length', 'legModes']\n",
    "MCsColumns_no_leg_modes = ['person','time','type','mode','length']\n",
    "\n",
    "\n",
    "summaryTable = pd.DataFrame()\n",
    "\n",
    "PTsModes = np.array(['walk','bike','bike_Sharing','bike_Sharing_empty','car','car_emer','car_hov2_emer','car_hov3_emer','car_RideHail','car_RideHail_empty','car_RideHail_WC','car_RideHail_WC_empty',\n",
    "                               'car_CAV','car_hov2','car_hov3','bus','tram','rail','subway',\n",
    "                               'cable_car','ferry','bus_empty','tram_empty','rail_empty',\n",
    "                               'subway_empty','cable_car_empty','ferry_empty'])\n",
    "\n",
    "PTsModesNames = ['Walk','Bike','Bike Sharing','Empty Bike Sharing','Car','Car Emergency','Car HOV2 Emergency','Car HOV3 Emergency','Ride Hail','Empty Ride Hail','Ride Hail WC','Empty Ride Hail WC',\n",
    "                           'CAV','Car HOV2','Car HOV3','Bus','Tram','Rail','Subway',\n",
    "                           'Cable Car','Ferry','Empty Bus','Empty Tram','Empty Rail',\n",
    "                           'Empty Subway','Empty Cable Car','Empty Ferry',]\n",
    "\n",
    "transit_modes = ['bus', 'subway', 'tram', 'rail','cable_car', 'ferry']\n",
    "\n",
    "transit_MCmodes = ['bus', 'subway', 'tram', 'rail', 'walk_transit', 'ride_hail_transit',\n",
    "                            'drive_transit', 'cable_car','bike_transit']\n",
    "\n",
    "MCsModes = np.array([ 'bus', 'subway', 'tram', 'rail', 'car', 'hov3_teleportation', \n",
    "                            'bike', 'hov2_teleportation', 'walk', 'car_hov2', 'car_hov3', \n",
    "                            'walk_transit', 'ride_hail', 'ride_hail_transit', 'ride_hail_pooled', \n",
    "                            'drive_transit', 'cable_car','bike_transit'])\n",
    "\n",
    "MCsModesNames = [ 'Bus', 'Subway', 'Tram', 'Rail', 'Car', 'HOV3 Passenger', 'Bike', \n",
    "                   'HOV2 Passenger', 'Walk', 'HOV2 Driver', 'HOV3 Driver', \n",
    "                   'Walk-Transit', 'Ride Hail', 'Ride Hail-Transit', 'Ride Hail Pooled', \n",
    "                   'Drive-Transit', 'Cable Car', 'Bike-Transit']\n",
    "\n",
    "primaryFuelTypes =['Biodiesel','Diesel','Gasoline','Electricity','Food']\n",
    "\n",
    "CtV = {0:'SUM',\n",
    "      1:'AV',\n",
    "      2:'VAR',\n",
    "      3:'STD',\n",
    "      4:'MIN',\n",
    "      5:'Q1ST',\n",
    "      6:'Q2ND',\n",
    "      7:'Q3RD',\n",
    "      8:'MAX',\n",
    "      }\n",
    "\n",
    "route_e_correction_cv = 1.1660\n",
    "route_e_correction_hev = 1.1252\n",
    "route_e_correction_ev = 1.3958\n",
    "\n",
    "\n",
    "# Regions: {'SF': [,,,,],\n",
    "#           'Cordon':[,,,,]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44dfae1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time 1689882680.547969 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print('Start time',start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fafde5b8-dd2c-4ad1-9d7a-091918524d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_by_region(region_filter, MCs, PTs, PEVs, PLVs, RPs, trips, PtoPTss):\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102925ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DA(data, code):\n",
    "    \n",
    "    #data is a list of values\n",
    "    #code - operation\n",
    "    #0 - Sum\n",
    "    #1 - Mean\n",
    "    #2 - Var\n",
    "    #3 - Std error\n",
    "    #4 - Min\n",
    "    #5 - Q1\n",
    "    #6 - Q2\n",
    "    #7 - Q3\n",
    "    #8 - Max\n",
    "    if len(data)>0:\n",
    "        if code == 0:\n",
    "            value = np.sum(data)\n",
    "        elif code == 1:\n",
    "            value = np.mean(data)\n",
    "        elif code == 2:\n",
    "            value = np.var(data)\n",
    "        elif code == 3:\n",
    "            value = np.std(data)\n",
    "        elif code == 4:\n",
    "            value = np.min(data)\n",
    "        elif code == 5:\n",
    "            value = np.percentile(data, 25)\n",
    "        elif code == 6:\n",
    "            value = np.percentile(data, 50)\n",
    "        elif code == 7:\n",
    "            value = np.percentile(data, 75)\n",
    "        elif code == 8:\n",
    "            value = np.max(data)\n",
    "    else:\n",
    "        value = np.nan\n",
    "\n",
    "        \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc1c7479-d2cf-4513-8b93-c586581ed12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def personToPathTraversal(PTs, PEVs, PLVs, personToTripDeparture):\n",
    "    print('personToPathTraversal...')\n",
    "    no_legs_after_time_check = []\n",
    "    no_legs = []\n",
    "    start = time.time()\n",
    "    for pt_mode in PTs['mode'].value_counts().keys():\n",
    "        if pt_mode == 'car_hov2':\n",
    "            print('expected PtoPTs from occupancy ',pt_mode,  int(np.sum(PTs[PTs['mode']==pt_mode]['occupancy']))/2)\n",
    "        elif pt_mode == 'car_hov3':\n",
    "            print('expected PtoPTs from occupancy ',pt_mode,  int(np.sum(PTs[PTs['mode']==pt_mode]['occupancy']))/3)\n",
    "        else:\n",
    "            print('expected PtoPTs from occupancy ',pt_mode,  int(np.sum(PTs[PTs['mode']==pt_mode]['occupancy'])))\n",
    "\n",
    "    print('expected PtoPTs from occupancy TOT = ', (np.sum(PTs['occupancy'])-\n",
    "          np.sum(PTs[PTs['mode']=='car_hov2']['occupancy'])/2-\n",
    "          np.sum(PTs[PTs['mode']=='car_hov3']['occupancy'])/3*2)\n",
    "         )\n",
    "    print('len of PEV = ', len(PEVs))\n",
    "    print('len of PLV = ', len(PLVs))\n",
    "\n",
    "    vehicleToPT = PTs.groupby('vehicle').apply(lambda x: list(x.index)).apply(\n",
    "        lambda x: {y: [] for y in x}).to_dict()\n",
    "    PEVlookup = PEVs[['person', 'vehicle', 'time']].value_counts().to_dict()\n",
    "    PLVlookup = PLVs.groupby(['person', 'vehicle']).apply(lambda x: list(x.time)).to_dict()\n",
    "\n",
    "    for key, counts in PEVlookup.items():\n",
    "        person = key[0]\n",
    "        vehicle = key[1]\n",
    "        departureTime = key[2]\n",
    "        n_new_leg = 0\n",
    "        if vehicle in vehicleToPT:\n",
    "            legs = vehicleToPT[vehicle]\n",
    "            if (person, vehicle) in PLVlookup:\n",
    "                if person in personToTripDeparture:\n",
    "                    planTrips = personToTripDeparture[person]\n",
    "                    tripsLeavingBeforeDeparture = [-1] + [t['planID'] for t in planTrips if\n",
    "                                                          t['departureTime'] <= (departureTime+1)]\n",
    "                                                                                     #+ 1800)]\n",
    "                else:\n",
    "                    tripsLeavingBeforeDeparture = [-1]\n",
    "                    print('no person',person, 'on personToTripDeparture...','vehicle',vehicle,'departureTime',departureTime,'personToTripDeparture',personToTripDeparture[person])\n",
    "\n",
    "                lastTripBeforeDeparture = tripsLeavingBeforeDeparture[-1]\n",
    "                if lastTripBeforeDeparture == -1:\n",
    "                    print('hmm...if person on personToTripDeparture, no plans starting before departure')\n",
    "                \n",
    "                endTimes = PLVlookup[(person, vehicle)]\n",
    "                plvsAfterDeparture = [t for t in endTimes if t > departureTime]\n",
    "                if len(plvsAfterDeparture) > 0:\n",
    "                    firstPLVafterDeparture = plvsAfterDeparture[0]\n",
    "                    n_new_leg = 0\n",
    "                    for leg in legs.keys():\n",
    "                        ptDepartureTime = PTs.at[leg, 'departureTime']\n",
    "                        if (ptDepartureTime >= departureTime) & (ptDepartureTime < firstPLVafterDeparture):\n",
    "                            n_new_leg +=1\n",
    "                            legs[leg].append((person, lastTripBeforeDeparture))\n",
    "                            \n",
    "                else:\n",
    "                    for leg in legs.keys():\n",
    "                        n_new_leg = 0\n",
    "                        ptDepartureTime = PTs.at[leg, 'departureTime']\n",
    "                        if ptDepartureTime >= departureTime:\n",
    "                            n_new_leg +=1\n",
    "                            legs[leg].append((person, lastTripBeforeDeparture))\n",
    "            else:\n",
    "\n",
    "                if person in personToTripDeparture:\n",
    "                    planTrips = personToTripDeparture[person]\n",
    "                    tripsLeavingBeforeDeparture = [-1] + [t['planID'] for t in planTrips if\n",
    "                                                          t['departureTime'] <= (departureTime+1)]\n",
    "                                                                                     #+ 1800)]\n",
    "                else:\n",
    "                    tripsLeavingBeforeDeparture = [-1]\n",
    "                    print('no person',person, 'on personToTripDeparture...','vehicle',vehicle,'departureTime',departureTime,'personToTripDeparture',personToTripDeparture[person])\n",
    "\n",
    "                lastTripBeforeDeparture = tripsLeavingBeforeDeparture[-1]\n",
    "                if lastTripBeforeDeparture == -1:\n",
    "                    print('hmm...if person on personToTripDeparture, no plans starting before departure')\n",
    "                n_new_leg = 0\n",
    "                for leg in legs.keys():\n",
    "                    ptDepartureTime = PTs.at[leg, 'departureTime']\n",
    "                    if ptDepartureTime >= departureTime:\n",
    "                        n_new_leg +=1\n",
    "                        legs[leg].append((person, lastTripBeforeDeparture))\n",
    "            if n_new_leg == 0:\n",
    "                no_legs_after_time_check.append(vehicle)\n",
    "#                 print(\"Warning: no vehicle legs (after time check) for person, vehicle, depTime\", person, vehicle, departureTime)\n",
    "        else:\n",
    "                no_legs.append(vehicle)\n",
    "#             print(\"Warning: no vehicle legs for person, vehicle, depTime\", person, vehicle, departureTime)\n",
    "\n",
    "    PtoPTssList = [(veh, pathTraversalID, passenger, planIndex) for veh, vehicleLegs in\n",
    "                                vehicleToPT.items() for pathTraversalID, passengers in vehicleLegs.items() for\n",
    "                                (passenger, planIndex) in passengers if len(passengers) > 0]\n",
    "    PtoPTss = pd.MultiIndex.from_tuples(PtoPTssList,\n",
    "                                                     name=['vehicleID', 'pathTraversalID', 'personID',\n",
    "                                                           'planIndex']).to_frame()\n",
    "    modes_PtoPTss = []\n",
    "    lengths_PtoPTss = []\n",
    "    durations_PtoPTss = []\n",
    "    prim_fuel_type_PtoPTss = []\n",
    "    prim_fuel_PtoPTss = []\n",
    "    sec_fuel_PtoPTss = []\n",
    "    \n",
    "    if is_GEO:\n",
    "        blocks_start = []\n",
    "        blocks_end = []\n",
    "    if is_LT:\n",
    "        links_PtoPTss = []\n",
    "        depTime_PtoPTss = []\n",
    "        arrTime_PtoPTss = []\n",
    "        # print('len PtoPTss before remove nan in links', len(PtoPTss))\n",
    "        # PtoPTss.dropna(subset=['links'])\n",
    "        # print('len PtoPTss after remove nan in links', len(PtoPTss))\n",
    "    for pt_id in PtoPTss['pathTraversalID']:\n",
    "        modes_PtoPTss.append(PTs.at[pt_id,'mode'])\n",
    "        lengths_PtoPTss.append(PTs.at[pt_id,'length'])\n",
    "        durations_PtoPTss.append(PTs.at[pt_id,'duration'])\n",
    "        prim_fuel_type_PtoPTss.append(PTs.at[pt_id,'primaryFuelType'])\n",
    "        prim_fuel_PtoPTss.append(PTs.at[pt_id,'primaryFuel'])\n",
    "        sec_fuel_PtoPTss.append(PTs.at[pt_id,'secondaryFuel'])\n",
    "        if is_GEO:\n",
    "            blocks_start.append(PTs.at[pt_id,'startBlockGroup'])\n",
    "            blocks_end.append(PTs.at[pt_id,'endBlockGroup'])\n",
    "        if is_LT:\n",
    "            depTime_PtoPTss.append(PTs.at[pt_id,'departureTime'])\n",
    "            arrTime_PtoPTss.append(PTs.at[pt_id,'arrivalTime'])\n",
    "            links_PtoPTss.append(PTs.at[pt_id,'links'])\n",
    "\n",
    "    PtoPTss['mode'] = modes_PtoPTss\n",
    "    PtoPTss['length'] = lengths_PtoPTss\n",
    "    PtoPTss['duration'] = durations_PtoPTss\n",
    "    PtoPTss['primaryFuelType'] = prim_fuel_type_PtoPTss\n",
    "    PtoPTss['primaryFuel'] = prim_fuel_PtoPTss\n",
    "    PtoPTss['secondaryFuel'] = sec_fuel_PtoPTss\n",
    "    \n",
    "    if is_GEO:\n",
    "        PtoPTss['startBlockGroup'] = blocks_start\n",
    "        PtoPTss['endBlockGroup'] = blocks_end\n",
    "\n",
    "    if is_LT:\n",
    "        PtoPTss['links'] = links_PtoPTss\n",
    "        PtoPTss['arrivalTime'] = depTime_PtoPTss\n",
    "        PtoPTss['departureTime'] = arrTime_PtoPTss\n",
    "\n",
    "    vehicles_2 = []\n",
    "    for pt_id in PtoPTss['pathTraversalID']:\n",
    "        vehicles_2.append(PTs.at[pt_id,'vehicle'][:len_id_transit])\n",
    "    vehicles_2 = np.array(vehicles_2)\n",
    "    PtoPTss['vehicle2'] = vehicles_2\n",
    "    \n",
    "    modes,counts = np.unique(modes_PtoPTss, return_counts = True)\n",
    "    for mode, count in zip(modes, counts):\n",
    "        print('len PtoPTs after matching agents and vehicles',mode,count)\n",
    "        \n",
    "        \n",
    "    print('no legs found:', len(no_legs))\n",
    "    print('no legs found after time check:', len(no_legs_after_time_check))\n",
    "    print('no vehicle body found, probably because with zero duration (discarded by PT):', \n",
    "          len(list(filter(lambda k: 'body' in k, no_legs))))\n",
    "    print('no vehicle body found after time check, probably because with zero duration (discarded by PT):', \n",
    "          len(list(filter(lambda k: 'body' in k, no_legs_after_time_check))))\n",
    "\n",
    "    print('Tot created PtoPTs = ', len(PtoPTss))\n",
    "    PtoPTss.index = range(len(PtoPTss))\n",
    "    print('Total time:', time.time()-start)\n",
    "    return PtoPTss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b5fb350-422f-4711-98b6-dc70d7122849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def updateTransitMode(MC):\n",
    "    transit = MC['mode'] == 'walk_transit'\n",
    "    try:\n",
    "        railTrips = transit & MC['legModes'].str.contains(\"RAIL\")\n",
    "        ferryTrips = transit & ~railTrips & MC['legModes'].str.contains(\"FERRY\")\n",
    "        subwayTrips = transit & ~railTrips & ~ferryTrips & MC['legModes'].str.contains(\"SUBWAY\")\n",
    "        busTrips = transit & ~railTrips & ~ferryTrips & ~subwayTrips\n",
    "        MC.loc[subwayTrips, 'mode'] = \"subway\"\n",
    "        MC.loc[railTrips, 'mode'] = \"rail\"\n",
    "        MC.loc[ferryTrips, 'mode'] = \"ferry\"\n",
    "        MC.loc[busTrips, 'mode'] = \"bus\"\n",
    "    except:\n",
    "        print('Warning: probably no legModes')\n",
    "\n",
    "    MC['miles'] = MC['length'] / 1609.34\n",
    "    MC['distBin'] = [binnames.get(val, 'Other') for val in np.digitize(MC['miles'], distanceBinsMiles)]\n",
    "    return MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e70e50-9441-4f8a-bb95-b2b326794086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def processPlans(directory):\n",
    "    #fullPath = directory + 'plans.csv.gz'\n",
    "    print('processPlans...')\n",
    "    start = time.time()\n",
    "    trips = []\n",
    "    activities = []\n",
    "    personToTripDeparture = {}\n",
    "    print(directory)\n",
    "    df = pd.read_csv(directory, nrows = None)\n",
    "    # print(df.keys())\n",
    "    df = df[df['planSelected']==True]\n",
    "    # print(df[df['personId']==194])\n",
    "    df = addTimesToPlans(df)\n",
    "    legs = df.loc[(df['planElementType'].str.lower().str.contains('leg'))].dropna(how='all', axis=1)\n",
    "    legs = (legs[legs['legDepartureTime']>=0])\n",
    "    # print(legs.keys())\n",
    "    # print(legs)\n",
    "    try:\n",
    "        legsSub = legs[['personId', 'legDepartureTime',  'planElementIndex', 'legMode', 'originX', 'originY', 'destinationX', 'destinationY']]\n",
    "        is_leg_mode = True\n",
    "    except:\n",
    "        legsSub = legs[['personId', 'legDepartureTime',  'planElementIndex', 'originX', 'originY', 'destinationX', 'destinationY']]\n",
    "        is_leg_mode = False\n",
    "\n",
    "    for rowID, val in legsSub.iterrows():\n",
    "        personToTripDeparture.setdefault(val.personId, []).append(\n",
    "            {\"planID\": val.planElementIndex, \"departureTime\": val.legDepartureTime})\n",
    "    #TRIPS\n",
    "    trips.append(legsSub)\n",
    "    #ACTS\n",
    "    acts = df.loc[(df['planElementType'].str.lower().str.contains('activity'))].dropna(how='all', axis=1)\n",
    "    actsSub = acts[['personId', 'activityType', 'activityLocationX', 'activityLocationY', 'activityEndTime']]\n",
    "    activities.append(actsSub)\n",
    "    print('Total time:', time.time()-start)\n",
    "    return pd.concat(trips), pd.concat(activities), personToTripDeparture, is_leg_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "724571a8-9308-495f-bf2d-7ddffdfd600d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def addTimesToPlans(plans):\n",
    "    print('addTimesToPlans...')\n",
    "    start = time.time()\n",
    "    legInds = np.where(plans['planElementType'].str.lower() == \"leg\")[0]\n",
    "    plans.loc[:, 'legDepartureTime'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('legDepartureTime')] = plans['activityEndTime'].iloc[legInds - 1].copy()\n",
    "    plans.loc[:, 'originX'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('originX')] = plans['activityLocationX'].iloc[legInds - 1].copy()\n",
    "    plans.loc[:, 'originY'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('originY')] = plans['activityLocationY'].iloc[legInds - 1].copy()\n",
    "    plans.loc[:, 'destinationX'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('destinationX')] = plans['activityLocationX'].iloc[legInds + 1].copy()\n",
    "    plans.loc[:, 'destinationY'] = np.nan\n",
    "    plans.iloc[legInds, plans.columns.get_loc('destinationY')] = plans['activityLocationY'].iloc[legInds + 1].copy()\n",
    "    print('Total time:', time.time()-start)\n",
    "    return plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "869d0012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readEvents(directory):\n",
    "    #fullPath = directory + 'ITERS/it.0/0.events.csv.gz'\n",
    "    PTs = []\n",
    "    PEVs = []\n",
    "    PLVs = []\n",
    "    MCs = []\n",
    "    RPs = []\n",
    "    ASs = []\n",
    "\n",
    "    print('Reading ', directory)\n",
    "    for chunk in pd.read_csv(directory, chunksize=2500000, nrows = nrows):\n",
    "        if sum((chunk['type'] == 'PathTraversal')) > 0:\n",
    "            chunk['vehicle'] = chunk['vehicle'].astype(str)\n",
    "            \n",
    "            #PT\n",
    "            print(len(chunk.loc[(chunk['type'] == 'PathTraversal')]),': len chunk PT')\n",
    "            PT = chunk.loc[(chunk['type'] == 'PathTraversal') & (chunk['length'] > 0)].dropna(how='all', axis=1)\n",
    "            PT['links'] =  PT['links'].fillna('0')\n",
    "            PT['departureTime'] = PT['departureTime'].astype(int)\n",
    "            PT['arrivalTime'] = PT['arrivalTime'].astype(int)\n",
    "            PTs.append(PT[PTsColumns])\n",
    "            print(len(PT),': after filtering zero-length PT')\n",
    "            #PEV\n",
    "            print(len(chunk.loc[(chunk['type'] == 'PersonEntersVehicle')]),': len chunk PEV')\n",
    "#             PEV = chunk.loc[(chunk.type == \"PersonEntersVehicle\") & \n",
    "#                             ~(chunk['person'].apply(str).str.contains('Agent').fillna(False)) & \n",
    "#                             ~(chunk['vehicle'].str.contains('body').fillna(False)), :].dropna(how='all', axis=1)\n",
    "            PEV = chunk.loc[(chunk.type == \"PersonEntersVehicle\") &\n",
    "                            ~(chunk['person'].apply(str).str.contains('Agent').fillna(False))\n",
    "                            , :].dropna(how='all', axis=1)\n",
    "            print(len(PEV),': after filtering drivers')\n",
    "                                                                                                                    \n",
    "            if len(PEV)>0:\n",
    "                PEV['person'] = PEV['person'].astype(int)\n",
    "                PEV['time'] = PEV['time'].astype(int)\n",
    "                PEVs.append(PEV)\n",
    "\n",
    "            #PLV\n",
    "#             PLV = chunk.loc[(chunk.type == \"PersonLeavesVehicle\") & \n",
    "#                             ~(chunk['person'].apply(str).str.contains('Agent').fillna(False)) & \n",
    "#                             ~(chunk['vehicle'].str.contains('body').fillna(False)), :].dropna(how='all', axis=1)\n",
    "            print(len(chunk.loc[(chunk['type'] == 'PersonLeavesVehicle')]),': len chunk PLV')\n",
    "            PLV = chunk.loc[(chunk.type == \"PersonLeavesVehicle\") &\n",
    "                            ~(chunk['person'].apply(str).str.contains('Agent').fillna(False))\n",
    "                            , :].dropna(how='all', axis=1) \n",
    "            print(len(PLV),': after filtering drivers')\n",
    "            if len(PLV)>0:\n",
    "                PLV['person'] = PLV['person'].astype(int)\n",
    "                PLV['time'] = PLV['time'].astype(int)\n",
    "                PLVs.append(PLV)\n",
    "        if sum((chunk['type'] == 'ModeChoice')) > 0:\n",
    "            #MC\n",
    "            MC = chunk.loc[(chunk['type'] == 'ModeChoice') & (chunk['length'] > 0)].dropna(how='all', axis=1)\n",
    "            try:\n",
    "                MCs.append(MC[MCsColumns])\n",
    "            except:\n",
    "                MCs.append(MC[MCsColumns_no_leg_modes])\n",
    "                print('WARNING: probably no legModes')\n",
    "            \n",
    "        if sum((chunk['type'] == 'Replanning')) > 0:\n",
    "            #RP\n",
    "            RP = chunk.loc[(chunk['type'] == 'Replanning')].dropna(how='all', axis=1)\n",
    "            RPs.append(RP)\n",
    "            \n",
    "        if sum((chunk['type'] == 'actstart')) > 0:\n",
    "            #RP\n",
    "            AS = chunk.loc[(chunk['type'] == 'actstart')].dropna(how='all', axis=1)\n",
    "            ASs.append(AS)\n",
    "        \n",
    "        # print(chunk['type'].value_counts())\n",
    "    print(len(pd.concat(PEVs)),':len PEVs')\n",
    "    print(len(pd.concat(PLVs)),':len PLVs')\n",
    "    \n",
    "    \n",
    "    PEVs = pd.concat(PEVs)\n",
    "    PLVs = pd.concat(PLVs)\n",
    "    PTs = pd.concat(PTs)\n",
    "    MCs = pd.concat(MCs)\n",
    "    RPs = pd.concat(RPs)\n",
    "    ASs = pd.concat(ASs)\n",
    "\n",
    "    \n",
    "    print(len(PTs),':len PTs')\n",
    "    print(len(MCs),':len MCs')\n",
    "    print(len(RPs),':len RPs')\n",
    "    print(len(ASs),':len ASs')\n",
    "\n",
    "    \n",
    "    return MCs, PTs, PEVs, PLVs, RPs, ASs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5be67b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fixData(Mcs, PTs, PEVs, PLVs,len_id_transit):\n",
    "\n",
    "\n",
    "    PTs['duration'] = PTs['arrivalTime'] - PTs['departureTime']\n",
    "    PTs['gallonsGasoline'] = 0\n",
    "    PTs.loc[PTs['primaryFuelType'] == 'Gasoline',\n",
    "            'gallonsGasoline'] += PTs.loc[PTs['primaryFuelType'] == 'Gasoline', 'primaryFuel'] * 8.3141841e-9\n",
    "    PTs.loc[PTs['secondaryFuelType'] == 'Gasoline',\n",
    "            'gallonsGasoline'] += PTs.loc[PTs['secondaryFuelType'] == 'Gasoline', 'secondaryFuel'] * 8.3141841e-9\n",
    "    PTs['occupancy'] = PTs['numPassengers']\n",
    "    \n",
    "    PTs['isCAV'] = PTs['vehicleType'].str.contains('L5')\n",
    "    PTs['isRH'] = PTs['vehicle'].str.contains('rideHail')\n",
    "    PTs['isBS'] = PTs['vehicle'].str.contains('bay_wheels')\n",
    "    PTs['isRH_WC'] = PTs['vehicleType'].str.contains('RH_Car-wheelchair')\n",
    "    PTs['is_empty'] = PTs['numPassengers'] == 0\n",
    "    PTs['is_RHempty'] = PTs['isRH']*PTs['is_empty']\n",
    "    PTs['is_car_emer'] = PTs['vehicle'].str.contains('emergency')\n",
    "    \n",
    "    PTs.loc[PTs['mode'] == 'car', 'capacity'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'car_hov2', 'capacity'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'car_hov3', 'capacity'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'walk', 'capacity'] = 1\n",
    "    PTs.loc[PTs['mode'] == 'bike', 'capacity'] = 1\n",
    "    \n",
    "    PTs.loc[PTs['isRH'], 'mode'] += '_RideHail'\n",
    "    PTs.loc[PTs['isBS'], 'mode'] += '_Sharing'\n",
    "    PTs.loc[PTs['isRH_WC'], 'mode'] += '_WC'\n",
    "    PTs.loc[PTs['isCAV'], 'mode'] += '_CAV'\n",
    "    PTs.loc[PTs['is_RHempty'], 'mode'] += '_empty'\n",
    "    PTs.loc[PTs['is_car_emer'], 'mode'] += '_emer'\n",
    "    \n",
    "    PTs.loc[PTs['mode'] == 'car', 'occupancy'] = 1\n",
    "    PTs.loc[PTs['mode'] == 'car_emer', 'occupancy'] = 1\n",
    "    PTs.loc[PTs['mode'] == 'car_hov2', 'occupancy'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'car_hov3', 'occupancy'] += 1\n",
    "    PTs.loc[PTs['mode'] == 'car_hov3_emer', 'occupancy'] = 1\n",
    "    PTs.loc[PTs['mode'] == 'walk', 'occupancy'] = 1\n",
    "    PTs.loc[PTs['mode'] == 'bike', 'occupancy'] = 1\n",
    "\n",
    "    PTs['vehicleMiles'] = PTs['length'] / 1609.34\n",
    "    PTs['passengerMiles'] = (PTs['length'] * PTs['occupancy']) / 1609.34\n",
    "    PTs['totalEnergyInJoules'] = PTs['primaryFuel'] + PTs['secondaryFuel']\n",
    "    \n",
    "    for tm in transit_modes:\n",
    "        PTs['is'+tm] = PTs['mode'].str.contains(tm)\n",
    "    for tm in transit_modes:\n",
    "        PTs['is_'+tm+'_empty'] = PTs['is'+tm]*PTs['is_empty']\n",
    "    PTs['is_transit'] = 0\n",
    "    for tm in transit_modes:\n",
    "        PTs['is_transit']+=PTs['is'+tm]\n",
    "    for tm in transit_modes:\n",
    "        PTs.loc[PTs['is_'+tm+'_empty'], 'mode'] += '_empty'\n",
    "        PTs.drop(columns=['is'+tm])\n",
    "        PTs.drop(columns=['is_'+tm+'_empty'])\n",
    "        \n",
    "    PTs.drop(columns=['isCAV','is_empty','is_RHempty','isRH_WC','is_car_emer'])\n",
    "    \n",
    "    vehicles_2 = []\n",
    "    vehicles = PTs['vehicle']\n",
    "    for vehicle in vehicles:\n",
    "        vehicles_2.append(vehicle[:len_id_transit])\n",
    "    vehicles_2 = np.array(vehicles_2)\n",
    "    PTs['vehicle2'] = vehicles_2\n",
    "    \n",
    "    vehicles_2 = []\n",
    "    vehicles = PEVs['vehicle']\n",
    "    for vehicle in vehicles:\n",
    "        vehicles_2.append(vehicle[:len_id_transit])\n",
    "    PEVs['vehicle2'] = vehicles_2\n",
    "    \n",
    "    vehicles_2 = []\n",
    "    vehicles = PLVs['vehicle']\n",
    "    for vehicle in vehicles:\n",
    "        vehicles_2.append(vehicle[:len_id_transit])\n",
    "    PLVs['vehicle2'] = vehicles_2\n",
    "    \n",
    "    \n",
    "    if is_LT:\n",
    "        links_PTs = []\n",
    "        for links in PTs['links']:\n",
    "            if ',' in str(links):\n",
    "                links_PTs.append(links.split(','))\n",
    "            else:\n",
    "                links_PTs.append(['0'])\n",
    "        PTs['links'] = links_PTs\n",
    "    \n",
    "    if is_GEO:\n",
    "        PTs = addGeometryIdToDataFrame(PTs, BGs, 'startX', 'startY', 'startBlockGroup', df_geom='epsg:4326')\n",
    "        PTs = addGeometryIdToDataFrame(PTs, BGs, 'endX', 'endY', 'endBlockGroup', df_geom='epsg:4326')\n",
    "    \n",
    "    return Mcs, PTs, PEVs, PLVs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba70cdc-5473-4716-a7c2-7aa88f3d3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLT_build(data_name,PtoPTss, network, link_taz):\n",
    "    print('PLT..')\n",
    "    link_map = {}\n",
    "    PLT = pd.DataFrame()\n",
    "    for link, length, fromx, tox, fromy, toy  in zip(network['linkId'],network['linkLength'],network['fromLocationX'],network['toLocationX'],\n",
    "                                network['fromLocationY'],network['toLocationY']):\n",
    "        link_map[link] = list([ int(length), fromx, tox, fromy, toy ])\n",
    "\n",
    "    #link ID, person ID, vehicle ID, Time (av depart and arrive), link length, block ID, \n",
    "    #other link attributes, energy consumption (weighted based on link and trip lengths)\n",
    "    # vehicleID\tpathTraversalID\tpersonID\tplanIndex\tmode\tlength\tduration\tprimaryFuelType\tlinks\tvehicle2\n",
    "    print('len PTtoPTs = ', len(PtoPTss))\n",
    "    len_links = 0\n",
    "    for links  in PtoPTss['links']:\n",
    "        if links != '0':\n",
    "            len_links+=len(links)\n",
    "    print('len linkstoP = ', len_links)\n",
    "    linkss = list(np.zeros((len_links)))\n",
    "    persons = list(np.zeros((len_links)))\n",
    "    modes = list(np.zeros((len_links)))\n",
    "    vehicles = list(np.zeros((len_links)))\n",
    "    estTimes = list(np.zeros((len_links)))\n",
    "    lengths = list(np.zeros((len_links)))\n",
    "    xs_center = list(np.zeros((len_links)))\n",
    "    ys_center = list(np.zeros((len_links)))\n",
    "    estEnergies = list(np.zeros((len_links)))\n",
    "    if is_GEO:\n",
    "        tazs = list(np.zeros((len_links)))\n",
    "    empty_links = 0\n",
    "    i = -1\n",
    "    for links, person, mode, arrTime, depTime, vehicle, primaryFuel, secondaryFuel, length  in zip(PtoPTss['links'],\n",
    "                               PtoPTss['personID'],PtoPTss['mode'],PtoPTss['arrivalTime'],PtoPTss['departureTime'],\n",
    "                               PtoPTss['vehicleID'],PtoPTss['primaryFuel'],PtoPTss['secondaryFuel'],PtoPTss['length']):\n",
    "        \n",
    "        \n",
    "        if links != '0':\n",
    "            for link in links:\n",
    "                i+=1\n",
    "                if i%1000000 == 0:\n",
    "                    print(i,'/',len_links)\n",
    "                try:\n",
    "                    row = link_map[int(link)]\n",
    "                    if is_GEO:\n",
    "                        tazs[i] = link_taz[int(link)]\n",
    "                    estEnergies[i] = row[0]/length*(primaryFuel+secondaryFuel)\n",
    "                    lengths[i] = row[0]\n",
    "                    xs_center[i] = np.mean([row[1],\n",
    "                                                    row[2]])\n",
    "                    ys_center[i] = np.mean([row[3],\n",
    "                                                row[4]])\n",
    "                except:\n",
    "                    print('Warning:',link)\n",
    "                    ys_center[i] = np.nan\n",
    "                    xs_center[i] = np.nan\n",
    "                    estEnergies[i] = np.nan\n",
    "                    if is_GEO:\n",
    "                        tazs[i] = np.nan\n",
    "                linkss[i] = link\n",
    "                persons[i] = person\n",
    "                modes[i] = mode\n",
    "                vehicles[i] = vehicle\n",
    "                estTimes[i] = np.mean([arrTime,depTime])\n",
    "\n",
    "        else:\n",
    "            empty_links += 1\n",
    "                \n",
    "    PLT['linkId']=linkss\n",
    "    PLT['personId']=persons\n",
    "    PLT['mode']=modes\n",
    "    PLT['vehicleID']=vehicles\n",
    "    PLT['estTime']=estTimes\n",
    "    PLT['estEnergies']=estEnergies\n",
    "    PLT['length']=lengths\n",
    "    PLT['X_center']=xs_center\n",
    "    PLT['Y_center']=ys_center\n",
    "    if is_GEO:\n",
    "        PLT['BlockGroup']=tazs\n",
    "\n",
    "    print( 'PtoPTs without link IDs:',   empty_links,'/', len(PtoPTss))\n",
    "\n",
    "    print('len PLT = ', len(PLT))\n",
    "\n",
    "    #link ID, vehicle ID,..\n",
    "    # 'vehicle', 'time', 'type', 'mode', 'length', 'vehicleType',\n",
    "    #    'arrivalTime', 'departureTime', 'capacity', 'secondaryFuel',\n",
    "    #    'primaryFuelType', 'secondaryFuelType', 'numPassengers', 'primaryFuel',\n",
    "    #    'links', 'duration', 'gallonsGasoline', 'occupancy', 'isCAV', 'isRH',\n",
    "    #    'isRH_WC', 'is_empty', 'is_RHempty', 'is_car_emer', 'isbus', 'issubway',\n",
    "    #    'istram', 'israil', 'iscable_car', 'isferry', 'is_bus_empty',\n",
    "    #    'is_subway_empty', 'is_tram_empty', 'is_rail_empty',\n",
    "    #    'is_cable_car_empty', 'is_ferry_empty', 'is_transit', 'vehicle2'\n",
    "    # for links in zip(PTs['links'],PTs['vehicle'],PTs['links'],PTs['links'],PTs['links'],PTs['links'],):\n",
    "    #     if links != '0':\n",
    "    #         for link in links:\n",
    "    #             pass\n",
    "    #Aggregate: for each link guess VMT, PMT, Energy, Mode split and vehicle type split, speed\n",
    "\n",
    "    # Aggregate per TAZ\n",
    "\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "\n",
    "    return PLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "485668ff-a59c-4b76-ab98-9f5862d8e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addGeometryIdToDataFrame(df, gdf, xcol, ycol, idColumn=\"geometry\", df_geom='epsg:32610'): \n",
    "    gdf.crs = {'init': 'epsg:4326'}\n",
    "    gdf_data = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[xcol], df[ycol]))\n",
    "    gdf_data.crs = {'init': df_geom}\n",
    "    joined = gpd.sjoin(gdf_data.to_crs('epsg:26910'), gdf.to_crs('epsg:26910'))\n",
    "    gdf_data = gdf_data.merge(joined['blkgrpid'], left_index=True, right_index=True, how=\"left\")\n",
    "    gdf_data.rename(columns={'blkgrpid': idColumn}, inplace=True)\n",
    "    df = pd.DataFrame(gdf_data.drop(columns='geometry'))\n",
    "    # df.drop(columns=[xcol, ycol], inplace=True)\n",
    "    print(len(df))\n",
    "    print(len(df.loc[~df.index.duplicated(keep='first'), :]))\n",
    "\n",
    "    return df.loc[~df.index.duplicated(keep='first'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bb8e6c8-7eb4-42e5-9396-9ea21c071eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_TAZ_fun(network, link_stat):\n",
    "    link_tazs = []\n",
    "    for link in link_stat['link']:    \n",
    "        link_tazs.append(list(network[network['linkId']==link]['BlockGroup'])[0])\n",
    "    link_stat['BlockGroup']   =  link_tazs                                           \n",
    "    return link_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e926a1-2934-4935-801b-a53841deb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_TAZ(network):\n",
    "    network_x = []\n",
    "    network_y = []\n",
    "    link_taz = {}\n",
    "    for link, linkfromx, linktox, linkfromy,linktoy in zip(network['linkId'],network['fromLocationX'],network['toLocationX'],\n",
    "                                network['fromLocationY'],network['toLocationY']):    \n",
    "        network_x.append(np.mean([linkfromx, linktox,]))\n",
    "        network_y.append(np.mean([linkfromy, linktoy,]))\n",
    "    network['X_center'] = network_x\n",
    "    network['Y_center'] = network_y\n",
    "    network = addGeometryIdToDataFrame(network, BGs, 'X_center', 'Y_center', 'BlockGroup')\n",
    "    for link, block in zip(network['linkId'],network['BlockGroup']):\n",
    "        link_taz[link] = block\n",
    "\n",
    "                                                           \n",
    "    return network, link_taz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6a3235e-5811-4a5a-b779-63ff6e7b3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VLT_build(data_name,PTs, network, link_taz):\n",
    "    print('VLT..')\n",
    "    link_map = {}\n",
    "    VLT = pd.DataFrame()\n",
    "    \n",
    "    for link, length, fromx, tox, fromy, toy  in zip(network['linkId'],network['linkLength'],network['fromLocationX'],network['toLocationX'],\n",
    "                                network['fromLocationY'],network['toLocationY']):\n",
    "        link_map[link] = list([int(length), fromx, tox, fromy, toy ])\n",
    "\n",
    "    print('len PTs = ', len(PTs))\n",
    "    len_links = 0\n",
    "    for links  in PTs['links']:\n",
    "        if links != '0':\n",
    "            len_links+=len(links)\n",
    "    print('len linkstoP = ', len_links)\n",
    "    linkss = list(np.zeros((len_links)))\n",
    "    modes = list(np.zeros((len_links)))\n",
    "    vehicles = list(np.zeros((len_links)))\n",
    "    estTimes = list(np.zeros((len_links)))\n",
    "    lengths = list(np.zeros((len_links)))\n",
    "    xs_center = list(np.zeros((len_links)))\n",
    "    ys_center = list(np.zeros((len_links)))\n",
    "    estEnergies = list(np.zeros((len_links)))\n",
    "    if is_GEO:\n",
    "        tazs = list(np.zeros((len_links)))\n",
    "    empty_links = 0\n",
    "    i = -1\n",
    "    for links, mode, arrTime, depTime, vehicle, primaryFuel, secondaryFuel, length in zip(PTs['links'],\n",
    "                                            PTs['mode'],\n",
    "                                  PTs['arrivalTime'],PTs['departureTime'],PTs['vehicle']\n",
    "                                                             ,PTs['primaryFuel'],PTs['secondaryFuel'],PTs['length'] ):\n",
    "        if links != '0':\n",
    "            for link in links:\n",
    "                i+=1\n",
    "                if i%1000000 == 0:\n",
    "                    print(i,'/',len_links)\n",
    "                try:\n",
    "                    row = link_map[int(link)]\n",
    "                    if is_GEO:\n",
    "                        tazs[i] = link_taz[int(link)]\n",
    "                    estEnergies[i] = row[0]/length*(primaryFuel+secondaryFuel)\n",
    "                    lengths[i] = row[0]\n",
    "                    xs_center[i] = np.mean([row[1],\n",
    "                                                    row[2]])\n",
    "                    ys_center[i] = np.mean([row[3],\n",
    "                                                row[4]])\n",
    "                except:\n",
    "                    print('Warning:',link)\n",
    "                    ys_center[i] = np.nan\n",
    "                    xs_center[i] = np.nan\n",
    "                    estEnergies[i] = np.nan\n",
    "                    if is_GEO:\n",
    "                        tazs[i] = np.nan\n",
    "                linkss[i] = link\n",
    "                modes[i] = mode\n",
    "                vehicles[i] = vehicle\n",
    "                estTimes[i] = np.mean([arrTime,depTime])\n",
    "\n",
    "\n",
    "        else:\n",
    "            empty_links += 1\n",
    "    VLT['linkId']=linkss\n",
    "    VLT['mode']=modes\n",
    "    VLT['vehicleID']=vehicles\n",
    "    VLT['estTime']=estTimes\n",
    "    VLT['estEnergies']=estEnergies\n",
    "    VLT['length']=lengths\n",
    "    VLT['X_center']=xs_center\n",
    "    VLT['Y_center']=ys_center\n",
    "    if is_GEO:\n",
    "        VLT['BlockGroup']=tazs\n",
    "\n",
    "    print( 'PTs without link IDs:',   empty_links,'/', len(PTs))\n",
    "    print('len VLT = ', len(VLT))\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "    return VLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6e3958d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3252292339.py, line 188)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 188\u001b[0;36m\u001b[0m\n\u001b[0;31m    fot prim, sec in zip(PTs['primaryFuelType'], PTs['secondaryFuelType']):\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def SummaryTable(ST, data_name, name, plan_name, MCs, PTs, PEVs, PLVs, RPs, trips, PtoPTss, codes, transitCompanies,is_leg_mode):\n",
    "    \n",
    "#----------Indexes\n",
    "    PTsModeIndexes = {}\n",
    "    PTsTransitIndexes = {}\n",
    "    PTsFuelIndexes = {}\n",
    "    MCsModeIndexes = {}\n",
    "    MCsReplanIndexes = {}\n",
    "    MCsPlanIndexes = {}\n",
    "    PtoPTssModeIndexes = {}\n",
    "    PtoPTssTransitIndexes = {}\n",
    "    PtoPTssFuelIndexes = {}\n",
    "    #Replanning\n",
    "    reasons = []\n",
    "    for reason in RPs['reason']:\n",
    "        reasons.append(reason.split()[1].lower())\n",
    "    RPs['mode'] = reasons\n",
    "    totalTrips_replan = len(RPs['mode'])\n",
    "    \n",
    "    for MCsMode, MCsModesName in zip(MCsModes, MCsModesNames):\n",
    "        MCsReplanIndexes[MCsMode] = RPs[(RPs['mode'] == MCsMode)].index\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        PTsModeIndexes[PTsMode] = PTs[(PTs['mode'] == PTsMode)].index\n",
    "        PtoPTssModeIndexes[PTsMode] = PtoPTss[(PtoPTss['mode'] == PTsMode)].index\n",
    "    for company in transitCompanies:\n",
    "        PTsTransitIndexes[company] = PTs[(PTs['vehicle2'] == company)].index\n",
    "        PtoPTssTransitIndexes[company] = PtoPTss[(PtoPTss['vehicle2'] == company)].index\n",
    "    for primaryFuelType in primaryFuelTypes:\n",
    "        PTsFuelIndexes[primaryFuelType] = PTs[(PTs['primaryFuelType'] == primaryFuelType)].index\n",
    "        PtoPTssFuelIndexes[primaryFuelType] = PtoPTss[(PtoPTss['primaryFuelType'] == primaryFuelType)].index\n",
    "    for MCsMode, MCsModesName in zip(MCsModes, MCsModesNames):\n",
    "        MCsModeIndexes[MCsMode] = MCs[(MCs['mode'] == MCsMode)].index\n",
    "    if is_leg_mode:\n",
    "        for MCsMode, MCsModesName in zip(MCsModes, MCsModesNames):\n",
    "            MCsPlanIndexes[MCsMode] = trips[(trips['legMode'] == MCsMode)].index\n",
    "\n",
    "    ST.at['Simulated Agents ', name] = len(pd.unique(trips['personId'])) \n",
    "    ST.at['Trips per Agent AV ', name] = len(trips)/len(pd.unique(trips['personId']))\n",
    "    \n",
    "#----------Number Trips\n",
    "#check plans for estimated mode share, trip per person\n",
    "    totalTrips_vehicle = len(PTs['mode'])\n",
    "    totalTrips_est = len(trips)\n",
    "    totalTrips_mode = len(MCs['mode'])\n",
    "    totalTrips_replan = len(RPs)\n",
    "    totalTrips_exec = totalTrips_mode-len(RPs)\n",
    "    \n",
    "    print('Number Trips...',name)\n",
    "    ST.at['Trip Vehicle Total ', name] = totalTrips_vehicle\n",
    "    ST.at['Trip Est Total ', name] = totalTrips_est\n",
    "    ST.at['Trip Mode Total ', name] = totalTrips_mode\n",
    "    ST.at['Trip Replanning Total ', name] = totalTrips_replan\n",
    "    ST.at['Trip Exectuted Total ', name] = totalTrips_exec\n",
    "\n",
    "    \n",
    "    \n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        ST.at['Trip Vehicle '+PTsModesName, name] = len(PTsModeIndexes[PTsMode])\n",
    "    if is_leg_mode:\n",
    "        for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "            ST.at['Trip Est '+MCsName, name] = len(MCsPlanIndexes[MCsMode])\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Mode '+MCsName, name] = len(MCsModeIndexes[MCsMode])\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Replan '+MCsName, name] = len(MCsReplanIndexes[MCsMode])\n",
    "    transit_exec = 0\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Exec '+MCsName, name] = len(MCsModeIndexes[MCsMode])-len(MCsReplanIndexes[MCsMode])\n",
    "        if MCsMode in transit_MCmodes:\n",
    "            transit_exec += len(MCsModeIndexes[MCsMode])-len(MCsReplanIndexes[MCsMode])\n",
    "    for primaryFuelType in primaryFuelTypes:\n",
    "        ST.at['Trip Vehicle '+primaryFuelType, name] = len(PTsFuelIndexes[primaryFuelType])\n",
    "    for company in transitCompanies:\n",
    "        ST.at['Trip Vehicle '+company, name] = len(PTsTransitIndexes[company])\n",
    "        \n",
    "#----------Share Trips\n",
    "    print('Share Trips...',name)\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        ST.at['Trip Vehicle Share '+PTsModesName, name] = len(PTsModeIndexes[PTsMode])/totalTrips_vehicle\n",
    "    for company in transitCompanies:\n",
    "        ST.at['Trip Vehicle Share '+company, name] = len(PTsTransitIndexes[company])/totalTrips_vehicle\n",
    "    if is_leg_mode:\n",
    "        for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "            ST.at['Trip Est Share '+MCsName, name] = len(MCsPlanIndexes[MCsMode])/totalTrips_est\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Mode Share '+MCsName, name] = len(MCsModeIndexes[MCsMode])/totalTrips_mode\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Replan Share '+MCsName, name] = len(MCsReplanIndexes[MCsMode])/totalTrips_replan\n",
    "    for MCsMode, MCsName in zip(MCsModes, MCsModesNames):\n",
    "        ST.at['Trip Exec Share '+MCsName, name] = (len(MCsModeIndexes[MCsMode])-len(MCsReplanIndexes[MCsMode]))/totalTrips_exec\n",
    "    for primaryFuelType in primaryFuelTypes:\n",
    "        ST.at['Trip Vehicle Share '+primaryFuelType, name] = len(PTsFuelIndexes[primaryFuelType])/totalTrips_vehicle\n",
    "\n",
    "\n",
    "\n",
    "#----------Trip Lengths\n",
    "    #----------------------Vehicles\n",
    "    print('Lengths Vehicles...',name)\n",
    "    lengths = PTs['length']/1000.\n",
    "    for code in codes:\n",
    "        ST.at['Length Vehicle '+CtV[code]+' [km]', name] = DA(lengths, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            lengths_mode = lengths[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Length Vehicle '+CtV[code]+' '+PTsModesName+' [km]', name] = DA(lengths_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            lengths_company = lengths[PTsTransitIndexes[company]]\n",
    "            ST.at['Length Vehicle '+CtV[code]+' '+company+' [km]', name] = DA(lengths_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            lengths_fueltype = lengths[PTsFuelIndexes[primaryFuelType]]\n",
    "            ST.at['Length Vehicle '+CtV[code]+' '+primaryFuelType+' [km]', name] = DA(lengths_fueltype, code)  \n",
    "    \n",
    "    #----------------------Persons\n",
    "    print('Lengths Persons...',name)\n",
    "    lengths = PtoPTss['length']/1000.\n",
    "    for code in codes:\n",
    "        ST.at['Length Person '+CtV[code]+' [km]', name] = DA(lengths, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            lengths_mode = lengths[PtoPTssModeIndexes[PTsMode]]\n",
    "            ST.at['Length Person '+CtV[code]+' '+PTsModesName+' [km]', name] = DA(lengths_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            lengths_company = lengths[PtoPTssTransitIndexes[company]]\n",
    "            ST.at['Length Person '+CtV[code]+' '+company+' [km]', name] = DA(lengths_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            lengths_fueltype = lengths[PtoPTssFuelIndexes[primaryFuelType]]\n",
    "            ST.at['Length Person '+CtV[code]+' '+primaryFuelType+' [km]', name] = DA(lengths_fueltype, code)  \n",
    "    \n",
    "    \n",
    "    #----------------------Modes\n",
    "    print('Lengths Modes...',name)\n",
    "    lengths = MCs['length']/1000.\n",
    "    for code in codes:\n",
    "        ST.at['Length Mode '+CtV[code]+'[km]', name] = DA(lengths, code)\n",
    "        for MCsMode, MCsModesName in zip(MCsModes, MCsModesNames):\n",
    "            lengths_mode = lengths[MCsModeIndexes[MCsMode]]\n",
    "            ST.at['Length Mode '+CtV[code]+' '+MCsModesName+' [km]', name] = DA(lengths_mode, code)\n",
    "   \n",
    "    lengths = PTs['length']/1000.\n",
    "    \n",
    " #----------Trip Durations\n",
    "    print('Durations Vehicle...',name)\n",
    "    durations = PTs['duration']/3600.\n",
    "    for code in codes:\n",
    "        ST.at['Duration Vehicle'+CtV[code]+' [h]', name] = DA(durations, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            durations_mode = durations[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Duration Vehicle '+CtV[code]+' '+PTsModesName+' [h]', name] = DA(durations_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            durations_company = durations[PTsTransitIndexes[company]]\n",
    "            ST.at['Duration Vehicle '+CtV[code]+' '+company+' [h]', name] = DA(durations_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            durations_fueltype = durations[PTsFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Duration Vehicle '+CtV[code]+' '+primaryFuelType+' [h]', name] = DA(durations_fueltype, code)   \n",
    "     \n",
    "    #----------Persons\n",
    "    print('Durations Person...',name)\n",
    "    durations = PtoPTss['duration']/3600.\n",
    "    for code in codes:\n",
    "        ST.at['Duration Person'+CtV[code]+' [h]', name] = DA(durations, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            durations_mode = durations[PtoPTssModeIndexes[PTsMode]]\n",
    "            ST.at['Duration Person '+CtV[code]+' '+PTsModesName+' [h]', name] = DA(durations_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            durations_company = durations[PtoPTssTransitIndexes[company]]\n",
    "            ST.at['Duration Person '+CtV[code]+' '+company+' [h]', name] = DA(durations_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            durations_fueltype = durations[PtoPTssFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Duration Person '+CtV[code]+' '+primaryFuelType+' [h]', name] = DA(durations_fueltype, code)   \n",
    "    \n",
    "    \n",
    "#----------Trip Speeds\n",
    "    print('Speeds Vehicle...',name)\n",
    "    speeds = lengths/durations[(durations>0)]\n",
    "    for code in codes:\n",
    "        ST.at['Speed Vehicle'+CtV[code]+' [km/h]', name] = DA(speeds, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            speeds_mode = speeds[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Speed Vehicle '+CtV[code]+' '+PTsModesName+' [km/h]', name] = DA(speeds_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            speeds_company = speeds[PTsTransitIndexes[company]]\n",
    "            ST.at['Speed Vehicle '+CtV[code]+' '+company+' [km/h]', name] = DA(speeds_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            speeds_fueltype = speeds[PTsFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Speed Vehicle '+CtV[code]+' '+primaryFuelType+' [km/h]', name] = DA(speeds_fueltype, code)   \n",
    "    \n",
    "#----------Energy Consumption\n",
    "    #----------Route-e correction\n",
    "    corrections_routee = []\n",
    "    fot prim, sec in zip(PTs['primaryFuelType'], PTs['secondaryFuelType']):\n",
    "        if prim in 'Electricity' and sec in ['Biodiesel','Diesel','Gasoline']:\n",
    "            corrections_routee.append(route_e_correction_hev)\n",
    "        elif prim in ['Biodiesel','Diesel','Gasoline']:\n",
    "            corrections_routee.append(route_e_correction_cv)\n",
    "        elif prim in ['Electricity']:\n",
    "            corrections_routee.append(route_e_correction_ev)\n",
    "        else:\n",
    "            corrections_routee.append(1)\n",
    "    PTs['routee correction'] = corrections_routee     \n",
    "    print(PTs['routee correction'].value_counts())\n",
    "\n",
    "    print('Energy Usage Vehicle...',name)\n",
    "    energies = (PTs['primaryFuel']/1000000000.+PTs['secondaryFuel']/1000000000.)*PTs['routee correction']\n",
    "    for code in codes:\n",
    "        ST.at['Energy Vehicle'+CtV[code]+' [GJ]', name] = DA(energies, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            energies_mode = energies[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Energy Vehicle '+CtV[code]+' '+PTsModesName+' [GJ]', name] = DA(energies_mode, code)\n",
    "        for company in transitCompanies:\n",
    "            energies_company = energies[PTsTransitIndexes[company]]\n",
    "            ST.at['Energy Vehicle '+CtV[code]+' '+company+' [GJ]', name] = DA(energies_company, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            energies_fueltype = energies[PTsFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Energy Vehicle '+CtV[code]+' '+primaryFuelType+' [GJ]', name] = DA(energies_fueltype, code)   \n",
    "\n",
    "#----------Trip Gallons\n",
    "    print('Trip Gallons Vehicle...',name)\n",
    "    gallons = PTs['gallonsGasoline']*PTs['routee correction']\n",
    "    for code in codes:\n",
    "        ST.at['Gallons Gas Vehicle'+CtV[code]+' [gallon]', name] = DA(gallons, code)\n",
    "        for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "            gallons_mode = gallons[PTsModeIndexes[PTsMode]]\n",
    "            ST.at['Gallons Gas Vehicle '+CtV[code]+' '+PTsModesName+' [gallon]', name] = DA(gallons_mode*beta_routee_cv, code)\n",
    "        for company in transitCompanies:\n",
    "            gallons_company = gallons[PTsTransitIndexes[company]]\n",
    "            ST.at['Gallons Gas Vehicle '+CtV[code]+' '+company+' [gallon]', name] = DA(gallons_company*beta_routee_cv, code)\n",
    "        for primaryFuelType in primaryFuelTypes:\n",
    "            gallons_fueltype = gallons[PTsFuelIndexes[primaryFuelType] ]\n",
    "            ST.at['Gallons Gas Vehicle '+CtV[code]+' '+primaryFuelType+' [gallon]', name] = DA(gallons_fueltype, code)   \n",
    "\n",
    "            \n",
    "#----------Occupancy\n",
    "    print('Occupancy Vehicle...',name)\n",
    "    passengers = PTs['occupancy']\n",
    "    capacities = PTs['capacity']\n",
    "\n",
    "    for company in transitCompanies:\n",
    "        passenger_company = passengers[PTsTransitIndexes[company]]\n",
    "        ST.at['Vehicle Passengers stops '+company, name] = np.sum(passenger_company)\n",
    "\n",
    "    for company in transitCompanies:\n",
    "        passenger_company = passengers[PTsTransitIndexes[company]]\n",
    "        lengths_company = lengths[PTsTransitIndexes[company]]\n",
    "        ST.at['Vehicle Passengers km '+company, name] = np.sum(passenger_company*lengths_company)\n",
    "\n",
    "    for company in transitCompanies:\n",
    "        lengths_company = lengths[PTsTransitIndexes[company]]\n",
    "        capacities_company = capacities[PTsTransitIndexes[company]]\n",
    "        ST.at['Vehicle Capacity km '+company, name] = np.sum(capacities_company*lengths_company)\n",
    "\n",
    "    for company in transitCompanies:\n",
    "        passenger_company = passengers[PTsTransitIndexes[company]]\n",
    "        lengths_company = lengths[PTsTransitIndexes[company]]\n",
    "        capacities_company = capacities[PTsTransitIndexes[company]]\n",
    "        if np.sum(capacities_company*lengths_company)>0:\n",
    "            ST.at['Vehicle Load Factor '+company, name] = np.sum(passenger_company*lengths_company)/np.sum(capacities_company*lengths_company)\n",
    "\n",
    "    ST.at['Vehicle Person km Total ', name] = np.sum(lengths*passengers)\n",
    "\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        if PTsMode != 'bike' and PTsMode != 'walk':\n",
    "            lengths_mode = lengths[PTsModeIndexes[PTsMode]]\n",
    "            passengers_mode = passengers[PTsModeIndexes[PTsMode]] \n",
    "            ST.at['Vehicle Person km '+PTsModesName, name] = np.sum(lengths_mode*passengers_mode)\n",
    "\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        if PTsMode != 'bike' and PTsMode != 'walk':\n",
    "            lengths_mode = lengths[PTsModeIndexes[PTsMode]]\n",
    "            capacities_mode = capacities[PTsModeIndexes[PTsMode]] \n",
    "            ST.at['Vehicle Capacity km '+PTsModesName, name] = np.sum(lengths_mode*capacities_mode)\n",
    "\n",
    "    for PTsMode, PTsModesName in zip(PTsModes, PTsModesNames):\n",
    "        if PTsMode != 'bike' and PTsMode != 'walk':\n",
    "            lengths_mode = lengths[PTsModeIndexes[PTsMode]]\n",
    "            passengers_mode = passengers[PTsModeIndexes[PTsMode]] \n",
    "            capacities_mode = capacities[PTsModeIndexes[PTsMode]] \n",
    "            if np.sum(lengths_mode*capacities_mode)>0:\n",
    "                ST.at['Vehicle Load Factor '+PTsModesName, name] = np.sum(lengths_mode*passengers_mode)/np.sum(lengths_mode*capacities_mode)\n",
    "\n",
    "#----------Ridership\n",
    "    print('Ridership Transit...',name)\n",
    "    total_rs = 0\n",
    "    for company in transitCompanies:\n",
    "        ridership_company = len(PEVs['vehicle'][(PEVs['vehicle2'] == company)])\n",
    "        ST.at['Ridership '+company, name] = ridership_company\n",
    "        total_rs += ridership_company\n",
    "    for company in transitCompanies:\n",
    "        ridership_company = len(PEVs['vehicle'][(PEVs['vehicle2'] == company)])\n",
    "        ST.at['Ridership '+company+' Share', name] = ridership_company/total_rs\n",
    "\n",
    "################################################################################################\n",
    "# ################################################EXTRA FOR NYC################################################\n",
    "    if is_NYC:\n",
    "        PEVs_NJ = PEVs[(PEVs['vehicle2'] == 'NJ_Transit')]\n",
    "        NJ_ridership_bus = 0\n",
    "        NJ_ridership_rail = 0\n",
    "        NJ_ridership_lrail = 0\n",
    "        GTFS_NJ_RAIL_trips = pd.read_csv('GTFS/trips.txt')\n",
    "        for NJ_vehicle in PEVs_NJ['vehicle']:\n",
    "            if NJ_vehicle[:12] == 'NJ_Transit_B':\n",
    "                NJ_ridership_bus += 1\n",
    "            elif NJ_vehicle[:12] == 'NJ_Transit_R':\n",
    "                trip_id = NJ_vehicle.split(':')[1]\n",
    "                route_id = list(GTFS_NJ_RAIL_trips['route_id'][GTFS_NJ_RAIL_trips['trip_id'].astype(str)==trip_id])[0]\n",
    "                if route_id in [4,12,16]:\n",
    "                    NJ_ridership_lrail += 1\n",
    "                else:\n",
    "                    NJ_ridership_rail +=1\n",
    "\n",
    "        ST.at['Ridership NJ Transit Bus', name] = NJ_ridership_bus\n",
    "        ST.at['Ridership NJ Transit Rail', name] = NJ_ridership_rail\n",
    "        ST.at['Ridership NJ Transit Light Rail', name] = NJ_ridership_lrail\n",
    "        ST.at['Ridership NJ Transit Bus Share', name] = NJ_ridership_bus/total_rs\n",
    "        ST.at['Ridership NJ Transit Rail Share', name] = NJ_ridership_rail/total_rs\n",
    "        ST.at['Ridership NJ Transit Light Rail Share', name] = NJ_ridership_lrail/total_rs\n",
    "        \n",
    "    #Check ridership Subway\n",
    "\n",
    "        agencies = []\n",
    "        for vehicle in PtoPTss['vehicleID']:\n",
    "            agencies.append(vehicle[:20])\n",
    "        PtoPTss['agency'] = agencies\n",
    "\n",
    "        grouping = PtoPTss.groupby(['personID','planIndex']).apply(lambda x: [y[0] for y in groupby(x.agency)]).to_dict()\n",
    "\n",
    "        combinations = []\n",
    "        i = 0\n",
    "        for key in grouping.keys():\n",
    "            i+=1\n",
    "            combinations.append(grouping[key])\n",
    "\n",
    "        ridership_Subway = 0\n",
    "        ridership_LIRR = 0\n",
    "        ridership_MN = 0\n",
    "        for comb in combinations:\n",
    "            for c in comb:\n",
    "                if c[:10] =='NYC_Subway':\n",
    "                    ridership_Subway += 1\n",
    "                if c[:10] =='Long_Islan':\n",
    "                    ridership_LIRR += 1\n",
    "                if c[:10] =='Metro-Nort':\n",
    "                    ridership_MN += 1\n",
    "    \n",
    "        ST.at['Ridership NYC Subway Without Transfers', name] = ridership_Subway\n",
    "        ST.at['Ridership LIRR Without Transfers', name] = ridership_LIRR\n",
    "        ST.at['Ridership Metro North Without Transfers', name] = ridership_MN\n",
    "\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "\n",
    "    ST.at['Ridership Total', name] = total_rs\n",
    "    ST.at['Transit Transfer per trip AV', name] = total_rs/transit_exec-1.\n",
    "#----------RH\n",
    "\n",
    "\n",
    "    start_RH = time.time()\n",
    "    print('Ride hail...',name)\n",
    "    \n",
    "    try:\n",
    "        rh_waittime = pd.read_csv(fp+data_name[:-13]+'rideHailIndividualWaitingTimes.csv')\n",
    "        ST.at['Number RH vehicles', name] = len(np.unique(list(rh_waittime['rideHailVehicleId'])))\n",
    "        ST.at['AV Waiting Time RH', name] = np.mean(list(rh_waittime['waitingTimeInSeconds']))\n",
    "        ST.at['AV Waiting Time RH Pooled', name] = np.mean(list(rh_waittime[rh_waittime['modeChoice']=='ride_hail_pooled']['waitingTimeInSeconds']))\n",
    "        ST.at['AV Waiting Time RH Single', name]  = np.mean(list(rh_waittime[rh_waittime['modeChoice']=='ride_hail']['waitingTimeInSeconds']))    \n",
    "    except:\n",
    "        print('WARNING: probably not modeChoice column on pd.read_csv(fp+data_name[:-13]+\\'rideHailIndividualWaitingTimes.csv\\'')\n",
    "    \n",
    "    PTsRH = PTs[PTs['isRH']]\n",
    "    ST.at['Empty Trips RH', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']==0])\n",
    "    ST.at['Not Empty Trips RH', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']>0])\n",
    "    if len(PTsRH['vehicle']) >0:\n",
    "        ST.at['Empty Trips RH Share', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']==0])/len(PTsRH['vehicle'])\n",
    "        ST.at['Not Empty Trips RH Share', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']>0])/len(PTsRH['vehicle'])\n",
    "    \n",
    "    for code in codes:\n",
    "        ST.at[CtV[code]+' Trips per RH Vehicle', name] = DA(PTsRH['vehicle'].value_counts(), code)\n",
    "        \n",
    "    rh_vehicles = pd.unique(PTsRH['vehicle'])\n",
    "    n_empty = []\n",
    "    n_notempty = []\n",
    "    first_trip = []\n",
    "    last_trip = []\n",
    "    for rh_vehicle in rh_vehicles:\n",
    "        PTs_rh_vehicle = PTsRH[PTsRH['vehicle']==rh_vehicle]\n",
    "        n_empty.append(len(PTs_rh_vehicle['vehicle'][PTs_rh_vehicle['numPassengers']==0]))\n",
    "        n_notempty.append(len(PTs_rh_vehicle['vehicle'][PTs_rh_vehicle['numPassengers']>0]))\n",
    "        PTs_rh_vehicle = PTs_rh_vehicle.sort_values(by='time', ascending=True)\n",
    "        first_trip.append(list(PTs_rh_vehicle['numPassengers'])[0])\n",
    "        last_trip.append(list(PTs_rh_vehicle['numPassengers'])[-1])\n",
    "        \n",
    "    share_empty = np.array(n_empty)-np.array(n_notempty)\n",
    "    for code in codes:\n",
    "        ST.at[CtV[code]+' RH Vehicle (Empty - not Empty) Trips', name] = DA(share_empty, code)\n",
    "    \n",
    "    if len(first_trip) >0:\n",
    "        ST.at['RH Empty Share Firts Trip', name] = np.count_nonzero(np.array(first_trip) == 0)/len(first_trip)\n",
    "        ST.at['RH Empty Share Last Trip', name] = np.count_nonzero(np.array(last_trip) == 0)/len(first_trip)\n",
    "        ST.at['RH not Empty Share Firts Trip', name] = np.count_nonzero(np.array(first_trip) == 1)/len(first_trip)\n",
    "        ST.at['RH not Empty Share Last Trip', name] = np.count_nonzero(np.array(last_trip) == 1)/len(first_trip)\n",
    "\n",
    "#----------RH - WC\n",
    "    if is_WC == True:\n",
    "        \n",
    "        start_RH = time.time()\n",
    "        print('Ride hail WC...',name)\n",
    "        \n",
    "        try:\n",
    "            rh_waittime_wc =rh_waittime[rh_waittime['rideHailVehicleId'].isin(list(wc_vehicles))]\n",
    "            ST.at['Number RH WC vehicles', name] = len(np.unique(list(rh_waittime_wc['rideHailVehicleId'])))\n",
    "            ST.at['AV Waiting Time RH WC', name] = np.mean(list(rh_waittime_wc['waitingTimeInSeconds']))\n",
    "            ST.at['AV Waiting Time RH WC Pooled', name] = np.mean(list(rh_waittime_wc[rh_waittime_wc['modeChoice']=='ride_hail_pooled']['waitingTimeInSeconds']))\n",
    "            ST.at['AV Waiting Time RH WC Single', name]  = np.mean(list(rh_waittime_wc[rh_waittime_wc['modeChoice']=='ride_hail']['waitingTimeInSeconds'])) \n",
    "        except:\n",
    "            print('WARNING: probably not modeChoice column on pd.read_csv(fp+data_name[:-13]+\\'rideHailIndividualWaitingTimes.csv\\'')\n",
    "\n",
    "        PTsRH = PTs[PTs['isRH_WC']]\n",
    "        ST.at['Empty Trips RH WC', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']==0])\n",
    "        ST.at['Not Empty Trips RH WC', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']>0])\n",
    "        if len(PTsRH['vehicle']) >0:\n",
    "            ST.at['Empty Trips RH WC Share', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']==0])/len(PTsRH['vehicle'])\n",
    "            ST.at['Not Empty Trips RH WC Share', name] = len(PTsRH['vehicle'][PTsRH['numPassengers']>0])/len(PTsRH['vehicle'])\n",
    "\n",
    "        for code in codes:\n",
    "            ST.at[CtV[code]+' Trips per RH WC Vehicle', name] = DA(PTsRH['vehicle'].value_counts(), code)\n",
    "\n",
    "        rh_vehicles = pd.unique(PTsRH['vehicle'])\n",
    "        n_empty = []\n",
    "        n_notempty = []\n",
    "        first_trip = []\n",
    "        last_trip = []\n",
    "        wc_vehicles = []\n",
    "        for rh_vehicle in rh_vehicles:\n",
    "            PTs_rh_vehicle = PTsRH[PTsRH['vehicle']==rh_vehicle]\n",
    "            n_empty.append(len(PTs_rh_vehicle['vehicle'][PTs_rh_vehicle['numPassengers']==0]))\n",
    "            n_notempty.append(len(PTs_rh_vehicle['vehicle'][PTs_rh_vehicle['numPassengers']>0]))\n",
    "            PTs_rh_vehicle = PTs_rh_vehicle.sort_values(by='time', ascending=True)\n",
    "            first_trip.append(list(PTs_rh_vehicle['numPassengers'])[0])\n",
    "            last_trip.append(list(PTs_rh_vehicle['numPassengers'])[-1])\n",
    "            wc_vehicles.append(rh_vehicle)\n",
    "            \n",
    "        wc_vehicles = np.unique(wc_vehicles)\n",
    "\n",
    "        share_empty = np.array(n_empty)-np.array(n_notempty)\n",
    "        for code in codes:\n",
    "            ST.at[CtV[code]+' RH WC Vehicle (Empty - not Empty) Trips', name] = DA(share_empty, code)\n",
    "\n",
    "        if len(first_trip) >0:\n",
    "            ST.at['RH WC Empty Share Firts Trip', name] = np.count_nonzero(np.array(first_trip) == 0)/len(first_trip)\n",
    "            ST.at['RH WC Empty Share Last Trip', name] = np.count_nonzero(np.array(last_trip) == 0)/len(first_trip)\n",
    "            ST.at['RH WC not Empty Share Firts Trip', name] = np.count_nonzero(np.array(first_trip) == 1)/len(first_trip)\n",
    "            ST.at['RH WC not Empty Share Last Trip', name] = np.count_nonzero(np.array(last_trip) == 1)/len(first_trip)\n",
    "\n",
    "# #----------RH - Multi Agency\n",
    "    \n",
    "#     PTsRH['vehicle']\n",
    "#     RH_agencies = np.unique(PTsRH)\n",
    "\n",
    "            \n",
    "            \n",
    "    #Mode share per distance ranges\n",
    "    MCs = updateTransitMode(MCs)\n",
    "    gb = MCs[['mode','person', 'distBin']].groupby(['mode', 'distBin']).agg('size').unstack().fillna(0.0)\n",
    "    tot = gb.sum(axis=0)\n",
    "    gb = gb / gb.sum(axis=0)\n",
    "    gb.loc['total',:] = tot/tot.sum()\n",
    "    for mode in gb.index:\n",
    "        for key in gb.keys():\n",
    "            ST.at['Share Mode '+mode+' Miles '+key, name] = gb.at[mode,key]\n",
    "    \n",
    "    tripsPerPerson = (ASs[['person','actType']].groupby('actType').agg('size') / len(ASs['person'].value_counts())).to_dict()\n",
    "\n",
    "    for act in tripsPerPerson.keys():\n",
    "        ST.at['Activities AV per person '+act, name] = tripsPerPerson[act]\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "    return ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7aaaef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ST = pd.DataFrame()\n",
    "\n",
    "\n",
    "for data_name, name, plan_name, i in zip(data_names, names, plan_names, range(len(data_names))):\n",
    "    \n",
    "    MCs = []\n",
    "    PTs = []\n",
    "    PEVs = []\n",
    "    PLVs = []\n",
    "    PtoPTss = []\n",
    "    LT = False\n",
    "    PLT = False\n",
    "    VLT = False\n",
    "    MCs, PTs, PEVs, PLVs, RPs, ASs = readEvents(fp+data_name)\n",
    "    MCs, PTs, PEVs, PLVs = fixData(MCs, PTs, PEVs, PLVs, len_id_transit)\n",
    "    trips, activities, personToTripDepartures, is_leg_mode = processPlans(fp+plan_name)\n",
    "    PtoPTss = personToPathTraversal(PTs,PEVs,PLVs,personToTripDepartures)\n",
    "    \n",
    "    if is_filter_by_region:\n",
    "        MCs, PTs, PEVs, PLVs, RPs, trips, PtoPTss = filter_by_region(region_filter, MCs, PTs, PEVs, PLVs, RPs, trips, PtoPTss,)\n",
    "    \n",
    "    # if is_save_PTs_PtoPTs:\n",
    "    #     PTs.to_csv(fp_res+'PTs_'+name+'.csv')\n",
    "    #     PtoPTss.to_csv(fp_res+'PtoPTss_'+name+'.csv')\n",
    "    \n",
    "    codes = [0,1,2,3,4,5,6,7,8] \n",
    "    transitCompanies = PTs['vehicle2'][PTs['is_transit']>0].value_counts().keys()\n",
    "    \n",
    "    ST = SummaryTable(ST, data_name, name, plan_name, MCs, PTs, PEVs, PLVs, RPs, trips, PtoPTss, codes, transitCompanies, is_leg_mode)\n",
    "    \n",
    "    if is_LT:\n",
    "        # link_fp = fp+data_name[:-13]+'linkstats.csv.gz'\n",
    "        # VLT, PLT = LinkTable(VLT, PLT, name, link_fp, PTs, PtoPTss)\n",
    "        network = pd.read_csv(fp+data_name[:-(len(data_name.split('/')[-1])+len(data_name.split('/')[-2])+len(data_name.split('/')[-3])+2)]+'network.csv.gz')\n",
    "        if is_GEO:\n",
    "            network, link_taz = network_TAZ(network)\n",
    "        else:\n",
    "            link_taz = ''\n",
    "        LT = pd.read_csv(fp+data_name[:-13]+'linkstats.csv.gz')\n",
    "        if is_GEO:\n",
    "            LT = link_TAZ_fun(network, LT)\n",
    "        PLT = PLT_build(data_name,PtoPTss, network, link_taz)\n",
    "        VLT = VLT_build(data_name,PTs, network, link_taz)\n",
    "        # VLT.to_csv(fp_res+'VLT_'+name+'.csv')\n",
    "        # PLT.to_csv(fp_res+'PLT_'+name+'.csv')\n",
    "        # LT.to_csv(fp_res+'LT_'+name+'.csv')\n",
    "\n",
    "    print('Total Time', time.time()-start)\n",
    "    start = time.time()\n",
    "    print(ST[-6:],'Number of attributes',len(ST))\n",
    "    ST.to_csv(fp_res+output_nm)\n",
    "\n",
    "    if is_collect_data:\n",
    "        collectAllData(fp+data_name[:-(len(data_name.split('/')[-1])+len(data_name.split('/')[-2])+len(data_name.split('/')[-3])+len(data_name.split('/')[-4])+len(data_name.split('/')[-5])+4)],\n",
    "                  data_name.split('/')[-4],trips, activities, PTs, PtoPTss, LT, PLT, VLT, ST, name)\n",
    "        \n",
    "ST['code'] = range(len(ST[ST.keys()[0]]))\n",
    "print(ST[-6:],'Number of attributes',len(ST))\n",
    "ST.to_csv(fp_res+output_nm)\n",
    "\n",
    "end = time.time()\n",
    "print('Total time',end- start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bb2e4-93c4-4aaf-9517-c290020515cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Validation NYC\n",
    "\n",
    "ST2 = pd.DataFrame()\n",
    "ST = pd.read_csv('outputs/SummaryTable_NYC_baseline16.csv', index_col='Unnamed: 0')\n",
    "\n",
    "# subway_notransfs = [ \n",
    "            # 2922226,#1/3 part 1\n",
    "            # 345063,#7\n",
    "            # 241275,#11\n",
    "            # 251684,#12\n",
    "            # 270082,#13\n",
    "            # 223795,#15\n",
    "            # 196499,#16\n",
    "            # 167302,#17\n",
    "            # 255169,#18\n",
    "            # 239665,#19\n",
    "            # 231035,#20\n",
    "            # 516343,#0/10\n",
    "            # 514203,#3/10\n",
    "            # 518130,#4/10\n",
    "            # 515515,#5/10\n",
    "            # 518068,#6/10\n",
    "            # 511123,#7/10\n",
    "            # 517393,#8/10\n",
    "            # 517393,517393,517393\n",
    "                    # ]\n",
    "\n",
    "for name, share_pop in zip(names,shares_pop):\n",
    "    \n",
    "    ST2.at['Original Population share', name] = share_pop\n",
    "    \n",
    "    ST2.at['Scaled Total Simulated Agents', name] = ST.at['Simulated Agents ', name]/share_pop\n",
    "    \n",
    "\n",
    "    ST2.at['Total Trips Estimated per Agent in a Day', name] = ST.at['Trips per Agent AV ', name]\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Total Trips Estimated in a Day', name] = ST.at['Trips per Agent AV ', name]*ST.at['Simulated Agents ', name]/share_pop\n",
    "\n",
    "    if is_leg_mode:\n",
    "\n",
    "        ST2.at['Scaled Total Estimated Walk-Transit Trips in a Day', name] = ST.at['Trip Est Walk-Transit', name]/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Total Replanned Walk-Transit Trips in a Day', name] = ST.at['Trip Replan Walk-Transit', name]/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Total Executed Walk-Transit Trips in a Day', name] = ST.at['Trip Exec Walk-Transit', name]/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Total Modechoice Walk-Transit Trips in a Day', name] = ST.at['Trip Mode Walk-Transit', name]/share_pop\n",
    "\n",
    "    if is_leg_mode:\n",
    "\n",
    "        ST2.at['Share Estimated Walk-Transit Trips in a Day', name] = ST.at['Trip Est Share Walk-Transit', name]\n",
    "\n",
    "\n",
    "    ST2.at['Share Replanned Walk-Transit Trips in a Day', name] = ST.at['Trip Replan Share Walk-Transit', name]\n",
    "\n",
    "\n",
    "    ST2.at['Share Executed Walk-Transit Trips in a Day', name] = ST.at['Trip Exec Share Walk-Transit', name]\n",
    "    ST2.at['Share Executed Bike-Transit Trips in a Day', name] = ST.at['Trip Exec Share Bike-Transit', name]\n",
    "    ST2.at['Share Executed Ride Hail-Transit Trips in a Day', name] = ST.at['Trip Exec Share Ride Hail-Transit', name]\n",
    "    ST2.at['Share Executed Drive-Transit Trips in a Day', name] = ST.at['Trip Exec Share Drive-Transit', name]\n",
    "    ST2.at['Share Executed Transit Related Trips in a Day', name] = (ST.at['Trip Exec Share Walk-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Bike-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Ride Hail-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Drive-Transit', name])\n",
    "    ST2.at['Share Executed Bike Trips in a Day', name] = ST.at['Trip Exec Share Bike', name]\n",
    "    ST2.at['Share Executed Car Trips in a Day', name] = ST.at['Trip Exec Share Car', name]\n",
    "    ST2.at['Share Executed Ride Hail Trips in a Day', name] = (ST.at['Trip Exec Share Ride Hail', name] +\n",
    "                                                            ST.at['Trip Exec Share Ride Hail Pooled', name])\n",
    "    ST2.at['Share Executed Walk Trips in a Day', name] = ST.at['Trip Exec Share Walk', name]\n",
    "    ST2.at['Share Executed Other Trips in a Day', name] = 1-(ST.at['Trip Exec Share Walk-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Bike-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Ride Hail-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Drive-Transit', name] +\n",
    "                                                                    ST.at['Trip Exec Share Bike', name] +\n",
    "                                                                    ST.at['Trip Exec Share Car', name] +\n",
    "                                                                    ST.at['Trip Exec Share Ride Hail', name] +\n",
    "                                                                    ST.at['Trip Exec Share Ride Hail Pooled', name] +\n",
    "                                                                    ST.at['Trip Exec Share Walk', name])\n",
    "\n",
    "\n",
    "    ST2.at['Share Executed Walk-Transit Trips in a Day', name] = ST.at['Trip Exec Share Walk-Transit', name]\n",
    "\n",
    "\n",
    "    ST2.at['AV Transit Transfers per trip', name] = ST.at['Transit Transfer per trip AV', name]\n",
    "\n",
    "\n",
    "    ST2.at['Scaled MTA BUS Ridership (with transfers)', name] = (ST.at['Ridership MTA_Brookl', name]+\n",
    "                                                             ST.at['Ridership MTA_Bronx_', name]+\n",
    "                                                             ST.at['Ridership MTA_Queens', name]+\n",
    "                                                             ST.at['Ridership MTA_Staten', name]+\n",
    "                                                             ST.at['Ridership MTA_Manhat', name]+\n",
    "                                                             ST.at['Ridership NYC_Bus_Co', name])/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled MTA SUB Ridership (with transfers)', name] = ST.at['Ridership NYC_Subway', name]/share_pop\n",
    "    \n",
    "    ST2.at['Scaled MTA SUB Ridership (without transfers)', name] = ST.at['Ridership NYC Subway Without Transfers', name]/share_pop\n",
    "    \n",
    "    ST2.at['Subway vs Bus', name] = ST2.at['Scaled MTA SUB Ridership (without transfers)', name]/ST2.at['Scaled MTA BUS Ridership (with transfers)', name]\n",
    "\n",
    "\n",
    "    ST2.at['Scaled Metro North Ridership (with transfers)', name] = ST.at['Ridership Metro-Nort', name]/share_pop\n",
    "    ST2.at['Scaled Metro North Ridership (without transfers)', name] = ST.at['Ridership Metro North Without Transfers', name]/share_pop\n",
    "\n",
    "\n",
    "    ST2.at['Scaled LIRR Ridership (with transfers)', name] = ST.at['Ridership Long_Islan', name]/share_pop\n",
    "    ST2.at['Scaled LIRR Ridership (without transfers)', name] = ST.at['Ridership LIRR Without Transfers', name]/share_pop\n",
    "    \n",
    "    try:\n",
    "        if ST.at['Ridership 151_631:t_', name] > 0:\n",
    "            ST2.at['Scaled PATH Ridership (with transfers)', name] = ST.at['Ridership 151_631:t_', name]/share_pop\n",
    "    except:      \n",
    "        ST2.at['Scaled PATH Ridership (with transfers)', name] = ST.at['Ridership path-nj-us', name]/share_pop\n",
    "\n",
    "    ST2.at['Scaled NJ BUS Ridership (with transfers)', name] = ST.at['Ridership NJ Transit Bus', name]/share_pop\n",
    "    ST2.at['Scaled NJ RAIL Ridership (with transfers)', name] = ST.at['Ridership NJ Transit Rail', name]/share_pop\n",
    "    ST2.at['Scaled NJ LIGHT RAIL Ridership (with transfers)', name] = ST.at['Ridership NJ Transit Light Rail', name]/share_pop\n",
    "    \n",
    "    for bin in range(len(binnames)):\n",
    "        bin = binnames[bin+1]\n",
    "        ST2.at['Share Mode Bike Miles '+bin, name] =  ST.at['Share Mode bike Miles '+bin, name]#+ST.at['Share Mode bike_transit Miles '+bin, name]\n",
    "        ST2.at['Share Mode Car Miles '+bin, name] =  ST.at['Share Mode car Miles '+bin, name]#+ST.at['Share Mode drive_transit Miles '+bin, name]\n",
    "        multimodal_shares = (ST.at['Share Mode bike_transit Miles '+bin, name]+\n",
    "                             ST.at['Share Mode drive_transit Miles '+bin, name]+\n",
    "                            ST.at['Share Mode ride_hail_transit Miles '+bin, name])\n",
    "        tot_transit = (ST.at['Share Mode bus Miles '+bin, name]+\n",
    "            ST.at['Share Mode ferry Miles '+bin, name]+\n",
    "            ST.at['Share Mode rail Miles '+bin, name]+\n",
    "            ST.at['Share Mode subway Miles '+bin, name]\n",
    "                    )\n",
    "        share_bus=ST.at['Share Mode bus Miles '+bin, name]/tot_transit\n",
    "        share_fer=ST.at['Share Mode ferry Miles '+bin, name]/tot_transit\n",
    "        share_rai=ST.at['Share Mode rail Miles '+bin, name]/tot_transit\n",
    "        share_sub=ST.at['Share Mode subway Miles '+bin, name]/tot_transit\n",
    "        ST2.at['Share Mode Bus Miles '+bin, name] =  ST.at['Share Mode bus Miles '+bin, name]+multimodal_shares*share_bus\n",
    "        ST2.at['Share Mode Ferry Miles '+bin, name] =  ST.at['Share Mode ferry Miles '+bin, name]+multimodal_shares*share_fer\n",
    "        ST2.at['Share Mode Rail Miles '+bin, name] =  ST.at['Share Mode rail Miles '+bin, name]+multimodal_shares*share_rai\n",
    "        ST2.at['Share Mode Subway Miles '+bin, name] =  ST.at['Share Mode subway Miles '+bin, name]+multimodal_shares*share_sub\n",
    "\n",
    "        try:\n",
    "            # st_rh = ST.at['Share Mode ride_hail Miles '+bin, name]\n",
    "            ST2.at['Share Mode Ridehail Miles '+bin, name] =  ST.at['Share Mode ride_hail Miles '+bin, name]#+ST.at['Share Mode ride_hail_transit Miles '+bin, name]\n",
    "            try:\n",
    "                ST2.at['Share Mode Ridehail Miles '+bin, name] =  ST.at['Share Mode ride_hail Miles '+bin, name]+ST.at['Share Mode ride_hail_pooled Miles '+bin, name]\n",
    "            except:\n",
    "                print('Ridehail is present, but not ridehail pooled')\n",
    "        except:\n",
    "            ST2.at['Share Mode Ridehail Miles '+bin, name] = 0\n",
    "            print('Warning, ride hail not in the simulation')\n",
    "        ST2.at['Share Mode Walk Miles '+bin, name] =  ST.at['Share Mode walk Miles '+bin, name]\n",
    "        ST2.at['Share Mode Other Miles '+bin, name] =  1-(ST2.at['Share Mode Bike Miles '+bin, name]+\n",
    "                                                            ST2.at['Share Mode Bus Miles '+bin, name]+\n",
    "                                                            ST2.at['Share Mode Car Miles '+bin, name]+\n",
    "                                                            ST2.at['Share Mode Ferry Miles '+bin, name]+\n",
    "                                                            ST2.at['Share Mode Rail Miles '+bin, name]+\n",
    "                                                            ST2.at['Share Mode Ridehail Miles '+bin, name]+\n",
    "                                                            ST2.at['Share Mode Subway Miles '+bin, name] +\n",
    "                                                            ST2.at['Share Mode Walk Miles '+bin, name])\n",
    "    \n",
    "    ST2.at['Activities AV per person Home', name] = ST.at['Activities AV per person Home', name]\n",
    "    ST2.at['Activities AV per person Meal', name] = ST.at['Activities AV per person Meal', name]  \n",
    "    ST2.at['Activities AV per person Shopping', name] = ST.at['Activities AV per person Shopping', name]  \n",
    "    ST2.at['Activities AV per person SocRec', name] = ST.at['Activities AV per person SocRec', name]  \n",
    "    ST2.at['Activities AV per person Work', name] = ST.at['Activities AV per person Work', name] \n",
    "    ST2.at['Activities AV per person Other', name] = ST.at['Activities AV per person Other', name] \n",
    "    \n",
    "ST2.at['Share Executed Transit Related Trips in a Day', 'Target Baseline'] = 'NHTS is 16.6%'\n",
    "ST2.at['Share Executed Bike Trips in a Day', 'Target Baseline'] = 'NHTS is 1.0%'\n",
    "ST2.at['Share Executed Car Trips in a Day', 'Target Baseline'] = 'NHTS is 53.9%'\n",
    "ST2.at['Share Executed Walk Trips in a Day', 'Target Baseline'] = 'NHTS is 26.1%'\n",
    "ST2.at['Share Executed Ride Hail Trips in a Day', 'Target Baseline'] = 'NHTS is 1.8%'\n",
    "ST2.at['Share Executed Other Trips in a Day', 'Target Baseline'] = 'NHTS is 0.6%'\n",
    "\n",
    "    \n",
    "ST2.at['Scaled PATH Ridership (with transfers)', 'Target Baseline'] = '297k'\n",
    "ST2.at['Scaled NJ BUS Ridership (with transfers)', 'Target Baseline'] =  '451k'\n",
    "ST2.at['Scaled NJ RAIL Ridership (with transfers)', 'Target Baseline'] =  '127k'\n",
    "ST2.at['Scaled NJ LIGHT RAIL Ridership (with transfers)', 'Target Baseline'] =  '14k'\n",
    "\n",
    "ST2.at['Scaled MTA BUS Ridership (with transfers)', 'Target Baseline'] = '2.19M'\n",
    "ST2.at['Scaled MTA BUS Ridership (with transfers)', 'Target 1 - 04-2020'] = '506k'\n",
    "ST2.at['Scaled MTA BUS Ridership (with transfers)', 'Target 2 - 08-2020'] = '1.21M'\n",
    "ST2.at['Scaled MTA BUS Ridership (with transfers)', 'Target 4 - 08-2021'] = '1.24M'\n",
    "ST2.at['Scaled MTA BUS Ridership (with transfers)', 'Target 3 - 01-2022'] = '1.04M'\n",
    "ST2.at['Scaled MTA BUS Ridership (with transfers)', 'Target 5 - 05-2022'] = '1.46M'\n",
    "ST2.at['Scaled MTA SUB Ridership (without transfers)', 'Target Baseline'] = '5.42M'\n",
    "ST2.at['Scaled MTA SUB Ridership (without transfers)', 'Target 1 - 04-2020'] = '508k'\n",
    "ST2.at['Scaled MTA SUB Ridership (without transfers)', 'Target 2 - 08-2020'] = '1.26M'\n",
    "ST2.at['Scaled MTA SUB Ridership (without transfers)', 'Target 3 - 01-2022'] = '2.25M'\n",
    "ST2.at['Scaled MTA SUB Ridership (without transfers)', 'Target 4 - 08-2021'] = '2.48M'\n",
    "ST2.at['Scaled MTA SUB Ridership (without transfers)', 'Target 5 - 05-2022'] = '3.34M'\n",
    "ST2.at['Subway vs Bus', 'Target Baseline', ] = '2.48'\n",
    "ST2.at['Subway vs Bus', 'Target 1 - 04-2020'] = '1.00'\n",
    "ST2.at['Subway vs Bus', 'Target 2 - 08-2020'] = '1.04'\n",
    "ST2.at['Subway vs Bus', 'Target 3 - 01-2022'] = '2.17'\n",
    "ST2.at['Subway vs Bus', 'Target 4 - 08-2021'] = '2.00'\n",
    "ST2.at['Subway vs Bus', 'Target 5 - 05-2022'] = '2.28'\n",
    "ST2.at['Scaled LIRR Ridership (without transfers)', 'Target Baseline'] = '250k'\n",
    "ST2.at['Scaled LIRR Ridership (without transfers)', 'Target 1 - 04-2020'] = '10k'\n",
    "ST2.at['Scaled LIRR Ridership (without transfers)', 'Target 2 - 08-2020'] = '60k'\n",
    "ST2.at['Scaled LIRR Ridership (without transfers)', 'Target 3 - 01-2022'] = '100k'\n",
    "ST2.at['Scaled LIRR Ridership (without transfers)', 'Target 4 - 08-2021'] = '123k'\n",
    "ST2.at['Scaled LIRR Ridership (without transfers)', 'Target 5 - 05-2022'] = '170k'\n",
    "ST2.at['Scaled Metro North Ridership (without transfers)','Target Baseline'] = '200k'\n",
    "ST2.at['Scaled Metro North Ridership (without transfers)', 'Target 1 - 04-2020'] = '14k'\n",
    "ST2.at['Scaled Metro North Ridership (without transfers)', 'Target 2 - 08-2020'] = '39k'\n",
    "ST2.at['Scaled Metro North Ridership (without transfers)', 'Target 3 - 01-2022'] = '80k'\n",
    "ST2.at['Scaled Metro North Ridership (without transfers)', 'Target 4 - 08-2021'] = '101k'\n",
    "ST2.at['Scaled Metro North Ridership (without transfers)', 'Target 5 - 05-2022'] = '149k'\n",
    "\n",
    "#########\n",
    "           \n",
    "ST2.at['Scaled PATH Ridership (with transfers)', 'Target 1 - 04-2020'] = '15k'\n",
    "ST2.at['Scaled PATH Ridership (with transfers)', 'Target 2 - 08-2020'] = '54k'\n",
    "ST2.at['Scaled PATH Ridership (with transfers)', 'Target 3 - 01-2022'] = '98k'\n",
    "ST2.at['Scaled PATH Ridership (with transfers)', 'Target 4 - 08-2021'] = '85k'\n",
    "# ST2.at['Ridership Metro North Subway Without Transfers', 'Target 5 - 07-2022'] = '5.4M'\n",
    "#########\n",
    "ST2.at['Scaled NJ BUS Ridership (with transfers)', 'Target 1 - 04-2020'] = '93k'\n",
    "ST2.at['Scaled NJ BUS Ridership (with transfers)', 'Target 2 - 08-2020'] = '219k'\n",
    "ST2.at['Scaled NJ BUS Ridership (with transfers)', 'Target 3 - 01-2022'] = '280k'\n",
    "ST2.at['Scaled NJ BUS Ridership (with transfers)', 'Target 4 - 08-2021'] = '232k'\n",
    "# ST2.at['Ridership Metro North Subway Without Transfers', 'Target 5 - 07-2022'] = '5.4M'\n",
    "#########\n",
    "ST2.at['Scaled NJ RAIL Ridership (with transfers)', 'Target 1 - 04-2020'] = '4k'\n",
    "ST2.at['Scaled NJ RAIL Ridership (with transfers)', 'Target 2 - 08-2020'] = '31k'\n",
    "ST2.at['Scaled NJ RAIL Ridership (with transfers)', 'Target 3 - 01-2022'] = '73k'\n",
    "ST2.at['Scaled NJ RAIL Ridership (with transfers)', 'Target 4 - 08-2021'] = '52k'\n",
    "# ST2.at['Ridership Metro North Subway Without Transfers', 'Target 5 - 07-2022'] = '5.4M'\n",
    "#########\n",
    "ST2.at['Scaled NJ LIGHT RAIL Ridership (with transfers)', 'Target 1 - 04-2020'] = '2k'\n",
    "ST2.at['Scaled NJ LIGHT RAIL Ridership (with transfers)', 'Target 2 - 08-2020'] = '6k'\n",
    "ST2.at['Scaled NJ LIGHT RAIL Ridership (with transfers)', 'Target 3 - 01-2022'] = '8k'\n",
    "ST2.at['Scaled NJ LIGHT RAIL Ridership (with transfers)', 'Target 4 - 08-2021'] = '7k'\n",
    "# ST2.at['Ridership Metro North Subway Without Transfers', 'Target 5 - 07-2022'] = '5.4M'\n",
    "\n",
    "   \n",
    "ST2.at['Share Mode Bike Miles 0-1', 'Target Baseline'] =  '0.86%'\n",
    "ST2.at['Share Mode Bus Miles 0-1', 'Target Baseline'] =  '1.92%'\n",
    "ST2.at['Share Mode Car Miles 0-1', 'Target Baseline'] =  '27.02%'\n",
    "ST2.at['Share Mode Ferry Miles 0-1', 'Target Baseline'] =  '0.00%'\n",
    "ST2.at['Share Mode Rail Miles 0-1', 'Target Baseline'] =  '0.03%'\n",
    "ST2.at['Share Mode Ridehail Miles 0-1', 'Target Baseline'] =  '0.51%'\n",
    "ST2.at['Share Mode Subway Miles 0-1', 'Target Baseline'] =  '0.73%'\n",
    "ST2.at['Share Mode Walk Miles 0-1', 'Target Baseline'] =  '68.61%'\n",
    "ST2.at['Share Mode Other Miles 0-1', 'Target Baseline'] =  '0.32%'\n",
    "\n",
    "ST2.at['Share Mode Bike Miles 1-2', 'Target Baseline'] =  '1.88%'\n",
    "ST2.at['Share Mode Bus Miles 1-2', 'Target Baseline'] =  '10.51%'\n",
    "ST2.at['Share Mode Car Miles 1-2', 'Target Baseline'] =  '62.69%'\n",
    "ST2.at['Share Mode Ferry Miles 1-2', 'Target Baseline'] =  '0.01%'\n",
    "ST2.at['Share Mode Rail Miles 1-2', 'Target Baseline'] =  '0.05%'\n",
    "ST2.at['Share Mode Ridehail Miles 1-2', 'Target Baseline'] =  '4.89%'\n",
    "ST2.at['Share Mode Subway Miles 1-2', 'Target Baseline'] =  '4.07%'\n",
    "ST2.at['Share Mode Walk Miles 1-2', 'Target Baseline'] =  '14.90%'\n",
    "ST2.at['Share Mode Other Miles 1-2', 'Target Baseline'] =  '1.00%'\n",
    "\n",
    "ST2.at['Share Mode Bike Miles 2-5', 'Target Baseline'] =  '1.57%'\n",
    "ST2.at['Share Mode Bus Miles 2-5', 'Target Baseline'] =  '9.69%'\n",
    "ST2.at['Share Mode Car Miles 2-5', 'Target Baseline'] =  '68.28%'\n",
    "ST2.at['Share Mode Ferry Miles 2-5', 'Target Baseline'] =  '0.00%'\n",
    "ST2.at['Share Mode Rail Miles 2-5', 'Target Baseline'] =  '0.00%'\n",
    "ST2.at['Share Mode Ridehail Miles 2-5', 'Target Baseline'] =  '3.03%'\n",
    "ST2.at['Share Mode Subway Miles 2-5', 'Target Baseline'] =  '13.26%'\n",
    "ST2.at['Share Mode Walk Miles 2-5', 'Target Baseline'] =  '3.18%'\n",
    "ST2.at['Share Mode Other Miles 2-5', 'Target Baseline'] =  '0.99%'\n",
    "\n",
    "ST2.at['Share Mode Bike Miles 5-15', 'Target Baseline'] =  '0.38%'\n",
    "ST2.at['Share Mode Bus Miles 5-15', 'Target Baseline'] =  '7.45%'\n",
    "ST2.at['Share Mode Car Miles 5-15', 'Target Baseline'] =  '67.58%'\n",
    "ST2.at['Share Mode Ferry Miles 5-15', 'Target Baseline'] =  '0.34%'\n",
    "ST2.at['Share Mode Rail Miles 5-15', 'Target Baseline'] =  '1.22%'\n",
    "ST2.at['Share Mode Ridehail Miles 5-15', 'Target Baseline'] =  '0.83%'\n",
    "ST2.at['Share Mode Subway Miles 5-15', 'Target Baseline'] =  '20.64%'\n",
    "ST2.at['Share Mode Walk Miles 5-15', 'Target Baseline'] =  '1.19%'\n",
    "ST2.at['Share Mode Other Miles 5-15', 'Target Baseline'] =  '0.38%'\n",
    "\n",
    "ST2.at['Share Mode Bike Miles 15+', 'Target Baseline'] =  '0.10%'\n",
    "ST2.at['Share Mode Bus Miles 15+', 'Target Baseline'] =  '6.05%'\n",
    "ST2.at['Share Mode Car Miles 15+', 'Target Baseline'] =  '72.21%'\n",
    "ST2.at['Share Mode Ferry Miles 15+', 'Target Baseline'] =  '0.33%'\n",
    "ST2.at['Share Mode Rail Miles 15+', 'Target Baseline'] =  '8.42%'\n",
    "ST2.at['Share Mode Ridehail Miles 15+', 'Target Baseline'] =  '1.43%'\n",
    "ST2.at['Share Mode Subway Miles 15+', 'Target Baseline'] =  '10.15%'\n",
    "ST2.at['Share Mode Walk Miles 15+', 'Target Baseline'] =  '0.61%'\n",
    "ST2.at['Share Mode Other Miles 15+', 'Target Baseline'] =  '0.70%'\n",
    "\n",
    "ST2.at['Activities AV per person Home', 'Target Baseline'] =  '1.307'\n",
    "ST2.at['Activities AV per person Meal', 'Target Baseline'] =  '0.260'\n",
    "ST2.at['Activities AV per person Shopping', 'Target Baseline'] =  '0.515'\n",
    "ST2.at['Activities AV per person SocRec', 'Target Baseline'] =  '0.431'\n",
    "ST2.at['Activities AV per person Work', 'Target Baseline'] =  '0.742'\n",
    "ST2.at['Activities AV per person Other', 'Target Baseline'] =  '0.566'\n",
    "\n",
    "\n",
    "\n",
    "ST2.to_csv('outputs/validationNYC16.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3dd13-44f5-4c2f-80c7-b19270080853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bridge_link_ids=[542014,88230,853928,779898,853900,30814,154,731748,1367888,487778,13722,\n",
    "                 1071576,62416,729848,765880,1090614,788122,788140,788118,1341064,53416,\n",
    "                 732358,865062,999610,\n",
    "                 308, 540388, #lincloln tunnel I 2\n",
    "                 87186, #lincloln tunnel O 2\n",
    "                 87176, 767820, #washington I\n",
    "                 88110, 735454, #washington O\n",
    "                 540918, #Holland Tunnel I\n",
    "                 87188, #Holland Tunnel O\n",
    "                 852460, #Outerbridge Crossing I\n",
    "                 852458, #Outerbridge Crossing O \n",
    "                 1226968, #Goethals Bridge I \n",
    "                 1292432, #Goethals Bridge O\n",
    "                 759498, #Bayonne Bridge I\n",
    "                 759500, #Bayonne Bridge O\n",
    "                ]\n",
    "\n",
    "for data_name, name, plan_name, share_pop in zip(data_names, names, plan_names, shares_pop):\n",
    "    # print(data_name)\n",
    "    #Contains flows\n",
    "    print(name,'...')\n",
    "    try:\n",
    "        pte = pd.read_csv(fp+data_name[:-13]+'linkstats.csv.gz')\n",
    "        #Contains coord\n",
    "        network = pd.read_csv(fp+data_name[:-(len(data_name.split('/')[-1])+len(data_name.split('/')[-2])+len(data_name.split('/')[-3])+2)]+'network.csv.gz')\n",
    "        pte = pte[pte['link'].isin(bridge_link_ids)]\n",
    "        network = network[network['linkId'].isin(bridge_link_ids)]\n",
    "\n",
    "        #Transfer volume info to the netork database\n",
    "        # share_pop = 0.1\n",
    "        volumes = []\n",
    "        pte.index = pte['link']\n",
    "        for link in network['linkId']:\n",
    "            volumes.append(np.sum(pte.at[link,'volume'])/share_pop)\n",
    "        network['volume'] = volumes\n",
    "\n",
    "        # Bridge_flows = pd.DataFrame()\n",
    "        ST2.at['henry_hudson_bridge I',name] = network.at[542014, 'volume']\n",
    "        ST2.at['henry_hudson_bridge O', name] =  network.at[88230, 'volume']\n",
    "        ST2.at['robert_f_kennedy_bridge Queen I',name] =  network.at[853928, 'volume']\n",
    "        ST2.at['robert_f_kennedy_bridge Queen O', name] =  network.at[779898, 'volume']\n",
    "        ST2.at['robert_f_kennedy_bridge Bronx I',name] =  network.at[853900, 'volume']\n",
    "        ST2.at['robert_f_kennedy_bridge Bronx O', name] =  network.at[30814, 'volume']\n",
    "        ST2.at['robert_f_kennedy_bridge Manh I',name] =  network.at[154, 'volume']\n",
    "        ST2.at['robert_f_kennedy_bridge Manh O', name] =  network.at[731748, 'volume']\n",
    "        ST2.at['queens_midtown_tunnel I',name] =  network.at[1367888, 'volume']\n",
    "        ST2.at['queens_midtown_tunnel O', name] =  network.at[487778, 'volume']\n",
    "        ST2.at['hugh_l_carey_tunnel I',name] =  network.at[13722, 'volume']\n",
    "        ST2.at['hugh_l_carey_tunnel O', name] =  network.at[1071576, 'volume']\n",
    "        ST2.at['bronx_whitestone_bridge I',name] =  network.at[62416, 'volume']\n",
    "        ST2.at['bronx_whitestone_bridge O', name] =  network.at[729848, 'volume']\n",
    "        ST2.at['throgs_neck_bridge I',name] =  network.at[765880, 'volume']\n",
    "        ST2.at['throgs_neck_bridge O',name] =  network.at[1090614, 'volume']\n",
    "        ST2.at['varrazzano_narrows_bridge I',name] =  network.at[788122, 'volume']+network.at[788140, 'volume']\n",
    "        ST2.at['varrazzano_narrows_bridge O',name] =  network.at[788118, 'volume']+ network.at[1341064, 'volume']\n",
    "        ST2.at['marine_parkwaygil_hodges_memorial_bridge I',name] =  network.at[53416, 'volume']\n",
    "        ST2.at['marine_parkwaygil_hodges_memorial_bridge O', name] =  network.at[732358, 'volume']\n",
    "        ST2.at['cross_bay_veterans_memorial_bridge I',name] =  network.at[865062, 'volume']\n",
    "        ST2.at['cross_bay_veterans_memorial_bridge O', name] =  network.at[999610, 'volume']\n",
    "\n",
    "        ST2.at['Lincoln Tunnel Total', name] =  network.at[540388, 'volume']+network.at[87186, 'volume'] #network.at[308, 'volume']\n",
    "        ST2.at['George Washington Bridge Total', name] =  network.at[87176, 'volume']+network.at[767820, 'volume']+network.at[88110, 'volume']+network.at[735454, 'volume']\n",
    "        ST2.at['Holland Tunnel Total', name] =  network.at[540918, 'volume']+network.at[87188, 'volume']\n",
    "        ST2.at['Outerbridge Crossing Total', name] =  network.at[852458, 'volume']+network.at[852460, 'volume']\n",
    "        ST2.at['Goethals Bridge Total',name] =  network.at[1226968, 'volume']+network.at[1292432, 'volume']\n",
    "        ST2.at['Bayonne Bridge Total', name] =  network.at[759498, 'volume']+network.at[759500, 'volume']\n",
    "\n",
    "        ST2.at['Lincoln Tunnel I', name] =  network.at[540388, 'volume'] #network.at[308, 'volume']\n",
    "        ST2.at['George Washington Bridge I', name] =  network.at[87176, 'volume']+network.at[767820, 'volume']\n",
    "        ST2.at['Holland Tunnel I', name] =  network.at[540918, 'volume']\n",
    "        ST2.at['Outerbridge Crossing I', name] =  network.at[852460, 'volume']\n",
    "        ST2.at['Goethals Bridge I', name] =  network.at[1226968, 'volume']\n",
    "        ST2.at['Bayonne Bridge I', name] =  network.at[759498, 'volume']\n",
    "\n",
    "        ST2.at['Lincoln Tunnel O', name] =  network.at[87186, 'volume']\n",
    "        ST2.at['George Washington Bridge O', name] = network.at[88110, 'volume']+network.at[735454, 'volume']\n",
    "        ST2.at['Holland Tunnel O', name] =  network.at[87188, 'volume']\n",
    "        ST2.at['Outerbridge Crossing O', name] =  network.at[852458, 'volume']\n",
    "        ST2.at['Goethals Bridge O', name] = network.at[1292432, 'volume']\n",
    "        ST2.at['Bayonne Bridge O', name] =  network.at[759500, 'volume']\n",
    "\n",
    "        ST2.at['PATH Bridge and Tunnel Counts Total', name] = (ST2.at['Lincoln Tunnel Total', name]+\n",
    "                                                             ST2.at['George Washington Bridge Total', name]+\n",
    "                                                             ST2.at['Holland Tunnel Total', name]+\n",
    "                                                             ST2.at['Outerbridge Crossing Total', name]+\n",
    "                                                             ST2.at['Goethals Bridge Total',name]+\n",
    "                                                             ST2.at['Bayonne Bridge Total', name])\n",
    "        ST2.at['PATH Bridge and Tunnel Counts Total O', name] = (ST2.at['Lincoln Tunnel O', name]+\n",
    "                                                             ST2.at['George Washington Bridge O', name]+\n",
    "                                                             ST2.at['Holland Tunnel O', name]+\n",
    "                                                             ST2.at['Outerbridge Crossing O', name]+\n",
    "                                                             ST2.at['Goethals Bridge O',name]+\n",
    "                                                             ST2.at['Bayonne Bridge O', name])\n",
    "        ST2.at['PATH Bridge and Tunnel Counts Total I', name] = (ST2.at['Lincoln Tunnel I', name]+\n",
    "                                                             ST2.at['George Washington Bridge I', name]+\n",
    "                                                             ST2.at['Holland Tunnel I', name]+\n",
    "                                                             ST2.at['Outerbridge Crossing I', name]+\n",
    "                                                             ST2.at['Goethals Bridge I',name]+\n",
    "                                                             ST2.at['Bayonne Bridge I', name])\n",
    "        ST2.at['MTA Bridge and Tunnel Counts Total', name] =     (ST2.at['henry_hudson_bridge I',name] +\n",
    "                                                            ST2.at['henry_hudson_bridge O', name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Queen I',name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Queen O', name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Bronx I',name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Bronx O', name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Manh I',name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Manh O', name] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I',name] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', name] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I',name] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', name] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I',name] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', name] +\n",
    "                                                            ST2.at['throgs_neck_bridge I',name] +\n",
    "                                                            ST2.at['throgs_neck_bridge O',name] +\n",
    "                                                            ST2.at['varrazzano_narrows_bridge I',name] +\n",
    "                                                            ST2.at['varrazzano_narrows_bridge O',name] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I',name] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', name] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I',name] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', name])\n",
    "        ST2.at['MTA Bridge and Tunnel Counts Total I', name] =     (ST2.at['henry_hudson_bridge I',name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Queen I',name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Bronx I',name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Manh I',name] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I',name] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I',name] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I',name] +\n",
    "                                                            ST2.at['throgs_neck_bridge I',name] +\n",
    "                                                            ST2.at['varrazzano_narrows_bridge I',name] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I',name] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I',name] )\n",
    "        ST2.at['MTA Bridge and Tunnel Counts Total O', name] =     (\n",
    "                                                            ST2.at['henry_hudson_bridge O', name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Queen O', name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Bronx O', name] +\n",
    "                                                            ST2.at['robert_f_kennedy_bridge Manh O', name] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', name] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', name] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', name] +\n",
    "                                                            ST2.at['throgs_neck_bridge O',name] +\n",
    "                                                            ST2.at['varrazzano_narrows_bridge O',name] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', name] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', name])\n",
    "        ST2.at['MTA Bridge and Tunnel Counts Total - only observed bridges/tunnels', name] =     (ST2.at['henry_hudson_bridge I',name] +\n",
    "                                                            ST2.at['henry_hudson_bridge O', name] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I',name] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', name] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I',name] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', name] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I',name] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', name] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I',name] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', name] +\n",
    "                                                            ST2.at['throgs_neck_bridge I',name] +\n",
    "                                                            ST2.at['throgs_neck_bridge O',name] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O',name] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I',name] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', name] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I',name] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', name])\n",
    "        ST2.at['MTA Bridge and Tunnel Counts Total I- only observed bridges/tunnels', name] =     (ST2.at['henry_hudson_bridge I',name] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I',name] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I',name] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I',name] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I',name] +\n",
    "                                                            ST2.at['throgs_neck_bridge I',name] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I',name] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I',name])\n",
    "        ST2.at['MTA Bridge and Tunnel Counts Total O- only observed bridges/tunnels', name] =     (\n",
    "                                                            ST2.at['henry_hudson_bridge O', name] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', name] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', name] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', name] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', name] +\n",
    "                                                            ST2.at['throgs_neck_bridge O',name] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O',name] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', name] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', name])\n",
    "    except:\n",
    "        print('Warning: no linkstat')\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total', 'Target Baseline'] = '907k'\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total', 'Target 1 - 04-2020'] = '341k'\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total', 'Target 2 - 08-2020'] = '787k'\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total', 'Target 3 - 01-2022'] = '695k'\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total', 'Target 4 - 08-2021'] = '933k'\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total', 'Target 5 - 05-2022'] = '955k'\n",
    "\n",
    "######################BASELINE############################################\n",
    "\n",
    "ST2.at['Lincoln Tunnel I', 'Target Baseline'] =  40652\n",
    "ST2.at['George Washington Bridge I', 'Target Baseline'] =  128820\n",
    "ST2.at['Holland Tunnel I', 'Target Baseline'] = 41931\n",
    "ST2.at['Outerbridge Crossing I', 'Target Baseline'] =  38062\n",
    "ST2.at['Goethals Bridge I','Target Baseline'] =  42795\n",
    "ST2.at['Bayonne Bridge I', 'Target Baseline'] =  9603\n",
    "ST2.at['PATH Bridge and Tunnel Counts Total I', 'Target Baseline'] =  (ST2.at['Lincoln Tunnel I', 'Target Baseline']+\n",
    "                                                               ST2.at['George Washington Bridge I', 'Target Baseline']+\n",
    "                                                               ST2.at['Holland Tunnel I', 'Target Baseline']+\n",
    "                                                               ST2.at['Outerbridge Crossing I', 'Target Baseline']+\n",
    "                                                               ST2.at['Goethals Bridge I','Target Baseline']+\n",
    "                                                               ST2.at['Bayonne Bridge I', 'Target Baseline'])\n",
    "\n",
    "\n",
    "ST2.at['Lincoln Tunnel I', 'Target 1 - 04-2020'] =  383971/(8*1.182+22)\n",
    "ST2.at['George Washington Bridge I', 'Target 1 - 04-2020'] =  1529569/(8*1.133+22)\n",
    "ST2.at['Holland Tunnel I', 'Target 1 - 04-2020'] = 426493/(8*1.088+22)\n",
    "ST2.at['Outerbridge Crossing I', 'Target 1 - 04-2020'] =  491532/(8*1.156+22)\n",
    "ST2.at['Goethals Bridge I','Target 1 - 04-2020'] =  486631/(8*1.1566+22)\n",
    "ST2.at['Bayonne Bridge I', 'Target 1 - 04-2020'] =  127847/(8*1.041+22)\n",
    "ST2.at['PATH Bridge and Tunnel Counts Total I', 'Target 1 - 04-2020'] =  (ST2.at['Lincoln Tunnel I', 'Target 1 - 04-2020']+\n",
    "                                                               ST2.at['George Washington Bridge I', 'Target 1 - 04-2020']+\n",
    "                                                               ST2.at['Holland Tunnel I', 'Target 1 - 04-2020']+\n",
    "                                                               ST2.at['Outerbridge Crossing I', 'Target 1 - 04-2020']+\n",
    "                                                               ST2.at['Goethals Bridge I','Target 1 - 04-2020']+\n",
    "                                                               ST2.at['Bayonne Bridge I', 'Target 1 - 04-2020'])\n",
    "                                                                                                   \n",
    "\n",
    "ST2.at['Lincoln Tunnel I', 'Target 2 - 08-2020'] =  1130222/(10*1.182+21)\n",
    "ST2.at['George Washington Bridge I', 'Target 2 - 08-2020'] =  3818395/(10*1.133+21)\n",
    "ST2.at['Holland Tunnel I', 'Target 2 - 08-2020'] = 1012757/(10*1.088+21)\n",
    "ST2.at['Outerbridge Crossing I', 'Target 2 - 08-2020'] =  1188595/(10*1.156+21)\n",
    "ST2.at['Goethals Bridge I','Target 2 - 08-2020'] =  1303366/(10*1.1566+21)\n",
    "ST2.at['Bayonne Bridge I', 'Target 2 - 08-2020'] =  257493/(10*1.041+21)\n",
    "ST2.at['PATH Bridge and Tunnel Counts Total I', 'Target 2 - 08-2020'] =  (ST2.at['Lincoln Tunnel I', 'Target 2 - 08-2020']+\n",
    "                                                               ST2.at['George Washington Bridge I', 'Target 2 - 08-2020']+\n",
    "                                                               ST2.at['Holland Tunnel I', 'Target 2 - 08-2020']+\n",
    "                                                               ST2.at['Outerbridge Crossing I', 'Target 2 - 08-2020']+\n",
    "                                                               ST2.at['Goethals Bridge I','Target 2 - 08-2020']+\n",
    "                                                               ST2.at['Bayonne Bridge I', 'Target 2 - 08-2020'])\n",
    "                                                                \n",
    "\n",
    "ST2.at['Lincoln Tunnel I', 'Target 3 - 01-2022'] =  1135056/(12*1.182+19)\n",
    "ST2.at['George Washington Bridge I', 'Target 3 - 01-2022'] =  3190102/(12*1.133+19)\n",
    "ST2.at['Holland Tunnel I', 'Target 3 - 01-2022'] = 1013607/(12*1.088+19)\n",
    "ST2.at['Outerbridge Crossing I', 'Target 3 - 01-2022'] =  933625/(12*1.156+19)\n",
    "ST2.at['Goethals Bridge I','Target 3 - 01-2022'] =  1096469/(12*1.1566+19)\n",
    "ST2.at['Bayonne Bridge I', 'Target 3 - 01-2022'] =  235078/(12*1.041+19)\n",
    "ST2.at['PATH Bridge and Tunnel Counts Total I', 'Target 3 - 01-2022'] =  (ST2.at['Lincoln Tunnel I', 'Target 3 - 01-2022']+\n",
    "                                                               ST2.at['George Washington Bridge I', 'Target 3 - 01-2022']+\n",
    "                                                               ST2.at['Holland Tunnel I', 'Target 3 - 01-2022']+\n",
    "                                                               ST2.at['Outerbridge Crossing I', 'Target 3 - 01-2022']+\n",
    "                                                               ST2.at['Goethals Bridge I','Target 3 - 01-2022']+\n",
    "                                                               ST2.at['Bayonne Bridge I', 'Target 3 - 01-2022'])\n",
    "ST2.at['Lincoln Tunnel I', 'Target 4 - 08-2021'] =  1406138/(9*1.182+22)\n",
    "ST2.at['George Washington Bridge I', 'Target 4 - 08-2021'] =  4216928/(9*1.133+22)\n",
    "ST2.at['Holland Tunnel I', 'Target 4 - 08-2021'] = 1211681/(9*1.088+22)\n",
    "ST2.at['Outerbridge Crossing I', 'Target 4 - 08-2021'] =  1235441/(9*1.156+22)\n",
    "ST2.at['Goethals Bridge I','Target 4 - 08-2021'] =  1428752/(9*1.1566+22)\n",
    "ST2.at['Bayonne Bridge I', 'Target 4 - 08-2021'] =  321481/(9*1.041+22)\n",
    "ST2.at['PATH Bridge and Tunnel Counts Total I', 'Target 4 - 08-2021'] =  (ST2.at['Lincoln Tunnel I', 'Target 4 - 08-2021']+\n",
    "                                                               ST2.at['George Washington Bridge I', 'Target 4 - 08-2021']+\n",
    "                                                               ST2.at['Holland Tunnel I', 'Target 4 - 08-2021']+\n",
    "                                                               ST2.at['Outerbridge Crossing I', 'Target 4 - 08-2021']+\n",
    "                                                               ST2.at['Goethals Bridge I','Target 4 - 08-2021']+\n",
    "                                                               ST2.at['Bayonne Bridge I', 'Target 4 - 08-2021'])\n",
    "obs_data = pd.read_csv('inputs/Daily_Traffic_on_MTA_Bridges___Tunnels.csv')\n",
    "\n",
    "obs_data=obs_data[(obs_data['Date']=='03/02/2020')|\n",
    "                 (obs_data['Date']=='03/03/2020')|\n",
    "                 (obs_data['Date']=='03/04/2020')|\n",
    "                 (obs_data['Date']=='03/05/2020')|\n",
    "                 (obs_data['Date']=='03/06/2020')]\n",
    "\n",
    "obs_data['Total Flow'] = obs_data['# Vehicles - E-ZPass']+obs_data['# Vehicles - VToll']\n",
    "ST2.at['henry_hudson_bridge I','Target Baseline'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='I')])\n",
    "ST2.at['henry_hudson_bridge O', 'Target Baseline'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen I','Target Baseline'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='O')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh O', 'Target Baseline'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='O')])\n",
    "ST2.at['queens_midtown_tunnel I','Target Baseline'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='I')])\n",
    "ST2.at['queens_midtown_tunnel O', 'Target Baseline'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='O')])\n",
    "ST2.at['hugh_l_carey_tunnel I','Target Baseline'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='I')])\n",
    "ST2.at['hugh_l_carey_tunnel O', 'Target Baseline'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='O')])\n",
    "ST2.at['bronx_whitestone_bridge I','Target Baseline'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='I')])\n",
    "ST2.at['bronx_whitestone_bridge O', 'Target Baseline'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='O')])\n",
    "ST2.at['throgs_neck_bridge I','Target Baseline'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='I')])\n",
    "ST2.at['throgs_neck_bridge O', 'Target Baseline'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['varrazzano_narrows_bridge I','Target Baseline'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['varrazzano_narrows_bridge O', 'Target Baseline'] =     np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='O')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target Baseline'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='I')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target Baseline'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='O')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge I','Target Baseline'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='I')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge O', 'Target Baseline'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='O')])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total - only observed bridges/tunnels', 'Target Baseline'] = (ST2.at['henry_hudson_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target Baseline'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target Baseline'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target Baseline'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target Baseline'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target Baseline'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target Baseline'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target Baseline'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target Baseline'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target Baseline']) \n",
    "ST2.at['MTA Bridge and Tunnel Counts Total I- only observed bridges/tunnels', 'Target Baseline'] = (ST2.at['henry_hudson_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target Baseline'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target Baseline'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target Baseline'] )\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total O- only observed bridges/tunnels', 'Target Baseline'] = (\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target Baseline'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target Baseline'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target Baseline'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target Baseline'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target Baseline'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target Baseline'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target Baseline']) \n",
    "######################Scenario1############################################\n",
    "obs_data = pd.read_csv('inputs/Daily_Traffic_on_MTA_Bridges___Tunnels.csv')\n",
    "\n",
    "obs_data=obs_data[(obs_data['Date']=='04/03/2020')|\n",
    "                 (obs_data['Date']=='04/02/2020')|\n",
    "                 (obs_data['Date']=='04/01/2020')|\n",
    "                 (obs_data['Date']=='03/31/2020')|\n",
    "                 (obs_data['Date']=='03/30/2020')]\n",
    "\n",
    "obs_data['Total Flow'] = obs_data['# Vehicles - E-ZPass']+obs_data['# Vehicles - VToll']\n",
    "ST2.at['henry_hudson_bridge I','Target 1 - 04-2020'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='I')])\n",
    "ST2.at['henry_hudson_bridge O', 'Target 1 - 04-2020'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen I','Target 1 - 04-2020'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen O', 'Target 1 - 04-2020'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               # [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='O')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh I','Target 1 - 04-2020'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh O', 'Target 1 - 04-2020'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               # [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='O')])\n",
    "ST2.at['queens_midtown_tunnel I','Target 1 - 04-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='I')])\n",
    "ST2.at['queens_midtown_tunnel O', 'Target 1 - 04-2020'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='O')])\n",
    "ST2.at['hugh_l_carey_tunnel I','Target 1 - 04-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='I')])\n",
    "ST2.at['hugh_l_carey_tunnel O', 'Target 1 - 04-2020'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='O')])\n",
    "ST2.at['bronx_whitestone_bridge I','Target 1 - 04-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='I')])\n",
    "ST2.at['bronx_whitestone_bridge O', 'Target 1 - 04-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='O')])\n",
    "ST2.at['throgs_neck_bridge I','Target 1 - 04-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='I')])\n",
    "ST2.at['throgs_neck_bridge O', 'Target 1 - 04-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['varrazzano_narrows_bridge I','Target 1 - 04-2020'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['varrazzano_narrows_bridge O', 'Target 1 - 04-2020'] =     np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='O')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 1 - 04-2020'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='I')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 1 - 04-2020'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='O')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge I','Target 1 - 04-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='I')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 1 - 04-2020'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='O')])\n",
    "\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total - only observed bridges/tunnels', 'Target 1 - 04-2020'] = (ST2.at['henry_hudson_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target 1 - 04-2020'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 1 - 04-2020'])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total I- only observed bridges/tunnels', 'Target 1 - 04-2020'] = (ST2.at['henry_hudson_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target 1 - 04-2020'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 1 - 04-2020'])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total O- only observed bridges/tunnels', 'Target 1 - 04-2020'] = (\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target 1 - 04-2020'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target 1 - 04-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 1 - 04-2020'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 1 - 04-2020'])\n",
    "######################Scenario2############################################\n",
    "obs_data = pd.read_csv('inputs/Daily_Traffic_on_MTA_Bridges___Tunnels.csv')\n",
    "\n",
    "obs_data=obs_data[(obs_data['Date']=='08/07/2020')|\n",
    "                 (obs_data['Date']=='08/03/2020')|\n",
    "                 (obs_data['Date']=='08/04/2020')|\n",
    "                 (obs_data['Date']=='08/05/2020')|\n",
    "                 (obs_data['Date']=='08/06/2020')]\n",
    "\n",
    "obs_data['Total Flow'] = obs_data['# Vehicles - E-ZPass']+obs_data['# Vehicles - VToll']\n",
    "ST2.at['henry_hudson_bridge I','Target 2 - 08-2020'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='I')])\n",
    "ST2.at['henry_hudson_bridge O', 'Target 2 - 08-2020'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen I','Target 2 - 08-2020'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen O', 'Target 2 - 08-2020'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='O')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh I','Target 2 - 08-2020'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh O', 'Target 2 - 08-2020'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='O')])\n",
    "ST2.at['queens_midtown_tunnel I','Target 2 - 08-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='I')])\n",
    "ST2.at['queens_midtown_tunnel O', 'Target 2 - 08-2020'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='O')])\n",
    "ST2.at['hugh_l_carey_tunnel I','Target 2 - 08-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='I')])\n",
    "ST2.at['hugh_l_carey_tunnel O', 'Target 2 - 08-2020'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='O')])\n",
    "ST2.at['bronx_whitestone_bridge I','Target 2 - 08-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='I')])\n",
    "ST2.at['bronx_whitestone_bridge O', 'Target 2 - 08-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='O')])\n",
    "ST2.at['throgs_neck_bridge I','Target 2 - 08-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='I')])\n",
    "ST2.at['throgs_neck_bridge O', 'Target 2 - 08-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['varrazzano_narrows_bridge I','Target 2 - 08-2020'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['varrazzano_narrows_bridge O', 'Target 2 - 08-2020'] =     np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='O')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 2 - 08-2020'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='I')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 2 - 08-2020'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='O')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge I','Target 2 - 08-2020'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='I')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 2 - 08-2020'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='O')])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total - only observed bridges/tunnels', 'Target 2 - 08-2020'] = (ST2.at['henry_hudson_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target 2 - 08-2020'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 2 - 08-2020'])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total I- only observed bridges/tunnels', 'Target 2 - 08-2020'] = (ST2.at['henry_hudson_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target 2 - 08-2020'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 2 - 08-2020'])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total O- only observed bridges/tunnels', 'Target 2 - 08-2020'] = (\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target 2 - 08-2020'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target 2 - 08-2020'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 2 - 08-2020'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 2 - 08-2020'])\n",
    "######################Scenario3############################################\n",
    "obs_data = pd.read_csv('inputs/Daily_Traffic_on_MTA_Bridges___Tunnels.csv')\n",
    "\n",
    "obs_data=obs_data[(obs_data['Date']=='01/07/2022')|\n",
    "                 (obs_data['Date']=='01/03/2022')|\n",
    "                 (obs_data['Date']=='01/04/2022')|\n",
    "                 (obs_data['Date']=='01/05/2022')|\n",
    "                 (obs_data['Date']=='01/06/2022')]\n",
    "\n",
    "obs_data['Total Flow'] = obs_data['# Vehicles - E-ZPass']+obs_data['# Vehicles - VToll']\n",
    "ST2.at['henry_hudson_bridge I','Target 3 - 01-2022'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='I')])\n",
    "ST2.at['henry_hudson_bridge O', 'Target 3 - 01-2022'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen I','Target 3 - 01-2022'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen O', 'Target 3 - 01-2022'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='O')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh I','Target 3 - 01-2022'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh O', 'Target 3 - 01-2022'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='O')])\n",
    "ST2.at['queens_midtown_tunnel I','Target 3 - 01-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='I')])\n",
    "ST2.at['queens_midtown_tunnel O', 'Target 3 - 01-2022'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='O')])\n",
    "ST2.at['hugh_l_carey_tunnel I','Target 3 - 01-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='I')])\n",
    "ST2.at['hugh_l_carey_tunnel O', 'Target 3 - 01-2022'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='O')])\n",
    "ST2.at['bronx_whitestone_bridge I','Target 3 - 01-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='I')])\n",
    "ST2.at['bronx_whitestone_bridge O', 'Target 3 - 01-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='O')])\n",
    "ST2.at['throgs_neck_bridge I','Target 3 - 01-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='I')])\n",
    "ST2.at['throgs_neck_bridge O', 'Target 3 - 01-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['varrazzano_narrows_bridge I','Target 3 - 01-2022'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['varrazzano_narrows_bridge O', 'Target 3 - 01-2022'] =     np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='O')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 3 - 01-2022'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='I')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 3 - 01-2022'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='O')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge I','Target 3 - 01-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='I')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 3 - 01-2022'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='O')])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total - only observed bridges/tunnels', 'Target 3 - 01-2022'] = (ST2.at['henry_hudson_bridge I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 3 - 01-2022'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 3 - 01-2022'])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total I- only observed bridges/tunnels', 'Target 3 - 01-2022'] = (ST2.at['henry_hudson_bridge I','Target 3 - 01-2022'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 3 - 01-2022'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 3 - 01-2022'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 3 - 01-2022'] )\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total O- only observed bridges/tunnels', 'Target 3 - 01-2022'] = (\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 3 - 01-2022'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 3 - 01-2022'])\n",
    "######################Scenario4############################################\n",
    "obs_data = pd.read_csv('inputs/Daily_Traffic_on_MTA_Bridges___Tunnels.csv')\n",
    "\n",
    "obs_data=obs_data[(obs_data['Date']=='08/02/2021')|\n",
    "                 (obs_data['Date']=='08/03/2021')|\n",
    "                 (obs_data['Date']=='08/04/2021')|\n",
    "                 (obs_data['Date']=='08/05/2021')|\n",
    "                 (obs_data['Date']=='08/06/2021')]\n",
    "\n",
    "obs_data['Total Flow'] = obs_data['# Vehicles - E-ZPass']+obs_data['# Vehicles - VToll']\n",
    "ST2.at['henry_hudson_bridge I','Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='I')])\n",
    "ST2.at['henry_hudson_bridge O', 'Target 4 - 08-2021'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen I','Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen O', 'Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               # [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='O')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh I','Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh O', 'Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               # [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='O')])\n",
    "ST2.at['queens_midtown_tunnel I','Target 4 - 08-2021'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='I')])\n",
    "ST2.at['queens_midtown_tunnel O', 'Target 4 - 08-2021'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='O')])\n",
    "ST2.at['hugh_l_carey_tunnel I','Target 4 - 08-2021'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='I')])\n",
    "ST2.at['hugh_l_carey_tunnel O', 'Target 4 - 08-2021'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='O')])\n",
    "ST2.at['bronx_whitestone_bridge I','Target 4 - 08-2021'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='I')])\n",
    "ST2.at['bronx_whitestone_bridge O', 'Target 4 - 08-2021'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='O')])\n",
    "ST2.at['throgs_neck_bridge I','Target 4 - 08-2021'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='I')])\n",
    "ST2.at['throgs_neck_bridge O', 'Target 4 - 08-2021'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['varrazzano_narrows_bridge I','Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['varrazzano_narrows_bridge O', 'Target 4 - 08-2021'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               # [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='O')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 4 - 08-2021'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='I')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 4 - 08-2021'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='O')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge I','Target 4 - 08-2021'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='I')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 4 - 08-2021'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='O')])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total - only observed bridges/tunnels', 'Target 4 - 08-2021'] = (ST2.at['henry_hudson_bridge I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 4 - 08-2021'])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total I- only observed bridges/tunnels', 'Target 4 - 08-2021'] = (ST2.at['henry_hudson_bridge I','Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 4 - 08-2021'])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total O- only observed bridges/tunnels', 'Target 4 - 08-2021'] = (ST2.at['henry_hudson_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 4 - 08-2021'])\n",
    "\n",
    "######################Scenario5############################################\n",
    "obs_data = pd.read_csv('inputs/Daily_Traffic_on_MTA_Bridges___Tunnels.csv')\n",
    "\n",
    "obs_data=obs_data[(obs_data['Date']=='05/09/2021')|\n",
    "                 (obs_data['Date']=='05/10/2021')|\n",
    "                 (obs_data['Date']=='05/11/2021')|\n",
    "                 (obs_data['Date']=='05/12/2021')|\n",
    "                 (obs_data['Date']=='05/13/2021')]\n",
    "\n",
    "obs_data['Total Flow'] = obs_data['# Vehicles - E-ZPass']+obs_data['# Vehicles - VToll']\n",
    "ST2.at['henry_hudson_bridge I','Target 5 - 05-2022'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='I')])\n",
    "ST2.at['henry_hudson_bridge O', 'Target 5 - 05-2022'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==24)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen I','Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Queen O', 'Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               # [(obs_data['Plaza ID']==21)&(obs_data['Direction']=='O')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "# Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh I','Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['robert_f_kennedy_bridge Manh O', 'Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "                                                               # [(obs_data['Plaza ID']==22)&(obs_data['Direction']=='O')])\n",
    "ST2.at['queens_midtown_tunnel I','Target 5 - 05-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='I')])\n",
    "ST2.at['queens_midtown_tunnel O', 'Target 5 - 05-2022'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==27)&(obs_data['Direction']=='O')])\n",
    "ST2.at['hugh_l_carey_tunnel I','Target 5 - 05-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='I')])\n",
    "ST2.at['hugh_l_carey_tunnel O', 'Target 5 - 05-2022'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==28)&(obs_data['Direction']=='O')])\n",
    "ST2.at['bronx_whitestone_bridge I','Target 5 - 05-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='I')])\n",
    "ST2.at['bronx_whitestone_bridge O', 'Target 5 - 05-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==23)&(obs_data['Direction']=='O')])\n",
    "ST2.at['throgs_neck_bridge I','Target 5 - 05-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='I')])\n",
    "ST2.at['throgs_neck_bridge O', 'Target 5 - 05-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==29)&(obs_data['Direction']=='O')])\n",
    "# ST2.at['varrazzano_narrows_bridge I','Target 4 - 08-2021'] =  np.mean(obs_data['Total Flow']\n",
    "#                                                                [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='I')])\n",
    "# ST2.at['varrazzano_narrows_bridge O', 'Target 4 - 08-2021'] =     np.mean(obs_data['Total Flow']\n",
    "                                                               # [(obs_data['Plaza ID']==30)&(obs_data['Direction']=='O')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 5 - 05-2022'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='I')])\n",
    "ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 5 - 05-2022'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==25)&(obs_data['Direction']=='O')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge I','Target 5 - 05-2022'] =    np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='I')])\n",
    "ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 5 - 05-2022'] =   np.mean(obs_data['Total Flow']\n",
    "                                                               [(obs_data['Plaza ID']==26)&(obs_data['Direction']=='O')])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total - only observed bridges/tunnels', 'Target 5 - 05-2022'] = (ST2.at['henry_hudson_bridge I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['henry_hudson_bridge O', 'Target 5 - 05-2022'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 5 - 05-2022'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 5 - 05-2022'])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total I- only observed bridges/tunnels', 'Target 5 - 05-2022'] = (ST2.at['henry_hudson_bridge I','Target 5 - 05-2022'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen I','Target 4 - 08-2021'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['throgs_neck_bridge I','Target 5 - 05-2022'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge I','Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge I','Target 5 - 05-2022'])\n",
    "ST2.at['MTA Bridge and Tunnel Counts Total O- only observed bridges/tunnels', 'Target 5 - 05-2022'] = (ST2.at['henry_hudson_bridge O', 'Target 5 - 05-2022'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Queen O', 'Target Baseline'] +\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx I','observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='I')])\n",
    "                                                            # Bridge_flows.at['robert_f_kennedy_bridge Bronx O', 'observed'] =  np.mean(obs_data['Total Flow']\n",
    "                                                            #                                                                [(obs_data['Plaza ID']==)&(obs_data['Direction']=='O')])\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh I','Target Baseline'] +\n",
    "                                                            # ST2.at['robert_f_kennedy_bridge Manh O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['queens_midtown_tunnel O', 'Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['hugh_l_carey_tunnel O', 'Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['bronx_whitestone_bridge O', 'Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['throgs_neck_bridge O', 'Target 5 - 05-2022'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge I','Target Baseline'] +\n",
    "                                                            # ST2.at['varrazzano_narrows_bridge O', 'Target 4 - 08-2021'] +\n",
    "                                                            ST2.at['marine_parkwaygil_hodges_memorial_bridge O', 'Target 5 - 05-2022'] +\n",
    "                                                            ST2.at['cross_bay_veterans_memorial_bridge O', 'Target 5 - 05-2022'])\n",
    "\n",
    "ST2.to_csv('outputs/validationNYC16.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344542df-9f03-41d1-8d57-d3a27be9dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ST = pd.read_csv('outputs/SummaryTable_Pilates_RHM5.csv', index_col = 'Unnamed: 0')\n",
    "\n",
    "#Validation RHM\n",
    "STRH = pd.DataFrame()\n",
    "\n",
    "for name in names:\n",
    "    \n",
    "    STRH.at['Trip Est Ride Hail', name] = ST.at['Trip Est Ride Hail', name]\n",
    "    STRH.at['Trip Est Ride Hail-Transit', name] = ST.at['Trip Est Ride Hail-Transit', name]\n",
    "    STRH.at['Trip Est Ride Hail Pooled', name] = ST.at['Trip Est Ride Hail Pooled', name]\n",
    "    STRH.at['Trip Mode Ride Hail', name] = ST.at['Trip Mode Ride Hail', name]\n",
    "    STRH.at['Trip Mode Ride Hail-Transit', name] = ST.at['Trip Mode Ride Hail-Transit', name]\n",
    "    STRH.at['Trip Mode Ride Hail Pooled', name] = ST.at['Trip Mode Ride Hail Pooled', name]\n",
    "    STRH.at['Trip Replan Ride Hail Share', name] = (ST.at['Trip Replan Ride Hail', name]+\n",
    "                                                    ST.at['Trip Replan Ride Hail-Transit', name]+\n",
    "                                                    ST.at['Trip Replan Ride Hail Pooled', name])/(ST.at['Trip Mode Ride Hail', name]+\n",
    "                                                                                                  ST.at['Trip Mode Ride Hail-Transit', name]+\n",
    "                                                                                                  ST.at['Trip Mode Ride Hail Pooled', name])\n",
    "                                                        \n",
    "    STRH.at['Trip Replan Ride Hail', name] = ST.at['Trip Replan Ride Hail', name]\n",
    "    STRH.at['Trip Replan Ride Hail-Transit', name] = ST.at['Trip Replan Ride Hail-Transit', name]\n",
    "    STRH.at['Trip Replan Ride Hail Pooled', name] = ST.at['Trip Replan Ride Hail Pooled', name]\n",
    "    STRH.at['Trip Exec Ride Hail', name] = ST.at['Trip Exec Ride Hail', name]\n",
    "    STRH.at['Trip Exec Ride Hail-Transit', name] = ST.at['Trip Exec Ride Hail-Transit', name]\n",
    "    STRH.at['Trip Exec Ride Hail Pooled', name] = ST.at['Trip Exec Ride Hail Pooled', name]\n",
    "    STRH.at['Percentage RH Pooled Trips', name] = (ST.at['Trip Exec Ride Hail Pooled', name])/(ST.at['Trip Exec Ride Hail', name]+ST.at['Trip Exec Ride Hail Pooled', name])\n",
    "    STRH.at['Daily Trips per RH Driver', name] = (ST.at['Trip Exec Ride Hail', name]+\n",
    "                                                 ST.at['Trip Exec Ride Hail-Transit', name]+\n",
    "                                                 ST.at['Trip Exec Ride Hail Pooled', name])/ST.at['Number RH vehicles', name]\n",
    "    STRH.at['Daily RH Trips', name] = (ST.at['Trip Exec Ride Hail', name]+\n",
    "                                                 ST.at['Trip Exec Ride Hail-Transit', name]+\n",
    "                                                 ST.at['Trip Exec Ride Hail Pooled', name])\n",
    "    STRH.at['VMT Ride Hail [km]', name] = ST.at['Length Vehicle SUM Ride Hail [km]', name]+ST.at['Length Vehicle SUM Empty Ride Hail [km]', name]\n",
    "    STRH.at['Length Vehicle AV Ride Hail [km]', name] = ST.at['Length Vehicle AV Ride Hail [km]', name]\n",
    "    STRH.at['Length Vehicle AV Empty Ride Hail [km]', name] = ST.at['Length Vehicle AV Empty Ride Hail [km]', name]\n",
    "    STRH.at['Share deadhead VMT', name] = STRH.at['Length Vehicle AV Empty Ride Hail [km]', name]/(STRH.at['Length Vehicle AV Ride Hail [km]', name]+STRH.at['Length Vehicle AV Empty Ride Hail [km]', name])\n",
    "    STRH.at['Duration Vehicle AV Ride Hail [h]', name] = ST.at['Duration Vehicle AV Ride Hail [h]', name]\n",
    "    STRH.at['Duration Vehicle AV Empty Ride Hail [h]', name] = ST.at['Duration Vehicle AV Empty Ride Hail [h]', name]\n",
    "    STRH.at['Duration Person AV Ride Hail [h]', name] = ST.at['Duration Person AV Ride Hail [h]', name]\n",
    "    STRH.at['Duration Person AV Empty Ride Hail [h]', name] = ST.at['Duration Person AV Empty Ride Hail [h]', name]\n",
    "    STRH.at['Speed Vehicle AV Ride Hail [km/h]', name] = (ST.at['Length Vehicle SUM Ride Hail [km]', name])/(\n",
    "                                                        ST.at['Duration Vehicle SUM Ride Hail [h]', name])\n",
    "    STRH.at['Number RH vehicles', name] = ST.at['Number RH vehicles', name]\n",
    "    STRH.at['AV Waiting Time RH [s]', name] = ST.at['AV Waiting Time RH', name]\n",
    "    STRH.at['AV Waiting Time RH Pooled [s]', name] = ST.at['AV Waiting Time RH Pooled', name]\n",
    "    STRH.at['AV Waiting Time RH Single [s]', name] = ST.at['AV Waiting Time RH Single', name]\n",
    "\n",
    "STRH.at['Number RH vehicles', 'CPUC'] = 16920\n",
    "STRH.at['Length Vehicle AV Ride Hail [km]', 'CPUC'] = 6.88*1.60934\n",
    "STRH.at['Length Vehicle AV Empty Ride Hail [km]', 'CPUC'] = 2.54*1.60934\n",
    "STRH.at['Daily Trips per RH Driver', 'CPUC'] = 26.8\n",
    "STRH.at['Daily RH Trips', 'CPUC'] = 353000\n",
    "STRH.at['Duration Vehicle AV Ride Hail [h]', 'CPUC'] = 0.286\n",
    "STRH.at['AV Waiting Time RH [s]', 'CPUC'] = 344\n",
    "STRH.at['Percentage RH Pooled Trips', 'CPUC'] = 0.14\n",
    "STRH.at['Speed Vehicle AV Ride Hail [km/h]', 'CPUC'] = 24.4*1.60934\n",
    "STRH.at['Trip Replan Ride Hail Share', 'CPUC'] = 0.018\n",
    "STRH.at['VMT Ride Hail [km]', 'CPUC'] = 3300000*1.60934\n",
    "\n",
    "STRH.at['Number RH vehicles', 'CPUC 10% Sample'] = 16920/10\n",
    "STRH.at['Length Vehicle AV Ride Hail [km]', 'CPUC 10% Sample'] = 6.88*1.60934\n",
    "STRH.at['Length Vehicle AV Empty Ride Hail [km]', 'CPUC 10% Sample'] = 2.54*1.60934\n",
    "STRH.at['Daily Trips per RH Driver', 'CPUC 10% Sample'] = 26.8\n",
    "STRH.at['Daily RH Trips', 'CPUC 10% Sample'] = 353000/10\n",
    "STRH.at['Duration Vehicle AV Ride Hail [h]', 'CPUC 10% Sample'] = 0.286\n",
    "STRH.at['AV Waiting Time RH [s]', 'CPUC 10% Sample'] = 344\n",
    "STRH.at['Percentage RH Pooled Trips', 'CPUC 10% Sample'] = 0.14\n",
    "STRH.at['Speed Vehicle AV Ride Hail [km/h]', 'CPUC 10% Sample'] = 24.4*1.60934\n",
    "STRH.at['Trip Replan Ride Hail Share', 'CPUC 10% Sample'] = 0.018\n",
    "STRH.at['VMT Ride Hail [km]', 'CPUC 10% Sample'] = 3300000*1.60934/10\n",
    "\n",
    "STRH.at['Share deadhead VMT', name] = STRH.at['Length Vehicle AV Empty Ride Hail [km]', 'CPUC 10% Sample']/(STRH.at['Length Vehicle AV Empty Ride Hail [km]', 'CPUC 10% Sample']+STRH.at['Length Vehicle AV Ride Hail [km]', 'CPUC 10% Sample'])\n",
    "\n",
    "\n",
    "STRH.to_csv('outputs/validationRH5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3951898e-febb-420e-be17-773b3390a39e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mergePathTraversals(names, PTss, PtoPTss):\n",
    "    print('---------------------------------------------------------------')\n",
    "    print('mergePathTraversals...')\n",
    "    start = time.time()\n",
    "    count = 0\n",
    "    for name in names:\n",
    "        PTs = PTss[name]\n",
    "        PtoPTs = PtoPTss[name]\n",
    "        PtoPTs_toappend = []\n",
    "        if count == 0:\n",
    "            MergedPTs = PTs\n",
    "            MergedPtoPTs = PtoPTs\n",
    "            len_initial_PtoPTs = len(MergedPtoPTs)\n",
    "            len_initial_PTs = len(MergedPTs)\n",
    "            print('len(MergedPTs)',len_initial_PTs)\n",
    "            print('len(MergedPtoPTs)',len_initial_PtoPTs)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            new_PtoPTs_rows_tr_exp = 0\n",
    "\n",
    "            print('modes recorded:',PTs['mode'].value_counts().keys())\n",
    "            print('you are considering walk, bike, car, bus, subway, rail, tram, ferry')\n",
    "            \n",
    "\n",
    "            #Public modes\n",
    "            PTs_Toup = PTs[(PTs['mode']=='bus')|(PTs['mode']=='subway')|(PTs['mode']=='rail')|(PTs['mode']=='tram')|(PTs['mode']=='ferry')]\n",
    "            PTs_indexes = list(PTs_Toup.index)\n",
    "            #Filtert public PtoPTs\n",
    "            PtoPTs_toadd = PtoPTs[PtoPTs['pathTraversalID'].isin(PTs_indexes)]\n",
    "            print('Pts to update for public transport mode',len(PTs_Toup))\n",
    "            #Group PTS per 'departureTime', 'vehicle','startX'\n",
    "            PTs_Toup_lookup = PTs_Toup.groupby(['departureTime', 'vehicle','startX','endY','duration']).apply(lambda x: [x.index,\n",
    "                                                    x.occupancy,x.passengerMiles,x.capacity]).to_dict()\n",
    "            #Group mergedPTS per 'departureTime', 'vehicle','startX'\n",
    "            MergedPTs_lookup = MergedPTs.groupby(['departureTime', 'vehicle','startX','endY','duration']).apply(lambda x: list(x.index)).to_dict()\n",
    "            \n",
    "            i=0\n",
    "            \n",
    "            a = time.time()\n",
    "            b = time.time()\n",
    "            for key, val in PTs_Toup_lookup.items():\n",
    "                #tracking remaining time\n",
    "                i+=1\n",
    "                if i%10000 == 0:\n",
    "                    print(i)\n",
    "                    print(time.time()-a,'remaining time:',(time.time()-a)*(len(PTs_Toup)-1)/10000-(a-b),'s')\n",
    "                    a = time.time()\n",
    "                try:\n",
    "                    #look for the relative pathtraversal index on first simulation\n",
    "                    index = MergedPTs_lookup[(key[0],key[1],key[2],key[3],key[4])]\n",
    "                    #check number of pathtraversal found...if more than one probably is due to zero durations\n",
    "                    if len(index)!=1:\n",
    "                        print('mmh...')\n",
    "                        print('too many correspondances in the Merged PTs',len(index))\n",
    "                        print(index)\n",
    "                        print('PTs to update: depTime, vehicle, startX,endY,duration,capacity,passengerMiles,occupancy-------->',\n",
    "                              key[0],key[1],key[2],key[3],key[4],[list(val[3])[0],list(val[2])[0],list(val[1])[0]])\n",
    "                        print('Merget Pts -------->',MergedPTs.loc[index[:], ['vehicle','departureTime','capacity','passengerMiles','occupancy','startX']])\n",
    "                    else:\n",
    "                        PtoPTs_toadd = PtoPTs.iloc[np.where(PtoPTs.pathTraversalID.values==list(val[0])[0])]\n",
    "                        new_PtoPTs_rows_tr_exp += list(val[1])[0]\n",
    "                        #check if we found the right number of PtoPTs to add\n",
    "                        if len(PtoPTs_toadd)!=list(val[1])[0]:\n",
    "                            print('hmm... not all VVP trips were found')\n",
    "                            print(list(val[1])[0], 'expected, ',len(PtoPTs_toadd), 'found' )\n",
    "                            print('PTs to update: depTime, vehicle, startX,endY,duration, capacity,passengerMiles,occupancy -------->',\n",
    "                                  key[0],key[1],key[2],key[3],key[4],[list(val[3])[0],list(val[2])[0],list(val[1])[0]])\n",
    "                            print('Merget Pts -------->',MergedPTs.loc[index[0], ['vehicle','departureTime','capacity','passengerMiles','occupancy','startX']])\n",
    "                            print('PtoPTs_toadd', PtoPTs_toadd)\n",
    "                        #PtoPTs update pathTraversalID and add to the merged file\n",
    "                        # agents = ''\n",
    "                        if len(PtoPTs_toadd)>0:\n",
    "                            PtoPTs_toadd['pathTraversalID'] = PtoPTs_toadd['pathTraversalID'].apply(lambda x: index[0])\n",
    "                            PtoPTs_toappend.append(PtoPTs_toadd)\n",
    "\n",
    "                            \n",
    "                            # is_first_agent = True\n",
    "                            # for person in list(PtoPTs_toadd['personID']):\n",
    "                            #     if is_first_agent:\n",
    "                            #         agents = ':%s'%(str(person))\n",
    "                            #         is_first_agent = False\n",
    "                            #     else:\n",
    "                            #         agents += ':%s'%(str(person))\n",
    "                        MergedPTs.loc[index[0], ['capacity','passengerMiles','occupancy']] += [list(val[3])[0],list(val[2])[0],list(val[1])[0]]\n",
    "                        # MergedPTs.loc[index[0], ['riders']] += agents\n",
    "\n",
    "\n",
    "                except:\n",
    "                    print('mmh...')\n",
    "                    print([(key[0],key[1],key[2],key[3],key[4])],'not in the merged PTs')\n",
    "\n",
    "                \n",
    "            MergedPtoPTs = pd.concat([MergedPtoPTs,pd.concat(PtoPTs_toappend)])\n",
    "            new_PtoPTs_rows_tr = len(pd.concat(PtoPTs_toappend))\n",
    "\n",
    "\n",
    "            print('---------------------------------------------------------------')\n",
    "            #Private modes\n",
    "            #filter PTs\n",
    "            PTs_toadd = PTs[(PTs['mode']=='walk')|(PTs['mode']=='car')|(PTs['mode']=='bike')]\n",
    "            #Update vehicle name\n",
    "            PTs_toadd.loc[:,'vehicle'] = PTs_toadd['vehicle'].astype(str) + '_' + str(count)\n",
    "            #Update indexes\n",
    "            PTs_indexes = list(PTs_toadd.index)\n",
    "            PTs_toadd.index = PTs_toadd.index+count*1000000000\n",
    "            #Merge PTs\n",
    "            MergedPTs = pd.concat([MergedPTs,PTs_toadd])\n",
    "            #Filter PtoPTs\n",
    "            PtoPTs_toadd = PtoPTs[PtoPTs['pathTraversalID'].isin(PTs_indexes)]\n",
    "            #Update vehicle name\n",
    "            PtoPTs_toadd.loc[:,'vehicleID'] = PtoPTs_toadd['vehicleID'].astype(str) + '_' + str(count)\n",
    "            #Update indexes\n",
    "            PtoPTs_toadd.loc[:,'pathTraversalID'] = PtoPTs_toadd['pathTraversalID']+count*1000000000\n",
    "            #Merge PTs\n",
    "            MergedPtoPTs = pd.concat([MergedPtoPTs,PtoPTs_toadd])\n",
    "            \n",
    "            new_PTs_rows = len(PTs_toadd)\n",
    "            new_PtoPTs_rows = len(PtoPTs_toadd)\n",
    "            new_PtoPTs_rows_exp = np.sum(PTs_toadd[PTs_toadd['mode']!='walk']['occupancy'])\n",
    "        print('---------------------------------------------------------------')\n",
    "        if count > 0:\n",
    "            print('len(MergedPTs)',len(MergedPTs))\n",
    "            print('len(MergedPtoPTs)',len(MergedPtoPTs))\n",
    "            print('new PtoPTs rows =',len(MergedPtoPTs)-len_initial_PtoPTs)\n",
    "            print('new PTs rows =',len(MergedPTs)-len_initial_PTs)\n",
    "            print('expected new PtoPTs rows no transit:',new_PtoPTs_rows_exp)\n",
    "            print('expected new PtoPTs rows transit:',new_PtoPTs_rows_tr_exp)\n",
    "            print('new PtoPTs rows no transit:',new_PtoPTs_rows)\n",
    "            print('new PtoPTs rows transit:',new_PtoPTs_rows_tr)\n",
    "            print('new PTs rows no transit:',new_PTs_rows)\n",
    "        count+=1\n",
    "        print('---------------------------------------------------------------')\n",
    "    print('Total time:', time.time()-start)\n",
    "    return MergedPTs, MergedPtoPTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d00d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PTss = {}\n",
    "PEVss = {}\n",
    "PLVss = {}\n",
    "tripss = {}\n",
    "Rpss = {}\n",
    "activitiess = {}\n",
    "personToTripDepartures = {}\n",
    "PtoPTss = {}\n",
    "MCss = {}\n",
    "EFPs = data.keys()\n",
    "PFPs = plan_names\n",
    "FP = fp\n",
    "for EFP, PFP, name in zip(EFPs, PFPs, names):\n",
    "    MCs, PTss[name], PEVss[name], PLVss[name], RPs, ASs = readEvents(FP+EFP)\n",
    "    MCs, PTss[name], PEVss[name], PLVss[name] = fixData(MCs, PTss[name], PEVss[name], PLVss[name], len_id_transit)\n",
    "    tripss[name], activitiess[name], personToTripDepartures[name], is_leg_mode = processPlans(FP+PFP)\n",
    "    PtoPTss[name] = personToPathTraversal(PTss[name],\n",
    "                    PEVss[name], PLVss[name], personToTripDepartures[name])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "print('total time', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc864b8-e327-4874-9438-f14a84dacd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter only Bus companies of interest\n",
    "# 151_631:t_ 143005 trips\n",
    "# Long_Islan 178710 trips\n",
    "# Metro-Nort 105896 trips\n",
    "# MTA_Bronx_ 420082 trips\n",
    "# MTA_Brookl 783452 trips\n",
    "# MTA_Manhat 444432 trips\n",
    "# MTA_Queens 290973 trips\n",
    "# MTA_Staten 188297 trips\n",
    "# NJ_Transit 778050 trips\n",
    "# NYC_Bus_Co 486766 trips\n",
    "# NYC_Ferry_ 9810 trips\n",
    "# NYC_Subway 4430783 trips  NO!\n",
    "# Staten_Isl 5419 trips\n",
    "# Suffolk_Co 1043 trips\n",
    "# WCDOT_2019 138950 trips\n",
    "PTss_copy = PTss\n",
    "PtoPTss_copy = PtoPTss\n",
    "for name in names:\n",
    "    print('len PTss[name] pre',len(PTss[name]))\n",
    "    PTss[name] = PTss[name][(PTss[name]['vehicle'].str.contains('151_631:t_'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('Long_Islan'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('Metro-Nort'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('MTA_Bronx_'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('MTA_Brookl'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('MTA_Manhat'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('MTA_Queens'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('MTA_Staten'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('NJ_Transit'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('NYC_Bus_Co'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('NYC_Ferry_'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('NYC_Subway'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('Staten_Isl'))|\n",
    "                            (PTss[name]['vehicle'].str.contains('WCDOT_2019'))|\n",
    "                            # (PTss[name]['vehicle'].str.contains('Suffolk_Co'))|\n",
    "                            # (PTss[name]['vehicle'].str.contains('NICE_117_2'))|\n",
    "                            # (PTss[name]['vehicle'].str.contains('PATH_20200'))|\n",
    "                            # (PTss[name]['vehicle'].str.contains('JFK_Airtra'))\n",
    "                            ]\n",
    "    print('len PTss[name] post',len(PTss[name]))\n",
    "    print('len PtoPTss[name] pre',len(PtoPTss[name]))\n",
    "    PtoPTss[name] = PtoPTss[name][(PtoPTss[name]['vehicleID'].str.contains('151_631:t_'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('Long_Islan'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('Metro-Nort'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('MTA_Bronx_'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('MTA_Brookl'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('MTA_Manhat'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('MTA_Queens'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('MTA_Staten'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('NJ_Transit'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('NYC_Bus_Co'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('NYC_Ferry_'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('NYC_Subway'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('Staten_Isl'))|\n",
    "                            (PtoPTss[name]['vehicleID'].str.contains('WCDOT_2019'))|\n",
    "                            # (PtoPTss[name]['vehicleID'].str.contains('Suffolk_Co'))|\n",
    "                            # (PtoPTss[name]['vehicleID'].str.contains('NICE_117_2'))|\n",
    "                            # (PtoPTss[name]['vehicleID'].str.contains('PATH_20200'))|\n",
    "                            # (PtoPTss[name]['vehicleID'].str.contains('JFK_Airtra'))\n",
    "                            ]\n",
    "    \n",
    "    print('len PtoPTss[name] post',len(PtoPTss[name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e88f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "transit_agencies = ['NJ_Transit_Rail', \n",
    "                    'NJ_Transit_Bus', \n",
    "                    '151_631:t_',\n",
    "                    'Long_Islan',\n",
    "                    'Metro-Nort',\n",
    "                    'MTA_Bronx_', \n",
    "                    'MTA_Brookl', \n",
    "                    'MTA_Manhat', \n",
    "                    'MTA_Queens', \n",
    "                    'MTA_Staten',\n",
    "                    'NYC_Bus_Co', \n",
    "                    'NYC_Ferry_', \n",
    "                    'NYC_Subway', \n",
    "                    'Staten_Island_Ferry',\n",
    "                    #'Suffolk_Co', \n",
    "                    'WCDOT_2019']\n",
    "MergedPTs = []\n",
    "MergedPtoPTs = []\n",
    "for transit_agency in transit_agencies: \n",
    "    PTss_agency = {}\n",
    "    PtoPTss_agency= {}\n",
    "    print('---------------------------------------------------------------')\n",
    "    print('Analyzing the agency', transit_agency)\n",
    "    print('---------------------------------------------------------------')\n",
    "    for name in names:\n",
    "        PTss_agency[name] = PTss[name][PTss[name]['vehicle'].str.contains(transit_agency)]\n",
    "        PtoPTss_agency[name] = PtoPTss[name][PtoPTss[name]['vehicleID'].str.contains(transit_agency)]\n",
    "    MergedPTs_agency, MergedPtoPTs_agency = mergePathTraversals(names, PTss_agency,PtoPTss_agency)\n",
    "    MergedPTs.append(MergedPTs_agency)\n",
    "    MergedPtoPTs.append(MergedPtoPTs_agency)\n",
    "\n",
    "MergedPTs_final = pd.concat(MergedPTs)\n",
    "MergedPtoPTs_final = pd.concat(MergedPtoPTs)\n",
    "\n",
    "#add riders\n",
    "riders = {}\n",
    "for person, i, pathID  in zip(MergedPtoPTs_final['personID'],range(len(MergedPtoPTs_final.index)),MergedPtoPTs_final['pathTraversalID']):\n",
    "    if i%1000000 == 0:\n",
    "        print(i, pathID)\n",
    "    if pathID in riders:\n",
    "        riders[pathID].append(person) \n",
    "    else:\n",
    "        riders[pathID] = [person] \n",
    "\n",
    "persons = []\n",
    "for pathID, i in zip(MergedPTs_final.index, range(len(MergedPTs_final.index))):\n",
    "    if i%1000000 == 0:\n",
    "        print(i, pathID)\n",
    "    if pathID in riders:\n",
    "        persons.append(riders[pathID])\n",
    "    else:\n",
    "        persons.append([])\n",
    "MergedPTs_final['riders']=persons\n",
    "\n",
    "right = 0\n",
    "not_right = 0\n",
    "for rider, occupancy, i in zip(MergedPTs_final['riders'],MergedPTs_final['occupancy'], range(len(MergedPTs_final.index))):\n",
    "    if i%100000 == 0:\n",
    "        print(i, pathID)\n",
    "    # if rider != []:\n",
    "        # print(len(rider), occupancy)\n",
    "    if len(rider) == occupancy:\n",
    "        right +=1\n",
    "    else:\n",
    "        not_right+=1\n",
    "print('right', right,'not_right', not_right)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MergedPtoPTs_final['agency'] = MergedPtoPTs_final['agency'].apply(lambda x: x[:10])\n",
    "#Update Nj transit agency\n",
    "agencies = []\n",
    "for vehicle, agency in zip(MergedPtoPTs_final['vehicleID'],MergedPtoPTs_final['agency']):\n",
    "    if 'NJ_Transit_Bus' in vehicle:\n",
    "        agencies.append('NJ_Transit_Bus')\n",
    "    elif 'NJ_Transit_Rail' in vehicle:\n",
    "        agencies.append('NJ_Transit_Rail')\n",
    "    else:\n",
    "        agencies.append(agency)\n",
    "MergedPtoPTs_final['agency'] = agencies\n",
    "print('total time', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c771ad-12ec-42bb-9ed0-bcacb4dd35b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check\n",
    "for agency in transit_agencies:\n",
    "    print(agency)\n",
    "    print(int(np.sum(PT_final2[PT_final2['vehicle'].str.contains(agency)]['occupancy'])))\n",
    "    MergedPtoPTs_final['agency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca4b08-5370-46b3-8064-adec6d3bd51a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check\n",
    "for agency in transit_agencies:\n",
    "    print(agency)\n",
    "    print(int(np.sum(PT_final2[PT_final2['vehicle'].str.contains(agency)]['occupancy'])))\n",
    "    MergedPtoPTs_final['agency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ffd1ca-0c4d-484a-9fb6-723a77e4bc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'Baseline'\n",
    "MergedPTs_final.to_csv('outputs/MergedPTs_NYC_'+name+'.csv.gz')\n",
    "MergedPtoPTs_final.to_csv('outputs/MergedPtoPTs_NYC_'+name+'.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c808c8a-6232-411f-8d4c-1d205394bc16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check\n",
    "for agency in transit_agencies:\n",
    "    print(agency)\n",
    "    print(int(np.sum(PT_final2[PT_final2['vehicle'].str.contains(agency)]['occupancy'])))\n",
    "    MergedPtoPTs_final['agency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da581a-12ec-4c69-943d-70972147b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(PtoPTss['links']=='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce0142b-ce23-462d-af89-63848414c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = 0\n",
    "modes = []\n",
    "for links, mode in zip(PtoPTss['links'],PtoPTss['mode']):\n",
    "    if len(links)==1:\n",
    "        wrong+=1\n",
    "        modes.append(mode)\n",
    "print(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce67c76-8b44-4243-983b-ff204dc037dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PtoPTss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea4dfa-0ec5-47e1-b289-448fafbd7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=PTs[PTs['links']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72f63d-1336-4487-af9a-b12e8b36b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa43b16-e0eb-44b5-bfda-44659938bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(modes,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed716be1-2da9-42fe-a176-5b88f19dfc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb0075-387a-442c-a19a-969a2db9f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "        network = pd.read_csv(fp+data_name[:-(len(data_name.split('/')[-1])+len(data_name.split('/')[-2])+len(data_name.split('/')[-3])+2)]+'network.csv.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6671669-2f50-4cec-8c0d-4c05667a5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad35b2-4db8-444d-8784-ea4e2fc9827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv('s3://beam-outputs/pilates-outputs/sfbay-rhprice0.5-rhfleet0.5-20220903/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz'\n",
    "                     ,nrows = 900000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a1d1e-58cf-4790-87be-e7ba5119be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[(events['type']=='ModeChoice')]['tripId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f3001-1e31-4737-a2ec-531b2baa084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('gs://beam-core-outputs/beam-core-outputs/sfbay-2010-accessibility-fleetpct-0.5-wheelchair-0.5-20220917/beam/year-2012-iteration-3/ITERS/it.0/0.events.csv.gz')\n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0203a41f-e2e3-479b-a6e8-509b995a8f7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9420c-7782-4984-9eb4-f79e2095ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\n",
    "                'https://opendata.arcgis.com/datasets/'\n",
    "                'San_Francisco_Bay_Region_2010_Census_Block_Groups.geojson')\n",
    "gdf = gpd.read_file(url, crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75785a2f-e1f0-4cbe-af64-76b407a6c87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c251472-458f-4376-aaf8-35be87d5ab40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

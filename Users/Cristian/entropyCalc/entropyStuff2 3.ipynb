{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely import Point\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Polygon\n",
    "import os\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables to declare and modify based on user preferences\n",
    "\n",
    "# Time/Bin length\n",
    "binLength = 1800 #By default, BEAMCORE outputs time in seconds, so for hour-length bins use 3600\n",
    "\n",
    "# mainDirectory  = '/Users/cpoliziani/Downloads/entropyCalc/'#In my case I have the codes in a directory and the images are in a sub-directory\n",
    "mainDirectory = 'C:\\\\Users\\\\jmckinney\\\\ForReadingData\\\\' #I just added this because this is what works on Jack's PC\n",
    "\n",
    "minParkTime = 600\n",
    "\n",
    "# zoningFilepath = 'BlockIDS/geo_export_2642a579-6c47-479f-b94c-0d5f27ccb433.shp'\n",
    "# zoningFilepath = 'Grids/grid1000.shp'\n",
    "zoningFilepath1 = 'Grids\\\\grid500.shp'\n",
    "zoningFilepath2 = 'Grids\\\\grid1000.shp'\n",
    "zoningFilepath3 = 'Grids\\\\grid5000.shp'\n",
    "zoningFilepath4 = 'Grids\\\\grid10000.shp'\n",
    "\n",
    "# Adjusted park times for zoomed in cases\n",
    "binLengthZoom = 600\n",
    "minParkTimeZoom = 300\n",
    "\n",
    "# Parameters that could be prompted or automated depending on the scenario\n",
    "startHour = 64800\n",
    "endHour = 86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CP I've put all the functions here at the beginning\n",
    "def create_grid(xmin, xmax, ymin, ymax, grid_size, crs=\"EPSG:3857\", output_file=\"grid.shp\"):\n",
    "    # Generate the coordinates for the grid\n",
    "    x_coords = np.arange(xmin, xmax, grid_size)\n",
    "    y_coords = np.arange(ymin, ymax, grid_size)\n",
    "\n",
    "    # Create polygons for each grid cell\n",
    "    polygons = []\n",
    "    for x in x_coords:\n",
    "        for y in y_coords:\n",
    "            # Define the polygon corners\n",
    "            poly = Polygon([(x, y), (x + grid_size, y), \n",
    "                            (x + grid_size, y + grid_size), (x, y + grid_size)])\n",
    "            polygons.append(poly)\n",
    "\n",
    "    # Create a GeoDataFrame with the grid polygons\n",
    "    grid = gpd.GeoDataFrame({'geometry': polygons}, crs=crs)\n",
    "    \n",
    "    grid['geoid'] = range(len(grid))\n",
    "    \n",
    "    # Save the grid to a shapefile\n",
    "    grid.to_file(output_file)\n",
    "    \n",
    "def parkingTimecol(df):\n",
    "    \"\"\"\n",
    "    Calculate the parking time for each vehicle trip in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df: A DataFrame containing daily vehicle information, including\n",
    "                       'vehicle', 'departureTime', and 'arrivalTime' columns.\n",
    "\n",
    "    Returns:\n",
    "    A new DataFrame with an additional column 'Parking Time' \n",
    "                  representing the total parking time for each vehicle.\n",
    "    \"\"\"\n",
    "    vehicleList = df['vehicle'].unique()\n",
    "    column = []\n",
    "    for item in vehicleList:\n",
    "        subdf = df.loc[df['vehicle'] == item].copy() \n",
    "        subdf = subdf.sort_values(by = 'departureTime', ignore_index = True)\n",
    "        firstDepart = subdf['departureTime'].iloc[0]\n",
    "        subdf['departureTime'] = subdf['departureTime'].shift(-1) \n",
    "        subdf.loc[subdf.index[-1], 'departureTime'] = firstDepart + 24 * 3600  \n",
    "        subdf.loc[:, 'Parking Time'] = subdf['departureTime'] - subdf['arrivalTime'] \n",
    "        column.append(subdf)\n",
    "    return pd.concat(column)  \n",
    "\n",
    "def travelLengthCol(df):\n",
    "    \"\"\"\n",
    "    Calculate the daily cumulative travel length for each vehicle trip in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df: A DataFrame containing vehicle information, including\n",
    "                       'vehicle' and 'length' columns.\n",
    "\n",
    "    Returns:\n",
    "    A new DataFrame with an additional column 'Cumulative Travel Length' \n",
    "                  representing the total distance traveled by each vehicle.\n",
    "    \"\"\"\n",
    "    vehicleList = df['vehicle'].unique()\n",
    "    distanceTraveled = []\n",
    "    for item in vehicleList:\n",
    "        subdf = df.loc[df['vehicle'] == item].copy() \n",
    "        subdf = subdf.sort_values(by = 'departureTime', ignore_index = True)\n",
    "        subdf.loc[:, 'Cumulative Travel Length'] = subdf['length'].cumsum()  \n",
    "        distanceTraveled.append(subdf)\n",
    "    return pd.concat(distanceTraveled) \n",
    "\n",
    "def timeCorrecter(df):\n",
    "    \"\"\"\n",
    "    Transform Parking time column into a list of parking times per time bin\n",
    "    Time bins start from 0 and advance by binLength\n",
    "    \n",
    "    \"\"\"\n",
    "    listoflists = []\n",
    "    for index, row in df.iterrows():\n",
    "        listalike = []\n",
    "        parkResult = divmod(row['Parking Time'], binLength)\n",
    "        arriveResult = divmod(row['arrivalTime'], binLength)\n",
    "        i = 0\n",
    "        while i < parkResult[0]:\n",
    "            listalike.append(binLength)\n",
    "            i += 1\n",
    "        listalike.append(parkResult[1])\n",
    "        listalike[0] = listalike[0] - arriveResult[1]\n",
    "        listalike[-1] = listalike[-1] + arriveResult[1]\n",
    "        if listalike[-1] > binLength:\n",
    "            listalike[-1] = listalike[-1] - binLength\n",
    "            listalike.insert(-1, binLength)\n",
    "        listoflists.append(listalike)\n",
    "    return listoflists\n",
    "\n",
    "\n",
    "\n",
    "#CP I'd separate the entropy calculation from the entropy plot functions: have a unique entropy calculation file, and multiple plot functions\n",
    "\n",
    "def entropyPlot5(result_gdf):\n",
    "    #CP groupby geoid - might want to groupy by a new variable that you specify at the beginning as an input\n",
    "    #e.g. groupVariable = 'geoid' or 'link'\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plt.suptitle('Heatmap of Entropy by Location', y = 0.95)\n",
    "    plt.title(time)\n",
    "\n",
    "    img = result_gdf.plot(column = 'Entropy',\n",
    "                                cmap = 'Reds',\n",
    "                                ax = ax,\n",
    "                                legend = True,\n",
    "                                vmin = 0,\n",
    "                                vmax = 0.05\n",
    "                                )\n",
    "#SF     xlim=(-13650000, -13600000)\n",
    "#SF     ylim=(4530000, 4570000)    \n",
    "    xlim=(-13755000, -13485000)\n",
    "    ylim=(4420000, 4705000)\n",
    "    \n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, zoom=10, alpha = 0.4)\n",
    "    #plt.savefig(mainDirectory + 'images/heatmap' + str(time) +'.png', dpi = 100)\n",
    "    plt.savefig(mainDirectory + 'images\\\\heatmap' + str(time) +'.png', dpi = 100)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for higher resolution times, lower time range runs\n",
    "\n",
    "def timeCorrecterZoom(df):\n",
    "    \"\"\"\n",
    "    Transform Parking time column into a list of parking times per time bin\n",
    "    Time bins start from 0 and advance by binLength\n",
    "    \n",
    "    \"\"\"\n",
    "    listoflists = []\n",
    "    for index, row in df.iterrows():\n",
    "        listalike = []\n",
    "        parkResult = divmod(row['Parking Time'], binLengthZoom)\n",
    "        arriveResult = divmod(row['arrivalTime'], binLengthZoom)\n",
    "        i = 0\n",
    "        while i < parkResult[0]:\n",
    "            listalike.append(binLengthZoom)\n",
    "            i += 1\n",
    "        listalike.append(parkResult[1])\n",
    "        listalike[0] = listalike[0] - arriveResult[1]\n",
    "        listalike[-1] = listalike[-1] + arriveResult[1]\n",
    "        if listalike[-1] > binLengthZoom:\n",
    "            listalike[-1] = listalike[-1] - binLengthZoom\n",
    "            listalike.insert(-1, binLengthZoom)\n",
    "        listoflists.append(listalike)\n",
    "    return listoflists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing the BEAM CORE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Activate only when creating new grids\n",
    "\n",
    "# Create a grid shapefile\n",
    "# Inputs for the grid creation (you can easily change these)\n",
    "xmin = -13755000 # X min boundary\n",
    "xmax = -13485000# X max boundary\n",
    "ymin = 4420000    # Y min boundary\n",
    "ymax = 4705000  # Y max boundary\n",
    "grid_size = 500# Grid size in meters (1km)\n",
    "name = 'grid500'\n",
    "# Call the function to create the grid and save as shapefile\n",
    "create_grid(xmin, xmax, ymin, ymax, grid_size, crs='EPSG:3857', output_file= mainDirectory+'Grids\\\\'+name+'.shp')\n",
    "\n",
    "# Read and filter data\n",
    "events = pd.read_csv('https://storage.googleapis.com/beam-core-outputs/sfbay-tr_capacity_1_5-20230608/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz', \n",
    "                     usecols = [\n",
    "#                          'time',\n",
    "                                'length',\n",
    "                                'arrivalTime',\n",
    "                                'departureTime',\n",
    "                                'primaryFuelType',\n",
    "                                'vehicle',\n",
    "                                'mode',\n",
    "                                'type', \n",
    "#                                 'link',\n",
    "#                                 'links',\n",
    "#                                 'linkTravelTime', \n",
    "#                                 'startX',\n",
    "#                                 'startY',\n",
    "                                'endX',\n",
    "                                'endY'],\n",
    "#                     nrows = 10000000 # to have a smaller DF\n",
    "                    )\n",
    "\n",
    "#Slicing and merging dataframes\n",
    "print('Total Events: ', len(events))\n",
    "PTs = events.loc[events['type'] == 'PathTraversal']\n",
    "print('Total PathTraversal: ', len(PTs))\n",
    "PTs = PTs.drop(columns = 'type')\n",
    "\n",
    "PTs = PTs[PTs['arrivalTime']<104400]\n",
    "print('Total PathTraversal after filtering Arrival < 5am of Successive Day: ', len(PTs))\n",
    "\n",
    "\n",
    "print('Simulated PathTraversal Modes: ',PTs['mode'].value_counts())\n",
    "#More slicing, this time specifically isolating the electric cars in the events files\n",
    "PTs = PTs.loc[events['mode'].isin(['car',\n",
    "                                         'car_hov2',\n",
    "                                         'car_hov3',\n",
    "#                                          'ride_hail',\n",
    "#                                          'ride_hail_pooled',\n",
    "                                        ])]\n",
    "print('Total Length Car PathTraversal: ', len(PTs))\n",
    "PTs = PTs.loc[PTs['primaryFuelType'] == 'Electricity']\n",
    "print('Total Length Electric Car PathTraversal: ', len(PTs))\n",
    "PTs = PTs.drop(columns = ['mode','primaryFuelType'])\n",
    "\n",
    "#Sorting the rows by vehicle and then by departure time, making the accumulation sums easier to manage\n",
    "PTs = PTs.sort_values(by = ['vehicle', 'departureTime'], ignore_index = True)\n",
    "\n",
    "print('Total Travel Length in km',PTs['length'].sum()/1000)\n",
    "\n",
    "\n",
    "PTs.to_csv(mainDirectory + 'elecCarTrace.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTs2 = PTs.copy()\n",
    "# Calculate Parking Time\n",
    "PTs2 = parkingTimecol(PTs2)\n",
    "print('Total Parking Time in Hours',PTs2['Parking Time'].sum()/3600)\n",
    "\n",
    "\n",
    "# Calculate Cumulative Length\n",
    "PTs2 = travelLengthCol(PTs2)\n",
    "PTs2 = PTs2.drop(columns = ['length'])\n",
    "\n",
    "# Calculate Last Link\n",
    "# elecCarTrace['last_link'] = elecCarTrace['links'].str.split(',').apply(lambda x: x[-1])\n",
    "# elecCarTrace = elecCarTrace.drop(columns=['links'])\n",
    "\n",
    "#Filter small parking time and zero lengths\n",
    "#PTs2 = PTs2[PTs2['Parking Time']>minParkTime]\n",
    "PTs2 = PTs2[PTs2['Parking Time']>minParkTimeZoom]\n",
    "\n",
    "PTs2 = PTs2[PTs2['Cumulative Travel Length']>0]\n",
    "\n",
    "# Make sure it's still in order\n",
    "PTs2 = PTs2.sort_values(by=['vehicle', 'departureTime'], ignore_index=True)\n",
    "\n",
    "PTs2.reset_index(drop = True, inplace = True)\n",
    "\n",
    "PTs2.to_csv(mainDirectory + 'elecCarTrace2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "elecCarTrace = PTs2.copy()\n",
    "\n",
    "binLabel = np.divmod(elecCarTrace['arrivalTime'], binLength)\n",
    "elecCarTrace['Bin Label'] = binLabel[0]\n",
    "\n",
    "\n",
    "# Transfor the parking time column in lists of parking times per bin\n",
    "elecCarTrace['Parking Time'] = timeCorrecter(elecCarTrace)\n",
    "elecCarTrace = elecCarTrace.sort_values(by=['vehicle', 'departureTime'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "elecCarTrace = PTs2.copy()\n",
    "\n",
    "binLabel = np.divmod(elecCarTrace['arrivalTime'], binLengthZoom)\n",
    "elecCarTrace['Bin Label'] = binLabel[0]\n",
    "\n",
    "\n",
    "# Transfor the parking time column in lists of parking times per bin\n",
    "elecCarTrace['Parking Time'] = timeCorrecterZoom(elecCarTrace)\n",
    "elecCarTrace = elecCarTrace.sort_values(by=['vehicle', 'departureTime'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "elecCarTrace = PTs2.copy()\n",
    "\n",
    "binLabel = np.divmod(elecCarTrace['arrivalTime'], binLength)\n",
    "elecCarTrace['Bin Label'] = binLabel[0]\n",
    "\n",
    "\n",
    "# Transfor the parking time column in lists of parking times per bin\n",
    "elecCarTrace['Parking Time'] = timeCorrecter(elecCarTrace)\n",
    "elecCarTrace = elecCarTrace.sort_values(by=['vehicle', 'departureTime'], ignore_index=True)\n",
    "'''\n",
    "\n",
    "def assign_sequence(lst):\n",
    "    return [(i, val) for i, val in enumerate(lst)]  # (sequence_number, value)\n",
    "\n",
    "# Apply the function to 'Parking Time' to associate a sequence number\n",
    "elecCarTrace['Parking Time'] = elecCarTrace['Parking Time'].apply(assign_sequence)\n",
    "\n",
    "# Separate the sequence number and the 'Parking Time' into two columns\n",
    "elecCarTrace = elecCarTrace.explode('Parking Time')\n",
    "elecCarTrace['sequence_number'], elecCarTrace['Parking Time'] = zip(*elecCarTrace['Parking Time'])\n",
    "elecCarTrace['Bin Label'] += elecCarTrace['sequence_number']\n",
    "# Optionally reset the index if needed and sort if necessary\n",
    "elecCarTrace.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "#Transfor Bin column into actual time in seconds\n",
    "#elecCarTrace['Bin Label'] = elecCarTrace['Bin Label'] * binLength\n",
    "elecCarTrace['Bin Label'] = elecCarTrace['Bin Label'] * binLengthZoom\n",
    "\n",
    "#Calculate Charging Opportunity\n",
    "elecCarTrace['Charging Opportunity'] = elecCarTrace['Parking Time'] * elecCarTrace['Cumulative Travel Length']\n",
    "elecCarTrace['Charging Opportunity'] = elecCarTrace['Charging Opportunity'].astype(float)\n",
    "\n",
    "#Add up time bins from the second day to the first day\n",
    "elecCarTrace.loc[elecCarTrace['Bin Label'] >= 24*3600 , 'Bin Label'] -= 24 *3600\n",
    "print('Total Chargin Opportunities Entries:', len(elecCarTrace))\n",
    "elecCarTrace = elecCarTrace[elecCarTrace['Bin Label']<=24*3600]\n",
    "print('Total Chargin Opportunities Entries after filtering people departing for the first time after midnight:', len(elecCarTrace))\n",
    "\n",
    "\n",
    "#CP moved this here\n",
    "#Add block group info and normalize by area\n",
    "#CP try differnt geometries\n",
    "elecCarTrace = gpd.GeoDataFrame(elecCarTrace, geometry=gpd.points_from_xy(elecCarTrace['endX'], elecCarTrace['endY']))\n",
    "elecCarTrace = elecCarTrace.set_crs(epsg=4326)\n",
    "elecCarTrace = elecCarTrace.to_crs(epsg=3857)\n",
    "#block_groups_gdf = gpd.read_file(zoningFilepath)[['geoid','geometry']]\n",
    "block_groups_gdf = gpd.read_file(mainDirectory+zoningFilepath2)[['geoid','geometry']]\n",
    "if block_groups_gdf.crs != elecCarTrace.crs: block_groups_gdf = block_groups_gdf.to_crs(elecCarTrace.crs)\n",
    "elecCarTrace = gpd.sjoin(elecCarTrace, block_groups_gdf[['geoid','geometry']], how='left', op='within')\n",
    "print('Total Chargin Opportunities Entries with Valid Block Group:', len(elecCarTrace))\n",
    "elecCarTrace = elecCarTrace.drop(columns=['geometry'])\n",
    "elecCarTrace = elecCarTrace.merge(block_groups_gdf[['geoid','geometry']], how ='left', on = 'geoid')\n",
    "elecCarTrace = gpd.GeoDataFrame(elecCarTrace, geometry='geometry')\n",
    "\n",
    "\n",
    "elecCarTrace.to_csv(mainDirectory + 'elecCarTrace3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "elecCarTrace = elecCarTrace.loc[(elecCarTrace['Bin Label'] < endHour) & (elecCarTrace['Bin Label'] > startHour)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elecCarTrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Different Functions for Entropy Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_entropy_list = []\n",
    "total_opportunity_list = []\n",
    "time_labels = []\n",
    "\n",
    "for time in elecCarTrace['Bin Label'].sort_values().unique():\n",
    "    \n",
    "    print('Time', time)\n",
    "    time_labels.append(time) \n",
    "    \n",
    "    subdf = elecCarTrace.loc[elecCarTrace['Bin Label'] == time]\n",
    "    \n",
    "    result_gdf = subdf.groupby(['geoid']).agg(\n",
    "        {'Charging Opportunity': 'sum', \n",
    "        'geometry': 'first', \n",
    "        }    ).reset_index()\n",
    "    \n",
    "    result_gdf = gpd.GeoDataFrame(result_gdf, geometry='geometry')\n",
    "    \n",
    "    totalChargingOpportunity = subdf['Charging Opportunity'].sum()\n",
    "    print('Total Charging Opportunity', totalChargingOpportunity)\n",
    "    total_opportunity_list.append(totalChargingOpportunity)\n",
    "    \n",
    "    #Calculate Entropy of charging opportunity density\n",
    "    result_gdf['Density Charging Opportunity'] = result_gdf['Charging Opportunity'].div(result_gdf.geometry.area)\n",
    "    totalJunk = result_gdf['Density Charging Opportunity'].sum()\n",
    "    result_gdf['Probability'] = result_gdf['Density Charging Opportunity'] / totalJunk\n",
    "    result_gdf['Entropy'] = -result_gdf['Probability'] * np.log(result_gdf['Probability'])\n",
    "    \n",
    "    totalEntropy = result_gdf['Entropy'].sum()\n",
    "    print('Total Entropy', totalEntropy)\n",
    "    total_entropy_list.append(totalEntropy)\n",
    "\n",
    "    entropyPlot5(result_gdf)\n",
    "    \n",
    "\n",
    "#Plot Entropy\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot total charging opportunity on the first axis\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Total Charging Opportunity', color='tab:blue')\n",
    "ax1.plot(time_labels, total_opportunity_list, label='Total Charging Opportunity', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a second y-axis for the total entropy\n",
    "ax2 = ax1.twinx()  # Instantiate a second y-axis that shares the same x-axis\n",
    "ax2.set_ylabel('Total Entropy', color='tab:red')\n",
    "ax2.plot(time_labels, total_entropy_list, label='Total Entropy', color='tab:red')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# Add a title and display the plot\n",
    "plt.title('Temporal Evolution of Total Charging Opportunity and Total Entropy')\n",
    "fig.tight_layout()  # To prevent overlap of labels\n",
    "plt.savefig(mainDirectory + 'timeEvolution.png', dpi = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'images'\n",
    "#image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "image_files = [os.path.join(mainDirectory+image_dir, f) for f in os.listdir(mainDirectory+image_dir) if f.endswith('.png')]\n",
    "image_files = sorted(image_files, key=os.path.getmtime, reverse=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Function to update the plot for each frame\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    image = plt.imread(image_files[i])\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, extent = None)\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, animate, frames=len(image_files), interval=200)\n",
    "\n",
    "# Save the animation\n",
    "ani.save(mainDirectory + '/animation.gif', writer='pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cpoliziani/opt/miniconda3/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.11.3-CAPI-1.17.3) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_99002/3154988767.py:8: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely import Point\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import contextily as ctx\n",
    "from shapely.geometry import Polygon\n",
    "import os\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables to declare and modify based on user preferences\n",
    "\n",
    "# Time/Bin length\n",
    "binLength = 1800 #By default, BEAMCORE outputs time in seconds, so for hour-length bins use 3600\n",
    "\n",
    "mainDirectory  = '/Users/cpoliziani/Downloads/entropyCalc/'#In my case I have the codes in a directory and the images are in a sub-directory\n",
    "\n",
    "minParkTime = 600\n",
    "\n",
    "# zoningFilepath = 'BlockIDS/geo_export_2642a579-6c47-479f-b94c-0d5f27ccb433.shp'\n",
    "zoningFilepath = 'Grids/grid1000.shp'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CP I've put all the functions here at the beginning\n",
    "def create_grid(xmin, xmax, ymin, ymax, grid_size, crs=\"EPSG:3857\", output_file=\"grid.shp\"):\n",
    "    # Generate the coordinates for the grid\n",
    "    x_coords = np.arange(xmin, xmax, grid_size)\n",
    "    y_coords = np.arange(ymin, ymax, grid_size)\n",
    "\n",
    "    # Create polygons for each grid cell\n",
    "    polygons = []\n",
    "    for x in x_coords:\n",
    "        for y in y_coords:\n",
    "            # Define the polygon corners\n",
    "            poly = Polygon([(x, y), (x + grid_size, y), \n",
    "                            (x + grid_size, y + grid_size), (x, y + grid_size)])\n",
    "            polygons.append(poly)\n",
    "\n",
    "    # Create a GeoDataFrame with the grid polygons\n",
    "    grid = gpd.GeoDataFrame({'geometry': polygons}, crs=crs)\n",
    "    \n",
    "    grid['geoid'] = range(len(grid))\n",
    "    \n",
    "    # Save the grid to a shapefile\n",
    "    grid.to_file(output_file)\n",
    "    \n",
    "def parkingTimecol(df):\n",
    "    \"\"\"\n",
    "    Calculate the parking time for each vehicle trip in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df: A DataFrame containing daily vehicle information, including\n",
    "                       'vehicle', 'departureTime', and 'arrivalTime' columns.\n",
    "\n",
    "    Returns:\n",
    "    A new DataFrame with an additional column 'Parking Time' \n",
    "                  representing the total parking time for each vehicle.\n",
    "    \"\"\"\n",
    "    vehicleList = df['vehicle'].unique()\n",
    "    column = []\n",
    "    for item in vehicleList:\n",
    "        subdf = df.loc[df['vehicle'] == item].copy() \n",
    "        subdf = subdf.sort_values(by = 'departureTime', ignore_index = True)\n",
    "        firstDepart = subdf['departureTime'].iloc[0]\n",
    "        subdf['departureTime'] = subdf['departureTime'].shift(-1) \n",
    "        subdf.loc[subdf.index[-1], 'departureTime'] = firstDepart + 24 * 3600  \n",
    "        subdf.loc[:, 'Parking Time'] = subdf['departureTime'] - subdf['arrivalTime'] \n",
    "        column.append(subdf)\n",
    "    return pd.concat(column)  \n",
    "\n",
    "def travelLengthCol(df):\n",
    "    \"\"\"\n",
    "    Calculate the daily cumulative travel length for each vehicle trip in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df: A DataFrame containing vehicle information, including\n",
    "                       'vehicle' and 'length' columns.\n",
    "\n",
    "    Returns:\n",
    "    A new DataFrame with an additional column 'Cumulative Travel Length' \n",
    "                  representing the total distance traveled by each vehicle.\n",
    "    \"\"\"\n",
    "    vehicleList = df['vehicle'].unique()\n",
    "    distanceTraveled = []\n",
    "    for item in vehicleList:\n",
    "        subdf = df.loc[df['vehicle'] == item].copy() \n",
    "        subdf = subdf.sort_values(by = 'departureTime', ignore_index = True)\n",
    "        subdf.loc[:, 'Cumulative Travel Length'] = subdf['length'].cumsum()  \n",
    "        distanceTraveled.append(subdf)\n",
    "    return pd.concat(distanceTraveled) \n",
    "\n",
    "def timeCorrecter(df):\n",
    "    \"\"\"\n",
    "    Transform Parking time column into a list of parking times per time bin\n",
    "    Time bins start from 0 and advance by binLength\n",
    "    \n",
    "    \"\"\"\n",
    "    listoflists = []\n",
    "    for index, row in df.iterrows():\n",
    "        listalike = []\n",
    "        parkResult = divmod(row['Parking Time'], binLength)\n",
    "        arriveResult = divmod(row['arrivalTime'], binLength)\n",
    "        i = 0\n",
    "        while i < parkResult[0]:\n",
    "            listalike.append(binLength)\n",
    "            i += 1\n",
    "        listalike.append(parkResult[1])\n",
    "        listalike[0] = listalike[0] - arriveResult[1]\n",
    "        listalike[-1] = listalike[-1] + arriveResult[1]\n",
    "        if listalike[-1] > binLength:\n",
    "            listalike[-1] = listalike[-1] - binLength\n",
    "            listalike.insert(-1, binLength)\n",
    "        listoflists.append(listalike)\n",
    "    return listoflists\n",
    "\n",
    "\n",
    "\n",
    "#CP I'd separate the entropy calculation from the entropy plot functions: have a unique entropy calculation file, and multiple plot functions\n",
    "\n",
    "def entropyPlot5(result_gdf):\n",
    "    #CP groupby geoid - might want to groupy by a new variable that you specify at the beginning as an input\n",
    "    #e.g. groupVariable = 'geoid' or 'link'\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plt.suptitle('Heatmap of Entropy by Location', y = 0.95)\n",
    "    plt.title(time)\n",
    "\n",
    "    img = result_gdf.plot(column = 'Entropy',\n",
    "                                cmap = 'Reds',\n",
    "                                ax = ax,\n",
    "                                legend = True,\n",
    "                                vmin = 0,\n",
    "                                vmax = 0.05\n",
    "                                )\n",
    "#SF     xlim=(-13650000, -13600000)\n",
    "#SF     ylim=(4530000, 4570000)    \n",
    "    xlim=(-13755000, -13485000)\n",
    "    ylim=(4420000, 4705000)\n",
    "    \n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    \n",
    "    plt.savefig(mainDirectory + 'images/heatmap' + str(time) +'.png', dpi = 100)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing the BEAM CORE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h9/g8d27p9s5js3dx9z7b5y8k5c0000gr/T/ipykernel_99002/791406502.py:3: DtypeWarning: Columns (24,25,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  events = pd.read_csv('https://storage.googleapis.com/beam-core-outputs/sfbay-tr_capacity_1_5-20230608/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Events:  36807426\n",
      "Total PathTraversal:  8968315\n",
      "Total PathTraversal after filtering Arrival < 5m of Successive Day:  8955881\n",
      "Simulated PathTraversal Modes:  walk         4153525\n",
      "car          2693381\n",
      "bus          1285026\n",
      "car_hov2      407358\n",
      "car_hov3      287333\n",
      "tram           54929\n",
      "bike           40360\n",
      "cable_car      17836\n",
      "subway         14358\n",
      "rail            1702\n",
      "ferry             73\n",
      "Name: mode, dtype: int64\n",
      "Total Length Car PathTraversal:  3388072\n",
      "Total Length Electric Car PathTraversal:  11116\n",
      "Total Travel Length in km 71445.74804699999\n"
     ]
    }
   ],
   "source": [
    "########### Activate only when creating new grids\n",
    "\n",
    "# # Create a grid shapefile\n",
    "# # Inputs for the grid creation (you can easily change these)\n",
    "# xmin = -13755000 # X min boundary\n",
    "# xmax = -13485000# X max boundary\n",
    "# ymin = 4420000    # Y min boundary\n",
    "# ymax = 4705000  # Y max boundary\n",
    "# grid_size = 500# Grid size in meters (1km)\n",
    "# name = 'grid500'\n",
    "\n",
    "# # Call the function to create the grid and save as shapefile\n",
    "# create_grid(xmin, xmax, ymin, ymax, grid_size, crs='EPSG:3857', output_file= mainDirectory+'Grids/'+name+'.shp')\n",
    "\n",
    "# Read and filter data\n",
    "events = pd.read_csv('https://storage.googleapis.com/beam-core-outputs/sfbay-tr_capacity_1_5-20230608/beam/year-2020-iteration-4/ITERS/it.0/0.events.csv.gz', \n",
    "                     usecols = [\n",
    "#                          'time',\n",
    "                                'length',\n",
    "                                'arrivalTime',\n",
    "                                'departureTime',\n",
    "                                'primaryFuelType',\n",
    "                                'vehicle',\n",
    "                                'mode',\n",
    "                                'type', \n",
    "#                                 'link',\n",
    "#                                 'links',\n",
    "#                                 'linkTravelTime', \n",
    "#                                 'startX',\n",
    "#                                 'startY',\n",
    "                                'endX',\n",
    "                                'endY'],\n",
    "#                     nrows = 10000000 # to have a smaller DF\n",
    "                    )\n",
    "\n",
    "#Slicing and merging dataframes\n",
    "print('Total Events: ', len(events))\n",
    "PTs = events.loc[events['type'] == 'PathTraversal']\n",
    "print('Total PathTraversal: ', len(PTs))\n",
    "PTs = PTs.drop(columns = 'type')\n",
    "\n",
    "PTs = PTs[PTs['arrivalTime']<104400]\n",
    "print('Total PathTraversal after filtering Arrival < 5am of Successive Day: ', len(PTs))\n",
    "\n",
    "\n",
    "print('Simulated PathTraversal Modes: ',PTs['mode'].value_counts())\n",
    "#More slicing, this time specifically isolating the electric cars in the events files\n",
    "PTs = PTs.loc[events['mode'].isin(['car',\n",
    "                                         'car_hov2',\n",
    "                                         'car_hov3',\n",
    "#                                          'ride_hail',\n",
    "#                                          'ride_hail_pooled',\n",
    "                                        ])]\n",
    "print('Total Length Car PathTraversal: ', len(PTs))\n",
    "PTs = PTs.loc[PTs['primaryFuelType'] == 'Electricity']\n",
    "print('Total Length Electric Car PathTraversal: ', len(PTs))\n",
    "PTs = PTs.drop(columns = ['mode','primaryFuelType'])\n",
    "\n",
    "#Sorting the rows by vehicle and then by departure time, making the accumulation sums easier to manage\n",
    "PTs = PTs.sort_values(by = ['vehicle', 'departureTime'], ignore_index = True)\n",
    "\n",
    "print('Total Travel Length in km',PTs['length'].sum()/1000)\n",
    "\n",
    "\n",
    "PTs.to_csv(mainDirectory + 'elecCarTrace.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTs2 = PTs.copy()\n",
    "# Calculate Parking Time\n",
    "PTs2 = parkingTimecol(PTs2)\n",
    "print('Total Parking Time in Hours',PTs2['Parking Time'].sum()/3600)\n",
    "\n",
    "# Calculate Cumulative Length\n",
    "PTs2 = travelLengthCol(PTs2)\n",
    "PTs2 = PTs2.drop(columns = ['length'])\n",
    "\n",
    "# Calculate Last Link\n",
    "# elecCarTrace['last_link'] = elecCarTrace['links'].str.split(',').apply(lambda x: x[-1])\n",
    "# elecCarTrace = elecCarTrace.drop(columns=['links'])\n",
    "\n",
    "#Filter small parking time and zero lengths\n",
    "PTs2 = PTs2[PTs2['Parking Time']>minParkTime]\n",
    "PTs2 = PTs2[PTs2['Cumulative Travel Length']>0]\n",
    "\n",
    "# Make sure it's still in order\n",
    "PTs2 = PTs2.sort_values(by=['vehicle', 'departureTime'], ignore_index=True)\n",
    "\n",
    "PTs2.reset_index(drop = True, inplace = True)\n",
    "\n",
    "PTs2.to_csv(mainDirectory + 'elecCarTrace2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "elecCarTrace = PTs2.copy()\n",
    "\n",
    "binLabel = np.divmod(elecCarTrace['arrivalTime'], binLength)\n",
    "elecCarTrace['Bin Label'] = binLabel[0]\n",
    "\n",
    "\n",
    "# Transfor the parking time column in lists of parking times per bin\n",
    "elecCarTrace['Parking Time'] = timeCorrecter(elecCarTrace)\n",
    "elecCarTrace = elecCarTrace.sort_values(by=['vehicle', 'departureTime'], ignore_index=True)\n",
    "\n",
    "def assign_sequence(lst):\n",
    "    return [(i, val) for i, val in enumerate(lst)]  # (sequence_number, value)\n",
    "\n",
    "# Apply the function to 'Parking Time' to associate a sequence number\n",
    "elecCarTrace['Parking Time'] = elecCarTrace['Parking Time'].apply(assign_sequence)\n",
    "\n",
    "# Separate the sequence number and the 'Parking Time' into two columns\n",
    "elecCarTrace = elecCarTrace.explode('Parking Time')\n",
    "elecCarTrace['sequence_number'], elecCarTrace['Parking Time'] = zip(*elecCarTrace['Parking Time'])\n",
    "elecCarTrace['Bin Label'] += elecCarTrace['sequence_number']\n",
    "# Optionally reset the index if needed and sort if necessary\n",
    "elecCarTrace.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "#Transfor Bin column into actual time in seconds\n",
    "elecCarTrace['Bin Label'] = elecCarTrace['Bin Label'] * binLength\n",
    "\n",
    "#Calculate Charging Opportunity\n",
    "elecCarTrace['Charging Opportunity'] = elecCarTrace['Parking Time'] * elecCarTrace['Cumulative Travel Length']\n",
    "elecCarTrace['Charging Opportunity'] = elecCarTrace['Charging Opportunity'].astype(float)\n",
    "\n",
    "#Add up time bins from the second day to the first day\n",
    "elecCarTrace.loc[elecCarTrace['Bin Label'] >= 24*3600 , 'Bin Label'] -= 24 *3600\n",
    "print('Total Chargin Opportunities Entries:', len(elecCarTrace))\n",
    "elecCarTrace = elecCarTrace[elecCarTrace['Bin Label']<=24*3600]\n",
    "print('Total Chargin Opportunities Entries after filtering people departing for the first time after midnight:', len(elecCarTrace))\n",
    "\n",
    "\n",
    "#CP moved this here\n",
    "#Add block group info and normalize by area\n",
    "#CP try differnt geometries\n",
    "elecCarTrace = gpd.GeoDataFrame(elecCarTrace, geometry=gpd.points_from_xy(elecCarTrace['endX'], elecCarTrace['endY']))\n",
    "elecCarTrace = elecCarTrace.set_crs(epsg=4326)\n",
    "elecCarTrace = elecCarTrace.to_crs(epsg=3857)\n",
    "block_groups_gdf = gpd.read_file(zoningFilepath)[['geoid','geometry']]\n",
    "if block_groups_gdf.crs != elecCarTrace.crs: block_groups_gdf = block_groups_gdf.to_crs(elecCarTrace.crs)\n",
    "elecCarTrace = gpd.sjoin(elecCarTrace, block_groups_gdf[['geoid','geometry']], how='left', op='within')\n",
    "print('Total Chargin Opportunities Entries with Valid Block Group:', len(elecCarTrace))\n",
    "elecCarTrace = elecCarTrace.drop(columns=['geometry'])\n",
    "elecCarTrace = elecCarTrace.merge(block_groups_gdf[['geoid','geometry']], how ='left', on = 'geoid')\n",
    "elecCarTrace = gpd.GeoDataFrame(elecCarTrace, geometry='geometry')\n",
    "\n",
    "\n",
    "elecCarTrace.to_csv(mainDirectory + 'elecCarTrace3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Different Functions for Entropy Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_entropy_list = []\n",
    "total_opportunity_list = []\n",
    "time_labels = []\n",
    "\n",
    "for time in elecCarTrace['Bin Label'].sort_values().unique():\n",
    "    \n",
    "    print('Time', time)\n",
    "    time_labels.append(time) \n",
    "    \n",
    "    subdf = elecCarTrace.loc[elecCarTrace['Bin Label'] == time]\n",
    "    \n",
    "    result_gdf = subdf.groupby(['geoid']).agg(\n",
    "        {'Charging Opportunity': 'sum', \n",
    "        'geometry': 'first', \n",
    "        }    ).reset_index()\n",
    "    \n",
    "    result_gdf = gpd.GeoDataFrame(result_gdf, geometry='geometry')\n",
    "    \n",
    "    totalChargingOpportunity = subdf['Charging Opportunity'].sum()\n",
    "    print('Total Charging Opportunity', totalChargingOpportunity)\n",
    "    total_opportunity_list.append(totalChargingOpportunity)\n",
    "    \n",
    "    #Calculate Entropy of charging opportunity density\n",
    "    result_gdf['Density Charging Opportunity'] = result_gdf['Charging Opportunity'].div(result_gdf.geometry.area)\n",
    "    totalJunk = result_gdf['Density Charging Opportunity'].sum()\n",
    "    result_gdf['Probability'] = result_gdf['Density Charging Opportunity'] / totalJunk\n",
    "    result_gdf['Entropy'] = -result_gdf['Probability'] * np.log(result_gdf['Probability'])\n",
    "    \n",
    "    totalEntropy = result_gdf['Entropy'].sum()\n",
    "    print('Total Entropy', totalEntropy)\n",
    "    total_entropy_list.append(totalEntropy)\n",
    "\n",
    "    entropyPlot5(result_gdf)\n",
    "    \n",
    "\n",
    "#Plot Entropy\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot total charging opportunity on the first axis\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Total Charging Opportunity', color='tab:blue')\n",
    "ax1.plot(time_labels, total_opportunity_list, label='Total Charging Opportunity', color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a second y-axis for the total entropy\n",
    "ax2 = ax1.twinx()  # Instantiate a second y-axis that shares the same x-axis\n",
    "ax2.set_ylabel('Total Entropy', color='tab:red')\n",
    "ax2.plot(time_labels, total_entropy_list, label='Total Entropy', color='tab:red')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# Add a title and display the plot\n",
    "plt.title('Temporal Evolution of Total Charging Opportunity and Total Entropy')\n",
    "fig.tight_layout()  # To prevent overlap of labels\n",
    "plt.savefig(mainDirectory + 'timeEvolution.png', dpi = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'images'\n",
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "image_files = sorted(image_files, key=os.path.getmtime, reverse=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Function to update the plot for each frame\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    image = plt.imread(image_files[i])\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, extent = None)\n",
    "\n",
    "# Create the animation\n",
    "ani = FuncAnimation(fig, animate, frames=len(image_files), interval=200)\n",
    "\n",
    "# Save the animation\n",
    "ani.save(mainDirectory + '/animation.gif', writer='pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

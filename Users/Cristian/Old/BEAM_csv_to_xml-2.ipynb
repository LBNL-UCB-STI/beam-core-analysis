{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c876eb0-381a-4d1a-a1c2-40b8648cc40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e1f8c8-c487-4115-96ae-2f67f05f9573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (4.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593ff5b-3d73-4c0a-baaf-44de11edf219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89df00a-08d6-42b1-afb9-438609ddd14e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da16f12-c853-41c0-9f14-55df5e792706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "from lxml import etree\n",
    "import numpy as np\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from pyproj import Transformer\n",
    "\n",
    "# plans_fp = 'gs://beam-core-outputs/sfbay-baseline-20230526/beam/year-2020-iteration-4/ITERS/it.0/0.plans.csv.gz'\n",
    "# inexus_fp =  'gs://beam-core-outputs/sfbay-baseline-20230526/inexus/sfbay_baseline_default-1.0_2020__20230526.csv.gz'\n",
    "plans_fp = 'gs://beam-core-outputs/sfbay-baseline2018-30pct-20230825/beam/year-2018-iteration-9/ITERS/it.0/0.plans.csv.gz'\n",
    "inexus_fp =  'gs://beam-core-outputs/sfbay-baseline2018-30pct-20230825/inexus/sfbay_baseline_base-1.0_2018__20230825.csv.gz'\n",
    "\n",
    "\n",
    "Plans2 = pd.read_csv( plans_fp)\n",
    "Plans2 = Plans2[Plans2['planSelected']==True]\n",
    "Plans2['activityType'] = Plans2['activityType'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f460ddd-f396-4f4c-854d-5d44d1eafcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7483664\n",
      "7455103 after filtering invalid entries\n",
      "Merge..\n",
      "7187319 After dropping wrong merged\n"
     ]
    }
   ],
   "source": [
    "nrows = None\n",
    "\n",
    "columns_to_read = ['IDMerged', 'actStartType', 'actEndType', 'duration_travelling', 'distance_travelling', 'actStartTime', 'actEndTime',\n",
    "                   'startX','startY','endX','endY']\n",
    "Inexus2 = pd.read_csv( inexus_fp, \n",
    "                     nrows = nrows, usecols=columns_to_read)\n",
    "Inexus2 = Inexus2.rename(columns={'IDMerged': 'person_id', 'actStartType': 'activityTypeFrom', 'actEndType': 'activityTypeTo'})\n",
    "print(len(Inexus2))\n",
    "# print(Inexus2[:40])\n",
    "Inexus2 = Inexus2.dropna(subset=['activityTypeFrom'])\n",
    "print(len(Inexus2), 'after filtering invalid entries')\n",
    "Inexus2 = Inexus2.sort_values(['person_id','actEndTime'], ascending=True)  # Use ascending=False for descending order.\n",
    "Inexus2['planIndex_inexus'] = Inexus2.groupby('person_id').cumcount() * 2 + 1\n",
    "print('Merge..')\n",
    "df_final_merged = pd.merge(Inexus2,Plans2, left_on=['person_id', 'planIndex_inexus', 'activityTypeTo'], right_on=['personId', 'planElementIndex', 'activityType'], how='left')\n",
    "# df_final_merged_2 = pd.merge(Inexus2,Plans2, left_on=['person_id', 'planIndex_inexus'], right_on=['personId', 'planElementIndex', ], how='left')\n",
    "\n",
    "#Filter outliers\n",
    "df_final_merged = df_final_merged.dropna(subset=['planElementIndex'])\n",
    "# df_final_merged2 = df_final_merged_2.dropna(subset=['planElementIndex'])\n",
    "print(len(df_final_merged), 'After dropping wrong merged')\n",
    "# print(len(df_final_merged_2), 'After dropping wrong merged2')\n",
    "df_final_merged = df_final_merged.sort_values(['person_id','actEndTime'], ascending=True)  # Use ascending=False for descending order.\n",
    "df_final_merged['next_person'] = df_final_merged['person_id'].shift(-1)\n",
    "df_final_merged['pre_start'] = df_final_merged['actStartTime'].shift(+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f268e94-7fbb-44e3-938e-abca1b22f008",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 50000/7187319\n",
      "Processing row 100000/7187319\n",
      "Processing row 150000/7187319\n",
      "Processing row 200000/7187319\n",
      "Processing row 250000/7187319\n",
      "Processing row 300000/7187319\n",
      "Processing row 350000/7187319\n",
      "Processing row 400000/7187319\n",
      "Processing row 450000/7187319\n",
      "Processing row 500000/7187319\n",
      "Processing row 550000/7187319\n",
      "Processing row 600000/7187319\n",
      "Processing row 650000/7187319\n",
      "Processing row 700000/7187319\n",
      "Processing row 750000/7187319\n",
      "Processing row 800000/7187319\n",
      "Processing row 850000/7187319\n",
      "Processing row 900000/7187319\n",
      "Processing row 950000/7187319\n",
      "Processing row 1000000/7187319\n",
      "Processing row 1050000/7187319\n",
      "Processing row 1100000/7187319\n",
      "Processing row 1150000/7187319\n",
      "Processing row 1200000/7187319\n",
      "Processing row 1250000/7187319\n",
      "Processing row 1300000/7187319\n",
      "Processing row 1350000/7187319\n",
      "Processing row 1400000/7187319\n",
      "Processing row 1450000/7187319\n",
      "Processing row 1500000/7187319\n",
      "Processing row 1550000/7187319\n",
      "Processing row 1600000/7187319\n",
      "Processing row 1650000/7187319\n",
      "Processing row 1700000/7187319\n",
      "Processing row 1750000/7187319\n",
      "Processing row 1800000/7187319\n",
      "Processing row 1850000/7187319\n",
      "Processing row 1900000/7187319\n",
      "Processing row 1950000/7187319\n",
      "Processing row 2000000/7187319\n",
      "Processing row 2050000/7187319\n",
      "Processing row 2100000/7187319\n",
      "Processing row 2150000/7187319\n",
      "Processing row 2200000/7187319\n",
      "Processing row 2250000/7187319\n",
      "Processing row 2300000/7187319\n",
      "Processing row 2350000/7187319\n",
      "Processing row 2400000/7187319\n",
      "Processing row 2450000/7187319\n",
      "Processing row 2500000/7187319\n",
      "Processing row 2550000/7187319\n",
      "Processing row 2600000/7187319\n",
      "Processing row 2650000/7187319\n",
      "Processing row 2700000/7187319\n",
      "Processing row 2750000/7187319\n",
      "Processing row 2800000/7187319\n",
      "Processing row 2850000/7187319\n",
      "Processing row 2900000/7187319\n",
      "Processing row 2950000/7187319\n",
      "Processing row 3000000/7187319\n",
      "Processing row 3050000/7187319\n",
      "Processing row 3100000/7187319\n",
      "Processing row 3150000/7187319\n",
      "Processing row 3200000/7187319\n",
      "Processing row 3250000/7187319\n",
      "Processing row 3300000/7187319\n",
      "Processing row 3350000/7187319\n",
      "Processing row 3400000/7187319\n",
      "Processing row 3450000/7187319\n",
      "Processing row 3500000/7187319\n",
      "Processing row 3550000/7187319\n",
      "Processing row 3600000/7187319\n",
      "Processing row 3650000/7187319\n",
      "Processing row 3700000/7187319\n",
      "Processing row 3750000/7187319\n",
      "Processing row 3800000/7187319\n",
      "Processing row 3850000/7187319\n",
      "Processing row 3900000/7187319\n",
      "Processing row 3950000/7187319\n",
      "Processing row 4000000/7187319\n",
      "Processing row 4050000/7187319\n",
      "Processing row 4100000/7187319\n",
      "Processing row 4150000/7187319\n",
      "Processing row 4200000/7187319\n",
      "Processing row 4250000/7187319\n",
      "Processing row 4300000/7187319\n",
      "Processing row 4350000/7187319\n",
      "Processing row 4400000/7187319\n",
      "Processing row 4450000/7187319\n",
      "Processing row 4500000/7187319\n",
      "Processing row 4550000/7187319\n",
      "Processing row 4600000/7187319\n",
      "Processing row 4650000/7187319\n",
      "Processing row 4700000/7187319\n",
      "Processing row 4750000/7187319\n",
      "Processing row 4800000/7187319\n",
      "Processing row 4850000/7187319\n",
      "Processing row 4900000/7187319\n",
      "Processing row 4950000/7187319\n",
      "Processing row 5000000/7187319\n",
      "Processing row 5050000/7187319\n",
      "Processing row 5100000/7187319\n",
      "Processing row 5150000/7187319\n",
      "Processing row 5200000/7187319\n",
      "Processing row 5250000/7187319\n",
      "Processing row 5300000/7187319\n",
      "Processing row 5350000/7187319\n",
      "Processing row 5400000/7187319\n",
      "Processing row 5450000/7187319\n",
      "Processing row 5500000/7187319\n",
      "Processing row 5550000/7187319\n",
      "Processing row 5600000/7187319\n",
      "Processing row 5650000/7187319\n",
      "Processing row 5700000/7187319\n",
      "Processing row 5750000/7187319\n",
      "Processing row 5800000/7187319\n",
      "Processing row 5850000/7187319\n",
      "Processing row 5900000/7187319\n",
      "Processing row 5950000/7187319\n",
      "Processing row 6000000/7187319\n",
      "Processing row 6050000/7187319\n",
      "Processing row 6100000/7187319\n",
      "Processing row 6150000/7187319\n",
      "Processing row 6200000/7187319\n",
      "Processing row 6250000/7187319\n",
      "Processing row 6300000/7187319\n",
      "Processing row 6350000/7187319\n",
      "Processing row 6400000/7187319\n",
      "Processing row 6450000/7187319\n",
      "Processing row 6500000/7187319\n",
      "Processing row 6550000/7187319\n",
      "Processing row 6600000/7187319\n",
      "Processing row 6650000/7187319\n",
      "Processing row 6700000/7187319\n",
      "Processing row 6750000/7187319\n",
      "Processing row 6800000/7187319\n",
      "Processing row 6850000/7187319\n",
      "Processing row 6900000/7187319\n",
      "Processing row 6950000/7187319\n",
      "Processing row 7000000/7187319\n",
      "Processing row 7050000/7187319\n",
      "Processing row 7100000/7187319\n",
      "Processing row 7150000/7187319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def safe_str(obj):\n",
    "    \"\"\"Returns an empty string for None, nan and similar objects, otherwise str(obj).\"\"\"\n",
    "    return '' if pd.isnull(obj) else str(obj)\n",
    "\n",
    "transformer = Transformer.from_crs('epsg:4326', 'epsg:26910', always_xy=True)\n",
    "\n",
    "def convert_coords(lat, lon):\n",
    "    return transformer.transform(lon, lat)\n",
    "\n",
    "def seconds_to_hh_mm_ss(seconds):\n",
    "    # Convert seconds to hours, minutes, and seconds\n",
    "    hours = seconds // 3600  # 3600 seconds in an hour\n",
    "    minutes = (seconds % 3600) // 60  # 60 seconds in a minute\n",
    "    seconds = seconds % 60\n",
    "\n",
    "    # Format the time to have two digits for hours, minutes, and seconds\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "\n",
    "def convert_csv_to_xml(df_final_merged, xml_file_path):\n",
    "    root = ET.Element(\"people\")\n",
    "    person_pre = -1\n",
    "    score_pre = -1\n",
    "    row_count = 0  # Initialize a counter\n",
    "    total_rows = len(df_final_merged)  # Get the total number of rows\n",
    "    \n",
    "    for _, row in df_final_merged.iterrows():\n",
    "        \n",
    "        row_count += 1 \n",
    "        if row_count%50000 == 0:\n",
    "            print(f\"Processing row {row_count}/{total_rows}\")  # Print the progress\n",
    "\n",
    "        next_person = row['next_person']\n",
    "        # Create the 'person' element\n",
    "        if row['person_id'] != person_pre:\n",
    "            if pd.notna(row.get('person_id')):\n",
    "                person = ET.SubElement(root, \"person\", id=safe_str(int(row['person_id'])))\n",
    "            else:\n",
    "                person = ET.SubElement(root, \"person\", id='')\n",
    "\n",
    "        \n",
    "        # Ensure that 'planSelected' is a string 'true' or 'false', not a Python boolean\n",
    "        plan_selected_str = \"yes\" if row['planSelected'] else \"false\"\n",
    "        \n",
    "        # Create the 'plan' element\n",
    "        if row['planScore'] != score_pre:\n",
    "            plan = ET.SubElement(person, \"plan\", score=safe_str(row['planScore']), selected=plan_selected_str)\n",
    "        \n",
    "###\n",
    "        # Create 'activity' elements for start and end\n",
    "        if row['person_id'] != person_pre:\n",
    "            utm_x, utm_y = convert_coords(row['startY'], row['startX'])\n",
    "\n",
    "            activity = ET.SubElement(plan, \"activity\", \n",
    "                                     type=safe_str(row['activityTypeTo']), \n",
    "                                     x=safe_str(utm_x), \n",
    "                                     y=safe_str(utm_y))\n",
    "\n",
    "            # Add 'end_time' attribute if it exists and is not NaN\n",
    "\n",
    "            if pd.notna(row.get('actEndTime')):\n",
    "                activity.set('end_time', safe_str(seconds_to_hh_mm_ss(int(row['actEndTime']))))\n",
    "\n",
    "            activity.text = ' ' \n",
    "        else:\n",
    "            utm_x, utm_y = convert_coords(row['startY'], row['startX'])\n",
    "            activity = ET.SubElement(plan, \"activity\", \n",
    "                                     type=safe_str(row['activityTypeTo']), \n",
    "                                     x=safe_str(utm_x), \n",
    "                                     y=safe_str(utm_y))\n",
    "\n",
    "            # Add 'end_time' attribute if it exists and is not NaN\n",
    "            if pd.notna(row.get('pre_start')):\n",
    "                activity.set('start_time', safe_str(seconds_to_hh_mm_ss(int(row['pre_start']))))\n",
    "            if pd.notna(row.get('actEndTime')):\n",
    "                activity.set('end_time', safe_str(seconds_to_hh_mm_ss(int(row['actEndTime']))))\n",
    "\n",
    "            activity.text = ' ' \n",
    "\n",
    "###\n",
    "        # Create 'leg' element\n",
    "    \n",
    "        leg = ET.SubElement(plan, \"leg\", mode=safe_str(row['legMode']), \n",
    "                            dep_time = safe_str(seconds_to_hh_mm_ss(int(row['actEndTime']))),\n",
    "                            trav_time=safe_str(seconds_to_hh_mm_ss(int(row['duration_travelling']))))\n",
    "                            # dep_time=row['dep_time'], \n",
    "                            \n",
    "        \n",
    "        # Create 'route' element\n",
    "        if  pd.notna(row.get('legRouteStartLink')):\n",
    "            legRouteStartLink = int(row['legRouteStartLink'])\n",
    "        else:\n",
    "            legRouteStartLink = ''\n",
    "        if  pd.notna(row.get('legRouteEndLink')):\n",
    "            legRouteEndLink = int(row['legRouteEndLink'])\n",
    "        else:\n",
    "            legRouteEndLink = ''\n",
    "        if  pd.notna(row.get('distance_travelling')):\n",
    "            distance_travelling = int(row['distance_travelling'])\n",
    "        else:\n",
    "            distance_travelling = ''\n",
    "        if  pd.notna(row.get('duration_travelling')):\n",
    "            duration_travelling = int(row['duration_travelling'])\n",
    "        else:\n",
    "            duration_travelling = ''\n",
    "        route = ET.SubElement(leg, \"route\", \n",
    "                              type=safe_str(row['legRouteType']), \n",
    "                              start_link=safe_str(legRouteStartLink), \n",
    "                              end_link=safe_str(legRouteEndLink), \n",
    "                              distance=safe_str(distance_travelling),\n",
    "                              trav_time=safe_str(seconds_to_hh_mm_ss(duration_travelling)))\n",
    "        route.text = ' '.join(safe_str(row['legRouteLinks']).split(';'))   # Ensure that 'route_links' is converted to string\n",
    "                    \n",
    "###\n",
    "#         # Create 'activity' elements for start and end\n",
    "        if next_person != row['person_id']:\n",
    "            utm_x, utm_y = convert_coords(row['endY'], row['endX'])\n",
    "            activity = ET.SubElement(plan, \"activity\", \n",
    "                                     type=safe_str(row['activityTypeFrom']), \n",
    "                                     x=safe_str(utm_x), \n",
    "                                     y=safe_str(utm_y))\n",
    "\n",
    "            # Add 'end_time' attribute if it exists and is not NaN\n",
    "            if pd.notna(row.get('actStartTime')):\n",
    "                activity.set('start_time', safe_str(seconds_to_hh_mm_ss(int(row['actStartTime']))))\n",
    "            # if pd.notna(row.get('actEndTime')):\n",
    "            #     activity.set('end_time', safe_str(int(row['actEndTime'])))\n",
    "\n",
    "    \n",
    "            activity.text = ' '\n",
    "        \n",
    "        \n",
    "        person_pre = row['person_id']\n",
    "        score_pre = row['planScore']\n",
    "\n",
    "    xml_str = ET.tostring(root, encoding='utf-8', method='xml')\n",
    "    parsed_xml = minidom.parseString(xml_str)\n",
    "    pretty_xml_str = parsed_xml.toprettyxml(indent=\"   \", newl=\"\\n\", encoding='UTF-8')\n",
    "    \n",
    "    with open(xml_file_path, \"wb\") as f:  # Note that we open the file in binary mode\n",
    "        f.write(pretty_xml_str)\n",
    "        \n",
    "    return xml_file_path\n",
    "\n",
    "xml_file_path = f'outputs/output_file_{nrows}.xml'\n",
    "\n",
    "convert_csv_to_xml(df_final_merged, xml_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d4fdc-e3d7-42d5-82bd-0be1bffbae9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee672573-0370-4735-a96b-c932f34cf6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

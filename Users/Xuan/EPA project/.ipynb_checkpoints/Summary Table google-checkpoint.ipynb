{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5365f8a9-8413-4cc5-bf10-d961ec4ab961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Using cached s3fs-2023.3.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec==2023.3.0\n",
      "  Using cached fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "Collecting aiobotocore~=2.4.2\n",
      "  Using cached aiobotocore-2.4.2-py3-none-any.whl (66 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Using cached aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Collecting botocore<1.27.60,>=1.27.59\n",
      "  Using cached botocore-1.27.59-py3-none-any.whl (9.1 MB)\n",
      "Collecting wrapt>=1.10.10\n",
      "  Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Using cached aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.0.12)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.9/site-packages (from aioitertools>=0.5.1->aiobotocore~=2.4.2->s3fs) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (2.8.2)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore~=2.4.2->s3fs) (1.16.0)\n",
      "Installing collected packages: wrapt, multidict, jmespath, fsspec, frozenlist, async-timeout, aioitertools, yarl, botocore, aiosignal, aiohttp, aiobotocore, s3fs\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.3.0\n",
      "    Uninstalling fsspec-2022.3.0:\n",
      "      Successfully uninstalled fsspec-2022.3.0\n",
      "Successfully installed aiobotocore-2.4.2 aiohttp-3.8.4 aioitertools-0.11.0 aiosignal-1.3.1 async-timeout-4.0.2 botocore-1.27.59 frozenlist-1.3.3 fsspec-2023.3.0 jmespath-1.0.1 multidict-6.0.4 s3fs-2023.3.0 wrapt-1.15.0 yarl-1.8.2\n",
      "Collecting google-cloud-storage\n",
      "  Using cached google_cloud_storage-2.7.0-py2.py3-none-any.whl (110 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Using cached google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Using cached google_resumable_media-2.4.1-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-storage) (2.27.1)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Using cached google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-auth<3.0dev,>=1.25.0\n",
      "  Using cached google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.0rc2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.16.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.12)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, googleapis-common-protos, google-crc32c, cachetools, google-resumable-media, google-auth, google-api-core, google-cloud-core, google-cloud-storage\n",
      "Successfully installed cachetools-5.3.0 google-api-core-2.11.0 google-auth-2.16.2 google-cloud-core-2.3.2 google-cloud-storage-2.7.0 google-crc32c-1.5.0 google-resumable-media-2.4.1 googleapis-common-protos-1.59.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.9\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-storage) (2.27.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.9/site-packages (from google-cloud-storage) (2.11.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-storage) (2.3.2)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.9/site-packages (from google-cloud-storage) (2.16.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.59.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.0rc2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.9/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.12)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install s3fs\n",
    "!pip install google-cloud-storage \n",
    "!pip install --upgrade google-cloud-storage\n",
    "import gzip\n",
    "import io\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452fcd08-f880-436f-81c6-fae6ccec5222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1104/1298126890.py:24: DtypeWarning: Columns (0,2,5,6,16,17,24,26,27,29,30,34,35,37,38,39,40,41,46,47,53,55,57,59,60,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f_in_text)\n"
     ]
    }
   ],
   "source": [
    "# create an empty DataFrame to store the results\n",
    "EPASummary = pd.DataFrame()\n",
    "\n",
    "# create a client object for interacting with the Google Cloud Storage API\n",
    "client = storage.Client(project=\"BEAM CORE\")\n",
    "\n",
    "# set the prefix and bucket name for the files to download\n",
    "prefix = \"output/sfbay/sfbay-pilates-base__2023-03-16_22-27-58_xmg\"\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "\n",
    "# set the name of the file to download and create locally\n",
    "blob_name = prefix + \"/ITERS/it.0/0.events.csv.gz\"\n",
    "gz_file = 'example.csv.gz'\n",
    "\n",
    "# get a reference to the CSV file in the bucket\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "blob = bucket.blob(blob_name)\n",
    "\n",
    "# download the gzipped file to local storage\n",
    "blob.download_to_filename(gz_file)\n",
    "\n",
    "# unzip the file and decode the contents into a text stream\n",
    "with gzip.open(gz_file, 'rb') as f_in:\n",
    "    with io.TextIOWrapper(f_in, encoding='utf-8') as f_in_text:\n",
    "        # read the text stream into a pandas DataFrame\n",
    "        df = pd.read_csv(f_in_text)\n",
    "        \n",
    "# set a scale factor to convert the output to the desired units\n",
    "scalefactor = (0.3)\n",
    "\n",
    "# set some variables to store the output data\n",
    "name = 'baseline'\n",
    "data_name = 'baseline'\n",
    "carData = {}\n",
    "\n",
    "# create a new DataFrame containing only the path traversal data\n",
    "pathTraversal = df.loc[df.type == 'PathTraversal',:].dropna(how='all', axis=1)\n",
    "\n",
    "# create some additional columns in the path traversal DataFrame\n",
    "pathTraversal['mode_extended'] = pathTraversal['mode']\n",
    "pathTraversal['isRH'] = ((pathTraversal['driver'].str.contains('rideHail')== True))\n",
    "pathTraversal.loc[pathTraversal['isRH'], 'mode_extended'] += '_RH'\n",
    "pathTraversal['gallons'] = (pathTraversal['primaryFuel'] + pathTraversal['secondaryFuel']) * 8.3141841e-9\n",
    "pathTraversal['trueOccupancy'] = pathTraversal['numPassengers']\n",
    "pathTraversal.loc[pathTraversal['mode_extended'] == 'car', 'trueOccupancy'] += 1\n",
    "pathTraversal.loc[pathTraversal['mode_extended'] == 'walk', 'trueOccupancy'] += 1\n",
    "pathTraversal.loc[pathTraversal['mode_extended'] == 'bike', 'trueOccupancy'] += 1\n",
    "pathTraversal['vehicleMiles'] = pathTraversal['length']/1609.34\n",
    "pathTraversal['passengerMiles'] = (pathTraversal['length'] * pathTraversal['trueOccupancy'])/1609.34\n",
    "pathTraversal['vehicleHours'] = (pathTraversal['arrivalTime'] - pathTraversal['departureTime'])/3600.\n",
    "pathTraversal['passengerHours'] = pathTraversal['vehicleHours'] * pathTraversal['trueOccupancy']\n",
    "\n",
    "# group the path traversal data by mode and calculate some summary statistics\n",
    "byType = pathTraversal.groupby(['mode_extended']).agg({'vehicleMiles':'sum','vehicleHours':'sum','passengerMiles':'sum','passengerHours':'sum','gallons':'sum'})\n",
    "byType = byType\n",
    "\n",
    "# store the results in a dictionary\n",
    "carData[name] = byType\n",
    "\n",
    "# calculate some additional summary statistics and store the results in the EPASummary DataFrame\n",
    "EPASummary.at[name, 'LDV VMT (million)'] = carData[name].loc['car']['vehicleMiles'] / scalefactor / 1000000                                                                   \n",
    "EPASummary.at[name, 'LDV Energy ((million gallon eq.))'] = carData[name].loc['car']['gallons'] / scalefactor / 1000000\n",
    "\n",
    "# reading data\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "blob_name = prefix + \"/ITERS/it.0/0.realizedMode.csv\"\n",
    "storage_client = storage.Client(project=\"BEAM CORE\")\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(blob_name)\n",
    "\n",
    "with blob.open(\"r\") as f:\n",
    "    transit = pd.read_csv(f)\n",
    "\n",
    "\n",
    "transit_trips = (transit['bike_transit'].sum() + transit['drive_transit'].sum() + transit['ride_hail_transit'].sum() + transit['walk_transit'].sum()) / scalefactor / 1000000\n",
    "EPASummary.at[name, 'Transit trips (million)'] = transit_trips\n",
    "\n",
    "# reading data\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "blob_name = prefix + \"/ITERS/it.0/0.modeChoice.csv\"\n",
    "storage_client = storage.Client(project=\"BEAM CORE\")\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(blob_name)\n",
    "\n",
    "with blob.open(\"r\") as f:\n",
    "    total_transit = pd.read_csv(f)\n",
    "    \n",
    "number_of_trips = 0  # initialize a variable to store the number of trips\n",
    "\n",
    "# loop through 24 bins and add up the number of trips for each mode of transit\n",
    "for i in range(24):\n",
    "    # bike transit trips\n",
    "    number_of_trips += total_transit[total_transit['Modes'] == 'bike_transit']['Bin_' + str(i)].reset_index()['Bin_' + str(i)][0]\n",
    "    # drive transit trips\n",
    "    number_of_trips += total_transit[total_transit['Modes'] == 'drive_transit']['Bin_' + str(i)].reset_index()['Bin_' + str(i)][0]\n",
    "    # ride hail transit trips\n",
    "    number_of_trips += total_transit[total_transit['Modes'] == 'ride_hail_transit']['Bin_' + str(i)].reset_index()['Bin_' + str(i)][0]\n",
    "    # walk transit trips\n",
    "    number_of_trips += total_transit[total_transit['Modes'] == 'walk_transit']['Bin_' + str(i)].reset_index()['Bin_' + str(i)][0]\n",
    "\n",
    "# calculate the number of denied transit trips and update the EPASummary dataframe\n",
    "denied_transit_trips = number_of_trips / scalefactor / 1000000 - transit_trips\n",
    "EPASummary.at[name, 'Denied Transit trips (million)'] = denied_transit_trips\n",
    "EPASummary.at[name, 'Percentage of still choosing transit'] = 1.00\n",
    "\n",
    "# extract bikeshare data and update the EPASummary dataframe\n",
    "pathTraversal = df[df['type'] == 'PathTraversal']\n",
    "bikePathTraversal = pathTraversal[pathTraversal['mode'] == 'bike']\n",
    "sharedbike = bikePathTraversal[bikePathTraversal['vehicle'].str.contains('bay')]\n",
    "EPASummary.at[name, 'Bikeshare Trips (000s)'] = len(sharedbike) / scalefactor / 1000    \n",
    "\n",
    "# extract mode choice data and update the EPASummary dataframe with average distance traveled for each mode of transit\n",
    "modeChoice = df[df['type'] == 'ModeChoice']\n",
    "EPASummary.at[name, 'walk average distance'] = modeChoice[modeChoice['mode'] == 'walk']['length'].mean() * 0.000621371\n",
    "EPASummary.at[name, 'car average distance'] = modeChoice[modeChoice['mode'] == 'car']['length'].mean() * 0.000621371\n",
    "EPASummary.at[name, 'walk_transit average distance'] = modeChoice[modeChoice['mode'] == 'walk_transit']['length'].mean() * 0.000621371\n",
    "EPASummary.at[name, 'drive_transit average distance'] = modeChoice[modeChoice['mode'] == 'drive_transit']['length'].mean() * 0.000621371\n",
    "EPASummary.at[name, 'ride_hail_pooled average distance'] = modeChoice[modeChoice['mode'] == 'ride_hail_pooled']['length'].mean() * 0.000621371\n",
    "EPASummary.at[name, 'ride_hail_transit average distance'] = modeChoice[modeChoice['mode'] == 'ride_hail_transit']['length'].mean() * 0.000621371\n",
    "EPASummary.at[name, 'ride_hail average distance'] = modeChoice[modeChoice['mode'] == 'ride_hail']['length'].mean() * 0.000621371\n",
    "                                                                                                \n",
    "EPASummary.at[name, 'bike_transit average distance'] = modeChoice[modeChoice['mode'] == 'bike_transit']['length'].mean() * 0.000621371\n",
    "bikeModeChoice = modeChoice[modeChoice['mode'] == 'bike_transit']\n",
    "bikeshareToTransit = bikeModeChoice[bikeModeChoice['legVehicleIds'].str.contains('bay')]\n",
    "EPASummary.at[name, 'Bikeshare-to-Transit Trips (000s)'] = len(bikeshareToTransit) / scalefactor / 1000    \n",
    "EPASummary.at[name, 'Bikeshare VMT (000s)'] = sharedbike['length'].sum() / 1609.34 / scalefactor / 1000\n",
    "nonsharedbike = bikePathTraversal[bikePathTraversal['vehicle'].str.contains('bay') == False]\n",
    "EPASummary.at[name, 'Personal Bike Trips (000s)'] = len(nonsharedbike) / scalefactor / 1000\n",
    "personalToTransit = bikeModeChoice[bikeModeChoice['legVehicleIds'].str.contains('bay') == False]\n",
    "EPASummary.at[name, 'Personal Bike-to-Transit Trips (000s)'] = len(personalToTransit) / scalefactor / 1000\n",
    "EPASummary.at[name, 'Personal Bike VMT(000s)'] = nonsharedbike['length'].sum() / 1609.34 / scalefactor / 1000\n",
    "travel_time = (df[(df['type'] == 'PathTraversal') & (df['mode'] == 'car') & (df['departureTime'] != df['arrivalTime'])]['arrivalTime'] - df[(df['type'] == 'PathTraversal') & (df['mode'] == 'car') & (df['departureTime'] != df['arrivalTime'])]['departureTime']).mean() / 60\n",
    "EPASummary.at[name, 'LDV Avg Travel Time (min)'] = travel_time\n",
    "bikeData = pathTraversal.loc[pathTraversal['mode'] == 'bike']\n",
    "walkData = pathTraversal.loc[pathTraversal['mode'] == 'walk']\n",
    "walkData.reset_index(inplace=True)\n",
    "bikeData.reset_index(inplace=True)\n",
    "bikeData = bikeData[bikeData.vehicle.str.startswith('bay')]\n",
    "bikeData.reset_index(inplace=True)\n",
    "bikeData = bikeData.drop('level_0', axis=1)\n",
    "\n",
    "walkArrivalTime = walkData['arrivalTime']\n",
    "count = 0\n",
    "length = 0\n",
    "for i in range(len(bikeData)):\n",
    "    if (bikeData['departureTime'][i] in walkArrivalTime.tolist()):\n",
    "        walkRecord = walkData.loc[walkData['arrivalTime'] == bikeData['departureTime'][i]]\n",
    "        walkRecord.reset_index(inplace=True)\n",
    "        walkRecord = walkRecord.drop('level_0', axis=1)    \n",
    "        for j in range(len(walkRecord)):    \n",
    "            # probably we could filter out the distance equal to 0\n",
    "            if (bikeData['driver'][i] == walkRecord['driver'][j]):\n",
    "                count += 1\n",
    "                length += walkRecord['length'][j] / 1609.34\n",
    "            else:\n",
    "                continue\n",
    "if count == 0:\n",
    "    avg_distance = 0\n",
    "else:\n",
    "    avg_distance = length / count\n",
    "EPASummary.at[name, 'average walk distance to shared bikes(mile)'] = avg_distance\n",
    "\n",
    "# reading data\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "blob_name = prefix + \"/ITERS/it.0/0.realizedMode.csv\"\n",
    "storage_client = storage.Client(project=\"BEAM CORE\")\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(blob_name)\n",
    "\n",
    "with blob.open(\"r\") as f:\n",
    "    realizedModeChoice = pd.read_csv(f)\n",
    "    \n",
    "# reading data\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "blob_name = prefix + \"/ITERS/it.0/0.modeChoice.csv\"\n",
    "storage_client = storage.Client(project=\"BEAM CORE\")\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(blob_name)\n",
    "\n",
    "with blob.open(\"r\") as f:\n",
    "    modeChoice = pd.read_csv(f)\n",
    "\n",
    "Realized_Car_Trips = realizedModeChoice['car'].sum() / scalefactor\n",
    "EPASummary.at[name, 'Realized Car Trips'] = Realized_Car_Trips\n",
    "number_of_car_trips = 0\n",
    "number_of_car_trips = 0\n",
    "for i in range(30):\n",
    "    number_of_car_trips += modeChoice[modeChoice['Modes'] == 'car']['Bin_' + str(i)].reset_index()['Bin_' + str(i)][0]    \n",
    "number_of_car_trips = number_of_car_trips / scalefactor\n",
    "Realized_RH_Trips = realizedModeChoice['ride_hail'].sum() +  realizedModeChoice['ride_hail_pooled'].sum()\n",
    "Realized_RH_Trips = Realized_RH_Trips / scalefactor\n",
    "EPASummary.at[name, 'Realized Ridehail Trips'] = Realized_RH_Trips\n",
    "number_of_RH_trips = 0\n",
    "for i in range(30):\n",
    "    number_of_RH_trips += modeChoice[modeChoice['Modes'] == 'ride_hail']['Bin_' + str(i)].reset_index()['Bin_' + str(i)][0]\n",
    "    number_of_RH_trips += modeChoice[modeChoice['Modes'] == 'ride_hail_pooled']['Bin_' + str(i)].reset_index()['Bin_' + str(i)][0]\n",
    "number_of_RH_trips = number_of_RH_trips / scalefactor\n",
    "Denied_RH_Trips = number_of_RH_trips - Realized_RH_Trips\n",
    "EPASummary.at[name, 'Denied Ridehail Trips'] = Denied_RH_Trips\n",
    "carData = {}\n",
    "pathTraversal = df.loc[df.type == 'PathTraversal',:].dropna(how='all', axis=1)\n",
    "pathTraversal['mode_extended'] = pathTraversal['mode']\n",
    "pathTraversal['isRH'] = ((pathTraversal['driver'].str.contains('rideHail')== True))\n",
    "pathTraversal.loc[pathTraversal['isRH'], 'mode_extended'] += '_RH'\n",
    "\n",
    "pathTraversal.loc[pathTraversal.primaryFuelType == 'Gasoline', 'emission'] = pathTraversal['primaryFuel'] * 8.3141841e-9 * 8.89e-3\n",
    "pathTraversal.loc[pathTraversal.primaryFuelType == 'Diesel', 'emission'] = pathTraversal['primaryFuel'] * 8.3141841e-9 * 10.180e-3\n",
    "pathTraversal.loc[pathTraversal.primaryFuelType == 'Biod mnmsdxciesel', 'emission'] = pathTraversal['primaryFuel'] * 8.3141841e-9 * 10.180e-3\n",
    "pathTraversal.loc[pathTraversal.primaryFuelType == 'Electricity', 'emission'] = pathTraversal['primaryFuel'] * 2.77778e-10 * 947.2 * 0.0005\n",
    "pathTraversal.loc[pathTraversal.primaryFuelType == 'Food', 'emission'] = pathTraversal['primaryFuel'] * 8.3141841e-9 * 0\n",
    "\n",
    "pathTraversal.loc[pathTraversal.secondaryFuelType == 'Gasoline', 'emission'] = pathTraversal['emission'] + pathTraversal['secondaryFuel'] * 8.3141841e-9 * 8.89e-3\n",
    "\n",
    "byType = pathTraversal.groupby(['mode_extended']).agg({'emission':'sum'})\n",
    "byType = byType\n",
    "carData[name] = byType\n",
    "# pd.concat(carData).emission.unstack().to_csv('out/emission0.3pop-higher-transit.csv')\n",
    "EPASummary.at[name, 'CO2 Emissions. (1000s tons)'] = carData[name]['emission'].sum() / 1000\n",
    "\n",
    "filePath = data_name\n",
    "\n",
    "# reading data\n",
    "bucket_name = \"beam-core-outputs\"\n",
    "blob_name = prefix + \"/realizedModeChoice.csv\"\n",
    "storage_client = storage.Client(project=\"BEAM CORE\")\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(blob_name)\n",
    "\n",
    "with blob.open(\"r\") as f:\n",
    "    realizedmode = pd.read_csv(f)\n",
    "\n",
    "\n",
    "realizedmode['transit'] = realizedmode['bike_transit'] + realizedmode['drive_transit'] + realizedmode['ride_hail_transit'] + realizedmode['walk_transit']\n",
    "# realizedmode['ride_hail2'] = realizedmode['ride_hail_pooled'] + realizedmode['ride_hail']\n",
    "# modesplit = realizedmode[['bike', 'car', 'ride_hail2', 'walk', 'transit']]\n",
    "modesplit = realizedmode\n",
    "# modeSplitTable = modesplit.div(modesplit.sum(axis=1), axis=0)\n",
    "modeSplitTable = modesplit / scalefactor\n",
    "\n",
    "# EPASummary.at[name, 'bike'] = modeSplitTable['bike'][0]\n",
    "# EPASummary.at[name, 'bike_transit'] = modeSplitTable['bike_transit'][0]\n",
    "EPASummary.at[name, 'car'] = modeSplitTable['car'][0]\n",
    "EPASummary.at[name, 'drive_transit'] = modeSplitTable['drive_transit'][0]\n",
    "EPASummary.at[name, 'ride_hail'] = modeSplitTable['ride_hail'][0]\n",
    "EPASummary.at[name, 'ride_hail_pooled'] = modeSplitTable['ride_hail_pooled'][0]\n",
    "EPASummary.at[name, 'ride_hail_transit'] = modeSplitTable['ride_hail_transit'][0]\n",
    "EPASummary.at[name, 'walk'] = modeSplitTable['walk'][0]\n",
    "EPASummary.at[name, 'walk_transit'] = modeSplitTable['walk_transit'][0]\n",
    "\n",
    "\n",
    "EPASummary.at[name, 'Bikeshare Trips'] = len(sharedbike) / scalefactor\n",
    "EPASummary.at[name, 'Personalbike Trips'] = modeSplitTable['bike'][0] - len(sharedbike) / scalefactor\n",
    "EPASummary.at[name, 'Bikeshare-to-Transit Trips'] = len(bikeshareToTransit) / scalefactor\n",
    "EPASummary.at[name, 'Personalbike-to-Transit Trips'] = modeSplitTable['bike_transit'][0] - len(bikeshareToTransit) / scalefactor\n",
    "EPASummary.at[name, 'transit'] = modeSplitTable['drive_transit'][0] + modeSplitTable['ride_hail_transit'][0] + modeSplitTable['walk_transit'][0] + modeSplitTable['bike_transit'][0]\n",
    "\n",
    "\n",
    "del df\n",
    "EPASummary.to_csv('EPA_summarytablez_0.3pop_scaling_factor.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb40665e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\", color_codes=True)\n",
    "sns.set(font_scale=1.35, style=\"ticks\") #set styling preferences\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import math\n",
    "from math import pi\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.cluster.vq import kmeans2,vq, whiten\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import boto.s3\n",
    "import glob\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import dask.dataframe as dd\n",
    "from dask.delayed import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07b419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('C:\\Shared-Work\\Data\\Ridehail_Fleetsize_Price_Scenarios.csv')\n",
    "# Get the paths from the DataFrame\n",
    "paths = df['Outputs'][0:4].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f9160f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pilates-outputs/sfbay_1fleet_100price_100fleet_30pct_20230222/inexus/',\n",
       " 'pilates-outputs/sfbay_baseline_30pct_20230218/inexus/',\n",
       " 'pilates-outputs/sfbay_5fleets_100price_100fleet_30pct_20230218/inexus/',\n",
       " 'pilates-outputs/sfbay_5fleets_100price_164fleet_30pct_20230218/inexus/']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2549553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the S3 paths in the dataframe\n",
    "prefixs = []\n",
    "for path in paths:\n",
    "    prefix = path.replace('https://s3.us-east-2.amazonaws.com/beam-outputs/index.html#', '')\n",
    "    prefix = prefix + 'inexus/'\n",
    "    prefixs.append(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "652a8a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "bucket_name = 'beam-outputs'\n",
    "\n",
    "# read all files into a list of dataframes\n",
    "key_list = []\n",
    "\n",
    "# navigate the folder and read the CSV files\n",
    "for prefix in prefixs:\n",
    "    # Use the S3 client to list all objects in the bucket and prefix\n",
    "    objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    # extract the keys of the CSV files from the object list\n",
    "    keys = [obj[\"Key\"] for obj in objects[\"Contents\"] if '_2019_' in obj['Key'] and obj[\"Key\"].endswith(\".csv.gz\")]\n",
    "    keys = ''.join(keys)\n",
    "    key_list.append(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59919cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['tripIndex'] # Specify the columns to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa94ab29",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 5s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfs = []\n",
    "for key in key_list:\n",
    "    obj = s3.get_object(Bucket=\"beam-outputs\", Key=key_list)\n",
    "    sf_files = pd.read_csv(obj['Body'], compression = 'gzip', usecols = cols_to_use)\n",
    "    sf_files['year'] = 2018\n",
    "    dfs.append(sf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494b26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_table():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

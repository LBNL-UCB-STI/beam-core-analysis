{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2746852f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pilates'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpilates\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_taz_geoms\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpilates\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_args_and_settings\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pilates'"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import glob\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import os\n",
    "from pilates.utils.geog import get_taz_geoms\n",
    "from pilates.utils.io import parse_args_and_settings\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import cpu_count\n",
    "import zipfile\n",
    "from datetime import date\n",
    "import logging\n",
    "from pilates.activitysim.postprocessor import get_usim_datastore_fname\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "dtypes = {\n",
    "    \"time\": \"float32\",\n",
    "    \"type\": \"category\",\n",
    "    \"legMode\": \"category\",\n",
    "    \"actType\": \"category\",\n",
    "    \"primaryFuelLevel\": \"float64\",\n",
    "    \"chargingPointType\": \"category\",\n",
    "    \"pricingModel\": \"category\",\n",
    "    \"parkingType\": \"category\",\n",
    "    \"mode\": \"category\",\n",
    "    \"personalVehicleAvailable\": \"category\",\n",
    "    \"person\": \"str\",\n",
    "    \"driver\": \"str\",\n",
    "    \"riders\": \"str\",\n",
    "    'primaryFuelType': \"category\",\n",
    "    'secondaryFuelType': 'category',\n",
    "    'currentTourMode': 'category',\n",
    "    'currentActivity': 'category',\n",
    "    'nextActivity': 'category',\n",
    "    'tripId': \"str\"\n",
    "}\n",
    "\n",
    "\n",
    "def copy_outputs_to_mep(settings, year, iter):\n",
    "    asim_output_data_dir = settings['asim_local_output_folder']\n",
    "    mep_output_data_dir = os.path.join(settings['mep_local_output_folder'], str(year))\n",
    "    if not os.path.exists(mep_output_data_dir):\n",
    "        os.makedirs(mep_output_data_dir)\n",
    "    beam_iter_output_dir = os.path.join(settings['beam_local_output_folder'], settings['region'],\n",
    "                                        \"year-{0}-iteration-{1}\".format(year, iter))\n",
    "\n",
    "    def copy_with_compression_asim_file_to_mep(asim_file_name, mep_file_name):\n",
    "        asim_file_path = os.path.join(asim_output_data_dir, asim_file_name)\n",
    "        mep_file_path = os.path.join(mep_output_data_dir, mep_file_name)\n",
    "        logger.info(\"Copying asim file %s to beam input scenario file %s\", asim_file_path, mep_file_path)\n",
    "\n",
    "        if os.path.exists(asim_file_path):\n",
    "            with open(asim_file_path, 'rb') as f_in, gzip.open(\n",
    "                    mep_file_path, 'wb') as f_out:\n",
    "                f_out.writelines(f_in)\n",
    "\n",
    "    def copy_urbansim_outputs_to_mep():\n",
    "        data_dir = settings['usim_local_data_folder']\n",
    "        usim_output_store_name = get_usim_datastore_fname(\n",
    "            settings, io='input', year=year)\n",
    "        usim_output_store_path = os.path.join(data_dir, usim_output_store_name)\n",
    "        if not os.path.exists(usim_output_store_path):\n",
    "            raise ValueError('No output data store found at {0}'.format(\n",
    "                usim_output_store_path))\n",
    "        usim_output_store = pd.HDFStore(usim_output_store_path)\n",
    "        jobs = usim_output_store.get('jobs')\n",
    "        blocks = usim_output_store.get('blocks')\n",
    "        jobs.to_csv(os.path.join(mep_output_data_dir, \"jobs.csv.gz\"))\n",
    "        blocks.to_csv(os.path.join(mep_output_data_dir, \"blocks.csv.gz\"))\n",
    "\n",
    "    def copy_asim_files_to_mep():\n",
    "        ds = pd.HDFStore(os.path.join(asim_output_data_dir, \"pipeline.h5\"))\n",
    "        trips = ds.get('trips/trip_mode_choice')\n",
    "        trips.value_counts([\"destination\", \"purpose\"]).unstack(fill_value=0).to_csv(\n",
    "            os.path.join(mep_output_data_dir, \"activity_frequency.csv.gz\"))\n",
    "        copy_with_compression_asim_file_to_mep('final_plans.csv', 'plans.csv.gz')\n",
    "        copy_with_compression_asim_file_to_mep('final_households.csv', 'households.csv.gz')\n",
    "        copy_with_compression_asim_file_to_mep('final_persons.csv', 'persons.csv.gz')\n",
    "        copy_with_compression_asim_file_to_mep('final_land_use.csv', 'land_use.csv.gz')\n",
    "\n",
    "    def copy_beam_files_to_mep():\n",
    "        shutil.copy(os.path.join(beam_iter_output_dir, \"network.csv.gz\"),\n",
    "                    os.path.join(mep_output_data_dir, \"network.csv.gz\"))\n",
    "        linkstats_path = os.path.join(beam_iter_output_dir, \"ITERS\", \"it.0\", \"0.linkstats.csv.gz\")\n",
    "        shutil.copy(linkstats_path, os.path.join(mep_output_data_dir, \"linkstats.csv.gz\"))\n",
    "        parkingStats = os.path.join(beam_iter_output_dir, \"ITERS\", \"it.0\", \"0.parkingStats.csv.gz\")\n",
    "        shutil.copy(parkingStats, os.path.join(mep_output_data_dir, \"parkingStats.csv.gz\"))\n",
    "        ridehailSkims = os.path.join(beam_iter_output_dir, \"ITERS\", \"it.0\", \"0.skimsRidehail.csv.gz\")\n",
    "        shutil.copy(ridehailSkims, os.path.join(mep_output_data_dir, \"ridehailSkims.csv.gz\"))\n",
    "        odSkims = os.path.join(beam_iter_output_dir, \"ITERS\", \"it.0\", \"0.skimsTAZ.csv.gz\")\n",
    "        shutil.copy(odSkims, os.path.join(mep_output_data_dir, \"odSkims.csv.gz\"))\n",
    "        beam_router_dir = os.path.join(settings['beam_local_input_folder'], settings['region'],\n",
    "                                       settings['beam_router_directory'])\n",
    "        mep_gtfs_dir = os.path.join(mep_output_data_dir, \"GTFS\")\n",
    "        if not os.path.exists(mep_gtfs_dir):\n",
    "            os.makedirs(mep_gtfs_dir)\n",
    "        for file in os.listdir(beam_router_dir):\n",
    "            if file.endswith(\".zip\"):\n",
    "                shutil.copy(os.path.join(beam_router_dir, file), os.path.join(mep_gtfs_dir, file))\n",
    "        try:\n",
    "            shutil.copy(os.path.join(beam_iter_output_dir, \"totalsByMode.csv\"),\n",
    "                        os.path.join(mep_gtfs_dir, \"totalsByMode.csv\"))\n",
    "        except:\n",
    "            logger.error(\"Totals by mode were not generated by the postprocessor, expected at {0}\".format(\n",
    "                os.path.join(beam_iter_output_dir, \"totalsByMode.csv\")))\n",
    "\n",
    "        # Also add skims, ridehail and parking info\n",
    "\n",
    "    copy_urbansim_outputs_to_mep()\n",
    "    copy_asim_files_to_mep()\n",
    "    copy_beam_files_to_mep()\n",
    "\n",
    "\n",
    "def _load_events_file(settings, year, replanning_iteration_number, beam_iteration=0):\n",
    "    beam_output_dir = settings['beam_local_output_folder']\n",
    "    region = settings['region']\n",
    "    iteration_output_dir = \"year-{0}-iteration-{1}\".format(year, replanning_iteration_number)\n",
    "    events_dir = os.path.join(\"ITERS\", \"it.{0}\".format(beam_iteration), \"{0}.events.csv.gz\".format(beam_iteration))\n",
    "    path = os.path.join(beam_output_dir, region, iteration_output_dir, events_dir)\n",
    "    events = pd.read_csv(path, dtype=dtypes)\n",
    "\n",
    "    # Adding scenario info\n",
    "    scenario_defs = settings['scenario_definitions']\n",
    "    events['scenario'] = scenario_defs['name']\n",
    "    events['scenario'] = events['scenario'].astype(\"category\")\n",
    "    events['lever'] = scenario_defs['lever']\n",
    "    events['lever'] = events['lever'].astype(\"category\")\n",
    "    events['year'] = year\n",
    "    events['lever_position'] = scenario_defs['lever_position']\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "def _reformat_events_file(events):\n",
    "    # Rename the \"mode\" column\n",
    "\n",
    "    events.rename(columns={\"mode\": \"modeBEAM\"}, inplace=True)\n",
    "\n",
    "    # Replace \"Work\" with \"work\" in the \"actType\" column\n",
    "    events[\"actType\"].replace({\"Work\": \"work\"}, inplace=True)\n",
    "    events = events[~events.person.str.contains(\"Agent\", na=False)].reset_index(drop=True)\n",
    "\n",
    "    # shift column 'person' to first position\n",
    "    first_column = events.pop('person')\n",
    "    second_column = events.pop('driver')\n",
    "    third_column = events.pop('riders')\n",
    "\n",
    "    # insert column using insert(position,column_name,first_column) function\n",
    "    events.insert(0, 'person', first_column)\n",
    "    events.insert(1, 'driver', second_column)\n",
    "    events.insert(2, 'riders', third_column)\n",
    "\n",
    "    # Adding the IDMerged Column\n",
    "    events['UniqueID'] = events['person']  # make a copy of the person column\n",
    "    events['personID'] = np.where(events['person'].isin(events['driver']), events['person'], np.nan)\n",
    "    events['driverID'] = np.where(events['driver'].isin(events['person']), events['driver'], np.nan)\n",
    "\n",
    "    # Merging person and driver ids in one column\n",
    "    events['IDMerged'] = events['personID'].combine_first(events['driverID'])\n",
    "    events['IDMerged'] = events['UniqueID'].combine_first(events['IDMerged'])\n",
    "\n",
    "    # Dropping unused columns\n",
    "    events = events.drop(['personID', 'driverID', 'UniqueID'], axis=1)\n",
    "\n",
    "    # Shift column 'IDMerged' to first position\n",
    "    first_column = events.pop('IDMerged')\n",
    "    # Insert column using insert(position,column_name,first_column) function\n",
    "    events.insert(0, 'IDMerged', first_column)\n",
    "\n",
    "    # Split the \"riders' column and replicated rows for every rider\n",
    "    events['riders'] = events['riders'].str.split(':')\n",
    "    events = events.explode('riders')\n",
    "\n",
    "    # Combine riderID with IDMerged\n",
    "    events['riderID'] = np.where(events['riders'].isin(events['person']), events['riders'], np.nan)\n",
    "    events['IDMerged'] = events['riderID'].combine_first(events['IDMerged'])\n",
    "\n",
    "    # Dropping unused columns\n",
    "    events = events.drop(['riderID'], axis=1)\n",
    "\n",
    "    # Remove driver = TransitDriver or RidehailDriver for IDMerged = NAN because there are no agent information in\n",
    "    # these rows\n",
    "    events = events[~((events.driver.str.contains(\"Agent\", na=False)) & (events.IDMerged.isna()))].reset_index(\n",
    "        drop=True)\n",
    "\n",
    "    events[\"chargeID\"] = events.groupby('vehicle')['IDMerged'].transform(lambda x: x.ffill().bfill())\n",
    "\n",
    "    # Combining chargeID with IDMerged so no NANs anymore\n",
    "    events['IDMerged'] = events['chargeID'].combine_first(events['IDMerged'])\n",
    "\n",
    "    # Dropping unused columns\n",
    "    events = events.drop(['chargeID'], axis=1)\n",
    "\n",
    "    # Change the IDMerged column type to numeric\n",
    "    events[\"IDMerged\"] = pd.to_numeric(events.IDMerged)\n",
    "\n",
    "    # Sort by IDMerged and time columns\n",
    "    events = events.sort_values(['IDMerged', 'time']).reset_index(drop=True)\n",
    "\n",
    "    # We assume that the number of passengers is 1 for ride_hail_pooled\n",
    "    events['modeBEAM_rh'] = np.where(events.driver.str.contains(\"rideHailAgent\", na=False), 'ride_hail',\n",
    "                                     events['modeBEAM'])\n",
    "\n",
    "    # Adding teleportation mode to the type = TeleportationEvent row\n",
    "    events[\"modeBEAM_rh\"] = np.where(events['type'] == 'TeleportationEvent',\n",
    "                                     events.modeBEAM_rh.fillna(method='ffill'), events[\"modeBEAM_rh\"])\n",
    "    events['modeBEAM_rh_pooled'] = np.where(\n",
    "        (events['type'] == 'PersonCost') & (events['modeBEAM'] == 'ride_hail_pooled'), 'ride_hail_pooled', np.nan)\n",
    "    events['modeBEAM_rh_ride_hail_transit'] = np.where(\n",
    "        (events['type'] == 'PersonCost') & (events['modeBEAM'] == 'ride_hail_transit'), 'ride_hail_transit', np.nan)\n",
    "    events['modeBEAM_rh_pooled'] = events['modeBEAM_rh_pooled'].shift(+1)\n",
    "    events['modeBEAM_rh_ride_hail_transit'] = events['modeBEAM_rh_ride_hail_transit'].shift(+1)\n",
    "    events['modeBEAM_rh'] = np.where((events['type'] == 'PathTraversal') & (events['modeBEAM'] == 'car') & (\n",
    "        events['driver'].str.contains(\"rideHailAgent\", na=False)) & (events['modeBEAM_rh_pooled'] != 'nan'),\n",
    "                                     events['modeBEAM_rh_pooled'], events['modeBEAM_rh'])\n",
    "    # We don't know if ridehail_transit is ride_hail or ride_hail_pooled\n",
    "    events['modeBEAM_rh'] = np.where((events['type'] == 'PathTraversal') & (events['modeBEAM'] == 'car') & (\n",
    "        events['driver'].str.contains(\"rideHailAgent\", na=False)) & (\n",
    "                                             events['modeBEAM_rh_ride_hail_transit'] != 'nan'),\n",
    "                                     events['modeBEAM_rh_ride_hail_transit'], events['modeBEAM_rh'])\n",
    "\n",
    "    # Dropping the temporary columns\n",
    "    events = events.drop(['modeBEAM_rh_pooled'], axis=1)\n",
    "    events = events.drop(['modeBEAM_rh_ride_hail_transit'], axis=1)\n",
    "    return events\n",
    "\n",
    "\n",
    "def _expand_events_file(events):\n",
    "    events['actEndTime'] = np.where(events['type'] == 'actend', events['time'], np.nan)\n",
    "    events['actStartTime'] = np.where(events['type'] == 'actstart', events['time'], np.nan)\n",
    "    events['duration_travelling'] = np.where(\n",
    "        (events['type'] == 'PathTraversal') | (events['type'] == 'TeleportationEvent'),\n",
    "        events['arrivalTime'] - events['departureTime'], np.nan)\n",
    "    events['distance_travelling'] = np.where(\n",
    "        (events['type'] == 'PathTraversal') |\n",
    "        ((events['type'] == 'ModeChoice') & ((events['modeBEAM'] == 'hov2_teleportation') |\n",
    "                                             (events['modeBEAM'] == 'hov3_teleportation'))),\n",
    "        events['length'], np.nan)\n",
    "    events['distance_mode_choice'] = np.where(events['type'] == 'ModeChoice', events['length'], np.nan)\n",
    "    events['duration_walking'] = np.where(events['modeBEAM'] == 'walk', events['duration_travelling'], np.nan)\n",
    "    events['distance_walking'] = np.where(events['modeBEAM'] == 'walk', events['distance_travelling'], np.nan)\n",
    "    events['duration_on_bike'] = np.where(events['modeBEAM'] == 'bike', events['duration_travelling'], np.nan)\n",
    "    events['distance_bike'] = np.where(events['modeBEAM'] == 'bike', events['distance_travelling'], np.nan)\n",
    "    events['duration_in_ridehail'] = np.where(\n",
    "        (events['modeBEAM_rh'] == 'ride_hail') |\n",
    "        (events['modeBEAM_rh'] == 'ride_hail_pooled') |\n",
    "        (events['modeBEAM_rh'] == 'ride_hail_transit'), events['duration_travelling'], np.nan)\n",
    "    events['distance_ridehail'] = np.where(\n",
    "        (events['modeBEAM_rh'] == 'ride_hail') |\n",
    "        (events['modeBEAM_rh'] == 'ride_hail_pooled') |\n",
    "        (events['modeBEAM_rh'] == 'ride_hail_transit'), events['distance_travelling'], np.nan)\n",
    "    events['duration_in_privateCar'] = np.where(\n",
    "        (events['modeBEAM_rh'] == 'car') |\n",
    "        (events['modeBEAM_rh'] == 'car_hov3') |\n",
    "        (events['modeBEAM_rh'] == 'car_hov2') |\n",
    "        (events['modeBEAM_rh'] == 'hov2_teleportation') |\n",
    "        (events['modeBEAM_rh'] == 'hov3_teleportation'), events['duration_travelling'], np.nan)\n",
    "    events['distance_privateCar'] = np.where(\n",
    "        (events['modeBEAM_rh'] == 'car') |\n",
    "        (events['modeBEAM_rh'] == 'car_hov3') |\n",
    "        (events['modeBEAM_rh'] == 'car_hov2') |\n",
    "        (events['modeBEAM_rh'] == 'hov2_teleportation') |\n",
    "        (events['modeBEAM_rh'] == 'hov3_teleportation'), events['distance_travelling'], np.nan)\n",
    "    events['duration_in_transit'] = np.where(\n",
    "        (events['modeBEAM'] == 'bike_transit') | (events['modeBEAM'] == 'drive_transit') |\n",
    "        (events['modeBEAM'] == 'walk_transit') | (events['modeBEAM'] == 'bus') |\n",
    "        (events['modeBEAM'] == 'tram') | (events['modeBEAM'] == 'subway') |\n",
    "        (events['modeBEAM'] == 'rail') | (events['modeBEAM'] == 'cable_car') |\n",
    "        (events['modeBEAM'] == 'ride_hail_transit'), events['duration_travelling'], np.nan)\n",
    "    events['distance_transit'] = np.where(\n",
    "        (events['modeBEAM'] == 'bike_transit') | (events['modeBEAM'] == 'drive_transit') |\n",
    "        (events['modeBEAM'] == 'walk_transit') | (events['modeBEAM'] == 'bus') |\n",
    "        (events['modeBEAM'] == 'tram') | (events['modeBEAM'] == 'subway') |\n",
    "        (events['modeBEAM'] == 'rail') | (events['modeBEAM'] == 'cable_car') |\n",
    "        (events['modeBEAM'] == 'ride_hail_transit'), events['distance_travelling'], np.nan)\n",
    "\n",
    "    # Removing the extra tour index happening after replanning events\n",
    "    events['replanningTime'] = np.where(events['type'] == 'Replanning', events['time'], np.nan)\n",
    "    events['replanningTime'] = events['replanningTime'].shift(+1)\n",
    "    events['tourIndex_fixed'] = np.where((events['type'] == 'ModeChoice') & (events['replanningTime'].notna()),\n",
    "                                         np.nan, events['tourIndex'])\n",
    "    events['fuelFood'] = np.where((events['type'] == 'PathTraversal') & (events['primaryFuelType'] == 'Food'),\n",
    "                                  events['primaryFuel'], np.nan)\n",
    "    events['emissionFood'] = events['fuelFood'] * 8.3141841e-9 * 0\n",
    "    events['fuelElectricity'] = np.where(\n",
    "        (events['type'] == 'PathTraversal') & (events['primaryFuelType'] == 'Electricity'),\n",
    "        events['primaryFuel'], np.nan)\n",
    "    events['emissionElectricity'] = events['fuelElectricity'] * 2.77778e-10 * 947.2 * 0.0005\n",
    "    events['fuelDiesel'] = np.where((events['type'] == 'PathTraversal') & (events['primaryFuelType'] == 'Diesel'),\n",
    "                                    events['primaryFuel'], np.nan)\n",
    "    events['emissionDiesel'] = events['fuelDiesel'] * 8.3141841e-9 * 10.180e-3\n",
    "    events['fuelBiodiesel'] = np.where(\n",
    "        (events['type'] == 'PathTraversal') & (events['primaryFuelType'] == 'Biodiesel'),\n",
    "        events['primaryFuel'], np.nan)\n",
    "    events['emissionBiodiesel'] = events['fuelBiodiesel'] * 8.3141841e-9 * 10.180e-3\n",
    "    events['fuel_not_Food'] = np.where((events['type'] == 'PathTraversal') & (events['primaryFuelType'] != 'Food')\n",
    "                                       , events['primaryFuel'] + events['secondaryFuel'], np.nan)\n",
    "    events['fuelGasoline'] = np.where((events['type'] == 'PathTraversal') & (\n",
    "            (events['primaryFuelType'] == 'Gasoline') | (events['secondaryFuelType'] == 'Gasoline')),\n",
    "                                      events['primaryFuel'] + events['secondaryFuel'], np.nan)\n",
    "    events['emissionGasoline'] = events['fuelGasoline'] * 8.3141841e-9 * 8.89e-3\n",
    "\n",
    "    # Marginal fuel\n",
    "    conditions = [(events['modeBEAM_rh'] == 'ride_hail_pooled'),\n",
    "                  (events['modeBEAM_rh'] == 'walk_transit') | (events['modeBEAM_rh'] == 'drive_transit') |\n",
    "                  (events['modeBEAM_rh'] == 'ride_hail_transit') | (events['modeBEAM_rh'] == 'bus') | (\n",
    "                          events['modeBEAM_rh'] == 'subway') |\n",
    "                  (events['modeBEAM_rh'] == 'rail') | (events['modeBEAM_rh'] == 'tram') | (\n",
    "                          events['modeBEAM_rh'] == 'cable_car') |\n",
    "                  (events['modeBEAM_rh'] == 'bike_transit'),\n",
    "                  (events['modeBEAM_rh'] == 'walk') | (events['modeBEAM_rh'] == 'bike'),\n",
    "                  (events['modeBEAM_rh'] == 'ride_hail') | (events['modeBEAM_rh'] == 'car') |\n",
    "                  (events['modeBEAM_rh'] == 'car_hov2') | (events['modeBEAM_rh'] == 'car_hov3') |\n",
    "                  (events['modeBEAM_rh'] == 'hov2_teleportation') | (events['modeBEAM_rh'] == 'hov3_teleportation')]\n",
    "    choices = [events['fuel_not_Food'] / events['numPassengers'], 0, events['fuelFood'],\n",
    "               events['fuel_not_Food']]\n",
    "    events['fuel_marginal'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "    # Marginal emission\n",
    "    conditions1 = [(events['modeBEAM_rh'] == 'ride_hail_pooled') & (events['fuelElectricity'].notna() != 0),\n",
    "                   (events['modeBEAM_rh'] == 'ride_hail_pooled') & (events['fuelGasoline'].notna() != 0),\n",
    "                   (events['modeBEAM_rh'] == 'ride_hail_pooled') & (events['fuelBiodiesel'].notna() != 0),\n",
    "                   (events['modeBEAM_rh'] == 'ride_hail_pooled') & (events['fuelDiesel'].notna() != 0),\n",
    "                   (events['modeBEAM_rh'] == 'walk_transit') | (events['modeBEAM_rh'] == 'drive_transit') |\n",
    "                   (events['modeBEAM_rh'] == 'ride_hail_transit') | (events['modeBEAM_rh'] == 'bus') | (\n",
    "                           events['modeBEAM_rh'] == 'subway') |\n",
    "                   (events['modeBEAM_rh'] == 'rail') | (events['modeBEAM_rh'] == 'tram') | (\n",
    "                           events['modeBEAM_rh'] == 'cable_car') |\n",
    "                   (events['modeBEAM_rh'] == 'bike_transit'),\n",
    "\n",
    "                   (events['modeBEAM_rh'] == 'walk') | (events['modeBEAM_rh'] == 'bike'),\n",
    "\n",
    "                   (events['modeBEAM_rh'] == 'ride_hail') | (events['modeBEAM_rh'] == 'car') |\n",
    "                   (events['modeBEAM_rh'] == 'car_hov2') | (events['modeBEAM_rh'] == 'car_hov3') |\n",
    "                   (events['modeBEAM_rh'] == 'hov2_teleportation') | (\n",
    "                           events['modeBEAM_rh'] == 'hov3_teleportation') &\n",
    "                   (events['fuelElectricity'].notna() != 0),\n",
    "\n",
    "                   (events['modeBEAM_rh'] == 'ride_hail') | (events['modeBEAM_rh'] == 'car') |\n",
    "                   (events['modeBEAM_rh'] == 'car_hov2') | (events['modeBEAM_rh'] == 'car_hov3') |\n",
    "                   (events['modeBEAM_rh'] == 'hov2_teleportation') | (\n",
    "                           events['modeBEAM_rh'] == 'hov3_teleportation') &\n",
    "                   (events['fuelGasoline'].notna() != 0),\n",
    "\n",
    "                   (events['modeBEAM_rh'] == 'ride_hail') | (events['modeBEAM_rh'] == 'car') |\n",
    "                   (events['modeBEAM_rh'] == 'car_hov2') | (events['modeBEAM_rh'] == 'car_hov3') |\n",
    "                   (events['modeBEAM_rh'] == 'hov2_teleportation') | (\n",
    "                           events['modeBEAM_rh'] == 'hov3_teleportation') &\n",
    "                   (events['fuelBiodiesel'].notna() != 0),\n",
    "\n",
    "                   (events['modeBEAM_rh'] == 'ride_hail') | (events['modeBEAM_rh'] == 'car') |\n",
    "                   (events['modeBEAM_rh'] == 'car_hov2') | (events['modeBEAM_rh'] == 'car_hov3') |\n",
    "                   (events['modeBEAM_rh'] == 'hov2_teleportation') | (\n",
    "                           events['modeBEAM_rh'] == 'hov3_teleportation') &\n",
    "                   (events['fuelDiesel'].notna() != 0),\n",
    "\n",
    "                   (events['modeBEAM_rh'] == 'ride_hail') | (events['modeBEAM_rh'] == 'car') |\n",
    "                   (events['modeBEAM_rh'] == 'car_hov2') | (events['modeBEAM_rh'] == 'car_hov3') |\n",
    "                   (events['modeBEAM_rh'] == 'hov2_teleportation') | (\n",
    "                           events['modeBEAM_rh'] == 'hov3_teleportation') &\n",
    "                   (events['fuelFood'].notna() != 0)]\n",
    "\n",
    "    choices1 = [events['emissionElectricity'] / events['numPassengers'],\n",
    "                events['emissionGasoline'] / events['numPassengers'],\n",
    "                events['emissionBiodiesel'] / events['numPassengers'],\n",
    "                events['emissionDiesel'] / events['numPassengers'],\n",
    "                0,\n",
    "                events['emissionFood'],\n",
    "                events['emissionElectricity'],\n",
    "                events['emissionGasoline'],\n",
    "                events['emissionBiodiesel'],\n",
    "                events['emissionDiesel'],\n",
    "                events['emissionFood']]\n",
    "\n",
    "    events['emission_marginal'] = np.select(conditions1, choices1, default=np.nan)\n",
    "    events['actEndType'] = np.where(events['type'] == 'actend', events['actType'], \"\")\n",
    "    events['actStartType'] = np.where(events['type'] == 'actstart', events['actType'], \"\")\n",
    "    events[\"tripIndex\"] = events.tripId.fillna(method='ffill')\n",
    "    events['mode_choice_actual_BEAM'] = events.groupby(['IDMerged', 'tripId', 'type'])['modeBEAM'].transform('last')\n",
    "    events['mode_choice_planned_BEAM'] = events.groupby(['IDMerged', 'tripId', 'type'])['modeBEAM'].transform(\n",
    "        'first')\n",
    "    events['mode_choice_actual_BEAM'] = np.where(events['type'] != 'ModeChoice', np.nan,\n",
    "                                                 events['mode_choice_actual_BEAM'])\n",
    "    events['mode_choice_planned_BEAM'] = np.where(events['type'] != 'ModeChoice', np.nan,\n",
    "                                                  events['mode_choice_planned_BEAM'])\n",
    "\n",
    "    # Rename the \"netCost\" column\n",
    "    events.rename(columns={\"netCost\": \"cost_BEAM\"}, inplace=True)\n",
    "    # Replanning events = 1, the rest = 0\n",
    "    events['replanning_status'] = np.where(events['type'] == 'Replanning', 1, 0)\n",
    "    events['reason'].replace('nan', np.NaN)\n",
    "    events['transit_bus'] = np.where(events['modeBEAM_rh'] == 'bus', 1, 0)\n",
    "    events['transit_subway'] = np.where(events['modeBEAM_rh'] == 'subway', 1, 0)\n",
    "    events['transit_tram'] = np.where(events['modeBEAM_rh'] == 'tram', 1, 0)\n",
    "    events['transit_rail'] = np.where(events['modeBEAM_rh'] == 'rail', 1, 0)\n",
    "    events['transit_cable_car'] = np.where(events['modeBEAM_rh'] == 'cable_car', 1, 0)\n",
    "    events['ride_hail_pooled'] = np.where(events['modeBEAM_rh'] == 'ride_hail_pooled', 1, 0)\n",
    "    return events\n",
    "\n",
    "\n",
    "def _add_geometry_id_to_DataFrame(df, gdf, xcol, ycol, idColumn=\"geometry\", df_geom='epsg:4326'):\n",
    "    gdf_data = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[xcol], df[ycol]))\n",
    "    gdf_data.set_crs(df_geom, inplace=True)\n",
    "    joined = gpd.sjoin(gdf_data.to_crs('epsg:26910'), gdf.to_crs('epsg:26910'))\n",
    "    gdf_data = gdf_data.merge(joined['zone_id'], left_index=True, right_index=True, how=\"left\")\n",
    "    gdf_data.rename(columns={'zone_id': idColumn}, inplace=True)\n",
    "    df = pd.DataFrame(gdf_data.drop(columns='geometry'))\n",
    "    df.drop(columns=[xcol, ycol], inplace=True)\n",
    "    return df.loc[~df.index.duplicated(keep='first'), :]\n",
    "\n",
    "\n",
    "def _add_geometry_to_events(settings, events):\n",
    "    if settings['region'] == 'austin':\n",
    "        taz_id_col_in = 'GEOID'\n",
    "    else:\n",
    "        taz_id_col_in = 'taz1454'\n",
    "    taz = get_taz_geoms(settings, taz_id_col_in=taz_id_col_in)\n",
    "    processed_list = Parallel(n_jobs=cpu_count() - 1)(\n",
    "        delayed(_add_geometry_id_to_DataFrame)(ev, taz, \"startX\", \"startY\", \"BlockGroupStart\") for ev in\n",
    "        np.array_split(events, cpu_count() - 1))\n",
    "    processed_list = Parallel(n_jobs=cpu_count() - 1)(\n",
    "        delayed(_add_geometry_id_to_DataFrame)(ev, taz, \"endX\", \"endY\", \"BlockGroupEnd\") for ev in\n",
    "        processed_list)\n",
    "    events = pd.concat(processed_list)\n",
    "    return events\n",
    "\n",
    "\n",
    "def _aggregate_on_trip(df, name):\n",
    "    aggfunc = {'actStartTime': np.sum,\n",
    "               'actEndTime': np.sum,\n",
    "               'duration_travelling': np.sum,\n",
    "               'cost_BEAM': np.sum,\n",
    "               'actStartType': np.sum,\n",
    "               'actEndType': np.sum,\n",
    "               'duration_walking': np.sum,\n",
    "               'duration_in_privateCar': np.sum,\n",
    "               'duration_on_bike': np.sum,\n",
    "               'duration_in_ridehail': np.sum,\n",
    "               'distance_travelling': np.sum,\n",
    "               'duration_in_transit': np.sum,\n",
    "               'distance_walking': np.sum,\n",
    "               'distance_bike': np.sum,\n",
    "               'distance_ridehail': np.sum,\n",
    "               'distance_privateCar': np.sum,\n",
    "               'distance_transit': np.sum,\n",
    "               'legVehicleIds': np.sum,\n",
    "               'mode_choice_planned_BEAM': lambda x: ', '.join(set(x.dropna().astype(str))),\n",
    "               'mode_choice_actual_BEAM': lambda x: ', '.join(set(x.dropna().astype(str))),\n",
    "               'vehicle': lambda x: ', '.join(set(x.dropna().astype(str))),\n",
    "               'numPassengers': lambda x: ', '.join(list(x.dropna().astype(str))),\n",
    "               'distance_mode_choice': np.sum,\n",
    "               'replanning_status': np.sum,\n",
    "               'reason': lambda x: ', '.join(list(x.dropna().astype(str))),\n",
    "               'parkingType': lambda x: ', '.join(list(x.dropna().astype(str))),\n",
    "               'transit_bus': np.sum,\n",
    "               'transit_subway': np.sum,\n",
    "               'transit_tram': np.sum,\n",
    "               'transit_cable_car': np.sum,\n",
    "               'ride_hail_pooled': np.sum,\n",
    "               'transit_rail': np.sum,\n",
    "               'fuelFood': np.sum,\n",
    "               'fuelElectricity': np.sum,\n",
    "               'fuelBiodiesel': np.sum,\n",
    "               'fuelDiesel': np.sum,\n",
    "               'fuel_not_Food': np.sum,\n",
    "               'fuelGasoline': np.sum,\n",
    "               'fuel_marginal': np.sum,\n",
    "               'BlockGroupStart': 'first',\n",
    "               'BlockGroupEnd': 'last',\n",
    "               'emissionFood': np.sum,\n",
    "               'emissionElectricity': np.sum,\n",
    "               'emissionDiesel': np.sum,\n",
    "               'emissionGasoline': np.sum,\n",
    "               'emissionBiodiesel': np.sum,\n",
    "               'emission_marginal': np.sum\n",
    "               }\n",
    "    agg = df.groupby('tripIndex').agg(aggfunc)\n",
    "    return pd.concat({name: agg}, names=[\"IDMerged\"])\n",
    "\n",
    "\n",
    "def _build_person_trip_events(events):\n",
    "    gb = events.groupby('IDMerged')\n",
    "    processed_list = Parallel(n_jobs=cpu_count() - 1)(delayed(_aggregate_on_trip)(group, name) for name, group in gb)\n",
    "    person_trip_events = pd.concat(processed_list)\n",
    "    return person_trip_events\n",
    "\n",
    "\n",
    "def _process_person_trip_events(person_trip_events):\n",
    "    person_trip_events['duration_door_to_door'] = person_trip_events['actStartTime'] - person_trip_events[\n",
    "        'actEndTime']\n",
    "    person_trip_events['waitTime'] = person_trip_events['duration_door_to_door'] - person_trip_events[\n",
    "        'duration_travelling']\n",
    "    person_trip_events['actPurpose'] = person_trip_events['actEndType'].astype(str) + \"_to_\" + person_trip_events[\n",
    "        'actStartType'].astype(str)\n",
    "    person_trip_events.rename(columns={\"legVehicleIds\": \"vehicleIds_estimate\"}, inplace=True)\n",
    "    person_trip_events.rename(columns={\"vehicle\": \"vehicleIds\"}, inplace=True)\n",
    "    # Column with five summarized modes\n",
    "    conditions = [(person_trip_events['mode_choice_actual_BEAM'] == 'ride_hail') | (\n",
    "            person_trip_events['mode_choice_actual_BEAM'] == 'ride_hail_pooled'),\n",
    "                  (person_trip_events['mode_choice_actual_BEAM'] == 'walk_transit') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'drive_transit') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'ride_hail_transit') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'bike_transit'),\n",
    "                  (person_trip_events['mode_choice_actual_BEAM'] == 'walk'),\n",
    "                  (person_trip_events['mode_choice_actual_BEAM'] == 'bike'),\n",
    "                  (person_trip_events['mode_choice_actual_BEAM'] == 'car') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'car_hov2') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'car_hov3') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'hov2_teleportation') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'hov3_teleportation')]\n",
    "    choices = ['ride_hail', 'transit', 'walk', 'bike', 'car']\n",
    "    person_trip_events['mode_choice_actual_5'] = np.select(conditions, choices, default=np.nan)\n",
    "    # Column with six summarized modes\n",
    "    conditions = [(person_trip_events['mode_choice_actual_BEAM'] == 'ride_hail') | (\n",
    "            person_trip_events['mode_choice_actual_BEAM'] == 'ride_hail_pooled'),\n",
    "                  (person_trip_events['mode_choice_actual_BEAM'] == 'walk_transit') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'drive_transit') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'bike_transit'),\n",
    "                  (person_trip_events['mode_choice_actual_BEAM'] == 'walk'),\n",
    "                  (person_trip_events['mode_choice_actual_BEAM'] == 'bike'),\n",
    "                  (person_trip_events['mode_choice_actual_BEAM'] == 'car') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'car_hov2') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'car_hov3') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'hov2_teleportation') | (\n",
    "                          person_trip_events['mode_choice_actual_BEAM'] == 'hov3_teleportation'),\n",
    "                  (person_trip_events['mode_choice_actual_BEAM'] == 'ride_hail_transit')]\n",
    "    choices = ['ride_hail', 'transit', 'walk', 'bike', 'car', 'ride_hail_transit']\n",
    "    person_trip_events['mode_choice_actual_6'] = np.select(conditions, choices, default=np.nan)\n",
    "    return person_trip_events.sort_values(by=['IDMerged', 'tripIndex']).reset_index(drop=False)\n",
    "\n",
    "\n",
    "def _read_asim_utilities(settings, year, iteration):\n",
    "    asim_output_data_dir = settings['asim_local_output_folder']\n",
    "    iteration_output_dir = \"year-{0}-iteration-{1}\".format(year, iteration)\n",
    "    trip_utility_location = os.path.join(asim_output_data_dir, iteration_output_dir, \"trip_mode_choice.zip\")\n",
    "    chunks = []\n",
    "    with zipfile.ZipFile(trip_utility_location) as z:\n",
    "        for filename in z.namelist():\n",
    "            if not os.path.isdir(filename):\n",
    "                if filename.endswith(\"utilities.csv\"):\n",
    "                    chunks.append(pd.read_csv(z.open(filename)))\n",
    "    return pd.concat(chunks, ignore_index=True).sort_values(by=['trip_id'])\n",
    "\n",
    "\n",
    "def _merge_trips_with_utilities(asim_trips, asim_utilities, beam_trips):\n",
    "    SFActMerged = pd.merge(left=asim_trips, right=asim_utilities, how='left', on=['trip_id']).sort_values(\n",
    "        by=['person_id', 'trip_id']).reset_index(drop=True)\n",
    "    eventsASim = pd.merge(left=beam_trips, right=SFActMerged, how='left', left_on=[\"IDMerged\", 'tripIndex'],\n",
    "                          right_on=['person_id', 'trip_id'])\n",
    "    eventsASim.rename(columns={\"mode_choice_logsum_y\": \"logsum_tours_mode_AS_tours\"}, inplace=True)\n",
    "    eventsASim.rename(columns={\"tour_mode\": \"tour_mode_AS_tours\"}, inplace=True)\n",
    "    eventsASim.rename(columns={\"mode_choice_logsum_x\": \"logsum_trip_mode_AS_trips\"}, inplace=True)\n",
    "    eventsASim.rename(columns={\"trip_mode\": \"trip_mode_AS_trips\"}, inplace=True)\n",
    "    return eventsASim\n",
    "\n",
    "\n",
    "def _read_asim_plans(settings, year, iteration):\n",
    "    asim_output_data_dir = settings['asim_local_output_folder']\n",
    "    iteration_output_dir = \"year-{0}-iteration-{1}\".format(year, iteration)\n",
    "    path = os.path.join(asim_output_data_dir, iteration_output_dir)\n",
    "    households = pd.read_csv(os.path.join(path, \"households.csv.gz\")).sort_values(by=['household_id']).reset_index(\n",
    "        drop=True)\n",
    "    persons = pd.read_csv(os.path.join(path, \"persons.csv.gz\")).sort_values(by=['household_id']).reset_index(drop=True)\n",
    "    tours = pd.read_csv(os.path.join(path, \"final_tours.csv.gz\")).sort_values(by=['person_id']).reset_index(drop=True)\n",
    "    trips = pd.read_csv(os.path.join(path, \"final_trips.csv.gz\")).sort_values(by=['person_id', 'tour_id']).reset_index(\n",
    "        drop=True)\n",
    "    hhpersons = pd.merge(left=persons, right=households, how='left', on='household_id')\n",
    "    hhperTours = pd.merge(left=tours, right=hhpersons, how='left', on='person_id').sort_values(\n",
    "        by=['person_id', 'tour_id']).reset_index(drop=True)\n",
    "    tour_trips = pd.merge(left=trips, right=hhperTours, how='left', on=['person_id', 'tour_id']).sort_values(\n",
    "        by=['trip_id'])\n",
    "    return tour_trips\n",
    "\n",
    "\n",
    "def build_mep_summaries(trips, settings, iteration):\n",
    "    totalsByMode = trips.loc[:,\n",
    "                   ['mode_choice_actual_BEAM', 'cost_BEAM', 'distance_mode_choice', 'fuel_marginal']].groupby(\n",
    "        'mode_choice_actual_BEAM').agg(sum)\n",
    "    totalsByMode.index = totalsByMode.index.str.replace(\"teleportation\", \"passenger\")\n",
    "    totalsByMode['cost_per_passenger_mile'] = totalsByMode['cost_BEAM'] / totalsByMode['distance_mode_choice'] * 1609.34\n",
    "    totalsByMode['joules_per_passenger_mile'] = totalsByMode['fuel_marginal'] / totalsByMode[\n",
    "        'distance_mode_choice'] * 1609.34\n",
    "    beam_output_dir = settings['beam_local_output_folder']\n",
    "    region = settings['region']\n",
    "    iteration_output_dir = \"year-{0}-iteration-{1}\".format(year, iteration)\n",
    "    totalsByMode.to_csv(os.path.join(beam_output_dir, region, iteration_output_dir, \"totalsByMode.csv\"))\n",
    "\n",
    "\n",
    "def process_event_file(settings, year, iteration):\n",
    "    try:\n",
    "        logger.info(\"Loading utilities\")\n",
    "        utils = _read_asim_utilities(settings, year, iteration)\n",
    "        logger.info(\"Loading events\")\n",
    "        events = _load_events_file(settings, year, iteration)\n",
    "        events = _reformat_events_file(events)\n",
    "        # TODO: get cost and energy per passenger mile for the different modes\n",
    "        logger.info(\"Adding geoms to events\")\n",
    "        events = _add_geometry_to_events(settings, events)\n",
    "        logger.info(\"Expanding events\")\n",
    "        events = _expand_events_file(events)\n",
    "        logger.info(\"Building person trip events\")\n",
    "        person_trip_events = _build_person_trip_events(events)\n",
    "        del events\n",
    "        person_trip_events = _process_person_trip_events(person_trip_events)\n",
    "        logger.info(\"Reading asim plans\")\n",
    "        tour_trips = _read_asim_plans(settings, year, iteration)\n",
    "        logger.info(\"Merging final outputs\")\n",
    "        final_output = _merge_trips_with_utilities(tour_trips, utils, person_trip_events)\n",
    "        build_mep_summaries(final_output, settings, iteration)\n",
    "        scenario_defs = settings['scenario_definitions']\n",
    "\n",
    "        post_output_folder = settings['postprocessing_output_folder']\n",
    "\n",
    "        filename = \"{0}_{1}_{2}-{3}_{4}__{5}.csv.gz\".format(settings['region'],\n",
    "                                                            scenario_defs['name'],\n",
    "                                                            scenario_defs['lever'],\n",
    "                                                            scenario_defs['lever_position'],\n",
    "                                                            year,\n",
    "                                                            date.today().strftime(\"%Y%m%d\"))\n",
    "        final_output.to_csv(os.path.join(post_output_folder, filename), compression=\"gzip\")\n",
    "    except:\n",
    "        logger.error(\"Did not successfully run the postproccessor, did activitysim fail?\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.chdir(\"../..\")\n",
    "    settings = parse_args_and_settings(os.path.join(\"settings.yaml\"))\n",
    "    beam_output_dir = settings['beam_local_output_folder']\n",
    "    region = settings['region']\n",
    "    output_path = os.path.join(beam_output_dir, region, \"year*\")\n",
    "    outputDirs = glob.glob(output_path)\n",
    "    yearsAndIters = [(loc.split('-', 3)[-3], loc.split('-', 3)[-1]) for loc in outputDirs]\n",
    "    yrs = dict()\n",
    "    # Only do this for the latest available iteration in each year\n",
    "    for year, iter in yearsAndIters:\n",
    "        if year in yrs:\n",
    "            if int(iter) > int(yrs[year]):\n",
    "                yrs[year] = iter\n",
    "        else:\n",
    "            yrs[year] = iter\n",
    "    for year, iter in yrs.items():\n",
    "        process_event_file(settings, year, iter)\n",
    "        copy_outputs_to_mep(settings, year, iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff64f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

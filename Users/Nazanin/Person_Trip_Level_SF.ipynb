{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f55cd92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import boto.s3\n",
    "import glob\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5337b34",
   "metadata": {},
   "source": [
    "#### Read the files directly from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be7945a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:25: DtypeWarning: Columns (13,21,22,37,41,42,46,51) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 17s\n",
      "Wall time: 3min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s3 = boto3.client(\"s3\")\n",
    "key = \"pilates-outputs/sfbay-baseline-20220822/beam/year-2018-iteration-5/ITERS/it.0/0.events.csv.gz\"  #the path should be updated\n",
    "obj = s3.get_object(Bucket=\"beam-outputs\", Key=key)\n",
    "dtypes = {\n",
    "    \"time\": \"float32\",\n",
    "    \"type\": \"category\",\n",
    "    \"legMode\": \"category\",\n",
    "    \"actType\": \"category\", \n",
    "    \"primaryFuelLevel\": \"float64\",\n",
    "    \"legMode\": \"category\",\n",
    "    \"chargingPointType\":\"category\",\n",
    "    \"pricingModel\":\"category\",\n",
    "    \"parkingType\":\"category\",\n",
    "    \"mode\":\"category\",\n",
    "    \"personalVehicleAvailable\": \"category\",\n",
    "    \"person\": \"object\",\n",
    "    \"driver\": \"object\",\n",
    "    \"riders\": \"object\",\n",
    "    'primaryFuelType': \"category\",\n",
    "    'secondaryFuelType': 'category',\n",
    "    'currentTourMode': 'category',\n",
    "    'currentActivity': 'category',\n",
    "    'nextActivity': 'category'    \n",
    "}\n",
    "eventsSF = pd.read_csv(obj['Body'], compression = 'gzip', dtype = dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44a5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns and rows\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f2c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the entire number in dataframe\n",
    "pd.set_option('float_format', '{:f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c33f5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding scenario info\n",
    "eventsSF['scenario'] = \"baseline\"\n",
    "eventsSF['scenario'] = eventsSF['scenario'].astype(\"category\")\n",
    "eventsSF['lever'] = \"default\"\n",
    "eventsSF['lever'] = eventsSF['lever'].astype(\"category\")\n",
    "eventsSF['year'] = 2018\n",
    "eventsSF['lever_position'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fbd0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the \"mode\" column\n",
    "eventsSF.rename(columns={\"mode\":\"modeBEAM\"}, inplace=True) \n",
    "# Replace \"Work\" with \"work\" in the \"actType\" column\n",
    "eventsSF[\"actType\"].replace({\"Work\": \"work\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d74acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove person = TransitDriver or RidehailDriver because there are no agent information in these rows\n",
    "eventsSF = eventsSF[~eventsSF.person.str.contains(\"Agent\", na=False)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a95d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the cases where parking events have time = 0 which are additional parking events that were thrown at the beginning \n",
    "# of the day when vehicles are first assigned to a parking spot \n",
    "eventsSF = eventsSF[~((eventsSF.type.str.contains(\"ParkingEvent\", na=False))&(eventsSF['time']==0))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64b6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift column 'person' to first position\n",
    "first_column = eventsSF.pop('person')\n",
    "second_column = eventsSF.pop('driver')\n",
    "third_column = eventsSF.pop('riders')\n",
    "# insert column using insert(position,column_name,first_column) function\n",
    "eventsSF.insert(0, 'person', first_column)\n",
    "eventsSF.insert(1, 'driver', second_column)\n",
    "eventsSF.insert(2, 'riders', third_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77e7695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the IDMerged Column\n",
    "eventsSF['UniqueID'] = eventsSF['person'] #make a copy of the person column\n",
    "eventsSF['personID'] = np.where(eventsSF['person'].isin(eventsSF['driver']), eventsSF['person'], np.nan) \n",
    "eventsSF['driverID'] = np.where(eventsSF['driver'].isin(eventsSF['person']), eventsSF['driver'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f2b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging person and driver ids in one column\n",
    "eventsSF['IDMerged'] = eventsSF['personID'].combine_first(eventsSF['driverID'])\n",
    "eventsSF['IDMerged'] = eventsSF['UniqueID'].combine_first(eventsSF['IDMerged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ccea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unused columns\n",
    "eventsSF = eventsSF.drop(['personID','driverID','UniqueID'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f6d5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift column 'IDMerged' to first position\n",
    "first_column = eventsSF.pop('IDMerged')\n",
    "# Insert column using insert(position,column_name,first_column) function\n",
    "eventsSF.insert(0, 'IDMerged', first_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dffe8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 43s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Split the \"riders' column and replicated rows for every rider\n",
    "eventsSF['riders'] = eventsSF['riders'].str.split(':')\n",
    "eventsSF = eventsSF.explode('riders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cad273bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine riderID with IDMerged\n",
    "eventsSF['riderID'] = np.where(eventsSF['riders'].isin(eventsSF['person']), eventsSF['riders'], np.nan)\n",
    "eventsSF['IDMerged'] = eventsSF['riderID'].combine_first(eventsSF['IDMerged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65de33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unused columns\n",
    "eventsSF = eventsSF.drop(['riderID'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8a62eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove driver = TransitDriver or RidehailDriver for IDMerged = NAN because there are no agent information in these rows \n",
    "eventsSF = eventsSF[~((eventsSF.driver.str.contains(\"Agent\", na=False))&(eventsSF.IDMerged.isna()))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60db4199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#IDnan = eventsSF[eventsSF['IDMerged'].isna()]\n",
    "#IDnan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "994ab676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 30s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Filling NANs in ID related to charging events\n",
    "eventsSF[\"chargeID\"] = eventsSF.groupby('vehicle')['IDMerged'].transform(lambda x: x.ffill().bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0165322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining chargeID with IDMerged so no NANs anymore\n",
    "eventsSF['IDMerged'] = eventsSF['chargeID'].combine_first(eventsSF['IDMerged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "525d0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDnan = eventsSF[eventsSF['IDMerged'].isna()]\n",
    "#IDnan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dff0f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unused columns\n",
    "eventsSF = eventsSF.drop(['chargeID'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad36c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.8 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Change the IDMerged column type to numeric\n",
    "eventsSF[\"IDMerged\"] = pd.to_numeric(eventsSF.IDMerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "983217d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by IDMerged and time columns\n",
    "eventsSF = eventsSF.sort_values(['IDMerged','time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2db653ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume that the number of passengers is 1 for ride_hail_pooled\n",
    "eventsSF['modeBEAM_rh'] = np.where(eventsSF.driver.str.contains(\"rideHailAgent\", na=False), 'ride_hail' , eventsSF['modeBEAM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd4c6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding teleportation mode to the type = TeleportationEvent row \n",
    "eventsSF[\"modeBEAM_rh\"] = np.where(eventsSF['type']=='TeleportationEvent', eventsSF.modeBEAM_rh.fillna(method='ffill'), eventsSF[\"modeBEAM_rh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e1ba837",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['modeBEAM_rh_pooled'] = np.where((eventsSF['type'] == 'PersonCost') & (eventsSF['modeBEAM'] == 'ride_hail_pooled'), 'ride_hail_pooled', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3339c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['modeBEAM_rh_ride_hail_transit'] = np.where((eventsSF['type'] == 'PersonCost') & (eventsSF['modeBEAM'] == 'ride_hail_transit'), 'ride_hail_transit', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1eb832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['modeBEAM_rh_pooled'] = eventsSF['modeBEAM_rh_pooled'].shift(+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92e73beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['modeBEAM_rh_ride_hail_transit'] = eventsSF['modeBEAM_rh_ride_hail_transit'].shift(+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "120a46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['modeBEAM_rh'] = np.where((eventsSF['type'] == 'PathTraversal') & (eventsSF['modeBEAM'] == 'car') & (eventsSF['driver'].str.contains(\"rideHailAgent\", na=False)) & (eventsSF['modeBEAM_rh_pooled'] != 'nan'), eventsSF['modeBEAM_rh_pooled'], eventsSF['modeBEAM_rh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99d82b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't know if ridehail_transit is ride_hail or ride_hail_pooled\n",
    "eventsSF['modeBEAM_rh'] = np.where((eventsSF['type'] == 'PathTraversal') & (eventsSF['modeBEAM'] == 'car') & (eventsSF['driver'].str.contains(\"rideHailAgent\", na=False)) & (eventsSF['modeBEAM_rh_ride_hail_transit'] != 'nan'), eventsSF['modeBEAM_rh_ride_hail_transit'], eventsSF['modeBEAM_rh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3db04d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the temporary columns\n",
    "eventsSF = eventsSF.drop(['modeBEAM_rh_pooled'], axis=1)\n",
    "eventsSF = eventsSF.drop(['modeBEAM_rh_ride_hail_transit'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f3a97",
   "metadata": {},
   "source": [
    "#### Adding the census blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdaeafcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addGeometryIdToDataFrame(df, gdf, xcol, ycol, idColumn=\"geometry\", df_geom='epsg:4326'):\n",
    "    gdf_data = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[xcol], df[ycol]))\n",
    "    gdf_data.crs = {'init': df_geom}\n",
    "    joined = gpd.sjoin(gdf_data.to_crs('epsg:26910'), gdf.to_crs('epsg:26910'))\n",
    "    gdf_data = gdf_data.merge(joined['blkgrpid'], left_index=True, right_index=True, how=\"left\")\n",
    "    gdf_data.rename(columns={'blkgrpid': idColumn}, inplace=True)\n",
    "    df = pd.DataFrame(gdf_data.drop(columns='geometry'))\n",
    "    #df.drop(columns=[xcol, ycol], inplace=True)\n",
    "    return df.loc[~df.index.duplicated(keep='first'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "411a779f",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# census_2010 = \"https://beam-core-act.s3.amazonaws.com/deepDive/RawData/Census_Blocks/Scenario_2010_shp/\"\n",
    "BGs = gpd.read_file('/vsicurl/https://github.com/LBNL-UCB-STI/beam-core-analysis/raw/main/Users/Zach/scenario/sfbay-blockgroups-2010/641aa0d4-ce5b-4a81-9c30-8790c4ab8cfb202047-1-wkkklf.j5ouj.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcc7abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazanin\\.conda\\envs\\geo_env\\lib\\site-packages\\pyproj\\crs\\crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 57min 39s\n",
      "Wall time: 57min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eventsSF = addGeometryIdToDataFrame(eventsSF, BGs, 'startX', 'startY', 'BlockGroupStart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1588177c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgid</th>\n",
       "      <th>tractid</th>\n",
       "      <th>juris_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>mpo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60014001001</td>\n",
       "      <td>6001400100</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60855044171</td>\n",
       "      <td>6085504417</td>\n",
       "      <td>Milpitas</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60750228032</td>\n",
       "      <td>6075022803</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>San Francisco County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60750228033</td>\n",
       "      <td>6075022803</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>San Francisco County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60750229011</td>\n",
       "      <td>6075022901</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>San Francisco County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60750229012</td>\n",
       "      <td>6075022901</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>San Francisco County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60750229013</td>\n",
       "      <td>6075022901</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>San Francisco County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60750229021</td>\n",
       "      <td>6075022902</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>San Francisco County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60014034003</td>\n",
       "      <td>6001403400</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60014054012</td>\n",
       "      <td>6001405401</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>San Francisco Bay Area (MTC)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bgid     tractid     juris_name           county_name  \\\n",
       "0  60014001001  6001400100        Oakland        Alameda County   \n",
       "1  60855044171  6085504417       Milpitas    Santa Clara County   \n",
       "2  60750228032  6075022803  San Francisco  San Francisco County   \n",
       "3  60750228033  6075022803  San Francisco  San Francisco County   \n",
       "4  60750229011  6075022901  San Francisco  San Francisco County   \n",
       "5  60750229012  6075022901  San Francisco  San Francisco County   \n",
       "6  60750229013  6075022901  San Francisco  San Francisco County   \n",
       "7  60750229021  6075022902  San Francisco  San Francisco County   \n",
       "8  60014034003  6001403400        Oakland        Alameda County   \n",
       "9  60014054012  6001405401        Oakland        Alameda County   \n",
       "\n",
       "                            mpo  \n",
       "0  San Francisco Bay Area (MTC)  \n",
       "1  San Francisco Bay Area (MTC)  \n",
       "2  San Francisco Bay Area (MTC)  \n",
       "3  San Francisco Bay Area (MTC)  \n",
       "4  San Francisco Bay Area (MTC)  \n",
       "5  San Francisco Bay Area (MTC)  \n",
       "6  San Francisco Bay Area (MTC)  \n",
       "7  San Francisco Bay Area (MTC)  \n",
       "8  San Francisco Bay Area (MTC)  \n",
       "9  San Francisco Bay Area (MTC)  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "118e809f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tazs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tazs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m block_info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbg_w_geog_labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m eventsSF[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtazs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43meventsSF\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtazs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tazs'"
     ]
    }
   ],
   "source": [
    "block_info = pd.read_csv('bg_w_geog_labels.csv')\n",
    "eventsSF['tazs'] = eventsSF['tazs'].fillna(0).astype(int)\n",
    "eventsSF = pd.merge(eventsSF, block_info,  how='left',  left_on = 'tazs', right_on = 'bgid',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9eae57c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 832. MiB for an array with shape (3, 36360951) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "Input \u001b[1;32mIn [83]\u001b[0m, in \u001b[0;36maddGeometryIdToDataFrame\u001b[1;34m(df, gdf, xcol, ycol, idColumn, df_geom)\u001b[0m\n\u001b[0;32m      2\u001b[0m gdf_data \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(df, geometry\u001b[38;5;241m=\u001b[39mgpd\u001b[38;5;241m.\u001b[39mpoints_from_xy(df[xcol], df[ycol]))\n\u001b[0;32m      3\u001b[0m gdf_data\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m'\u001b[39m: df_geom}\n\u001b[1;32m----> 4\u001b[0m joined \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39msjoin(\u001b[43mgdf_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_crs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepsg:26910\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, gdf\u001b[38;5;241m.\u001b[39mto_crs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsg:26910\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m gdf_data \u001b[38;5;241m=\u001b[39m gdf_data\u001b[38;5;241m.\u001b[39mmerge(joined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblkgrpid\u001b[39m\u001b[38;5;124m'\u001b[39m], left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m gdf_data\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblkgrpid\u001b[39m\u001b[38;5;124m'\u001b[39m: idColumn}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\geopandas\\geodataframe.py:1246\u001b[0m, in \u001b[0;36mGeoDataFrame.to_crs\u001b[1;34m(self, crs, epsg, inplace)\u001b[0m\n\u001b[0;32m   1244\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1246\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1247\u001b[0m geom \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mto_crs(crs\u001b[38;5;241m=\u001b[39mcrs, epsg\u001b[38;5;241m=\u001b[39mepsg)\n\u001b[0;32m   1248\u001b[0m df\u001b[38;5;241m.\u001b[39mgeometry \u001b[38;5;241m=\u001b[39m geom\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\generic.py:6032\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5926\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   5927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, deep: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   5928\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5929\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   5930\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6030\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   6031\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6032\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6033\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6034\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:603\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    601\u001b[0m     new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 603\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:643\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    641\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 643\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(values, placement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr_locs, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 832. MiB for an array with shape (3, 36360951) and data type int64"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eventsSF = addGeometryIdToDataFrame(eventsSF, BGs, 'endX', 'endY', 'BlockGroupEnd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a8b31",
   "metadata": {},
   "source": [
    "#### Adding new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff786a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['actEndTime'] = np.where(eventsSF['type']=='actend'\n",
    "                     , eventsSF['time'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57f2a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['actStartTime'] = np.where(eventsSF['type']=='actstart'\n",
    "                     , eventsSF['time'], np.nan)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f47b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['duration_travelling'] = np.where((eventsSF['type']=='PathTraversal')|(eventsSF['type']=='TeleportationEvent')\n",
    "                     , eventsSF['arrivalTime'] - eventsSF['departureTime'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e427fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['distance_travelling'] = np.where((eventsSF['type']=='PathTraversal')|((eventsSF['type']=='ModeChoice')&((eventsSF['modeBEAM']=='hov2_teleportation')|(eventsSF['modeBEAM']=='hov3_teleportation'))), eventsSF['length'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63c8c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['distance_mode_choice'] = np.where(eventsSF['type']=='ModeChoice', eventsSF['length'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6403c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['duration_walking'] = np.where(eventsSF['modeBEAM']=='walk', eventsSF['duration_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9edb77aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['distance_walking'] = np.where(eventsSF['modeBEAM']=='walk', eventsSF['distance_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4a0af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['duration_on_bike'] = np.where(eventsSF['modeBEAM']=='bike', eventsSF['duration_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "148a3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['distance_bike'] = np.where(eventsSF['modeBEAM']=='bike', eventsSF['distance_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3624b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['duration_in_ridehail'] = np.where((eventsSF['modeBEAM_rh']=='ride_hail')|(eventsSF['modeBEAM_rh']=='ride_hail_pooled')|(eventsSF['modeBEAM_rh']=='ride_hail_transit'), \n",
    "                                            eventsSF['duration_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90d4c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['distance_ridehail'] = np.where((eventsSF['modeBEAM_rh']=='ride_hail')|(eventsSF['modeBEAM_rh']=='ride_hail_pooled')|(eventsSF['modeBEAM_rh']=='ride_hail_transit'), eventsSF['distance_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4bb825fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['duration_in_privateCar'] = np.where((eventsSF['modeBEAM_rh']=='car')|(eventsSF['modeBEAM_rh']=='car_hov3')|(eventsSF['modeBEAM_rh']=='car_hov2')|\n",
    "                                              (eventsSF['modeBEAM_rh']=='hov2_teleportation')|(eventsSF['modeBEAM_rh']=='hov3_teleportation') \n",
    "                                              , eventsSF['duration_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3473c8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['distance_privateCar'] = np.where((eventsSF['modeBEAM_rh']=='car')|(eventsSF['modeBEAM_rh']=='car_hov3')|(eventsSF['modeBEAM_rh']=='car_hov2')|\n",
    "                                              (eventsSF['modeBEAM_rh']=='hov2_teleportation')|(eventsSF['modeBEAM_rh']=='hov3_teleportation'), eventsSF['distance_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b735038",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['duration_in_transit'] = np.where((eventsSF['modeBEAM']=='bike_transit')|(eventsSF['modeBEAM']=='drive_transit')|\n",
    "                                           (eventsSF['modeBEAM']=='walk_transit')|(eventsSF['modeBEAM']=='bus')|\n",
    "                                           (eventsSF['modeBEAM']=='tram')|(eventsSF['modeBEAM']=='subway')|\n",
    "                                           (eventsSF['modeBEAM']=='rail')|(eventsSF['modeBEAM']=='cable_car')|\n",
    "                                           (eventsSF['modeBEAM']=='ride_hail_transit'), eventsSF['duration_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92c358e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['distance_transit'] = np.where((eventsSF['modeBEAM']=='bike_transit')|(eventsSF['modeBEAM']=='drive_transit')|\n",
    "                                        (eventsSF['modeBEAM']=='walk_transit')|(eventsSF['modeBEAM']=='bus')|\n",
    "                                        (eventsSF['modeBEAM']=='tram')|(eventsSF['modeBEAM']=='subway')|\n",
    "                                        (eventsSF['modeBEAM']=='rail')|(eventsSF['modeBEAM']=='cable_car')|\n",
    "                                        (eventsSF['modeBEAM']=='ride_hail_transit'), eventsSF['distance_travelling'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b4e8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the extra tour index happening after replanning events\n",
    "eventsSF['replanningTime'] = np.where(eventsSF['type'] == 'Replanning', eventsSF['time'], np.nan)\n",
    "eventsSF['replanningTime'] = eventsSF['replanningTime'].shift(+1)\n",
    "eventsSF['tourIndex_fixed'] = np.where((eventsSF['type'] == 'ModeChoice')&(eventsSF['replanningTime'].notna()), np.nan, eventsSF['tourIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1335cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eventsSF = eventsSF.set_index('IDMerged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5beb42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['fuelFood'] = np.where((eventsSF['type']=='PathTraversal')&(eventsSF['primaryFuelType']=='Food'), \n",
    "                                eventsSF['primaryFuel'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6880cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['emissionFood'] = eventsSF['fuelFood'] * 8.3141841e-9 * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4104324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['fuelElectricity'] = np.where((eventsSF['type']=='PathTraversal')&(eventsSF['primaryFuelType']=='Electricity'), \n",
    "                                eventsSF['primaryFuel'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac8a70b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['emissionElectricity'] = eventsSF['fuelElectricity'] * 2.77778e-10 * 947.2 * 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "32f9c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['fuelDiesel'] = np.where((eventsSF['type']=='PathTraversal')&(eventsSF['primaryFuelType']=='Diesel'), \n",
    "                                eventsSF['primaryFuel'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "791a7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['emissionDiesel'] = eventsSF['fuelDiesel'] * 8.3141841e-9 * 10.180e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8f68e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['fuelBiodiesel'] = np.where((eventsSF['type']=='PathTraversal')&(eventsSF['primaryFuelType']=='Biodiesel'), \n",
    "                                eventsSF['primaryFuel'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfcfbcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['emissionBiodiesel'] = eventsSF['fuelBiodiesel'] * 8.3141841e-9 * 10.180e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e752231",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['fuel_not_Food'] = np.where((eventsSF['type']=='PathTraversal')&(eventsSF['primaryFuelType']!='Food')\n",
    "                            , eventsSF['primaryFuel']+eventsSF['secondaryFuel'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bfc1273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['fuelGasoline'] = np.where((eventsSF['type']=='PathTraversal')&((eventsSF['primaryFuelType']=='Gasoline')|(eventsSF['secondaryFuelType']=='Gasoline')), \n",
    "                           eventsSF['primaryFuel']+eventsSF['secondaryFuel'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa3174aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['emissionGasoline'] = eventsSF['fuelGasoline'] * 8.3141841e-9 * 8.89e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a62efea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginal fuel\n",
    "conditions  = [(eventsSF['modeBEAM_rh'] == 'ride_hail_pooled'), \n",
    "               (eventsSF['modeBEAM_rh'] == 'walk_transit') | (eventsSF['modeBEAM_rh'] == 'drive_transit')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail_transit')|(eventsSF['modeBEAM_rh'] == 'bus')|(eventsSF['modeBEAM_rh'] == 'subway')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'rail')|(eventsSF['modeBEAM_rh'] == 'tram')|(eventsSF['modeBEAM_rh'] == 'cable_car')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'bike_transit'),\n",
    "               (eventsSF['modeBEAM_rh'] == 'walk')|(eventsSF['modeBEAM_rh'] == 'bike'),\n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail')|(eventsSF['modeBEAM_rh'] == 'car')| \n",
    "               (eventsSF['modeBEAM_rh'] == 'car_hov2')| (eventsSF['modeBEAM_rh'] == 'car_hov3')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'hov2_teleportation')| (eventsSF['modeBEAM_rh'] == 'hov3_teleportation')]\n",
    "choices = [eventsSF['fuel_not_Food']/eventsSF['numPassengers'], 0 , eventsSF['fuelFood'], eventsSF['fuel_not_Food']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdd142f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['fuel_marginal'] = np.select(conditions, choices, default=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4eca5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginal emission\n",
    "conditions1  = [(eventsSF['modeBEAM_rh'] == 'ride_hail_pooled') & (eventsSF['fuelElectricity'].notna() != 0), \n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail_pooled') & (eventsSF['fuelGasoline'].notna() != 0),\n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail_pooled') & (eventsSF['fuelBiodiesel'].notna() != 0),\n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail_pooled') & (eventsSF['fuelDiesel'].notna() != 0),             \n",
    "               (eventsSF['modeBEAM_rh'] == 'walk_transit') | (eventsSF['modeBEAM_rh'] == 'drive_transit')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail_transit')|(eventsSF['modeBEAM_rh'] == 'bus')|(eventsSF['modeBEAM_rh'] == 'subway')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'rail')|(eventsSF['modeBEAM_rh'] == 'tram')|(eventsSF['modeBEAM_rh'] == 'cable_car')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'bike_transit'),\n",
    "\n",
    "               (eventsSF['modeBEAM_rh'] == 'walk')|(eventsSF['modeBEAM_rh'] == 'bike'),\n",
    "               \n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail')|(eventsSF['modeBEAM_rh'] == 'car')| \n",
    "               (eventsSF['modeBEAM_rh'] == 'car_hov2')| (eventsSF['modeBEAM_rh'] == 'car_hov3')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'hov2_teleportation')| (eventsSF['modeBEAM_rh'] == 'hov3_teleportation')&\n",
    "               (eventsSF['fuelElectricity'].notna() != 0),\n",
    "              \n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail')|(eventsSF['modeBEAM_rh'] == 'car')| \n",
    "               (eventsSF['modeBEAM_rh'] == 'car_hov2')| (eventsSF['modeBEAM_rh'] == 'car_hov3')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'hov2_teleportation')| (eventsSF['modeBEAM_rh'] == 'hov3_teleportation')&\n",
    "               (eventsSF['fuelGasoline'].notna() != 0),           \n",
    "              \n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail')|(eventsSF['modeBEAM_rh'] == 'car')| \n",
    "               (eventsSF['modeBEAM_rh'] == 'car_hov2')| (eventsSF['modeBEAM_rh'] == 'car_hov3')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'hov2_teleportation')| (eventsSF['modeBEAM_rh'] == 'hov3_teleportation')&\n",
    "               (eventsSF['fuelBiodiesel'].notna() != 0),   \n",
    "               \n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail')|(eventsSF['modeBEAM_rh'] == 'car')| \n",
    "               (eventsSF['modeBEAM_rh'] == 'car_hov2')| (eventsSF['modeBEAM_rh'] == 'car_hov3')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'hov2_teleportation')| (eventsSF['modeBEAM_rh'] == 'hov3_teleportation')&\n",
    "               (eventsSF['fuelDiesel'].notna() != 0),\n",
    "\n",
    "               (eventsSF['modeBEAM_rh'] == 'ride_hail')|(eventsSF['modeBEAM_rh'] == 'car')| \n",
    "               (eventsSF['modeBEAM_rh'] == 'car_hov2')| (eventsSF['modeBEAM_rh'] == 'car_hov3')|\n",
    "               (eventsSF['modeBEAM_rh'] == 'hov2_teleportation')| (eventsSF['modeBEAM_rh'] == 'hov3_teleportation')&\n",
    "               (eventsSF['fuelFood'].notna() != 0)]\n",
    "\n",
    "choices1 = [eventsSF['emissionElectricity']/eventsSF['numPassengers'],\n",
    "           eventsSF['emissionGasoline']/eventsSF['numPassengers'],\n",
    "           eventsSF['emissionBiodiesel']/eventsSF['numPassengers'],\n",
    "           eventsSF['emissionDiesel']/eventsSF['numPassengers'],           \n",
    "           0 , \n",
    "           eventsSF['emissionFood'], \n",
    "           eventsSF['emissionElectricity'],\n",
    "           eventsSF['emissionGasoline'],\n",
    "           eventsSF['emissionBiodiesel'],\n",
    "           eventsSF['emissionDiesel'],\n",
    "           eventsSF['emissionFood']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb19ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['emission_marginal'] = np.select(conditions1, choices1, default=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bb135e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['actEndType'] = np.where(eventsSF['type']=='actend', eventsSF['actType'], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52f9f171",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['actStartType'] = np.where(eventsSF['type']=='actstart', eventsSF['actType'], \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8bb89",
   "metadata": {},
   "source": [
    "#### Trip Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5be797be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eventsSF[\"tripIndex\"] = eventsSF.groupby(\"IDMerged\")[\"tourIndex_fixed\"].rank(method=\"first\", ascending=True)\n",
    "eventsSF[\"tripIndex\"] = eventsSF.tripId.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd20fe1",
   "metadata": {},
   "source": [
    "#### Mode Choice planned and actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ecaf4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 22s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eventsSF['mode_choice_actual_BEAM'] = eventsSF.groupby(['IDMerged','tripId', 'type'])['modeBEAM'].transform('last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed171398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 22s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eventsSF['mode_choice_planned_BEAM'] = eventsSF.groupby(['IDMerged','tripId', 'type'])['modeBEAM'].transform('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "723f03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['mode_choice_actual_BEAM'] = np.where(eventsSF['type'] != 'ModeChoice' , np.nan, eventsSF['mode_choice_actual_BEAM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8bac64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['mode_choice_planned_BEAM'] = np.where(eventsSF['type'] != 'ModeChoice' , np.nan, eventsSF['mode_choice_planned_BEAM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd021670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the \"netCost\" column\n",
    "eventsSF.rename(columns={\"netCost\":\"cost_BEAM\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6dca051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replanning events = 1, the rest = 0\n",
    "eventsSF['replanning_status'] = np.where(eventsSF['type']=='Replanning', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11d6986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.86 s\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eventsSF['reason'].replace('nan', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2809aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['transit_bus'] = np.where(eventsSF['modeBEAM_rh']=='bus', 1, 0)\n",
    "eventsSF['transit_subway'] = np.where(eventsSF['modeBEAM_rh']=='subway', 1, 0)\n",
    "eventsSF['transit_tram'] = np.where(eventsSF['modeBEAM_rh']=='tram', 1, 0)\n",
    "eventsSF['transit_rail'] = np.where(eventsSF['modeBEAM_rh']=='rail', 1, 0)\n",
    "eventsSF['transit_cable_car'] = np.where(eventsSF['modeBEAM_rh']=='cable_car', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07b5229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsSF['ride_hail_pooled'] = np.where(eventsSF['modeBEAM_rh']=='ride_hail_pooled', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4a679675",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['BlockGroupEnd', 'BlockGroupStart'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:95\u001b[0m, in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m     92\u001b[0m     table \u001b[38;5;241m=\u001b[39m concat(pieces, keys\u001b[38;5;241m=\u001b[39mkeys, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43m__internal_pivot_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmargins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmargins_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39m__finalize__(data, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpivot_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py:165\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m    162\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(values)\n\u001b[0;32m    164\u001b[0m grouped \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(keys, observed\u001b[38;5;241m=\u001b[39mobserved, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[1;32m--> 165\u001b[0m agged \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropna \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(agged, ABCDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agged\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m    167\u001b[0m     agged \u001b[38;5;241m=\u001b[39m agged\u001b[38;5;241m.\u001b[39mdropna(how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:869\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    866\u001b[0m func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[0;32m    868\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args, kwargs)\n\u001b[1;32m--> 869\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\apply.py:168\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(arg):\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\apply.py:467\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    464\u001b[0m     selected_obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_selected_obj\n\u001b[0;32m    465\u001b[0m     selection \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_selection\n\u001b[1;32m--> 467\u001b[0m arg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_dictlike_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(selection, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\geo_env\\lib\\site-packages\\pandas\\core\\apply.py:585\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    584\u001b[0m         cols_sorted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(safe_sort(\u001b[38;5;28mlist\u001b[39m(cols)))\n\u001b[1;32m--> 585\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcols_sorted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m do not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    587\u001b[0m is_aggregator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m))\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['BlockGroupEnd', 'BlockGroupStart'] do not exist\""
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Person_Trip_eventsSF = pd.pivot_table(\n",
    "   eventsSF,\n",
    "   index=['IDMerged','tripIndex'],\n",
    "   aggfunc={'actStartTime': np.sum, \n",
    "            'actEndTime': np.sum, \n",
    "            'duration_travelling': np.sum, \n",
    "            'cost_BEAM': np.sum, \n",
    "            'actStartType': np.sum, \n",
    "            'actEndType': np.sum, \n",
    "            'duration_walking': np.sum, \n",
    "            'duration_in_privateCar': np.sum, \n",
    "            'duration_on_bike': np.sum, \n",
    "            'duration_in_ridehail': np.sum, \n",
    "            'distance_travelling': np.sum, \n",
    "            'duration_in_transit': np.sum, \n",
    "            'distance_walking': np.sum, \n",
    "            'distance_bike': np.sum, \n",
    "            'distance_ridehail': np.sum, \n",
    "            'distance_privateCar': np.sum, \n",
    "            'distance_transit': np.sum, \n",
    "            'legVehicleIds': np.sum, \n",
    "            'mode_choice_planned_BEAM':lambda x: ', '.join(set(x.dropna().astype(str))),\n",
    "            'mode_choice_actual_BEAM':lambda x: ', '.join(set(x.dropna().astype(str))),\n",
    "            'vehicle': lambda x: ', '.join(set(x.dropna().astype(str))),\n",
    "            'numPassengers': lambda x: ', '.join(list(x.dropna().astype(str))),\n",
    "            'distance_mode_choice': np.sum,\n",
    "            'replanning_status': np.sum,\n",
    "            'reason': lambda x: ', '.join(list(x.dropna().astype(str))),\n",
    "            'parkingType': lambda x: ', '.join(list(x.dropna().astype(str))),\n",
    "            'transit_bus': np.sum, \n",
    "            'transit_subway': np.sum, \n",
    "            'transit_tram': np.sum, \n",
    "            'transit_cable_car': np.sum,\n",
    "            'ride_hail_pooled': np.sum, \n",
    "            'transit_rail': np.sum,\n",
    "            'year': lambda x: ', '.join(set(x.dropna().astype(str))),\n",
    "            'lever_position': lambda x: ', '.join(set(x.dropna().astype(str))),\n",
    "            'scenario': lambda x: ', '.join(set(x.dropna().astype(str))),\n",
    "            'fuelFood': np.sum, \n",
    "            'fuelElectricity': np.sum, \n",
    "            'fuelBiodiesel': np.sum, \n",
    "            'fuelDiesel': np.sum, \n",
    "            'fuel_not_Food': np.sum, \n",
    "            'fuelGasoline': np.sum, \n",
    "            'fuel_marginal': np.sum,\n",
    "            'BlockGroupStart': 'first',\n",
    "            'BlockGroupEnd': 'last',\n",
    "            'startX': 'first',\n",
    "            'startY': 'first',\n",
    "            'endX': 'last',\n",
    "            'endY': 'last',\n",
    "            'emissionFood': np.sum, \n",
    "            'emissionElectricity': np.sum, \n",
    "            'emissionDiesel': np.sum, \n",
    "            'emissionGasoline': np.sum,\n",
    "            'emissionBiodiesel': np.sum, \n",
    "            'emission_marginal': np.sum,\n",
    "            'lever': lambda x: ', '.join(set(x.dropna().astype(str)))\n",
    "           }).reset_index() \n",
    "\n",
    "#'numPassengers': lambda x: ', '.join(set(x.dropna().astype(str))) \n",
    "#'mode_choice_actual_BEAM':lambda x: ', '.join(set(x.dropna().astype(str))) #\n",
    "#'modeBEAM_rh': lambda x: ', '.join(list(x.dropna().astype(str))), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc3ac897",
   "metadata": {},
   "outputs": [],
   "source": [
    "Person_Trip_eventsSF['duration_door_to_door'] = Person_Trip_eventsSF['actStartTime'] - Person_Trip_eventsSF['actEndTime'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "03bd08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Person_Trip_eventsSF['waitTime'] = Person_Trip_eventsSF['duration_door_to_door'] - Person_Trip_eventsSF['duration_travelling'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "28560b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Person_Trip_eventsSF['actPurpose'] = Person_Trip_eventsSF['actEndType'].astype(str) + \"_to_\" + Person_Trip_eventsSF['actStartType'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d3a96721",
   "metadata": {},
   "outputs": [],
   "source": [
    "Person_Trip_eventsSF.rename(columns={\"legVehicleIds\":\"vehicleIds_estimate\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b8d2f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "Person_Trip_eventsSF.rename(columns={\"vehicle\":\"vehicleIds\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3c0e1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column with five summarized modes\n",
    "conditions  = [(Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'ride_hail') | (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'ride_hail_pooled'), \n",
    "               (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'walk_transit') | (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'drive_transit')| (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'ride_hail_transit')|(Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'bike_transit'),\n",
    "               (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'walk'), (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'bike'),\n",
    "               (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'car') | (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'car_hov2')| (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'car_hov3')|(Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'hov2_teleportation')| (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'hov3_teleportation')]\n",
    "choices = [ 'ride_hail', 'transit', 'walk', 'bike', 'car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "86cb946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Person_Trip_eventsSF['mode_choice_actual_5'] = np.select(conditions, choices, default= np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b02ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column with six summarized modes\n",
    "conditions  = [(Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'ride_hail') | (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'ride_hail_pooled'), \n",
    "               (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'walk_transit') | (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'drive_transit')|(Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'bike_transit'),\n",
    "               (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'walk'), (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'bike'),\n",
    "               (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'car') | (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'car_hov2')| (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'car_hov3')|(Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'hov2_teleportation')| (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'hov3_teleportation'),\n",
    "               (Person_Trip_eventsSF['mode_choice_actual_BEAM'] == 'ride_hail_transit')]\n",
    "choices = [ 'ride_hail', 'transit', 'walk', 'bike', 'car', 'ride_hail_transit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b63121f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Person_Trip_eventsSF['mode_choice_actual_6'] = pd.Series(np.select(conditions, choices, default= np.nan)).replace({'nan':np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8ea04962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column with four summarized modes\n",
    "Person_Trip_eventsSF['mode_choice_actual_4']  = np.where((Person_Trip_eventsSF['mode_choice_actual_5'] == 'walk')|(Person_Trip_eventsSF['mode_choice_actual_5'] == 'bike'),\n",
    "                                                        'walk/bike', Person_Trip_eventsSF['mode_choice_actual_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "649260ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Person_Trip_eventsSF = Person_Trip_eventsSF.drop(Person_Trip_eventsSF[Person_Trip_eventsSF.duration_door_to_door < 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d2b37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Person_Trip_eventsSF.to_csv('C:/Shared-Work/Data/CleanData/sf_2018_base_core_act.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c5804",
   "metadata": {},
   "source": [
    "#### Merging with ActivitySim files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "13594e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"pilates-outputs/sfbay-baseline-20220822/activitysim/year-2018-iteration-5/households.csv.gz\"  #the path should be updated\n",
    "obj = s3.get_object(Bucket=\"beam-outputs\", Key=key)\n",
    "households = pd.read_csv(obj['Body'], compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "df5a30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"pilates-outputs/sfbay-baseline-20220822/activitysim/year-2018-iteration-5/persons.csv.gz\"  #the path should be updated\n",
    "obj = s3.get_object(Bucket=\"beam-outputs\", Key=key)\n",
    "persons = pd.read_csv(obj['Body'], compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "60622ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"pilates-outputs/sfbay-baseline-20220822/activitysim/year-2018-iteration-5/final_tours.csv.gz\"  #the path should be updated\n",
    "obj = s3.get_object(Bucket=\"beam-outputs\", Key=key)\n",
    "tours = pd.read_csv(obj['Body'], compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "974cafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"pilates-outputs/sfbay-baseline-20220822/activitysim/year-2018-iteration-5/final_trips.csv.gz\"  #the path should be updated\n",
    "obj = s3.get_object(Bucket=\"beam-outputs\", Key=key)\n",
    "trips = pd.read_csv(obj['Body'], compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "47b6ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge BEAM households and persons \n",
    "persons = persons.sort_values(by=['household_id']).reset_index(drop=True)\n",
    "households = households.sort_values(by=['household_id']).reset_index(drop=True)\n",
    "hhpersons = pd.merge(left=persons, right=households, how='left', on='household_id')\n",
    "#hhpersons = pd.merge(left=persons, right=households, how='left', on='household_id', suffixes=('', '_drop'))\n",
    "#hhpersons.drop([col for col in hhpersons.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5b20c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tours, households and persons\n",
    "tours = tours.sort_values(by=['person_id']).reset_index(drop=True)\n",
    "hhpersons = hhpersons.sort_values(by=['person_id']).reset_index(drop=True)\n",
    "hhperTours = pd.merge(left=tours, right=hhpersons, how='left', on='person_id')\n",
    "#hhperTours = pd.merge(left=tours, right=hhpersons, how='left', on='person_id', suffixes=('', '_drop'))\n",
    "#hhperTours.drop([col for col in hhperTours.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6ef8c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge trips, tours, households and persons\n",
    "trips = trips.sort_values(by=['person_id', 'tour_id']).reset_index(drop=True)\n",
    "hhperTours = hhperTours.sort_values(by=['person_id','tour_id']).reset_index(drop=True)\n",
    "tourTripsMerged = pd.merge(left=trips, right=hhperTours, how='left', on=['person_id','tour_id'])\n",
    "#tourTripsMerged = pd.merge(left=trips, right=hhperTours, how='left', on=['person_id','tour_id'], suffixes=('', '_drop'))\n",
    "#tourTripsMerged.drop([col for col in tourTripsMerged.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aa064697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat mode_choice_utilities files - Download File from s3 bucket \n",
    "key = \"pilates-outputs/sfbay-baseline-20220822/activitysim/year-2018-iteration-5/trip_mode_choice.zip\"  #the path should be updated\n",
    "s3.download_file(\n",
    "    Bucket=\"beam-outputs\", Key=key, Filename=\"trip_mode_choice.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c00295c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically extracting ZipFile with a python command \n",
    "with ZipFile('trip_mode_choice.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "79e48f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat mode_choice_utilities files\n",
    "path = \"C:/Users/nazanin/Documents/beam-core-analysis/Users/Nazanin/trip_mode_choice/\" #the path should be updated\n",
    "all_files = glob.glob(path + \"*utilities.csv\")\n",
    "li_mapper = map(lambda filename: pd.read_csv(filename, index_col = None, header = 0), all_files)\n",
    "li2 = list(li_mapper)\n",
    "SFmode_choice_utilities = pd.concat(li2, axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5035b857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just utilities\n",
    "# Merge trips, tours, households, persons, trip_mode_choice_raw, and utilities\n",
    "tourTripsMerged = tourTripsMerged.sort_values(by=['trip_id'])\n",
    "SFmode_choice_utilities = SFmode_choice_utilities.sort_values(by=['trip_id'])\n",
    "SFActMerged= pd.merge(left=tourTripsMerged, right=SFmode_choice_utilities, how='left', on=['trip_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa758d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both raw and utilities\n",
    "# Merge trips, tours, households, persons, trip_mode_choice_raw, and utilities\n",
    "#tourTripsMerged = tourTripsMerged.sort_values(by=['trip_id'])\n",
    "#rawUtil = rawUtil.sort_values(by=['trip_id'])\n",
    "#SFActMerged= pd.merge(left=tourTripsMerged, right=rawUtil, how='left', on=['trip_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "96ae8686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge person_trip level BEAM with activity sim merged files\n",
    "SFActMerged = SFActMerged.sort_values(by=['person_id', 'trip_id']).reset_index(drop=True)\n",
    "Person_Trip_eventsSF = Person_Trip_eventsSF.sort_values(by=['IDMerged','tripIndex']).reset_index(drop=True)\n",
    "eventsASim = pd.merge(left=Person_Trip_eventsSF, right=SFActMerged, how='left', left_on=[\"IDMerged\", 'tripIndex'], right_on=['person_id', 'trip_id'])\n",
    "#eventsASim = pd.merge(left=Person_Trip_eventsSF, right=tourTripsMerged, how='left',left_on = [\"IDMerged\", 'tripId'] , right_on=['person_id', 'trip_id'], suffixes=('', '_drop'))\n",
    "#eventsASim.drop([col for col in eventsASim.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0679f40",
   "metadata": {},
   "source": [
    "#### Updated the cells below - Might consider adding the INEXUS metrics as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "72ae2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsASim.rename(columns={\"mode_choice_logsum_y\":\"logsum_tours_mode_AS_tours\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7a0b2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsASim.rename(columns={\"tour_mode\":\"tour_mode_AS_tours\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0def8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsASim.rename(columns={\"mode_choice_logsum_x\":\"logsum_trip_Potential_INEXUS\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "28906290",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsASim.rename(columns={\"trip_mode\":\"trip_mode_AS_trips\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "abe82170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of income quartiles\n",
    "quartiles = eventsASim['income'].quantile([0,.25, .5, .75,1]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b6be6801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add income deciles\n",
    "conditions  = [(eventsASim['income'] >= quartiles[0]) & (eventsASim['income'] < quartiles[1]), \n",
    "               (eventsASim['income'] >= quartiles[1]) & (eventsASim['income'] < quartiles[2]),\n",
    "               (eventsASim['income'] >=  quartiles[2]) & (eventsASim['income'] < quartiles[3]),\n",
    "               (eventsASim['income'] >= quartiles[3]) & (eventsASim['income'] <= quartiles[4])]\n",
    "\n",
    "choices = [ '1stQ', '2ndQ', '3rdQ', '4thD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8aee64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsASim['income_quartiles'] = np.select(conditions, choices, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "31dc9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of income deciles\n",
    "deciles = eventsASim['income'].quantile([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f7a26173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add income deciles\n",
    "conditions  = [(eventsASim['income'] >= deciles[0]) & (eventsASim['income'] < deciles[1]), \n",
    "               (eventsASim['income'] >= deciles[1]) & (eventsASim['income'] < deciles[2]),\n",
    "               (eventsASim['income'] >=  deciles[2]) & (eventsASim['income'] < deciles[3]),\n",
    "               (eventsASim['income'] >= deciles[3]) & (eventsASim['income'] < deciles[4]), \n",
    "               (eventsASim['income'] >=  deciles[4]) & (eventsASim['income'] < deciles[5]),\n",
    "               (eventsASim['income'] >=  deciles[5]) & (eventsASim['income'] < deciles[6]),\n",
    "               (eventsASim['income'] >=  deciles[6]) & (eventsASim['income'] < deciles[7]),\n",
    "               (eventsASim['income'] >=  deciles[7]) & (eventsASim['income'] < deciles[8]),\n",
    "               (eventsASim['income'] >=  deciles[8]) & (eventsASim['income'] < deciles[9]),\n",
    "               (eventsASim['income'] >=  deciles[9]) & (eventsASim['income'] <= deciles[10])]\n",
    "\n",
    "choices = [ '1stD', '2ndD', '3rdD', \n",
    "           '4thD', '5thD', '6thD', '7thD', '8thD', '9thD','10thD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "78665928",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsASim['income_deciles'] = np.select(conditions, choices, default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a3fe03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output file to S3\n",
    "eventsASim.to_csv('s3://beam-core-act/deepDive/CleanData/SanFrancisco/Ridehail_Price/sf_2018_rh_price_0.csv', index=False)  #the path should be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b97fa964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the utilities files downloaded and saved in the system\n",
    "os.remove('C:/Users/nazanin/Documents/beam-core-analysis/Users/Nazanin/trip_mode_choice.zip')   #the path should be updated\n",
    "shutil.rmtree('C:/Users/nazanin/Documents/beam-core-analysis/Users/Nazanin/trip_mode_choice')   #the path should be updated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
